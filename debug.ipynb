{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference_edit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from unilip.constants import *\n",
    "from unilip.model.builder import load_pretrained_model_general\n",
    "from unilip.utils import disable_torch_init\n",
    "from unilip.mm_utils import get_model_name_from_path\n",
    "from unilip.pipeline_edit import CustomEditPipeline\n",
    "import random\n",
    "\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "\n",
    "\n",
    "def create_image_grid(images, rows, cols):\n",
    "    \"\"\"Creates a grid of images and returns a single PIL Image.\"\"\"\n",
    "\n",
    "    assert len(images) == rows * cols\n",
    "\n",
    "    width, height = images[0].size\n",
    "    grid_width = width * cols\n",
    "    grid_height = height * rows\n",
    "\n",
    "    grid_image = Image.new('RGB', (grid_width, grid_height))\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        x = (i % cols) * width\n",
    "        y = (i // cols) * height\n",
    "        grid_image.paste(image, (x, y))\n",
    "\n",
    "    return grid_image\n",
    "\n",
    "def add_template(prompt):\n",
    "    instruction = ('<|im_start|>user\\n{input}<|im_end|>\\n'\n",
    "                 '<|im_start|>assistant\\n<img>')\n",
    "    pos_prompt = instruction.format(input=prompt[0])\n",
    "\n",
    "    cfg_prompt = instruction.format(input=prompt[1])\n",
    "    return [pos_prompt, cfg_prompt]\n",
    "\n",
    "def set_global_seed(seed=42):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class name!!!!!! UniLIP_InternVLForCausalLM <class 'unilip.model.language_model.unilip_internvl.UniLIP_InternVLForCausalLM'>\n",
      "should no drop out InternVisionModel(\n",
      "  (embeddings): InternVisionEmbeddings(\n",
      "    (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "  )\n",
      "  (encoder): InternVisionEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): InternVisionEncoderLayer(\n",
      "        (attn): InternAttention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (mlp): InternMLP(\n",
      "          (act): GELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop_path1): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1-23): 23 x InternVisionEncoderLayer(\n",
      "        (attn): InternAttention(\n",
      "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (mlp): InternMLP(\n",
      "          (act): GELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop_path1): DropPath(drop_prob=0.000)\n",
      "        (drop_path2): DropPath(drop_prob=0.000)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      " latent query size torch.Size([1, 256, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 10880.17it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.73it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# model_path = sys.argv[1]\n",
    "model_path = \"UniLIP-3B\"\n",
    "\n",
    "disable_torch_init()\n",
    "model_path = os.path.expanduser(model_path)\n",
    "model_name = get_model_name_from_path(model_path)\n",
    "tokenizer, multi_model, context_len = load_pretrained_model_general('UniLIP_InternVLForCausalLM', model_path, None, model_name)\n",
    "image_processor = AutoProcessor.from_pretrained(multi_model.config.mllm_hf_path).image_processor\n",
    "\n",
    "pipe = CustomEditPipeline(multimodal_encoder=multi_model, tokenizer=tokenizer, image_processor=image_processor)\n",
    "\n",
    "generator = torch.Generator(device=multi_model.device).manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps, guiance scale 20 4.5\n",
      "9.5\n",
      "finish Replace the camper van in the image with a hot air balloon.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Replace the camper van in the image with a hot air balloon.\"\n",
    "input_image_path = \"demo/edit_input.jpg\" #\"../demo/edit_input.jpg\"\n",
    "input_image = Image.open(input_image_path)\n",
    "set_global_seed(seed=42)\n",
    "gen_images = []\n",
    "for i in range(1):\n",
    "    multimodal_prompts = add_template([f\"Edit the image: {prompt}\\n<image>\", \"Edit the image.\\n<image>\"])\n",
    "    multimodal_prompts.append(input_image)\n",
    "    gen_img = pipe(multimodal_prompts, guidance_scale=4.5, generator=generator)\n",
    "    gen_images.append(gen_img)\n",
    "print(f\"finish {prompt}\")\n",
    "\n",
    "grid_image = create_image_grid(gen_images, 1, 1)\n",
    "grid_image.save(f\"{prompt[:100]}.png\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>user\\nEdit the image: Replace the camper van in the image with a hot air balloon.\\n<image><|im_end|>\\n<|im_start|>assistant\\n<img>',\n",
       " '<|im_start|>user\\nEdit the image.\\n<image><|im_end|>\\n<|im_start|>assistant\\n<img>',\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1024x1024>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodal_prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference csgo fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sft_instruction_custom(pose_5d):\n",
    "    \"\"\"\n",
    "    构造符合 CS2 自定义坐标系的 SFT 指令。\n",
    "\n",
    "    参数:\n",
    "    pose_5d (dict): 包含 x, y, z, yaw, pitch\n",
    "        - x, y: [0, 1024]\n",
    "        - z: [0.0, 1.0] (归一化后的高度)\n",
    "        - yaw: 度数, 0=East, Clockwise\n",
    "        - pitch: 度数, 0=Down, 180=Up\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 坐标系定义块 (System Definition Block)\n",
    "    # 这部分就像是给模型的 \"System Prompt\"，教它物理规则\n",
    "    definition_text = (\n",
    "        \"Task: Generate a First-Person View (FPV) image of CS2 map 'de_dust2' based on the Radar Map and Camera Pose.\\n\"\n",
    "        \"Coordinate System Definition:\\n\"\n",
    "        \"- Map Size: 1024x1024 pixels.\\n\"\n",
    "        \"- Yaw: 0 degrees is East, increases Clockwise.\\n\"\n",
    "        \"- Pitch: 0 degrees is looking straight Down (at feet), 180 degrees is looking straight Up (at sky).\\n\"\n",
    "        \"- Z-Height: Normalized relative height (0.0 to 1.0).\"\n",
    "    )\n",
    "\n",
    "    # 2. 具体数值块 (Data Block)\n",
    "    # 格式化数值，保留适当精度，避免 token 浪费\n",
    "    pose_str = (\n",
    "        f\"Position(x={pose_5d['x']:.1f}, y={pose_5d['y']:.1f}, z={pose_5d['z']:.3f}), \"\n",
    "        f\"Rotation(yaw={pose_5d['angle_h']:.1f}, pitch={pose_5d['angle_v']:.1f})\"\n",
    "    )\n",
    "\n",
    "    # 3. 组合最终指令\n",
    "    # <image> 放在最后，代表输入的 Radar Map\n",
    "    full_instruction = f\"{definition_text}\\n\\nCurrent Camera Pose: {pose_str}\\n<image>\"\n",
    "\n",
    "    return full_instruction\n",
    "\n",
    "\n",
    "def add_csgo_template(prompt):\n",
    "    # 这个函数负责把你的文本指令包装成模型能听懂的对话格式\n",
    "    instruction = ('<|im_start|>user\\n{input}<|im_end|>\\n'\n",
    "                   '<|im_start|>assistant\\n<img>')\n",
    "\n",
    "    # prompt[0] 是你的 SFT 完整指令 (包含 <image>)\n",
    "    # prompt[1] 是 CFG 的负向/通用提示词\n",
    "    pos_prompt = instruction.format(input=prompt[0])\n",
    "    cfg_prompt = instruction.format(input=prompt[1])\n",
    "    return [pos_prompt, cfg_prompt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust2_test_samples = [\n",
    "    {\n",
    "        \"x\": 471,\n",
    "        \"y\": 366,\n",
    "        \"z\": -14,\n",
    "        \"angle_h\": 1.3957727141646166,\n",
    "        \"angle_v\": 1.535916373365911,\n",
    "        \"map\": \"de_dust2\",\n",
    "        \"file_frame\": \"file_num159_frame_191\"\n",
    "    },\n",
    "    {\n",
    "        \"x\": 676,\n",
    "        \"y\": 211,\n",
    "        \"z\": 36,\n",
    "        \"angle_h\": 2.9035918059238095,\n",
    "        \"angle_v\": 1.5563313673341312,\n",
    "        \"map\": \"de_dust2\",\n",
    "        \"file_frame\": \"file_num309_frame_415\"\n",
    "    },\n",
    "    {\n",
    "        \"x\": 738,\n",
    "        \"y\": 125,\n",
    "        \"z\": 36,\n",
    "        \"angle_h\": 1.6858029410991509,\n",
    "        \"angle_v\": 1.593194843143008,\n",
    "        \"map\": \"de_dust2\",\n",
    "        \"file_frame\": \"file_num215_frame_207\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loc_data = dust2_test_samples[0]\n",
    "\n",
    "map_path = f\"data/preprocessed_data/de_dust2/{sample_loc_data['map']}_radar_psd.png\"\n",
    "gt_fps_path = f\"data/preprocessed_data/de_dust2/imgs/{sample_loc_data['file_frame']}.jpg\"\n",
    "\n",
    "sample_loc_data['angle_h'] = sample_loc_data['angle_h'] * 180 / np.pi\n",
    "sample_loc_data['angle_v'] = sample_loc_data['angle_v'] * 180 / np.pi\n",
    "prompt = build_sft_instruction_custom(sample_loc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps, guiance scale 20 4.5\n",
      "9.5\n",
      "finish Task: Generate a First-Person View (FPV) image of CS2 map 'de_dust2' based on the Radar Map and Camera Pose.\n",
      "Coordinate System Definition:\n",
      "- Map Size: 1024x1024 pixels.\n",
      "- Yaw: 0 degrees is East, increases Clockwise.\n",
      "- Pitch: 0 degrees is looking straight Down (at feet), 180 degrees is looking straight Up (at sky).\n",
      "- Z-Height: Normalized relative height (0.0 to 1.0).\n",
      "\n",
      "Current Camera Pose: Position(x=471.0, y=366.0, z=-14.000), Rotation(yaw=80.0, pitch=88.0)\n",
      "<image>\n"
     ]
    }
   ],
   "source": [
    "map_image = Image.open(map_path).convert(\"RGB\")\n",
    "set_global_seed(seed=42)\n",
    "gen_images = []\n",
    "for i in range(1):\n",
    "    multimodal_prompts = multimodal_prompts = add_csgo_template([prompt, \"Generate the image.\\n<image>\"])\n",
    "    multimodal_prompts.append(map_image)\n",
    "    gen_img = pipe(multimodal_prompts, guidance_scale=4.5, generator=generator)\n",
    "    # Guidance Scale (CFG Scale)：\n",
    "    #    如果生成的图像不像 CS2（画质差），尝试降低 scale (e.g., 2.0 - 3.5)。\n",
    "    #    如果生成的图像位置不对（忽略了坐标指令），尝试提高 scale (e.g., 7.0 - 9.0)。\n",
    "    gen_images.append(gen_img)\n",
    "print(f\"finish {prompt}\")\n",
    "\n",
    "grid_image = create_image_grid(gen_images, 1, 1)\n",
    "grid_image.save(f\"{prompt[:100]}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FreedomIntelligence/ShareGPT-4o-Image: 2_text_and_image_to_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 46539/46539 [00:00<00:00, 80361.46 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"FreedomIntelligence/ShareGPT-4o-Image\", \"2_text_and_image_to_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_prompt': 'Remove the wooden barrier running across the background.',\n",
       " 'input_image': ['image/v2v_42971.png'],\n",
       " 'input_image_resolution': [1024, 1024],\n",
       " 'output_image': 'image/v2v_42970.png',\n",
       " 'output_image_resolution': [1024, 1024]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下载部分ShareGPT-4o-Image用于调试SFT Editing任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "针对 `FreedomIntelligence/ShareGPT-4o-Image` 这种大型图像数据集，通常数据会被切分成多个分片文件（例如 `.tar` 或 `.zip`）。\n",
    "\n",
    "你完全不需要下载整个数据集。以下是三种针对不同需求的轻量化下载方案：\n",
    "\n",
    "### 方案 1：使用 CLI 下载特定分片（最推荐，适合本地开发）\n",
    "\n",
    "如果你需要把文件下载到硬盘上给 `load_dataset(\"webdataset\", ...)` 用，你可以只下载前几个 `.tar` 包。\n",
    "\n",
    "使用 `huggingface-cli` 的 `--include` 参数配合通配符。\n",
    "\n",
    "```bash\n",
    "# 只下载 sharegpt4o_image_00000.tar 到 sharegpt4o_image_00005.tar (假设这是文件名格式)\n",
    "# 或者更通用的：只下载包含 \"0000\" 的 tar 包\n",
    "huggingface-cli download --repo-type dataset FreedomIntelligence/ShareGPT-4o-Image --include \"*0000*.tar\" --local-dir ./partial_data --resume-download\n",
    "\n",
    "```\n",
    "\n",
    "* **`--include`**: 这是关键。你可以指定文件名，支持通配符 `*`。\n",
    "* **注意**: 你需要先去 Hugging Face 网页端的 \"Files and versions\" 页面看一眼具体的文件名格式（通常是 `data/train-00000-of-xxxxx.tar` 或类似的结构）。\n",
    "\n",
    "假设该数据集的文件结构是 `data/*.tar`，你可以只下载第一个文件夹：\n",
    "\n",
    "```bash\n",
    "huggingface-cli download --repo-type dataset FreedomIntelligence/ShareGPT-4o-Image --include \"data/sharegpt4o_image_00000.tar\" --local-dir ./partial_data\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 方案 2：Python 脚本下载（灵活控制）\n",
    "\n",
    "如果你想在 Python 代码里精确控制下载哪些文件，可以使用 `huggingface_hub` 库。\n",
    "\n",
    "```python\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# 只下载符合特定模式的文件\n",
    "local_dir = snapshot_download(\n",
    "    repo_id=\"FreedomIntelligence/ShareGPT-4o-Image\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"./partial_data\",\n",
    "    allow_patterns=[\"*.json\", \"*00000.tar\"],  # 只下载元数据json和第一个tar包\n",
    "    resume_download=True\n",
    ")\n",
    "\n",
    "print(f\"数据已下载到: {local_dir}\")\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 方案 3：流式加载（Streaming，不下载到硬盘）\n",
    "\n",
    "如果你只是想快速调试代码逻辑，或者查看数据格式，**完全不需要下载文件**。直接使用 Hugging Face 的 `streaming=True` 模式。\n",
    "\n",
    "数据会像看视频一样，边用边下，不占用硬盘空间。\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. 开启流式模式\n",
    "dataset = load_dataset(\n",
    "    \"FreedomIntelligence/ShareGPT-4o-Image\",\n",
    "    split=\"train\",\n",
    "    streaming=True  # <--- 关键点\n",
    ")\n",
    "\n",
    "# 2. 只取前 100 个样本进行查看或调试\n",
    "# 注意：流式数据集不能用 dataset[0] 访问，必须用迭代器\n",
    "small_dataset = dataset.take(100)\n",
    "\n",
    "for sample in small_dataset:\n",
    "    print(sample.keys())\n",
    "    # print(sample['image'])\n",
    "    break\n",
    "\n",
    "```\n",
    "\n",
    "**适用场景**：\n",
    "\n",
    "* 检查数据结构（key的名字）。\n",
    "* 测试你的 Preprocessing / Transform 代码是否报错。\n",
    "* 编写 Demo。\n",
    "\n",
    "### 总结\n",
    "\n",
    "* **要存文件测试训练代码**：用 **方案 1**，下载 `*00000.tar` 这样一个包就足够跑通流程了。\n",
    "* **只是看一眼数据**：用 **方案 3**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiahao/miniconda3/envs/UniLIP/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/jiahao/miniconda3/envs/UniLIP/lib/python3.11/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Fetching 2 files: 100%|██████████| 2/2 [3:05:44<00:00, 5572.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已下载到: /home/jiahao/task/UniLIP/partial_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# 只下载符合特定模式的文件\n",
    "local_dir = snapshot_download(\n",
    "    repo_id=\"FreedomIntelligence/ShareGPT-4o-Image\",\n",
    "    repo_type=\"dataset\",\n",
    "    local_dir=\"./partial_data\",\n",
    "    allow_patterns=[\"text_and_image_to_image.json\", \"text_and_image_to_image_part_0.tar\"],  # 只下载元数据json和第一个tar包\n",
    "    resume_download=True\n",
    ")\n",
    "\n",
    "print(f\"数据已下载到: {local_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UniLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
