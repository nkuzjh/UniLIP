2026-01-07 15:31:49 - INFO - Loaded WandB API key from .wandb_api_key.txt - (2851716:train_csgo.py:1280)
2026-01-07 15:31:51 - INFO - model_args: ModelArguments(model_name_or_path='UniLIP-1B', version='internvl', freeze_backbone=True, tune_mm_mlp_adapter=False, vision_tower=None, gen_vision_tower=None, mm_vision_select_layer=-1, pretrain_mm_mlp_adapter=None, pretrain_gen_mlp_adapter=None, vision_tower_pretrained=None, mm_projector_type='linear', gen_projector_type='linear', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_patch_merge_type='flat', mm_vision_select_feature='patch', n_query=256, n_und_query=0, gen_pooling='all', unilip_path='', unilip_factor=10.6, weighting_scheme='logit_normal', fix_dit=False, fix_connect=False, fix_vit=True, fix_llm=True, connect_layer=6, mllm_path='', mllm_hf_path='OpenGVLab/InternVL3-1B-hf', vae_path='', dit_path='', action_dit_layer=3) - (2851716:train_csgo.py:1292)
2026-01-07 15:31:51 - INFO - data_args: DataArguments(csgo_config='csgo_configs/exp3.yaml', data_path=None, lazy_preprocess=True, is_multimodal=False, csgo_image_folder='data/preprocessed_data', shortcaption_image_folder=None, data_type='mix', image_aspect_ratio='square') - (2851716:train_csgo.py:1293)
2026-01-07 15:31:51 - INFO - training_args: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
bits=16,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=8,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=deepspeed_scripts/zero0.json,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
double_quant=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
freeze_mm_mlp_adapter=False,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
group_by_modality_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=outputs/csgo_1b/exp3/runs/Jan07_15-31-49_gpu-05,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=IntervalStrategy.STEPS,
lora_alpha=16,
lora_bias=none,
lora_dropout=0.05,
lora_enable=False,
lora_r=64,
lora_weight_path=,
lr_scheduler_kwargs={'min_lr': 1e-05},
lr_scheduler_type=SchedulerType.COSINE_WITH_MIN_LR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mm_projector_lr=None,
model_max_length=1024,
mp_parameters=,
mpt_attn_impl=triton,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=100.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=outputs/csgo_1b/exp3,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
pretrain_path=none,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
quant_type=nf4,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=5000,
save_strategy=SaveStrategy.STEPS,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.003,
warmup_steps=0,
weight_decay=0.0,
) - (2851716:train_csgo.py:1294)
2026-01-07 15:31:51 - INFO - csgo_config: {'debug': False, 'is_multi_task': True, 'data_dir': 'data/preprocessed_data', 'train_maps': ['de_dust2', 'de_nuke', 'de_ancient'], 'val_maps': ['de_dust2', 'de_nuke', 'de_ancient'], 'test_maps': ['de_dust2', 'de_nuke', 'de_ancient']} - (2851716:train_csgo.py:1295)
2026-01-07 15:31:52 - INFO - vision_select_layer: -1 - (2851716:configuration_internvl_chat.py:69)
2026-01-07 15:31:52 - INFO - ps_version: v2 - (2851716:configuration_internvl_chat.py:70)
2026-01-07 15:31:52 - INFO - min_dynamic_patch: 1 - (2851716:configuration_internvl_chat.py:71)
2026-01-07 15:31:52 - INFO - max_dynamic_patch: 12 - (2851716:configuration_internvl_chat.py:72)
2026-01-07 15:31:52 - INFO - vision_config is None. Initializing the InternVisionConfig with default values. - (2851716:configuration_internvl_chat.py:42)
2026-01-07 15:31:52 - INFO - llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`). - (2851716:configuration_internvl_chat.py:46)
2026-01-07 15:31:52 - INFO - vision_select_layer: -1 - (2851716:configuration_internvl_chat.py:69)
2026-01-07 15:31:52 - INFO - ps_version: v1 - (2851716:configuration_internvl_chat.py:70)
2026-01-07 15:31:52 - INFO - min_dynamic_patch: 1 - (2851716:configuration_internvl_chat.py:71)
2026-01-07 15:31:52 - INFO - max_dynamic_patch: 6 - (2851716:configuration_internvl_chat.py:72)
2026-01-07 15:31:52 - INFO - num_image_token: 256 - (2851716:modeling_internvl_chat.py:59)
2026-01-07 15:31:52 - INFO - ps_version: v2 - (2851716:modeling_internvl_chat.py:60)
2026-01-07 15:32:06 - INFO - Using conversation format: internvl - (2851716:train_csgo.py:1377)
2026-01-07 15:32:06 - INFO - fix connect False - (2851716:unified_unilip.py:183)
2026-01-07 15:32:06 - INFO - fix dit False - (2851716:unified_unilip.py:184)
2026-01-07 15:32:06 - INFO - unilip load from checkpoint!!! - (2851716:unified_unilip.py:251)
2026-01-07 15:32:06 - INFO - DiT load from checkpoint!!! - (2851716:unified_unilip.py:264)
2026-01-07 15:32:06 - INFO - Connector load from checkpoint!!! - (2851716:unified_unilip.py:285)
2026-01-07 15:32:06 - INFO - latent_queries load from checkpoint!!! - (2851716:unified_unilip.py:307)
2026-01-07 15:32:06 - INFO - Initializing Action Connector from OpenGVLab/InternVL3-1B-hf slice... - (2851716:unified_unilip.py:328)
2026-01-07 15:32:07 - INFO - Action DiT weights initialized successfully! - (2851716:unified_unilip.py:339)
2026-01-07 15:32:07 - INFO - Action VAE weights initialized successfully! - (2851716:unified_unilip.py:360)
2026-01-07 15:32:14 - INFO -      trainable params: model.latent_queries - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.patch_embed.proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.patch_embed.proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_1.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_1.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_2.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_2.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.linear.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.linear.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_1.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_1.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_2.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_2.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_norm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.proj_out.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.proj_out.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.norm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.projector.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.projector.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.norm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_in_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_in_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_in.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_in.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_out.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_out.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_out_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_out_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO - Total parameters: 1696253544 - (2851716:train_csgo.py:1424)
2026-01-07 15:32:14 - INFO - Trainable parameters: 729874469 - (2851716:train_csgo.py:1425)
2026-01-07 15:32:14 - INFO - trainable percent: 43.028619 % - (2851716:train_csgo.py:1426)
2026-01-07 15:32:14 - INFO -  Loading Multi-Task CS2 Dataset... - (2851716:unified_task_dataset.py:489)
2026-01-07 15:32:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_dust2/splits_20000_5000/train_split.json... - (2851716:unified_task_dataset.py:497)
2026-01-07 15:32:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_nuke/splits_20000_5000/train_split.json... - (2851716:unified_task_dataset.py:497)
2026-01-07 15:32:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_ancient/splits_20000_5000/train_split.json... - (2851716:unified_task_dataset.py:497)
2026-01-07 15:32:14 - INFO -  Total entries: 60000 - (2851716:unified_task_dataset.py:528)
2026-01-07 15:32:28 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -c /tmp/tmpe4z542uz/test.c -o /tmp/tmpe4z542uz/test.o - (2851716:spawn.py:77)
2026-01-07 15:32:28 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat /tmp/tmpe4z542uz/test.o -laio -o /tmp/tmpe4z542uz/a.out - (2851716:spawn.py:77)
2026-01-07 15:32:28 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -c /tmp/tmp9a9bgyly/test.c -o /tmp/tmp9a9bgyly/test.o - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat /tmp/tmp9a9bgyly/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp9a9bgyly/a.out - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -c /tmp/tmpfs7_mcnw/test.c -o /tmp/tmpfs7_mcnw/test.o - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat /tmp/tmpfs7_mcnw/test.o -laio -o /tmp/tmpfs7_mcnw/a.out - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO -   idx  name                                                                              shape                           trainable
-----  --------------------------------------------------------------------------------  ------------------------------  -----------
    0  model.latent_queries                                                              torch.Size([1, 256, 896])       True
    1  model.vision_tower.embeddings.class_embedding                                     torch.Size([1, 1, 1024])        False
    2  model.vision_tower.embeddings.position_embedding                                  torch.Size([1, 1025, 1024])     False
    3  model.vision_tower.embeddings.patch_embedding.weight                              torch.Size([1024, 3, 14, 14])   False
    4  model.vision_tower.embeddings.patch_embedding.bias                                torch.Size([1024])              False
    5  model.vision_tower.encoder.layers.0.ls1                                           torch.Size([1024])              False
    6  model.vision_tower.encoder.layers.0.ls2                                           torch.Size([1024])              False
    7  model.vision_tower.encoder.layers.0.attn.qkv.weight                               torch.Size([3072, 1024])        False
    8  model.vision_tower.encoder.layers.0.attn.qkv.bias                                 torch.Size([3072])              False
    9  model.vision_tower.encoder.layers.0.attn.proj.weight                              torch.Size([1024, 1024])        False
   10  model.vision_tower.encoder.layers.0.attn.proj.bias                                torch.Size([1024])              False
   11  model.vision_tower.encoder.layers.0.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   12  model.vision_tower.encoder.layers.0.mlp.fc1.bias                                  torch.Size([4096])              False
   13  model.vision_tower.encoder.layers.0.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   14  model.vision_tower.encoder.layers.0.mlp.fc2.bias                                  torch.Size([1024])              False
   15  model.vision_tower.encoder.layers.0.norm1.weight                                  torch.Size([1024])              False
   16  model.vision_tower.encoder.layers.0.norm1.bias                                    torch.Size([1024])              False
   17  model.vision_tower.encoder.layers.0.norm2.weight                                  torch.Size([1024])              False
   18  model.vision_tower.encoder.layers.0.norm2.bias                                    torch.Size([1024])              False
   19  model.vision_tower.encoder.layers.1.ls1                                           torch.Size([1024])              False
   20  model.vision_tower.encoder.layers.1.ls2                                           torch.Size([1024])              False
   21  model.vision_tower.encoder.layers.1.attn.qkv.weight                               torch.Size([3072, 1024])        False
   22  model.vision_tower.encoder.layers.1.attn.qkv.bias                                 torch.Size([3072])              False
   23  model.vision_tower.encoder.layers.1.attn.proj.weight                              torch.Size([1024, 1024])        False
   24  model.vision_tower.encoder.layers.1.attn.proj.bias                                torch.Size([1024])              False
   25  model.vision_tower.encoder.layers.1.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   26  model.vision_tower.encoder.layers.1.mlp.fc1.bias                                  torch.Size([4096])              False
   27  model.vision_tower.encoder.layers.1.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   28  model.vision_tower.encoder.layers.1.mlp.fc2.bias                                  torch.Size([1024])              False
   29  model.vision_tower.encoder.layers.1.norm1.weight                                  torch.Size([1024])              False
   30  model.vision_tower.encoder.layers.1.norm1.bias                                    torch.Size([1024])              False
   31  model.vision_tower.encoder.layers.1.norm2.weight                                  torch.Size([1024])              False
   32  model.vision_tower.encoder.layers.1.norm2.bias                                    torch.Size([1024])              False
   33  model.vision_tower.encoder.layers.2.ls1                                           torch.Size([1024])              False
   34  model.vision_tower.encoder.layers.2.ls2                                           torch.Size([1024])              False
   35  model.vision_tower.encoder.layers.2.attn.qkv.weight                               torch.Size([3072, 1024])        False
   36  model.vision_tower.encoder.layers.2.attn.qkv.bias                                 torch.Size([3072])              False
   37  model.vision_tower.encoder.layers.2.attn.proj.weight                              torch.Size([1024, 1024])        False
   38  model.vision_tower.encoder.layers.2.attn.proj.bias                                torch.Size([1024])              False
   39  model.vision_tower.encoder.layers.2.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   40  model.vision_tower.encoder.layers.2.mlp.fc1.bias                                  torch.Size([4096])              False
   41  model.vision_tower.encoder.layers.2.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   42  model.vision_tower.encoder.layers.2.mlp.fc2.bias                                  torch.Size([1024])              False
   43  model.vision_tower.encoder.layers.2.norm1.weight                                  torch.Size([1024])              False
   44  model.vision_tower.encoder.layers.2.norm1.bias                                    torch.Size([1024])              False
   45  model.vision_tower.encoder.layers.2.norm2.weight                                  torch.Size([1024])              False
   46  model.vision_tower.encoder.layers.2.norm2.bias                                    torch.Size([1024])              False
   47  model.vision_tower.encoder.layers.3.ls1                                           torch.Size([1024])              False
   48  model.vision_tower.encoder.layers.3.ls2                                           torch.Size([1024])              False
   49  model.vision_tower.encoder.layers.3.attn.qkv.weight                               torch.Size([3072, 1024])        False
   50  model.vision_tower.encoder.layers.3.attn.qkv.bias                                 torch.Size([3072])              False
   51  model.vision_tower.encoder.layers.3.attn.proj.weight                              torch.Size([1024, 1024])        False
   52  model.vision_tower.encoder.layers.3.attn.proj.bias                                torch.Size([1024])              False
   53  model.vision_tower.encoder.layers.3.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   54  model.vision_tower.encoder.layers.3.mlp.fc1.bias                                  torch.Size([4096])              False
   55  model.vision_tower.encoder.layers.3.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   56  model.vision_tower.encoder.layers.3.mlp.fc2.bias                                  torch.Size([1024])              False
   57  model.vision_tower.encoder.layers.3.norm1.weight                                  torch.Size([1024])              False
   58  model.vision_tower.encoder.layers.3.norm1.bias                                    torch.Size([1024])              False
   59  model.vision_tower.encoder.layers.3.norm2.weight                                  torch.Size([1024])              False
   60  model.vision_tower.encoder.layers.3.norm2.bias                                    torch.Size([1024])              False
   61  model.vision_tower.encoder.layers.4.ls1                                           torch.Size([1024])              False
   62  model.vision_tower.encoder.layers.4.ls2                                           torch.Size([1024])              False
   63  model.vision_tower.encoder.layers.4.attn.qkv.weight                               torch.Size([3072, 1024])        False
   64  model.vision_tower.encoder.layers.4.attn.qkv.bias                                 torch.Size([3072])              False
   65  model.vision_tower.encoder.layers.4.attn.proj.weight                              torch.Size([1024, 1024])        False
   66  model.vision_tower.encoder.layers.4.attn.proj.bias                                torch.Size([1024])              False
   67  model.vision_tower.encoder.layers.4.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   68  model.vision_tower.encoder.layers.4.mlp.fc1.bias                                  torch.Size([4096])              False
   69  model.vision_tower.encoder.layers.4.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   70  model.vision_tower.encoder.layers.4.mlp.fc2.bias                                  torch.Size([1024])              False
   71  model.vision_tower.encoder.layers.4.norm1.weight                                  torch.Size([1024])              False
   72  model.vision_tower.encoder.layers.4.norm1.bias                                    torch.Size([1024])              False
   73  model.vision_tower.encoder.layers.4.norm2.weight                                  torch.Size([1024])              False
   74  model.vision_tower.encoder.layers.4.norm2.bias                                    torch.Size([1024])              False
   75  model.vision_tower.encoder.layers.5.ls1                                           torch.Size([1024])              False
   76  model.vision_tower.encoder.layers.5.ls2                                           torch.Size([1024])              False
   77  model.vision_tower.encoder.layers.5.attn.qkv.weight                               torch.Size([3072, 1024])        False
   78  model.vision_tower.encoder.layers.5.attn.qkv.bias                                 torch.Size([3072])              False
   79  model.vision_tower.encoder.layers.5.attn.proj.weight                              torch.Size([1024, 1024])        False
   80  model.vision_tower.encoder.layers.5.attn.proj.bias                                torch.Size([1024])              False
   81  model.vision_tower.encoder.layers.5.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   82  model.vision_tower.encoder.layers.5.mlp.fc1.bias                                  torch.Size([4096])              False
   83  model.vision_tower.encoder.layers.5.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   84  model.vision_tower.encoder.layers.5.mlp.fc2.bias                                  torch.Size([1024])              False
   85  model.vision_tower.encoder.layers.5.norm1.weight                                  torch.Size([1024])              False
   86  model.vision_tower.encoder.layers.5.norm1.bias                                    torch.Size([1024])              False
   87  model.vision_tower.encoder.layers.5.norm2.weight                                  torch.Size([1024])              False
   88  model.vision_tower.encoder.layers.5.norm2.bias                                    torch.Size([1024])              False
   89  model.vision_tower.encoder.layers.6.ls1                                           torch.Size([1024])              False
   90  model.vision_tower.encoder.layers.6.ls2                                           torch.Size([1024])              False
   91  model.vision_tower.encoder.layers.6.attn.qkv.weight                               torch.Size([3072, 1024])        False
   92  model.vision_tower.encoder.layers.6.attn.qkv.bias                                 torch.Size([3072])              False
   93  model.vision_tower.encoder.layers.6.attn.proj.weight                              torch.Size([1024, 1024])        False
   94  model.vision_tower.encoder.layers.6.attn.proj.bias                                torch.Size([1024])              False
   95  model.vision_tower.encoder.layers.6.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   96  model.vision_tower.encoder.layers.6.mlp.fc1.bias                                  torch.Size([4096])              False
   97  model.vision_tower.encoder.layers.6.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   98  model.vision_tower.encoder.layers.6.mlp.fc2.bias                                  torch.Size([1024])              False
   99  model.vision_tower.encoder.layers.6.norm1.weight                                  torch.Size([1024])              False
  100  model.vision_tower.encoder.layers.6.norm1.bias                                    torch.Size([1024])              False
  101  model.vision_tower.encoder.layers.6.norm2.weight                                  torch.Size([1024])              False
  102  model.vision_tower.encoder.layers.6.norm2.bias                                    torch.Size([1024])              False
  103  model.vision_tower.encoder.layers.7.ls1                                           torch.Size([1024])              False
  104  model.vision_tower.encoder.layers.7.ls2                                           torch.Size([1024])              False
  105  model.vision_tower.encoder.layers.7.attn.qkv.weight                               torch.Size([3072, 1024])        False
  106  model.vision_tower.encoder.layers.7.attn.qkv.bias                                 torch.Size([3072])              False
  107  model.vision_tower.encoder.layers.7.attn.proj.weight                              torch.Size([1024, 1024])        False
  108  model.vision_tower.encoder.layers.7.attn.proj.bias                                torch.Size([1024])              False
  109  model.vision_tower.encoder.layers.7.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  110  model.vision_tower.encoder.layers.7.mlp.fc1.bias                                  torch.Size([4096])              False
  111  model.vision_tower.encoder.layers.7.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  112  model.vision_tower.encoder.layers.7.mlp.fc2.bias                                  torch.Size([1024])              False
  113  model.vision_tower.encoder.layers.7.norm1.weight                                  torch.Size([1024])              False
  114  model.vision_tower.encoder.layers.7.norm1.bias                                    torch.Size([1024])              False
  115  model.vision_tower.encoder.layers.7.norm2.weight                                  torch.Size([1024])              False
  116  model.vision_tower.encoder.layers.7.norm2.bias                                    torch.Size([1024])              False
  117  model.vision_tower.encoder.layers.8.ls1                                           torch.Size([1024])              False
  118  model.vision_tower.encoder.layers.8.ls2                                           torch.Size([1024])              False
  119  model.vision_tower.encoder.layers.8.attn.qkv.weight                               torch.Size([3072, 1024])        False
  120  model.vision_tower.encoder.layers.8.attn.qkv.bias                                 torch.Size([3072])              False
  121  model.vision_tower.encoder.layers.8.attn.proj.weight                              torch.Size([1024, 1024])        False
  122  model.vision_tower.encoder.layers.8.attn.proj.bias                                torch.Size([1024])              False
  123  model.vision_tower.encoder.layers.8.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  124  model.vision_tower.encoder.layers.8.mlp.fc1.bias                                  torch.Size([4096])              False
  125  model.vision_tower.encoder.layers.8.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  126  model.vision_tower.encoder.layers.8.mlp.fc2.bias                                  torch.Size([1024])              False
  127  model.vision_tower.encoder.layers.8.norm1.weight                                  torch.Size([1024])              False
  128  model.vision_tower.encoder.layers.8.norm1.bias                                    torch.Size([1024])              False
  129  model.vision_tower.encoder.layers.8.norm2.weight                                  torch.Size([1024])              False
  130  model.vision_tower.encoder.layers.8.norm2.bias                                    torch.Size([1024])              False
  131  model.vision_tower.encoder.layers.9.ls1                                           torch.Size([1024])              False
  132  model.vision_tower.encoder.layers.9.ls2                                           torch.Size([1024])              False
  133  model.vision_tower.encoder.layers.9.attn.qkv.weight                               torch.Size([3072, 1024])        False
  134  model.vision_tower.encoder.layers.9.attn.qkv.bias                                 torch.Size([3072])              False
  135  model.vision_tower.encoder.layers.9.attn.proj.weight                              torch.Size([1024, 1024])        False
  136  model.vision_tower.encoder.layers.9.attn.proj.bias                                torch.Size([1024])              False
  137  model.vision_tower.encoder.layers.9.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  138  model.vision_tower.encoder.layers.9.mlp.fc1.bias                                  torch.Size([4096])              False
  139  model.vision_tower.encoder.layers.9.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  140  model.vision_tower.encoder.layers.9.mlp.fc2.bias                                  torch.Size([1024])              False
  141  model.vision_tower.encoder.layers.9.norm1.weight                                  torch.Size([1024])              False
  142  model.vision_tower.encoder.layers.9.norm1.bias                                    torch.Size([1024])              False
  143  model.vision_tower.encoder.layers.9.norm2.weight                                  torch.Size([1024])              False
  144  model.vision_tower.encoder.layers.9.norm2.bias                                    torch.Size([1024])              False
  145  model.vision_tower.encoder.layers.10.ls1                                          torch.Size([1024])              False
  146  model.vision_tower.encoder.layers.10.ls2                                          torch.Size([1024])              False
  147  model.vision_tower.encoder.layers.10.attn.qkv.weight                              torch.Size([3072, 1024])        False
  148  model.vision_tower.encoder.layers.10.attn.qkv.bias                                torch.Size([3072])              False
  149  model.vision_tower.encoder.layers.10.attn.proj.weight                             torch.Size([1024, 1024])        False
  150  model.vision_tower.encoder.layers.10.attn.proj.bias                               torch.Size([1024])              False
  151  model.vision_tower.encoder.layers.10.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  152  model.vision_tower.encoder.layers.10.mlp.fc1.bias                                 torch.Size([4096])              False
  153  model.vision_tower.encoder.layers.10.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  154  model.vision_tower.encoder.layers.10.mlp.fc2.bias                                 torch.Size([1024])              False
  155  model.vision_tower.encoder.layers.10.norm1.weight                                 torch.Size([1024])              False
  156  model.vision_tower.encoder.layers.10.norm1.bias                                   torch.Size([1024])              False
  157  model.vision_tower.encoder.layers.10.norm2.weight                                 torch.Size([1024])              False
  158  model.vision_tower.encoder.layers.10.norm2.bias                                   torch.Size([1024])              False
  159  model.vision_tower.encoder.layers.11.ls1                                          torch.Size([1024])              False
  160  model.vision_tower.encoder.layers.11.ls2                                          torch.Size([1024])              False
  161  model.vision_tower.encoder.layers.11.attn.qkv.weight                              torch.Size([3072, 1024])        False
  162  model.vision_tower.encoder.layers.11.attn.qkv.bias                                torch.Size([3072])              False
  163  model.vision_tower.encoder.layers.11.attn.proj.weight                             torch.Size([1024, 1024])        False
  164  model.vision_tower.encoder.layers.11.attn.proj.bias                               torch.Size([1024])              False
  165  model.vision_tower.encoder.layers.11.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  166  model.vision_tower.encoder.layers.11.mlp.fc1.bias                                 torch.Size([4096])              False
  167  model.vision_tower.encoder.layers.11.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  168  model.vision_tower.encoder.layers.11.mlp.fc2.bias                                 torch.Size([1024])              False
  169  model.vision_tower.encoder.layers.11.norm1.weight                                 torch.Size([1024])              False
  170  model.vision_tower.encoder.layers.11.norm1.bias                                   torch.Size([1024])              False
  171  model.vision_tower.encoder.layers.11.norm2.weight                                 torch.Size([1024])              False
  172  model.vision_tower.encoder.layers.11.norm2.bias                                   torch.Size([1024])              False
  173  model.vision_tower.encoder.layers.12.ls1                                          torch.Size([1024])              False
  174  model.vision_tower.encoder.layers.12.ls2                                          torch.Size([1024])              False
  175  model.vision_tower.encoder.layers.12.attn.qkv.weight                              torch.Size([3072, 1024])        False
  176  model.vision_tower.encoder.layers.12.attn.qkv.bias                                torch.Size([3072])              False
  177  model.vision_tower.encoder.layers.12.attn.proj.weight                             torch.Size([1024, 1024])        False
  178  model.vision_tower.encoder.layers.12.attn.proj.bias                               torch.Size([1024])              False
  179  model.vision_tower.encoder.layers.12.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  180  model.vision_tower.encoder.layers.12.mlp.fc1.bias                                 torch.Size([4096])              False
  181  model.vision_tower.encoder.layers.12.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  182  model.vision_tower.encoder.layers.12.mlp.fc2.bias                                 torch.Size([1024])              False
  183  model.vision_tower.encoder.layers.12.norm1.weight                                 torch.Size([1024])              False
  184  model.vision_tower.encoder.layers.12.norm1.bias                                   torch.Size([1024])              False
  185  model.vision_tower.encoder.layers.12.norm2.weight                                 torch.Size([1024])              False
  186  model.vision_tower.encoder.layers.12.norm2.bias                                   torch.Size([1024])              False
  187  model.vision_tower.encoder.layers.13.ls1                                          torch.Size([1024])              False
  188  model.vision_tower.encoder.layers.13.ls2                                          torch.Size([1024])              False
  189  model.vision_tower.encoder.layers.13.attn.qkv.weight                              torch.Size([3072, 1024])        False
  190  model.vision_tower.encoder.layers.13.attn.qkv.bias                                torch.Size([3072])              False
  191  model.vision_tower.encoder.layers.13.attn.proj.weight                             torch.Size([1024, 1024])        False
  192  model.vision_tower.encoder.layers.13.attn.proj.bias                               torch.Size([1024])              False
  193  model.vision_tower.encoder.layers.13.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  194  model.vision_tower.encoder.layers.13.mlp.fc1.bias                                 torch.Size([4096])              False
  195  model.vision_tower.encoder.layers.13.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  196  model.vision_tower.encoder.layers.13.mlp.fc2.bias                                 torch.Size([1024])              False
  197  model.vision_tower.encoder.layers.13.norm1.weight                                 torch.Size([1024])              False
  198  model.vision_tower.encoder.layers.13.norm1.bias                                   torch.Size([1024])              False
  199  model.vision_tower.encoder.layers.13.norm2.weight                                 torch.Size([1024])              False
  200  model.vision_tower.encoder.layers.13.norm2.bias                                   torch.Size([1024])              False
  201  model.vision_tower.encoder.layers.14.ls1                                          torch.Size([1024])              False
  202  model.vision_tower.encoder.layers.14.ls2                                          torch.Size([1024])              False
  203  model.vision_tower.encoder.layers.14.attn.qkv.weight                              torch.Size([3072, 1024])        False
  204  model.vision_tower.encoder.layers.14.attn.qkv.bias                                torch.Size([3072])              False
  205  model.vision_tower.encoder.layers.14.attn.proj.weight                             torch.Size([1024, 1024])        False
  206  model.vision_tower.encoder.layers.14.attn.proj.bias                               torch.Size([1024])              False
  207  model.vision_tower.encoder.layers.14.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  208  model.vision_tower.encoder.layers.14.mlp.fc1.bias                                 torch.Size([4096])              False
  209  model.vision_tower.encoder.layers.14.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  210  model.vision_tower.encoder.layers.14.mlp.fc2.bias                                 torch.Size([1024])              False
  211  model.vision_tower.encoder.layers.14.norm1.weight                                 torch.Size([1024])              False
  212  model.vision_tower.encoder.layers.14.norm1.bias                                   torch.Size([1024])              False
  213  model.vision_tower.encoder.layers.14.norm2.weight                                 torch.Size([1024])              False
  214  model.vision_tower.encoder.layers.14.norm2.bias                                   torch.Size([1024])              False
  215  model.vision_tower.encoder.layers.15.ls1                                          torch.Size([1024])              False
  216  model.vision_tower.encoder.layers.15.ls2                                          torch.Size([1024])              False
  217  model.vision_tower.encoder.layers.15.attn.qkv.weight                              torch.Size([3072, 1024])        False
  218  model.vision_tower.encoder.layers.15.attn.qkv.bias                                torch.Size([3072])              False
  219  model.vision_tower.encoder.layers.15.attn.proj.weight                             torch.Size([1024, 1024])        False
  220  model.vision_tower.encoder.layers.15.attn.proj.bias                               torch.Size([1024])              False
  221  model.vision_tower.encoder.layers.15.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  222  model.vision_tower.encoder.layers.15.mlp.fc1.bias                                 torch.Size([4096])              False
  223  model.vision_tower.encoder.layers.15.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  224  model.vision_tower.encoder.layers.15.mlp.fc2.bias                                 torch.Size([1024])              False
  225  model.vision_tower.encoder.layers.15.norm1.weight                                 torch.Size([1024])              False
  226  model.vision_tower.encoder.layers.15.norm1.bias                                   torch.Size([1024])              False
  227  model.vision_tower.encoder.layers.15.norm2.weight                                 torch.Size([1024])              False
  228  model.vision_tower.encoder.layers.15.norm2.bias                                   torch.Size([1024])              False
  229  model.vision_tower.encoder.layers.16.ls1                                          torch.Size([1024])              False
  230  model.vision_tower.encoder.layers.16.ls2                                          torch.Size([1024])              False
  231  model.vision_tower.encoder.layers.16.attn.qkv.weight                              torch.Size([3072, 1024])        False
  232  model.vision_tower.encoder.layers.16.attn.qkv.bias                                torch.Size([3072])              False
  233  model.vision_tower.encoder.layers.16.attn.proj.weight                             torch.Size([1024, 1024])        False
  234  model.vision_tower.encoder.layers.16.attn.proj.bias                               torch.Size([1024])              False
  235  model.vision_tower.encoder.layers.16.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  236  model.vision_tower.encoder.layers.16.mlp.fc1.bias                                 torch.Size([4096])              False
  237  model.vision_tower.encoder.layers.16.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  238  model.vision_tower.encoder.layers.16.mlp.fc2.bias                                 torch.Size([1024])              False
  239  model.vision_tower.encoder.layers.16.norm1.weight                                 torch.Size([1024])              False
  240  model.vision_tower.encoder.layers.16.norm1.bias                                   torch.Size([1024])              False
  241  model.vision_tower.encoder.layers.16.norm2.weight                                 torch.Size([1024])              False
  242  model.vision_tower.encoder.layers.16.norm2.bias                                   torch.Size([1024])              False
  243  model.vision_tower.encoder.layers.17.ls1                                          torch.Size([1024])              False
  244  model.vision_tower.encoder.layers.17.ls2                                          torch.Size([1024])              False
  245  model.vision_tower.encoder.layers.17.attn.qkv.weight                              torch.Size([3072, 1024])        False
  246  model.vision_tower.encoder.layers.17.attn.qkv.bias                                torch.Size([3072])              False
  247  model.vision_tower.encoder.layers.17.attn.proj.weight                             torch.Size([1024, 1024])        False
  248  model.vision_tower.encoder.layers.17.attn.proj.bias                               torch.Size([1024])              False
  249  model.vision_tower.encoder.layers.17.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  250  model.vision_tower.encoder.layers.17.mlp.fc1.bias                                 torch.Size([4096])              False
  251  model.vision_tower.encoder.layers.17.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  252  model.vision_tower.encoder.layers.17.mlp.fc2.bias                                 torch.Size([1024])              False
  253  model.vision_tower.encoder.layers.17.norm1.weight                                 torch.Size([1024])              False
  254  model.vision_tower.encoder.layers.17.norm1.bias                                   torch.Size([1024])              False
  255  model.vision_tower.encoder.layers.17.norm2.weight                                 torch.Size([1024])              False
  256  model.vision_tower.encoder.layers.17.norm2.bias                                   torch.Size([1024])              False
  257  model.vision_tower.encoder.layers.18.ls1                                          torch.Size([1024])              False
  258  model.vision_tower.encoder.layers.18.ls2                                          torch.Size([1024])              False
  259  model.vision_tower.encoder.layers.18.attn.qkv.weight                              torch.Size([3072, 1024])        False
  260  model.vision_tower.encoder.layers.18.attn.qkv.bias                                torch.Size([3072])              False
  261  model.vision_tower.encoder.layers.18.attn.proj.weight                             torch.Size([1024, 1024])        False
  262  model.vision_tower.encoder.layers.18.attn.proj.bias                               torch.Size([1024])              False
  263  model.vision_tower.encoder.layers.18.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  264  model.vision_tower.encoder.layers.18.mlp.fc1.bias                                 torch.Size([4096])              False
  265  model.vision_tower.encoder.layers.18.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  266  model.vision_tower.encoder.layers.18.mlp.fc2.bias                                 torch.Size([1024])              False
  267  model.vision_tower.encoder.layers.18.norm1.weight                                 torch.Size([1024])              False
  268  model.vision_tower.encoder.layers.18.norm1.bias                                   torch.Size([1024])              False
  269  model.vision_tower.encoder.layers.18.norm2.weight                                 torch.Size([1024])              False
  270  model.vision_tower.encoder.layers.18.norm2.bias                                   torch.Size([1024])              False
  271  model.vision_tower.encoder.layers.19.ls1                                          torch.Size([1024])              False
  272  model.vision_tower.encoder.layers.19.ls2                                          torch.Size([1024])              False
  273  model.vision_tower.encoder.layers.19.attn.qkv.weight                              torch.Size([3072, 1024])        False
  274  model.vision_tower.encoder.layers.19.attn.qkv.bias                                torch.Size([3072])              False
  275  model.vision_tower.encoder.layers.19.attn.proj.weight                             torch.Size([1024, 1024])        False
  276  model.vision_tower.encoder.layers.19.attn.proj.bias                               torch.Size([1024])              False
  277  model.vision_tower.encoder.layers.19.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  278  model.vision_tower.encoder.layers.19.mlp.fc1.bias                                 torch.Size([4096])              False
  279  model.vision_tower.encoder.layers.19.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  280  model.vision_tower.encoder.layers.19.mlp.fc2.bias                                 torch.Size([1024])              False
  281  model.vision_tower.encoder.layers.19.norm1.weight                                 torch.Size([1024])              False
  282  model.vision_tower.encoder.layers.19.norm1.bias                                   torch.Size([1024])              False
  283  model.vision_tower.encoder.layers.19.norm2.weight                                 torch.Size([1024])              False
  284  model.vision_tower.encoder.layers.19.norm2.bias                                   torch.Size([1024])              False
  285  model.vision_tower.encoder.layers.20.ls1                                          torch.Size([1024])              False
  286  model.vision_tower.encoder.layers.20.ls2                                          torch.Size([1024])              False
  287  model.vision_tower.encoder.layers.20.attn.qkv.weight                              torch.Size([3072, 1024])        False
  288  model.vision_tower.encoder.layers.20.attn.qkv.bias                                torch.Size([3072])              False
  289  model.vision_tower.encoder.layers.20.attn.proj.weight                             torch.Size([1024, 1024])        False
  290  model.vision_tower.encoder.layers.20.attn.proj.bias                               torch.Size([1024])              False
  291  model.vision_tower.encoder.layers.20.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  292  model.vision_tower.encoder.layers.20.mlp.fc1.bias                                 torch.Size([4096])              False
  293  model.vision_tower.encoder.layers.20.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  294  model.vision_tower.encoder.layers.20.mlp.fc2.bias                                 torch.Size([1024])              False
  295  model.vision_tower.encoder.layers.20.norm1.weight                                 torch.Size([1024])              False
  296  model.vision_tower.encoder.layers.20.norm1.bias                                   torch.Size([1024])              False
  297  model.vision_tower.encoder.layers.20.norm2.weight                                 torch.Size([1024])              False
  298  model.vision_tower.encoder.layers.20.norm2.bias                                   torch.Size([1024])              False
  299  model.vision_tower.encoder.layers.21.ls1                                          torch.Size([1024])              False
  300  model.vision_tower.encoder.layers.21.ls2                                          torch.Size([1024])              False
  301  model.vision_tower.encoder.layers.21.attn.qkv.weight                              torch.Size([3072, 1024])        False
  302  model.vision_tower.encoder.layers.21.attn.qkv.bias                                torch.Size([3072])              False
  303  model.vision_tower.encoder.layers.21.attn.proj.weight                             torch.Size([1024, 1024])        False
  304  model.vision_tower.encoder.layers.21.attn.proj.bias                               torch.Size([1024])              False
  305  model.vision_tower.encoder.layers.21.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  306  model.vision_tower.encoder.layers.21.mlp.fc1.bias                                 torch.Size([4096])              False
  307  model.vision_tower.encoder.layers.21.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  308  model.vision_tower.encoder.layers.21.mlp.fc2.bias                                 torch.Size([1024])              False
  309  model.vision_tower.encoder.layers.21.norm1.weight                                 torch.Size([1024])              False
  310  model.vision_tower.encoder.layers.21.norm1.bias                                   torch.Size([1024])              False
  311  model.vision_tower.encoder.layers.21.norm2.weight                                 torch.Size([1024])              False
  312  model.vision_tower.encoder.layers.21.norm2.bias                                   torch.Size([1024])              False
  313  model.vision_tower.encoder.layers.22.ls1                                          torch.Size([1024])              False
  314  model.vision_tower.encoder.layers.22.ls2                                          torch.Size([1024])              False
  315  model.vision_tower.encoder.layers.22.attn.qkv.weight                              torch.Size([3072, 1024])        False
  316  model.vision_tower.encoder.layers.22.attn.qkv.bias                                torch.Size([3072])              False
  317  model.vision_tower.encoder.layers.22.attn.proj.weight                             torch.Size([1024, 1024])        False
  318  model.vision_tower.encoder.layers.22.attn.proj.bias                               torch.Size([1024])              False
  319  model.vision_tower.encoder.layers.22.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  320  model.vision_tower.encoder.layers.22.mlp.fc1.bias                                 torch.Size([4096])              False
  321  model.vision_tower.encoder.layers.22.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  322  model.vision_tower.encoder.layers.22.mlp.fc2.bias                                 torch.Size([1024])              False
  323  model.vision_tower.encoder.layers.22.norm1.weight                                 torch.Size([1024])              False
  324  model.vision_tower.encoder.layers.22.norm1.bias                                   torch.Size([1024])              False
  325  model.vision_tower.encoder.layers.22.norm2.weight                                 torch.Size([1024])              False
  326  model.vision_tower.encoder.layers.22.norm2.bias                                   torch.Size([1024])              False
  327  model.vision_tower.encoder.layers.23.ls1                                          torch.Size([1024])              False
  328  model.vision_tower.encoder.layers.23.ls2                                          torch.Size([1024])              False
  329  model.vision_tower.encoder.layers.23.attn.qkv.weight                              torch.Size([3072, 1024])        False
  330  model.vision_tower.encoder.layers.23.attn.qkv.bias                                torch.Size([3072])              False
  331  model.vision_tower.encoder.layers.23.attn.proj.weight                             torch.Size([1024, 1024])        False
  332  model.vision_tower.encoder.layers.23.attn.proj.bias                               torch.Size([1024])              False
  333  model.vision_tower.encoder.layers.23.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  334  model.vision_tower.encoder.layers.23.mlp.fc1.bias                                 torch.Size([4096])              False
  335  model.vision_tower.encoder.layers.23.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  336  model.vision_tower.encoder.layers.23.mlp.fc2.bias                                 torch.Size([1024])              False
  337  model.vision_tower.encoder.layers.23.norm1.weight                                 torch.Size([1024])              False
  338  model.vision_tower.encoder.layers.23.norm1.bias                                   torch.Size([1024])              False
  339  model.vision_tower.encoder.layers.23.norm2.weight                                 torch.Size([1024])              False
  340  model.vision_tower.encoder.layers.23.norm2.bias                                   torch.Size([1024])              False
  341  model.multi_modal_projector.0.weight                                              torch.Size([4096])              False
  342  model.multi_modal_projector.0.bias                                                torch.Size([4096])              False
  343  model.multi_modal_projector.1.weight                                              torch.Size([896, 4096])         False
  344  model.multi_modal_projector.1.bias                                                torch.Size([896])               False
  345  model.multi_modal_projector.3.weight                                              torch.Size([896, 896])          False
  346  model.multi_modal_projector.3.bias                                                torch.Size([896])               False
  347  model.language_model.embed_tokens.weight                                          torch.Size([151678, 896])       False
  348  model.language_model.layers.0.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  349  model.language_model.layers.0.self_attn.q_proj.bias                               torch.Size([896])               False
  350  model.language_model.layers.0.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  351  model.language_model.layers.0.self_attn.k_proj.bias                               torch.Size([128])               False
  352  model.language_model.layers.0.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  353  model.language_model.layers.0.self_attn.v_proj.bias                               torch.Size([128])               False
  354  model.language_model.layers.0.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  355  model.language_model.layers.0.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  356  model.language_model.layers.0.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  357  model.language_model.layers.0.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  358  model.language_model.layers.0.input_layernorm.weight                              torch.Size([896])               False
  359  model.language_model.layers.0.post_attention_layernorm.weight                     torch.Size([896])               False
  360  model.language_model.layers.1.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  361  model.language_model.layers.1.self_attn.q_proj.bias                               torch.Size([896])               False
  362  model.language_model.layers.1.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  363  model.language_model.layers.1.self_attn.k_proj.bias                               torch.Size([128])               False
  364  model.language_model.layers.1.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  365  model.language_model.layers.1.self_attn.v_proj.bias                               torch.Size([128])               False
  366  model.language_model.layers.1.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  367  model.language_model.layers.1.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  368  model.language_model.layers.1.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  369  model.language_model.layers.1.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  370  model.language_model.layers.1.input_layernorm.weight                              torch.Size([896])               False
  371  model.language_model.layers.1.post_attention_layernorm.weight                     torch.Size([896])               False
  372  model.language_model.layers.2.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  373  model.language_model.layers.2.self_attn.q_proj.bias                               torch.Size([896])               False
  374  model.language_model.layers.2.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  375  model.language_model.layers.2.self_attn.k_proj.bias                               torch.Size([128])               False
  376  model.language_model.layers.2.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  377  model.language_model.layers.2.self_attn.v_proj.bias                               torch.Size([128])               False
  378  model.language_model.layers.2.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  379  model.language_model.layers.2.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  380  model.language_model.layers.2.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  381  model.language_model.layers.2.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  382  model.language_model.layers.2.input_layernorm.weight                              torch.Size([896])               False
  383  model.language_model.layers.2.post_attention_layernorm.weight                     torch.Size([896])               False
  384  model.language_model.layers.3.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  385  model.language_model.layers.3.self_attn.q_proj.bias                               torch.Size([896])               False
  386  model.language_model.layers.3.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  387  model.language_model.layers.3.self_attn.k_proj.bias                               torch.Size([128])               False
  388  model.language_model.layers.3.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  389  model.language_model.layers.3.self_attn.v_proj.bias                               torch.Size([128])               False
  390  model.language_model.layers.3.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  391  model.language_model.layers.3.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  392  model.language_model.layers.3.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  393  model.language_model.layers.3.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  394  model.language_model.layers.3.input_layernorm.weight                              torch.Size([896])               False
  395  model.language_model.layers.3.post_attention_layernorm.weight                     torch.Size([896])               False
  396  model.language_model.layers.4.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  397  model.language_model.layers.4.self_attn.q_proj.bias                               torch.Size([896])               False
  398  model.language_model.layers.4.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  399  model.language_model.layers.4.self_attn.k_proj.bias                               torch.Size([128])               False
  400  model.language_model.layers.4.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  401  model.language_model.layers.4.self_attn.v_proj.bias                               torch.Size([128])               False
  402  model.language_model.layers.4.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  403  model.language_model.layers.4.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  404  model.language_model.layers.4.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  405  model.language_model.layers.4.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  406  model.language_model.layers.4.input_layernorm.weight                              torch.Size([896])               False
  407  model.language_model.layers.4.post_attention_layernorm.weight                     torch.Size([896])               False
  408  model.language_model.layers.5.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  409  model.language_model.layers.5.self_attn.q_proj.bias                               torch.Size([896])               False
  410  model.language_model.layers.5.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  411  model.language_model.layers.5.self_attn.k_proj.bias                               torch.Size([128])               False
  412  model.language_model.layers.5.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  413  model.language_model.layers.5.self_attn.v_proj.bias                               torch.Size([128])               False
  414  model.language_model.layers.5.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  415  model.language_model.layers.5.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  416  model.language_model.layers.5.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  417  model.language_model.layers.5.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  418  model.language_model.layers.5.input_layernorm.weight                              torch.Size([896])               False
  419  model.language_model.layers.5.post_attention_layernorm.weight                     torch.Size([896])               False
  420  model.language_model.layers.6.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  421  model.language_model.layers.6.self_attn.q_proj.bias                               torch.Size([896])               False
  422  model.language_model.layers.6.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  423  model.language_model.layers.6.self_attn.k_proj.bias                               torch.Size([128])               False
  424  model.language_model.layers.6.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  425  model.language_model.layers.6.self_attn.v_proj.bias                               torch.Size([128])               False
  426  model.language_model.layers.6.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  427  model.language_model.layers.6.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  428  model.language_model.layers.6.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  429  model.language_model.layers.6.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  430  model.language_model.layers.6.input_layernorm.weight                              torch.Size([896])               False
  431  model.language_model.layers.6.post_attention_layernorm.weight                     torch.Size([896])               False
  432  model.language_model.layers.7.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  433  model.language_model.layers.7.self_attn.q_proj.bias                               torch.Size([896])               False
  434  model.language_model.layers.7.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  435  model.language_model.layers.7.self_attn.k_proj.bias                               torch.Size([128])               False
  436  model.language_model.layers.7.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  437  model.language_model.layers.7.self_attn.v_proj.bias                               torch.Size([128])               False
  438  model.language_model.layers.7.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  439  model.language_model.layers.7.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  440  model.language_model.layers.7.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  441  model.language_model.layers.7.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  442  model.language_model.layers.7.input_layernorm.weight                              torch.Size([896])               False
  443  model.language_model.layers.7.post_attention_layernorm.weight                     torch.Size([896])               False
  444  model.language_model.layers.8.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  445  model.language_model.layers.8.self_attn.q_proj.bias                               torch.Size([896])               False
  446  model.language_model.layers.8.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  447  model.language_model.layers.8.self_attn.k_proj.bias                               torch.Size([128])               False
  448  model.language_model.layers.8.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  449  model.language_model.layers.8.self_attn.v_proj.bias                               torch.Size([128])               False
  450  model.language_model.layers.8.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  451  model.language_model.layers.8.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  452  model.language_model.layers.8.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  453  model.language_model.layers.8.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  454  model.language_model.layers.8.input_layernorm.weight                              torch.Size([896])               False
  455  model.language_model.layers.8.post_attention_layernorm.weight                     torch.Size([896])               False
  456  model.language_model.layers.9.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  457  model.language_model.layers.9.self_attn.q_proj.bias                               torch.Size([896])               False
  458  model.language_model.layers.9.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  459  model.language_model.layers.9.self_attn.k_proj.bias                               torch.Size([128])               False
  460  model.language_model.layers.9.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  461  model.language_model.layers.9.self_attn.v_proj.bias                               torch.Size([128])               False
  462  model.language_model.layers.9.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  463  model.language_model.layers.9.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  464  model.language_model.layers.9.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  465  model.language_model.layers.9.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  466  model.language_model.layers.9.input_layernorm.weight                              torch.Size([896])               False
  467  model.language_model.layers.9.post_attention_layernorm.weight                     torch.Size([896])               False
  468  model.language_model.layers.10.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  469  model.language_model.layers.10.self_attn.q_proj.bias                              torch.Size([896])               False
  470  model.language_model.layers.10.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  471  model.language_model.layers.10.self_attn.k_proj.bias                              torch.Size([128])               False
  472  model.language_model.layers.10.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  473  model.language_model.layers.10.self_attn.v_proj.bias                              torch.Size([128])               False
  474  model.language_model.layers.10.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  475  model.language_model.layers.10.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  476  model.language_model.layers.10.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  477  model.language_model.layers.10.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  478  model.language_model.layers.10.input_layernorm.weight                             torch.Size([896])               False
  479  model.language_model.layers.10.post_attention_layernorm.weight                    torch.Size([896])               False
  480  model.language_model.layers.11.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  481  model.language_model.layers.11.self_attn.q_proj.bias                              torch.Size([896])               False
  482  model.language_model.layers.11.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  483  model.language_model.layers.11.self_attn.k_proj.bias                              torch.Size([128])               False
  484  model.language_model.layers.11.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  485  model.language_model.layers.11.self_attn.v_proj.bias                              torch.Size([128])               False
  486  model.language_model.layers.11.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  487  model.language_model.layers.11.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  488  model.language_model.layers.11.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  489  model.language_model.layers.11.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  490  model.language_model.layers.11.input_layernorm.weight                             torch.Size([896])               False
  491  model.language_model.layers.11.post_attention_layernorm.weight                    torch.Size([896])               False
  492  model.language_model.layers.12.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  493  model.language_model.layers.12.self_attn.q_proj.bias                              torch.Size([896])               False
  494  model.language_model.layers.12.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  495  model.language_model.layers.12.self_attn.k_proj.bias                              torch.Size([128])               False
  496  model.language_model.layers.12.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  497  model.language_model.layers.12.self_attn.v_proj.bias                              torch.Size([128])               False
  498  model.language_model.layers.12.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  499  model.language_model.layers.12.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  500  model.language_model.layers.12.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  501  model.language_model.layers.12.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  502  model.language_model.layers.12.input_layernorm.weight                             torch.Size([896])               False
  503  model.language_model.layers.12.post_attention_layernorm.weight                    torch.Size([896])               False
  504  model.language_model.layers.13.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  505  model.language_model.layers.13.self_attn.q_proj.bias                              torch.Size([896])               False
  506  model.language_model.layers.13.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  507  model.language_model.layers.13.self_attn.k_proj.bias                              torch.Size([128])               False
  508  model.language_model.layers.13.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  509  model.language_model.layers.13.self_attn.v_proj.bias                              torch.Size([128])               False
  510  model.language_model.layers.13.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  511  model.language_model.layers.13.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  512  model.language_model.layers.13.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  513  model.language_model.layers.13.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  514  model.language_model.layers.13.input_layernorm.weight                             torch.Size([896])               False
  515  model.language_model.layers.13.post_attention_layernorm.weight                    torch.Size([896])               False
  516  model.language_model.layers.14.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  517  model.language_model.layers.14.self_attn.q_proj.bias                              torch.Size([896])               False
  518  model.language_model.layers.14.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  519  model.language_model.layers.14.self_attn.k_proj.bias                              torch.Size([128])               False
  520  model.language_model.layers.14.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  521  model.language_model.layers.14.self_attn.v_proj.bias                              torch.Size([128])               False
  522  model.language_model.layers.14.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  523  model.language_model.layers.14.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  524  model.language_model.layers.14.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  525  model.language_model.layers.14.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  526  model.language_model.layers.14.input_layernorm.weight                             torch.Size([896])               False
  527  model.language_model.layers.14.post_attention_layernorm.weight                    torch.Size([896])               False
  528  model.language_model.layers.15.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  529  model.language_model.layers.15.self_attn.q_proj.bias                              torch.Size([896])               False
  530  model.language_model.layers.15.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  531  model.language_model.layers.15.self_attn.k_proj.bias                              torch.Size([128])               False
  532  model.language_model.layers.15.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  533  model.language_model.layers.15.self_attn.v_proj.bias                              torch.Size([128])               False
  534  model.language_model.layers.15.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  535  model.language_model.layers.15.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  536  model.language_model.layers.15.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  537  model.language_model.layers.15.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  538  model.language_model.layers.15.input_layernorm.weight                             torch.Size([896])               False
  539  model.language_model.layers.15.post_attention_layernorm.weight                    torch.Size([896])               False
  540  model.language_model.layers.16.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  541  model.language_model.layers.16.self_attn.q_proj.bias                              torch.Size([896])               False
  542  model.language_model.layers.16.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  543  model.language_model.layers.16.self_attn.k_proj.bias                              torch.Size([128])               False
  544  model.language_model.layers.16.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  545  model.language_model.layers.16.self_attn.v_proj.bias                              torch.Size([128])               False
  546  model.language_model.layers.16.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  547  model.language_model.layers.16.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  548  model.language_model.layers.16.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  549  model.language_model.layers.16.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  550  model.language_model.layers.16.input_layernorm.weight                             torch.Size([896])               False
  551  model.language_model.layers.16.post_attention_layernorm.weight                    torch.Size([896])               False
  552  model.language_model.layers.17.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  553  model.language_model.layers.17.self_attn.q_proj.bias                              torch.Size([896])               False
  554  model.language_model.layers.17.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  555  model.language_model.layers.17.self_attn.k_proj.bias                              torch.Size([128])               False
  556  model.language_model.layers.17.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  557  model.language_model.layers.17.self_attn.v_proj.bias                              torch.Size([128])               False
  558  model.language_model.layers.17.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  559  model.language_model.layers.17.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  560  model.language_model.layers.17.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  561  model.language_model.layers.17.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  562  model.language_model.layers.17.input_layernorm.weight                             torch.Size([896])               False
  563  model.language_model.layers.17.post_attention_layernorm.weight                    torch.Size([896])               False
  564  model.language_model.layers.18.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  565  model.language_model.layers.18.self_attn.q_proj.bias                              torch.Size([896])               False
  566  model.language_model.layers.18.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  567  model.language_model.layers.18.self_attn.k_proj.bias                              torch.Size([128])               False
  568  model.language_model.layers.18.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  569  model.language_model.layers.18.self_attn.v_proj.bias                              torch.Size([128])               False
  570  model.language_model.layers.18.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  571  model.language_model.layers.18.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  572  model.language_model.layers.18.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  573  model.language_model.layers.18.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  574  model.language_model.layers.18.input_layernorm.weight                             torch.Size([896])               False
  575  model.language_model.layers.18.post_attention_layernorm.weight                    torch.Size([896])               False
  576  model.language_model.layers.19.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  577  model.language_model.layers.19.self_attn.q_proj.bias                              torch.Size([896])               False
  578  model.language_model.layers.19.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  579  model.language_model.layers.19.self_attn.k_proj.bias                              torch.Size([128])               False
  580  model.language_model.layers.19.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  581  model.language_model.layers.19.self_attn.v_proj.bias                              torch.Size([128])               False
  582  model.language_model.layers.19.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  583  model.language_model.layers.19.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  584  model.language_model.layers.19.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  585  model.language_model.layers.19.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  586  model.language_model.layers.19.input_layernorm.weight                             torch.Size([896])               False
  587  model.language_model.layers.19.post_attention_layernorm.weight                    torch.Size([896])               False
  588  model.language_model.layers.20.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  589  model.language_model.layers.20.self_attn.q_proj.bias                              torch.Size([896])               False
  590  model.language_model.layers.20.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  591  model.language_model.layers.20.self_attn.k_proj.bias                              torch.Size([128])               False
  592  model.language_model.layers.20.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  593  model.language_model.layers.20.self_attn.v_proj.bias                              torch.Size([128])               False
  594  model.language_model.layers.20.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  595  model.language_model.layers.20.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  596  model.language_model.layers.20.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  597  model.language_model.layers.20.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  598  model.language_model.layers.20.input_layernorm.weight                             torch.Size([896])               False
  599  model.language_model.layers.20.post_attention_layernorm.weight                    torch.Size([896])               False
  600  model.language_model.layers.21.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  601  model.language_model.layers.21.self_attn.q_proj.bias                              torch.Size([896])               False
  602  model.language_model.layers.21.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  603  model.language_model.layers.21.self_attn.k_proj.bias                              torch.Size([128])               False
  604  model.language_model.layers.21.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  605  model.language_model.layers.21.self_attn.v_proj.bias                              torch.Size([128])               False
  606  model.language_model.layers.21.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  607  model.language_model.layers.21.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  608  model.language_model.layers.21.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  609  model.language_model.layers.21.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  610  model.language_model.layers.21.input_layernorm.weight                             torch.Size([896])               False
  611  model.language_model.layers.21.post_attention_layernorm.weight                    torch.Size([896])               False
  612  model.language_model.layers.22.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  613  model.language_model.layers.22.self_attn.q_proj.bias                              torch.Size([896])               False
  614  model.language_model.layers.22.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  615  model.language_model.layers.22.self_attn.k_proj.bias                              torch.Size([128])               False
  616  model.language_model.layers.22.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  617  model.language_model.layers.22.self_attn.v_proj.bias                              torch.Size([128])               False
  618  model.language_model.layers.22.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  619  model.language_model.layers.22.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  620  model.language_model.layers.22.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  621  model.language_model.layers.22.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  622  model.language_model.layers.22.input_layernorm.weight                             torch.Size([896])               False
  623  model.language_model.layers.22.post_attention_layernorm.weight                    torch.Size([896])               False
  624  model.language_model.layers.23.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  625  model.language_model.layers.23.self_attn.q_proj.bias                              torch.Size([896])               False
  626  model.language_model.layers.23.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  627  model.language_model.layers.23.self_attn.k_proj.bias                              torch.Size([128])               False
  628  model.language_model.layers.23.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  629  model.language_model.layers.23.self_attn.v_proj.bias                              torch.Size([128])               False
  630  model.language_model.layers.23.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  631  model.language_model.layers.23.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  632  model.language_model.layers.23.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  633  model.language_model.layers.23.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  634  model.language_model.layers.23.input_layernorm.weight                             torch.Size([896])               False
  635  model.language_model.layers.23.post_attention_layernorm.weight                    torch.Size([896])               False
  636  model.language_model.norm.weight                                                  torch.Size([896])               False
  637  model.dit.scale_shift_table                                                       torch.Size([2, 1152])           True
  638  model.dit.patch_embed.proj.weight                                                 torch.Size([1152, 32, 1, 1])    True
  639  model.dit.patch_embed.proj.bias                                                   torch.Size([1152])              True
  640  model.dit.time_embed.emb.timestep_embedder.linear_1.weight                        torch.Size([1152, 256])         True
  641  model.dit.time_embed.emb.timestep_embedder.linear_1.bias                          torch.Size([1152])              True
  642  model.dit.time_embed.emb.timestep_embedder.linear_2.weight                        torch.Size([1152, 1152])        True
  643  model.dit.time_embed.emb.timestep_embedder.linear_2.bias                          torch.Size([1152])              True
  644  model.dit.time_embed.linear.weight                                                torch.Size([6912, 1152])        True
  645  model.dit.time_embed.linear.bias                                                  torch.Size([6912])              True
  646  model.dit.caption_projection.linear_1.weight                                      torch.Size([1152, 2304])        True
  647  model.dit.caption_projection.linear_1.bias                                        torch.Size([1152])              True
  648  model.dit.caption_projection.linear_2.weight                                      torch.Size([1152, 1152])        True
  649  model.dit.caption_projection.linear_2.bias                                        torch.Size([1152])              True
  650  model.dit.caption_norm.weight                                                     torch.Size([1152])              True
  651  model.dit.transformer_blocks.0.scale_shift_table                                  torch.Size([6, 1152])           True
  652  model.dit.transformer_blocks.0.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  653  model.dit.transformer_blocks.0.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  654  model.dit.transformer_blocks.0.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  655  model.dit.transformer_blocks.0.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  656  model.dit.transformer_blocks.0.attn1.to_out.0.bias                                torch.Size([1152])              True
  657  model.dit.transformer_blocks.0.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  658  model.dit.transformer_blocks.0.attn2.to_q.bias                                    torch.Size([1152])              True
  659  model.dit.transformer_blocks.0.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  660  model.dit.transformer_blocks.0.attn2.to_k.bias                                    torch.Size([1152])              True
  661  model.dit.transformer_blocks.0.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  662  model.dit.transformer_blocks.0.attn2.to_v.bias                                    torch.Size([1152])              True
  663  model.dit.transformer_blocks.0.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  664  model.dit.transformer_blocks.0.attn2.to_out.0.bias                                torch.Size([1152])              True
  665  model.dit.transformer_blocks.0.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  666  model.dit.transformer_blocks.0.ff.conv_inverted.bias                              torch.Size([5760])              True
  667  model.dit.transformer_blocks.0.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  668  model.dit.transformer_blocks.0.ff.conv_depth.bias                                 torch.Size([5760])              True
  669  model.dit.transformer_blocks.0.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  670  model.dit.transformer_blocks.1.scale_shift_table                                  torch.Size([6, 1152])           True
  671  model.dit.transformer_blocks.1.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  672  model.dit.transformer_blocks.1.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  673  model.dit.transformer_blocks.1.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  674  model.dit.transformer_blocks.1.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  675  model.dit.transformer_blocks.1.attn1.to_out.0.bias                                torch.Size([1152])              True
  676  model.dit.transformer_blocks.1.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  677  model.dit.transformer_blocks.1.attn2.to_q.bias                                    torch.Size([1152])              True
  678  model.dit.transformer_blocks.1.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  679  model.dit.transformer_blocks.1.attn2.to_k.bias                                    torch.Size([1152])              True
  680  model.dit.transformer_blocks.1.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  681  model.dit.transformer_blocks.1.attn2.to_v.bias                                    torch.Size([1152])              True
  682  model.dit.transformer_blocks.1.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  683  model.dit.transformer_blocks.1.attn2.to_out.0.bias                                torch.Size([1152])              True
  684  model.dit.transformer_blocks.1.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  685  model.dit.transformer_blocks.1.ff.conv_inverted.bias                              torch.Size([5760])              True
  686  model.dit.transformer_blocks.1.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  687  model.dit.transformer_blocks.1.ff.conv_depth.bias                                 torch.Size([5760])              True
  688  model.dit.transformer_blocks.1.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  689  model.dit.transformer_blocks.2.scale_shift_table                                  torch.Size([6, 1152])           True
  690  model.dit.transformer_blocks.2.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  691  model.dit.transformer_blocks.2.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  692  model.dit.transformer_blocks.2.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  693  model.dit.transformer_blocks.2.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  694  model.dit.transformer_blocks.2.attn1.to_out.0.bias                                torch.Size([1152])              True
  695  model.dit.transformer_blocks.2.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  696  model.dit.transformer_blocks.2.attn2.to_q.bias                                    torch.Size([1152])              True
  697  model.dit.transformer_blocks.2.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  698  model.dit.transformer_blocks.2.attn2.to_k.bias                                    torch.Size([1152])              True
  699  model.dit.transformer_blocks.2.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  700  model.dit.transformer_blocks.2.attn2.to_v.bias                                    torch.Size([1152])              True
  701  model.dit.transformer_blocks.2.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  702  model.dit.transformer_blocks.2.attn2.to_out.0.bias                                torch.Size([1152])              True
  703  model.dit.transformer_blocks.2.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  704  model.dit.transformer_blocks.2.ff.conv_inverted.bias                              torch.Size([5760])              True
  705  model.dit.transformer_blocks.2.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  706  model.dit.transformer_blocks.2.ff.conv_depth.bias                                 torch.Size([5760])              True
  707  model.dit.transformer_blocks.2.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  708  model.dit.transformer_blocks.3.scale_shift_table                                  torch.Size([6, 1152])           True
  709  model.dit.transformer_blocks.3.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  710  model.dit.transformer_blocks.3.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  711  model.dit.transformer_blocks.3.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  712  model.dit.transformer_blocks.3.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  713  model.dit.transformer_blocks.3.attn1.to_out.0.bias                                torch.Size([1152])              True
  714  model.dit.transformer_blocks.3.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  715  model.dit.transformer_blocks.3.attn2.to_q.bias                                    torch.Size([1152])              True
  716  model.dit.transformer_blocks.3.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  717  model.dit.transformer_blocks.3.attn2.to_k.bias                                    torch.Size([1152])              True
  718  model.dit.transformer_blocks.3.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  719  model.dit.transformer_blocks.3.attn2.to_v.bias                                    torch.Size([1152])              True
  720  model.dit.transformer_blocks.3.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  721  model.dit.transformer_blocks.3.attn2.to_out.0.bias                                torch.Size([1152])              True
  722  model.dit.transformer_blocks.3.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  723  model.dit.transformer_blocks.3.ff.conv_inverted.bias                              torch.Size([5760])              True
  724  model.dit.transformer_blocks.3.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  725  model.dit.transformer_blocks.3.ff.conv_depth.bias                                 torch.Size([5760])              True
  726  model.dit.transformer_blocks.3.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  727  model.dit.transformer_blocks.4.scale_shift_table                                  torch.Size([6, 1152])           True
  728  model.dit.transformer_blocks.4.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  729  model.dit.transformer_blocks.4.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  730  model.dit.transformer_blocks.4.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  731  model.dit.transformer_blocks.4.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  732  model.dit.transformer_blocks.4.attn1.to_out.0.bias                                torch.Size([1152])              True
  733  model.dit.transformer_blocks.4.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  734  model.dit.transformer_blocks.4.attn2.to_q.bias                                    torch.Size([1152])              True
  735  model.dit.transformer_blocks.4.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  736  model.dit.transformer_blocks.4.attn2.to_k.bias                                    torch.Size([1152])              True
  737  model.dit.transformer_blocks.4.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  738  model.dit.transformer_blocks.4.attn2.to_v.bias                                    torch.Size([1152])              True
  739  model.dit.transformer_blocks.4.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  740  model.dit.transformer_blocks.4.attn2.to_out.0.bias                                torch.Size([1152])              True
  741  model.dit.transformer_blocks.4.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  742  model.dit.transformer_blocks.4.ff.conv_inverted.bias                              torch.Size([5760])              True
  743  model.dit.transformer_blocks.4.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  744  model.dit.transformer_blocks.4.ff.conv_depth.bias                                 torch.Size([5760])              True
  745  model.dit.transformer_blocks.4.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  746  model.dit.transformer_blocks.5.scale_shift_table                                  torch.Size([6, 1152])           True
  747  model.dit.transformer_blocks.5.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  748  model.dit.transformer_blocks.5.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  749  model.dit.transformer_blocks.5.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  750  model.dit.transformer_blocks.5.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  751  model.dit.transformer_blocks.5.attn1.to_out.0.bias                                torch.Size([1152])              True
  752  model.dit.transformer_blocks.5.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  753  model.dit.transformer_blocks.5.attn2.to_q.bias                                    torch.Size([1152])              True
  754  model.dit.transformer_blocks.5.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  755  model.dit.transformer_blocks.5.attn2.to_k.bias                                    torch.Size([1152])              True
  756  model.dit.transformer_blocks.5.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  757  model.dit.transformer_blocks.5.attn2.to_v.bias                                    torch.Size([1152])              True
  758  model.dit.transformer_blocks.5.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  759  model.dit.transformer_blocks.5.attn2.to_out.0.bias                                torch.Size([1152])              True
  760  model.dit.transformer_blocks.5.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  761  model.dit.transformer_blocks.5.ff.conv_inverted.bias                              torch.Size([5760])              True
  762  model.dit.transformer_blocks.5.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  763  model.dit.transformer_blocks.5.ff.conv_depth.bias                                 torch.Size([5760])              True
  764  model.dit.transformer_blocks.5.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  765  model.dit.transformer_blocks.6.scale_shift_table                                  torch.Size([6, 1152])           True
  766  model.dit.transformer_blocks.6.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  767  model.dit.transformer_blocks.6.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  768  model.dit.transformer_blocks.6.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  769  model.dit.transformer_blocks.6.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  770  model.dit.transformer_blocks.6.attn1.to_out.0.bias                                torch.Size([1152])              True
  771  model.dit.transformer_blocks.6.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  772  model.dit.transformer_blocks.6.attn2.to_q.bias                                    torch.Size([1152])              True
  773  model.dit.transformer_blocks.6.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  774  model.dit.transformer_blocks.6.attn2.to_k.bias                                    torch.Size([1152])              True
  775  model.dit.transformer_blocks.6.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  776  model.dit.transformer_blocks.6.attn2.to_v.bias                                    torch.Size([1152])              True
  777  model.dit.transformer_blocks.6.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  778  model.dit.transformer_blocks.6.attn2.to_out.0.bias                                torch.Size([1152])              True
  779  model.dit.transformer_blocks.6.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  780  model.dit.transformer_blocks.6.ff.conv_inverted.bias                              torch.Size([5760])              True
  781  model.dit.transformer_blocks.6.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  782  model.dit.transformer_blocks.6.ff.conv_depth.bias                                 torch.Size([5760])              True
  783  model.dit.transformer_blocks.6.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  784  model.dit.transformer_blocks.7.scale_shift_table                                  torch.Size([6, 1152])           True
  785  model.dit.transformer_blocks.7.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  786  model.dit.transformer_blocks.7.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  787  model.dit.transformer_blocks.7.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  788  model.dit.transformer_blocks.7.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  789  model.dit.transformer_blocks.7.attn1.to_out.0.bias                                torch.Size([1152])              True
  790  model.dit.transformer_blocks.7.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  791  model.dit.transformer_blocks.7.attn2.to_q.bias                                    torch.Size([1152])              True
  792  model.dit.transformer_blocks.7.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  793  model.dit.transformer_blocks.7.attn2.to_k.bias                                    torch.Size([1152])              True
  794  model.dit.transformer_blocks.7.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  795  model.dit.transformer_blocks.7.attn2.to_v.bias                                    torch.Size([1152])              True
  796  model.dit.transformer_blocks.7.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  797  model.dit.transformer_blocks.7.attn2.to_out.0.bias                                torch.Size([1152])              True
  798  model.dit.transformer_blocks.7.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  799  model.dit.transformer_blocks.7.ff.conv_inverted.bias                              torch.Size([5760])              True
  800  model.dit.transformer_blocks.7.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  801  model.dit.transformer_blocks.7.ff.conv_depth.bias                                 torch.Size([5760])              True
  802  model.dit.transformer_blocks.7.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  803  model.dit.transformer_blocks.8.scale_shift_table                                  torch.Size([6, 1152])           True
  804  model.dit.transformer_blocks.8.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  805  model.dit.transformer_blocks.8.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  806  model.dit.transformer_blocks.8.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  807  model.dit.transformer_blocks.8.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  808  model.dit.transformer_blocks.8.attn1.to_out.0.bias                                torch.Size([1152])              True
  809  model.dit.transformer_blocks.8.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  810  model.dit.transformer_blocks.8.attn2.to_q.bias                                    torch.Size([1152])              True
  811  model.dit.transformer_blocks.8.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  812  model.dit.transformer_blocks.8.attn2.to_k.bias                                    torch.Size([1152])              True
  813  model.dit.transformer_blocks.8.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  814  model.dit.transformer_blocks.8.attn2.to_v.bias                                    torch.Size([1152])              True
  815  model.dit.transformer_blocks.8.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  816  model.dit.transformer_blocks.8.attn2.to_out.0.bias                                torch.Size([1152])              True
  817  model.dit.transformer_blocks.8.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  818  model.dit.transformer_blocks.8.ff.conv_inverted.bias                              torch.Size([5760])              True
  819  model.dit.transformer_blocks.8.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  820  model.dit.transformer_blocks.8.ff.conv_depth.bias                                 torch.Size([5760])              True
  821  model.dit.transformer_blocks.8.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  822  model.dit.transformer_blocks.9.scale_shift_table                                  torch.Size([6, 1152])           True
  823  model.dit.transformer_blocks.9.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  824  model.dit.transformer_blocks.9.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  825  model.dit.transformer_blocks.9.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  826  model.dit.transformer_blocks.9.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  827  model.dit.transformer_blocks.9.attn1.to_out.0.bias                                torch.Size([1152])              True
  828  model.dit.transformer_blocks.9.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  829  model.dit.transformer_blocks.9.attn2.to_q.bias                                    torch.Size([1152])              True
  830  model.dit.transformer_blocks.9.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  831  model.dit.transformer_blocks.9.attn2.to_k.bias                                    torch.Size([1152])              True
  832  model.dit.transformer_blocks.9.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  833  model.dit.transformer_blocks.9.attn2.to_v.bias                                    torch.Size([1152])              True
  834  model.dit.transformer_blocks.9.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  835  model.dit.transformer_blocks.9.attn2.to_out.0.bias                                torch.Size([1152])              True
  836  model.dit.transformer_blocks.9.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  837  model.dit.transformer_blocks.9.ff.conv_inverted.bias                              torch.Size([5760])              True
  838  model.dit.transformer_blocks.9.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  839  model.dit.transformer_blocks.9.ff.conv_depth.bias                                 torch.Size([5760])              True
  840  model.dit.transformer_blocks.9.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  841  model.dit.transformer_blocks.10.scale_shift_table                                 torch.Size([6, 1152])           True
  842  model.dit.transformer_blocks.10.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  843  model.dit.transformer_blocks.10.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  844  model.dit.transformer_blocks.10.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  845  model.dit.transformer_blocks.10.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  846  model.dit.transformer_blocks.10.attn1.to_out.0.bias                               torch.Size([1152])              True
  847  model.dit.transformer_blocks.10.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  848  model.dit.transformer_blocks.10.attn2.to_q.bias                                   torch.Size([1152])              True
  849  model.dit.transformer_blocks.10.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  850  model.dit.transformer_blocks.10.attn2.to_k.bias                                   torch.Size([1152])              True
  851  model.dit.transformer_blocks.10.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  852  model.dit.transformer_blocks.10.attn2.to_v.bias                                   torch.Size([1152])              True
  853  model.dit.transformer_blocks.10.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  854  model.dit.transformer_blocks.10.attn2.to_out.0.bias                               torch.Size([1152])              True
  855  model.dit.transformer_blocks.10.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  856  model.dit.transformer_blocks.10.ff.conv_inverted.bias                             torch.Size([5760])              True
  857  model.dit.transformer_blocks.10.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  858  model.dit.transformer_blocks.10.ff.conv_depth.bias                                torch.Size([5760])              True
  859  model.dit.transformer_blocks.10.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  860  model.dit.transformer_blocks.11.scale_shift_table                                 torch.Size([6, 1152])           True
  861  model.dit.transformer_blocks.11.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  862  model.dit.transformer_blocks.11.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  863  model.dit.transformer_blocks.11.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  864  model.dit.transformer_blocks.11.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  865  model.dit.transformer_blocks.11.attn1.to_out.0.bias                               torch.Size([1152])              True
  866  model.dit.transformer_blocks.11.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  867  model.dit.transformer_blocks.11.attn2.to_q.bias                                   torch.Size([1152])              True
  868  model.dit.transformer_blocks.11.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  869  model.dit.transformer_blocks.11.attn2.to_k.bias                                   torch.Size([1152])              True
  870  model.dit.transformer_blocks.11.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  871  model.dit.transformer_blocks.11.attn2.to_v.bias                                   torch.Size([1152])              True
  872  model.dit.transformer_blocks.11.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  873  model.dit.transformer_blocks.11.attn2.to_out.0.bias                               torch.Size([1152])              True
  874  model.dit.transformer_blocks.11.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  875  model.dit.transformer_blocks.11.ff.conv_inverted.bias                             torch.Size([5760])              True
  876  model.dit.transformer_blocks.11.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  877  model.dit.transformer_blocks.11.ff.conv_depth.bias                                torch.Size([5760])              True
  878  model.dit.transformer_blocks.11.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  879  model.dit.transformer_blocks.12.scale_shift_table                                 torch.Size([6, 1152])           True
  880  model.dit.transformer_blocks.12.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  881  model.dit.transformer_blocks.12.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  882  model.dit.transformer_blocks.12.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  883  model.dit.transformer_blocks.12.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  884  model.dit.transformer_blocks.12.attn1.to_out.0.bias                               torch.Size([1152])              True
  885  model.dit.transformer_blocks.12.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  886  model.dit.transformer_blocks.12.attn2.to_q.bias                                   torch.Size([1152])              True
  887  model.dit.transformer_blocks.12.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  888  model.dit.transformer_blocks.12.attn2.to_k.bias                                   torch.Size([1152])              True
  889  model.dit.transformer_blocks.12.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  890  model.dit.transformer_blocks.12.attn2.to_v.bias                                   torch.Size([1152])              True
  891  model.dit.transformer_blocks.12.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  892  model.dit.transformer_blocks.12.attn2.to_out.0.bias                               torch.Size([1152])              True
  893  model.dit.transformer_blocks.12.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  894  model.dit.transformer_blocks.12.ff.conv_inverted.bias                             torch.Size([5760])              True
  895  model.dit.transformer_blocks.12.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  896  model.dit.transformer_blocks.12.ff.conv_depth.bias                                torch.Size([5760])              True
  897  model.dit.transformer_blocks.12.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  898  model.dit.transformer_blocks.13.scale_shift_table                                 torch.Size([6, 1152])           True
  899  model.dit.transformer_blocks.13.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  900  model.dit.transformer_blocks.13.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  901  model.dit.transformer_blocks.13.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  902  model.dit.transformer_blocks.13.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  903  model.dit.transformer_blocks.13.attn1.to_out.0.bias                               torch.Size([1152])              True
  904  model.dit.transformer_blocks.13.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  905  model.dit.transformer_blocks.13.attn2.to_q.bias                                   torch.Size([1152])              True
  906  model.dit.transformer_blocks.13.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  907  model.dit.transformer_blocks.13.attn2.to_k.bias                                   torch.Size([1152])              True
  908  model.dit.transformer_blocks.13.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  909  model.dit.transformer_blocks.13.attn2.to_v.bias                                   torch.Size([1152])              True
  910  model.dit.transformer_blocks.13.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  911  model.dit.transformer_blocks.13.attn2.to_out.0.bias                               torch.Size([1152])              True
  912  model.dit.transformer_blocks.13.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  913  model.dit.transformer_blocks.13.ff.conv_inverted.bias                             torch.Size([5760])              True
  914  model.dit.transformer_blocks.13.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  915  model.dit.transformer_blocks.13.ff.conv_depth.bias                                torch.Size([5760])              True
  916  model.dit.transformer_blocks.13.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  917  model.dit.transformer_blocks.14.scale_shift_table                                 torch.Size([6, 1152])           True
  918  model.dit.transformer_blocks.14.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  919  model.dit.transformer_blocks.14.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  920  model.dit.transformer_blocks.14.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  921  model.dit.transformer_blocks.14.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  922  model.dit.transformer_blocks.14.attn1.to_out.0.bias                               torch.Size([1152])              True
  923  model.dit.transformer_blocks.14.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  924  model.dit.transformer_blocks.14.attn2.to_q.bias                                   torch.Size([1152])              True
  925  model.dit.transformer_blocks.14.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  926  model.dit.transformer_blocks.14.attn2.to_k.bias                                   torch.Size([1152])              True
  927  model.dit.transformer_blocks.14.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  928  model.dit.transformer_blocks.14.attn2.to_v.bias                                   torch.Size([1152])              True
  929  model.dit.transformer_blocks.14.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  930  model.dit.transformer_blocks.14.attn2.to_out.0.bias                               torch.Size([1152])              True
  931  model.dit.transformer_blocks.14.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  932  model.dit.transformer_blocks.14.ff.conv_inverted.bias                             torch.Size([5760])              True
  933  model.dit.transformer_blocks.14.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  934  model.dit.transformer_blocks.14.ff.conv_depth.bias                                torch.Size([5760])              True
  935  model.dit.transformer_blocks.14.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  936  model.dit.transformer_blocks.15.scale_shift_table                                 torch.Size([6, 1152])           True
  937  model.dit.transformer_blocks.15.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  938  model.dit.transformer_blocks.15.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  939  model.dit.transformer_blocks.15.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  940  model.dit.transformer_blocks.15.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  941  model.dit.transformer_blocks.15.attn1.to_out.0.bias                               torch.Size([1152])              True
  942  model.dit.transformer_blocks.15.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  943  model.dit.transformer_blocks.15.attn2.to_q.bias                                   torch.Size([1152])              True
  944  model.dit.transformer_blocks.15.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  945  model.dit.transformer_blocks.15.attn2.to_k.bias                                   torch.Size([1152])              True
  946  model.dit.transformer_blocks.15.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  947  model.dit.transformer_blocks.15.attn2.to_v.bias                                   torch.Size([1152])              True
  948  model.dit.transformer_blocks.15.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  949  model.dit.transformer_blocks.15.attn2.to_out.0.bias                               torch.Size([1152])              True
  950  model.dit.transformer_blocks.15.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  951  model.dit.transformer_blocks.15.ff.conv_inverted.bias                             torch.Size([5760])              True
  952  model.dit.transformer_blocks.15.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  953  model.dit.transformer_blocks.15.ff.conv_depth.bias                                torch.Size([5760])              True
  954  model.dit.transformer_blocks.15.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  955  model.dit.transformer_blocks.16.scale_shift_table                                 torch.Size([6, 1152])           True
  956  model.dit.transformer_blocks.16.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  957  model.dit.transformer_blocks.16.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  958  model.dit.transformer_blocks.16.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  959  model.dit.transformer_blocks.16.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  960  model.dit.transformer_blocks.16.attn1.to_out.0.bias                               torch.Size([1152])              True
  961  model.dit.transformer_blocks.16.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  962  model.dit.transformer_blocks.16.attn2.to_q.bias                                   torch.Size([1152])              True
  963  model.dit.transformer_blocks.16.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  964  model.dit.transformer_blocks.16.attn2.to_k.bias                                   torch.Size([1152])              True
  965  model.dit.transformer_blocks.16.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  966  model.dit.transformer_blocks.16.attn2.to_v.bias                                   torch.Size([1152])              True
  967  model.dit.transformer_blocks.16.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  968  model.dit.transformer_blocks.16.attn2.to_out.0.bias                               torch.Size([1152])              True
  969  model.dit.transformer_blocks.16.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  970  model.dit.transformer_blocks.16.ff.conv_inverted.bias                             torch.Size([5760])              True
  971  model.dit.transformer_blocks.16.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  972  model.dit.transformer_blocks.16.ff.conv_depth.bias                                torch.Size([5760])              True
  973  model.dit.transformer_blocks.16.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  974  model.dit.transformer_blocks.17.scale_shift_table                                 torch.Size([6, 1152])           True
  975  model.dit.transformer_blocks.17.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  976  model.dit.transformer_blocks.17.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  977  model.dit.transformer_blocks.17.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  978  model.dit.transformer_blocks.17.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  979  model.dit.transformer_blocks.17.attn1.to_out.0.bias                               torch.Size([1152])              True
  980  model.dit.transformer_blocks.17.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  981  model.dit.transformer_blocks.17.attn2.to_q.bias                                   torch.Size([1152])              True
  982  model.dit.transformer_blocks.17.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  983  model.dit.transformer_blocks.17.attn2.to_k.bias                                   torch.Size([1152])              True
  984  model.dit.transformer_blocks.17.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  985  model.dit.transformer_blocks.17.attn2.to_v.bias                                   torch.Size([1152])              True
  986  model.dit.transformer_blocks.17.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  987  model.dit.transformer_blocks.17.attn2.to_out.0.bias                               torch.Size([1152])              True
  988  model.dit.transformer_blocks.17.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  989  model.dit.transformer_blocks.17.ff.conv_inverted.bias                             torch.Size([5760])              True
  990  model.dit.transformer_blocks.17.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  991  model.dit.transformer_blocks.17.ff.conv_depth.bias                                torch.Size([5760])              True
  992  model.dit.transformer_blocks.17.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  993  model.dit.transformer_blocks.18.scale_shift_table                                 torch.Size([6, 1152])           True
  994  model.dit.transformer_blocks.18.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  995  model.dit.transformer_blocks.18.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  996  model.dit.transformer_blocks.18.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  997  model.dit.transformer_blocks.18.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  998  model.dit.transformer_blocks.18.attn1.to_out.0.bias                               torch.Size([1152])              True
  999  model.dit.transformer_blocks.18.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1000  model.dit.transformer_blocks.18.attn2.to_q.bias                                   torch.Size([1152])              True
 1001  model.dit.transformer_blocks.18.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1002  model.dit.transformer_blocks.18.attn2.to_k.bias                                   torch.Size([1152])              True
 1003  model.dit.transformer_blocks.18.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1004  model.dit.transformer_blocks.18.attn2.to_v.bias                                   torch.Size([1152])              True
 1005  model.dit.transformer_blocks.18.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1006  model.dit.transformer_blocks.18.attn2.to_out.0.bias                               torch.Size([1152])              True
 1007  model.dit.transformer_blocks.18.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1008  model.dit.transformer_blocks.18.ff.conv_inverted.bias                             torch.Size([5760])              True
 1009  model.dit.transformer_blocks.18.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1010  model.dit.transformer_blocks.18.ff.conv_depth.bias                                torch.Size([5760])              True
 1011  model.dit.transformer_blocks.18.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1012  model.dit.transformer_blocks.19.scale_shift_table                                 torch.Size([6, 1152])           True
 1013  model.dit.transformer_blocks.19.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1014  model.dit.transformer_blocks.19.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1015  model.dit.transformer_blocks.19.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1016  model.dit.transformer_blocks.19.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1017  model.dit.transformer_blocks.19.attn1.to_out.0.bias                               torch.Size([1152])              True
 1018  model.dit.transformer_blocks.19.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1019  model.dit.transformer_blocks.19.attn2.to_q.bias                                   torch.Size([1152])              True
 1020  model.dit.transformer_blocks.19.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1021  model.dit.transformer_blocks.19.attn2.to_k.bias                                   torch.Size([1152])              True
 1022  model.dit.transformer_blocks.19.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1023  model.dit.transformer_blocks.19.attn2.to_v.bias                                   torch.Size([1152])              True
 1024  model.dit.transformer_blocks.19.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1025  model.dit.transformer_blocks.19.attn2.to_out.0.bias                               torch.Size([1152])              True
 1026  model.dit.transformer_blocks.19.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1027  model.dit.transformer_blocks.19.ff.conv_inverted.bias                             torch.Size([5760])              True
 1028  model.dit.transformer_blocks.19.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1029  model.dit.transformer_blocks.19.ff.conv_depth.bias                                torch.Size([5760])              True
 1030  model.dit.transformer_blocks.19.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1031  model.dit.transformer_blocks.20.scale_shift_table                                 torch.Size([6, 1152])           True
 1032  model.dit.transformer_blocks.20.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1033  model.dit.transformer_blocks.20.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1034  model.dit.transformer_blocks.20.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1035  model.dit.transformer_blocks.20.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1036  model.dit.transformer_blocks.20.attn1.to_out.0.bias                               torch.Size([1152])              True
 1037  model.dit.transformer_blocks.20.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1038  model.dit.transformer_blocks.20.attn2.to_q.bias                                   torch.Size([1152])              True
 1039  model.dit.transformer_blocks.20.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1040  model.dit.transformer_blocks.20.attn2.to_k.bias                                   torch.Size([1152])              True
 1041  model.dit.transformer_blocks.20.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1042  model.dit.transformer_blocks.20.attn2.to_v.bias                                   torch.Size([1152])              True
 1043  model.dit.transformer_blocks.20.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1044  model.dit.transformer_blocks.20.attn2.to_out.0.bias                               torch.Size([1152])              True
 1045  model.dit.transformer_blocks.20.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1046  model.dit.transformer_blocks.20.ff.conv_inverted.bias                             torch.Size([5760])              True
 1047  model.dit.transformer_blocks.20.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1048  model.dit.transformer_blocks.20.ff.conv_depth.bias                                torch.Size([5760])              True
 1049  model.dit.transformer_blocks.20.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1050  model.dit.transformer_blocks.21.scale_shift_table                                 torch.Size([6, 1152])           True
 1051  model.dit.transformer_blocks.21.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1052  model.dit.transformer_blocks.21.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1053  model.dit.transformer_blocks.21.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1054  model.dit.transformer_blocks.21.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1055  model.dit.transformer_blocks.21.attn1.to_out.0.bias                               torch.Size([1152])              True
 1056  model.dit.transformer_blocks.21.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1057  model.dit.transformer_blocks.21.attn2.to_q.bias                                   torch.Size([1152])              True
 1058  model.dit.transformer_blocks.21.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1059  model.dit.transformer_blocks.21.attn2.to_k.bias                                   torch.Size([1152])              True
 1060  model.dit.transformer_blocks.21.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1061  model.dit.transformer_blocks.21.attn2.to_v.bias                                   torch.Size([1152])              True
 1062  model.dit.transformer_blocks.21.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1063  model.dit.transformer_blocks.21.attn2.to_out.0.bias                               torch.Size([1152])              True
 1064  model.dit.transformer_blocks.21.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1065  model.dit.transformer_blocks.21.ff.conv_inverted.bias                             torch.Size([5760])              True
 1066  model.dit.transformer_blocks.21.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1067  model.dit.transformer_blocks.21.ff.conv_depth.bias                                torch.Size([5760])              True
 1068  model.dit.transformer_blocks.21.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1069  model.dit.transformer_blocks.22.scale_shift_table                                 torch.Size([6, 1152])           True
 1070  model.dit.transformer_blocks.22.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1071  model.dit.transformer_blocks.22.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1072  model.dit.transformer_blocks.22.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1073  model.dit.transformer_blocks.22.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1074  model.dit.transformer_blocks.22.attn1.to_out.0.bias                               torch.Size([1152])              True
 1075  model.dit.transformer_blocks.22.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1076  model.dit.transformer_blocks.22.attn2.to_q.bias                                   torch.Size([1152])              True
 1077  model.dit.transformer_blocks.22.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1078  model.dit.transformer_blocks.22.attn2.to_k.bias                                   torch.Size([1152])              True
 1079  model.dit.transformer_blocks.22.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1080  model.dit.transformer_blocks.22.attn2.to_v.bias                                   torch.Size([1152])              True
 1081  model.dit.transformer_blocks.22.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1082  model.dit.transformer_blocks.22.attn2.to_out.0.bias                               torch.Size([1152])              True
 1083  model.dit.transformer_blocks.22.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1084  model.dit.transformer_blocks.22.ff.conv_inverted.bias                             torch.Size([5760])              True
 1085  model.dit.transformer_blocks.22.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1086  model.dit.transformer_blocks.22.ff.conv_depth.bias                                torch.Size([5760])              True
 1087  model.dit.transformer_blocks.22.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1088  model.dit.transformer_blocks.23.scale_shift_table                                 torch.Size([6, 1152])           True
 1089  model.dit.transformer_blocks.23.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1090  model.dit.transformer_blocks.23.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1091  model.dit.transformer_blocks.23.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1092  model.dit.transformer_blocks.23.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1093  model.dit.transformer_blocks.23.attn1.to_out.0.bias                               torch.Size([1152])              True
 1094  model.dit.transformer_blocks.23.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1095  model.dit.transformer_blocks.23.attn2.to_q.bias                                   torch.Size([1152])              True
 1096  model.dit.transformer_blocks.23.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1097  model.dit.transformer_blocks.23.attn2.to_k.bias                                   torch.Size([1152])              True
 1098  model.dit.transformer_blocks.23.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1099  model.dit.transformer_blocks.23.attn2.to_v.bias                                   torch.Size([1152])              True
 1100  model.dit.transformer_blocks.23.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1101  model.dit.transformer_blocks.23.attn2.to_out.0.bias                               torch.Size([1152])              True
 1102  model.dit.transformer_blocks.23.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1103  model.dit.transformer_blocks.23.ff.conv_inverted.bias                             torch.Size([5760])              True
 1104  model.dit.transformer_blocks.23.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1105  model.dit.transformer_blocks.23.ff.conv_depth.bias                                torch.Size([5760])              True
 1106  model.dit.transformer_blocks.23.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1107  model.dit.transformer_blocks.24.scale_shift_table                                 torch.Size([6, 1152])           True
 1108  model.dit.transformer_blocks.24.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1109  model.dit.transformer_blocks.24.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1110  model.dit.transformer_blocks.24.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1111  model.dit.transformer_blocks.24.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1112  model.dit.transformer_blocks.24.attn1.to_out.0.bias                               torch.Size([1152])              True
 1113  model.dit.transformer_blocks.24.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1114  model.dit.transformer_blocks.24.attn2.to_q.bias                                   torch.Size([1152])              True
 1115  model.dit.transformer_blocks.24.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1116  model.dit.transformer_blocks.24.attn2.to_k.bias                                   torch.Size([1152])              True
 1117  model.dit.transformer_blocks.24.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1118  model.dit.transformer_blocks.24.attn2.to_v.bias                                   torch.Size([1152])              True
 1119  model.dit.transformer_blocks.24.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1120  model.dit.transformer_blocks.24.attn2.to_out.0.bias                               torch.Size([1152])              True
 1121  model.dit.transformer_blocks.24.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1122  model.dit.transformer_blocks.24.ff.conv_inverted.bias                             torch.Size([5760])              True
 1123  model.dit.transformer_blocks.24.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1124  model.dit.transformer_blocks.24.ff.conv_depth.bias                                torch.Size([5760])              True
 1125  model.dit.transformer_blocks.24.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1126  model.dit.transformer_blocks.25.scale_shift_table                                 torch.Size([6, 1152])           True
 1127  model.dit.transformer_blocks.25.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1128  model.dit.transformer_blocks.25.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1129  model.dit.transformer_blocks.25.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1130  model.dit.transformer_blocks.25.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1131  model.dit.transformer_blocks.25.attn1.to_out.0.bias                               torch.Size([1152])              True
 1132  model.dit.transformer_blocks.25.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1133  model.dit.transformer_blocks.25.attn2.to_q.bias                                   torch.Size([1152])              True
 1134  model.dit.transformer_blocks.25.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1135  model.dit.transformer_blocks.25.attn2.to_k.bias                                   torch.Size([1152])              True
 1136  model.dit.transformer_blocks.25.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1137  model.dit.transformer_blocks.25.attn2.to_v.bias                                   torch.Size([1152])              True
 1138  model.dit.transformer_blocks.25.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1139  model.dit.transformer_blocks.25.attn2.to_out.0.bias                               torch.Size([1152])              True
 1140  model.dit.transformer_blocks.25.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1141  model.dit.transformer_blocks.25.ff.conv_inverted.bias                             torch.Size([5760])              True
 1142  model.dit.transformer_blocks.25.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1143  model.dit.transformer_blocks.25.ff.conv_depth.bias                                torch.Size([5760])              True
 1144  model.dit.transformer_blocks.25.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1145  model.dit.transformer_blocks.26.scale_shift_table                                 torch.Size([6, 1152])           True
 1146  model.dit.transformer_blocks.26.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1147  model.dit.transformer_blocks.26.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1148  model.dit.transformer_blocks.26.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1149  model.dit.transformer_blocks.26.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1150  model.dit.transformer_blocks.26.attn1.to_out.0.bias                               torch.Size([1152])              True
 1151  model.dit.transformer_blocks.26.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1152  model.dit.transformer_blocks.26.attn2.to_q.bias                                   torch.Size([1152])              True
 1153  model.dit.transformer_blocks.26.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1154  model.dit.transformer_blocks.26.attn2.to_k.bias                                   torch.Size([1152])              True
 1155  model.dit.transformer_blocks.26.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1156  model.dit.transformer_blocks.26.attn2.to_v.bias                                   torch.Size([1152])              True
 1157  model.dit.transformer_blocks.26.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1158  model.dit.transformer_blocks.26.attn2.to_out.0.bias                               torch.Size([1152])              True
 1159  model.dit.transformer_blocks.26.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1160  model.dit.transformer_blocks.26.ff.conv_inverted.bias                             torch.Size([5760])              True
 1161  model.dit.transformer_blocks.26.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1162  model.dit.transformer_blocks.26.ff.conv_depth.bias                                torch.Size([5760])              True
 1163  model.dit.transformer_blocks.26.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1164  model.dit.transformer_blocks.27.scale_shift_table                                 torch.Size([6, 1152])           True
 1165  model.dit.transformer_blocks.27.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1166  model.dit.transformer_blocks.27.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1167  model.dit.transformer_blocks.27.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1168  model.dit.transformer_blocks.27.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1169  model.dit.transformer_blocks.27.attn1.to_out.0.bias                               torch.Size([1152])              True
 1170  model.dit.transformer_blocks.27.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1171  model.dit.transformer_blocks.27.attn2.to_q.bias                                   torch.Size([1152])              True
 1172  model.dit.transformer_blocks.27.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1173  model.dit.transformer_blocks.27.attn2.to_k.bias                                   torch.Size([1152])              True
 1174  model.dit.transformer_blocks.27.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1175  model.dit.transformer_blocks.27.attn2.to_v.bias                                   torch.Size([1152])              True
 1176  model.dit.transformer_blocks.27.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1177  model.dit.transformer_blocks.27.attn2.to_out.0.bias                               torch.Size([1152])              True
 1178  model.dit.transformer_blocks.27.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1179  model.dit.transformer_blocks.27.ff.conv_inverted.bias                             torch.Size([5760])              True
 1180  model.dit.transformer_blocks.27.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1181  model.dit.transformer_blocks.27.ff.conv_depth.bias                                torch.Size([5760])              True
 1182  model.dit.transformer_blocks.27.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1183  model.dit.proj_out.weight                                                         torch.Size([32, 1152])          True
 1184  model.dit.proj_out.bias                                                           torch.Size([32])                True
 1185  model.vae_decoder.decoder.conv_in.weight                                          torch.Size([1024, 32, 3, 3])    False
 1186  model.vae_decoder.decoder.conv_in.bias                                            torch.Size([1024])              False
 1187  model.vae_decoder.decoder.up_blocks.0.0.conv.weight                               torch.Size([128, 256, 3, 3])    False
 1188  model.vae_decoder.decoder.up_blocks.0.0.conv.bias                                 torch.Size([128])               False
 1189  model.vae_decoder.decoder.up_blocks.0.1.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1190  model.vae_decoder.decoder.up_blocks.0.1.conv1.bias                                torch.Size([128])               False
 1191  model.vae_decoder.decoder.up_blocks.0.1.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1192  model.vae_decoder.decoder.up_blocks.0.1.norm.weight                               torch.Size([128])               False
 1193  model.vae_decoder.decoder.up_blocks.0.1.norm.bias                                 torch.Size([128])               False
 1194  model.vae_decoder.decoder.up_blocks.0.2.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1195  model.vae_decoder.decoder.up_blocks.0.2.conv1.bias                                torch.Size([128])               False
 1196  model.vae_decoder.decoder.up_blocks.0.2.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1197  model.vae_decoder.decoder.up_blocks.0.2.norm.weight                               torch.Size([128])               False
 1198  model.vae_decoder.decoder.up_blocks.0.2.norm.bias                                 torch.Size([128])               False
 1199  model.vae_decoder.decoder.up_blocks.0.3.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1200  model.vae_decoder.decoder.up_blocks.0.3.conv1.bias                                torch.Size([128])               False
 1201  model.vae_decoder.decoder.up_blocks.0.3.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1202  model.vae_decoder.decoder.up_blocks.0.3.norm.weight                               torch.Size([128])               False
 1203  model.vae_decoder.decoder.up_blocks.0.3.norm.bias                                 torch.Size([128])               False
 1204  model.vae_decoder.decoder.up_blocks.1.0.conv.weight                               torch.Size([256, 512, 3, 3])    False
 1205  model.vae_decoder.decoder.up_blocks.1.0.conv.bias                                 torch.Size([256])               False
 1206  model.vae_decoder.decoder.up_blocks.1.1.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1207  model.vae_decoder.decoder.up_blocks.1.1.conv1.bias                                torch.Size([256])               False
 1208  model.vae_decoder.decoder.up_blocks.1.1.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1209  model.vae_decoder.decoder.up_blocks.1.1.norm.weight                               torch.Size([256])               False
 1210  model.vae_decoder.decoder.up_blocks.1.1.norm.bias                                 torch.Size([256])               False
 1211  model.vae_decoder.decoder.up_blocks.1.2.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1212  model.vae_decoder.decoder.up_blocks.1.2.conv1.bias                                torch.Size([256])               False
 1213  model.vae_decoder.decoder.up_blocks.1.2.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1214  model.vae_decoder.decoder.up_blocks.1.2.norm.weight                               torch.Size([256])               False
 1215  model.vae_decoder.decoder.up_blocks.1.2.norm.bias                                 torch.Size([256])               False
 1216  model.vae_decoder.decoder.up_blocks.1.3.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1217  model.vae_decoder.decoder.up_blocks.1.3.conv1.bias                                torch.Size([256])               False
 1218  model.vae_decoder.decoder.up_blocks.1.3.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1219  model.vae_decoder.decoder.up_blocks.1.3.norm.weight                               torch.Size([256])               False
 1220  model.vae_decoder.decoder.up_blocks.1.3.norm.bias                                 torch.Size([256])               False
 1221  model.vae_decoder.decoder.up_blocks.2.0.conv.weight                               torch.Size([512, 512, 3, 3])    False
 1222  model.vae_decoder.decoder.up_blocks.2.0.conv.bias                                 torch.Size([512])               False
 1223  model.vae_decoder.decoder.up_blocks.2.1.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1224  model.vae_decoder.decoder.up_blocks.2.1.conv1.bias                                torch.Size([512])               False
 1225  model.vae_decoder.decoder.up_blocks.2.1.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1226  model.vae_decoder.decoder.up_blocks.2.1.norm.weight                               torch.Size([512])               False
 1227  model.vae_decoder.decoder.up_blocks.2.1.norm.bias                                 torch.Size([512])               False
 1228  model.vae_decoder.decoder.up_blocks.2.2.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1229  model.vae_decoder.decoder.up_blocks.2.2.conv1.bias                                torch.Size([512])               False
 1230  model.vae_decoder.decoder.up_blocks.2.2.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1231  model.vae_decoder.decoder.up_blocks.2.2.norm.weight                               torch.Size([512])               False
 1232  model.vae_decoder.decoder.up_blocks.2.2.norm.bias                                 torch.Size([512])               False
 1233  model.vae_decoder.decoder.up_blocks.2.3.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1234  model.vae_decoder.decoder.up_blocks.2.3.conv1.bias                                torch.Size([512])               False
 1235  model.vae_decoder.decoder.up_blocks.2.3.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1236  model.vae_decoder.decoder.up_blocks.2.3.norm.weight                               torch.Size([512])               False
 1237  model.vae_decoder.decoder.up_blocks.2.3.norm.bias                                 torch.Size([512])               False
 1238  model.vae_decoder.decoder.up_blocks.3.0.conv.weight                               torch.Size([512, 1024, 3, 3])   False
 1239  model.vae_decoder.decoder.up_blocks.3.0.conv.bias                                 torch.Size([512])               False
 1240  model.vae_decoder.decoder.up_blocks.3.1.attn.to_q.weight                          torch.Size([512, 512])          False
 1241  model.vae_decoder.decoder.up_blocks.3.1.attn.to_k.weight                          torch.Size([512, 512])          False
 1242  model.vae_decoder.decoder.up_blocks.3.1.attn.to_v.weight                          torch.Size([512, 512])          False
 1243  model.vae_decoder.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1244  model.vae_decoder.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1245  model.vae_decoder.decoder.up_blocks.3.1.attn.to_out.weight                        torch.Size([512, 1024])         False
 1246  model.vae_decoder.decoder.up_blocks.3.1.attn.norm_out.weight                      torch.Size([512])               False
 1247  model.vae_decoder.decoder.up_blocks.3.1.attn.norm_out.bias                        torch.Size([512])               False
 1248  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1249  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1250  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1251  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1252  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1253  model.vae_decoder.decoder.up_blocks.3.1.conv_out.norm.weight                      torch.Size([512])               False
 1254  model.vae_decoder.decoder.up_blocks.3.1.conv_out.norm.bias                        torch.Size([512])               False
 1255  model.vae_decoder.decoder.up_blocks.3.2.attn.to_q.weight                          torch.Size([512, 512])          False
 1256  model.vae_decoder.decoder.up_blocks.3.2.attn.to_k.weight                          torch.Size([512, 512])          False
 1257  model.vae_decoder.decoder.up_blocks.3.2.attn.to_v.weight                          torch.Size([512, 512])          False
 1258  model.vae_decoder.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1259  model.vae_decoder.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1260  model.vae_decoder.decoder.up_blocks.3.2.attn.to_out.weight                        torch.Size([512, 1024])         False
 1261  model.vae_decoder.decoder.up_blocks.3.2.attn.norm_out.weight                      torch.Size([512])               False
 1262  model.vae_decoder.decoder.up_blocks.3.2.attn.norm_out.bias                        torch.Size([512])               False
 1263  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1264  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1265  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1266  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1267  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1268  model.vae_decoder.decoder.up_blocks.3.2.conv_out.norm.weight                      torch.Size([512])               False
 1269  model.vae_decoder.decoder.up_blocks.3.2.conv_out.norm.bias                        torch.Size([512])               False
 1270  model.vae_decoder.decoder.up_blocks.3.3.attn.to_q.weight                          torch.Size([512, 512])          False
 1271  model.vae_decoder.decoder.up_blocks.3.3.attn.to_k.weight                          torch.Size([512, 512])          False
 1272  model.vae_decoder.decoder.up_blocks.3.3.attn.to_v.weight                          torch.Size([512, 512])          False
 1273  model.vae_decoder.decoder.up_blocks.3.3.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1274  model.vae_decoder.decoder.up_blocks.3.3.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1275  model.vae_decoder.decoder.up_blocks.3.3.attn.to_out.weight                        torch.Size([512, 1024])         False
 1276  model.vae_decoder.decoder.up_blocks.3.3.attn.norm_out.weight                      torch.Size([512])               False
 1277  model.vae_decoder.decoder.up_blocks.3.3.attn.norm_out.bias                        torch.Size([512])               False
 1278  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1279  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1280  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1281  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1282  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1283  model.vae_decoder.decoder.up_blocks.3.3.conv_out.norm.weight                      torch.Size([512])               False
 1284  model.vae_decoder.decoder.up_blocks.3.3.conv_out.norm.bias                        torch.Size([512])               False
 1285  model.vae_decoder.decoder.up_blocks.4.0.conv.weight                               torch.Size([1024, 1024, 3, 3])  False
 1286  model.vae_decoder.decoder.up_blocks.4.0.conv.bias                                 torch.Size([1024])              False
 1287  model.vae_decoder.decoder.up_blocks.4.1.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1288  model.vae_decoder.decoder.up_blocks.4.1.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1289  model.vae_decoder.decoder.up_blocks.4.1.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1290  model.vae_decoder.decoder.up_blocks.4.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1291  model.vae_decoder.decoder.up_blocks.4.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1292  model.vae_decoder.decoder.up_blocks.4.1.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1293  model.vae_decoder.decoder.up_blocks.4.1.attn.norm_out.weight                      torch.Size([1024])              False
 1294  model.vae_decoder.decoder.up_blocks.4.1.attn.norm_out.bias                        torch.Size([1024])              False
 1295  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1296  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1297  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1298  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1299  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1300  model.vae_decoder.decoder.up_blocks.4.1.conv_out.norm.weight                      torch.Size([1024])              False
 1301  model.vae_decoder.decoder.up_blocks.4.1.conv_out.norm.bias                        torch.Size([1024])              False
 1302  model.vae_decoder.decoder.up_blocks.4.2.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1303  model.vae_decoder.decoder.up_blocks.4.2.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1304  model.vae_decoder.decoder.up_blocks.4.2.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1305  model.vae_decoder.decoder.up_blocks.4.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1306  model.vae_decoder.decoder.up_blocks.4.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1307  model.vae_decoder.decoder.up_blocks.4.2.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1308  model.vae_decoder.decoder.up_blocks.4.2.attn.norm_out.weight                      torch.Size([1024])              False
 1309  model.vae_decoder.decoder.up_blocks.4.2.attn.norm_out.bias                        torch.Size([1024])              False
 1310  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1311  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1312  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1313  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1314  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1315  model.vae_decoder.decoder.up_blocks.4.2.conv_out.norm.weight                      torch.Size([1024])              False
 1316  model.vae_decoder.decoder.up_blocks.4.2.conv_out.norm.bias                        torch.Size([1024])              False
 1317  model.vae_decoder.decoder.up_blocks.4.3.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1318  model.vae_decoder.decoder.up_blocks.4.3.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1319  model.vae_decoder.decoder.up_blocks.4.3.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1320  model.vae_decoder.decoder.up_blocks.4.3.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1321  model.vae_decoder.decoder.up_blocks.4.3.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1322  model.vae_decoder.decoder.up_blocks.4.3.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1323  model.vae_decoder.decoder.up_blocks.4.3.attn.norm_out.weight                      torch.Size([1024])              False
 1324  model.vae_decoder.decoder.up_blocks.4.3.attn.norm_out.bias                        torch.Size([1024])              False
 1325  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1326  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1327  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1328  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1329  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1330  model.vae_decoder.decoder.up_blocks.4.3.conv_out.norm.weight                      torch.Size([1024])              False
 1331  model.vae_decoder.decoder.up_blocks.4.3.conv_out.norm.bias                        torch.Size([1024])              False
 1332  model.vae_decoder.decoder.up_blocks.5.0.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1333  model.vae_decoder.decoder.up_blocks.5.0.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1334  model.vae_decoder.decoder.up_blocks.5.0.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1335  model.vae_decoder.decoder.up_blocks.5.0.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1336  model.vae_decoder.decoder.up_blocks.5.0.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1337  model.vae_decoder.decoder.up_blocks.5.0.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1338  model.vae_decoder.decoder.up_blocks.5.0.attn.norm_out.weight                      torch.Size([1024])              False
 1339  model.vae_decoder.decoder.up_blocks.5.0.attn.norm_out.bias                        torch.Size([1024])              False
 1340  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1341  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1342  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1343  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1344  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1345  model.vae_decoder.decoder.up_blocks.5.0.conv_out.norm.weight                      torch.Size([1024])              False
 1346  model.vae_decoder.decoder.up_blocks.5.0.conv_out.norm.bias                        torch.Size([1024])              False
 1347  model.vae_decoder.decoder.up_blocks.5.1.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1348  model.vae_decoder.decoder.up_blocks.5.1.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1349  model.vae_decoder.decoder.up_blocks.5.1.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1350  model.vae_decoder.decoder.up_blocks.5.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1351  model.vae_decoder.decoder.up_blocks.5.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1352  model.vae_decoder.decoder.up_blocks.5.1.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1353  model.vae_decoder.decoder.up_blocks.5.1.attn.norm_out.weight                      torch.Size([1024])              False
 1354  model.vae_decoder.decoder.up_blocks.5.1.attn.norm_out.bias                        torch.Size([1024])              False
 1355  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1356  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1357  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1358  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1359  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1360  model.vae_decoder.decoder.up_blocks.5.1.conv_out.norm.weight                      torch.Size([1024])              False
 1361  model.vae_decoder.decoder.up_blocks.5.1.conv_out.norm.bias                        torch.Size([1024])              False
 1362  model.vae_decoder.decoder.up_blocks.5.2.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1363  model.vae_decoder.decoder.up_blocks.5.2.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1364  model.vae_decoder.decoder.up_blocks.5.2.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1365  model.vae_decoder.decoder.up_blocks.5.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1366  model.vae_decoder.decoder.up_blocks.5.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1367  model.vae_decoder.decoder.up_blocks.5.2.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1368  model.vae_decoder.decoder.up_blocks.5.2.attn.norm_out.weight                      torch.Size([1024])              False
 1369  model.vae_decoder.decoder.up_blocks.5.2.attn.norm_out.bias                        torch.Size([1024])              False
 1370  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1371  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1372  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1373  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1374  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1375  model.vae_decoder.decoder.up_blocks.5.2.conv_out.norm.weight                      torch.Size([1024])              False
 1376  model.vae_decoder.decoder.up_blocks.5.2.conv_out.norm.bias                        torch.Size([1024])              False
 1377  model.vae_decoder.decoder.norm_out.weight                                         torch.Size([128])               False
 1378  model.vae_decoder.decoder.norm_out.bias                                           torch.Size([128])               False
 1379  model.vae_decoder.decoder.conv_out.weight                                         torch.Size([3, 128, 3, 3])      False
 1380  model.vae_decoder.decoder.conv_out.bias                                           torch.Size([3])                 False
 1381  model.vae_decoder.down_blocks.0.mlp.0.weight                                      torch.Size([896])               False
 1382  model.vae_decoder.down_blocks.0.mlp.0.bias                                        torch.Size([896])               False
 1383  model.vae_decoder.down_blocks.0.mlp.1.weight                                      torch.Size([896, 896])          False
 1384  model.vae_decoder.down_blocks.0.mlp.1.bias                                        torch.Size([896])               False
 1385  model.vae_decoder.down_blocks.0.mlp.3.weight                                      torch.Size([896, 896])          False
 1386  model.vae_decoder.down_blocks.0.mlp.3.bias                                        torch.Size([896])               False
 1387  model.vae_decoder.down_blocks.1.mlp.0.weight                                      torch.Size([896])               False
 1388  model.vae_decoder.down_blocks.1.mlp.0.bias                                        torch.Size([896])               False
 1389  model.vae_decoder.down_blocks.1.mlp.1.weight                                      torch.Size([896, 896])          False
 1390  model.vae_decoder.down_blocks.1.mlp.1.bias                                        torch.Size([896])               False
 1391  model.vae_decoder.down_blocks.1.mlp.3.weight                                      torch.Size([896, 896])          False
 1392  model.vae_decoder.down_blocks.1.mlp.3.bias                                        torch.Size([896])               False
 1393  model.vae_decoder.down_blocks.2.mlp.0.weight                                      torch.Size([896])               False
 1394  model.vae_decoder.down_blocks.2.mlp.0.bias                                        torch.Size([896])               False
 1395  model.vae_decoder.down_blocks.2.mlp.1.weight                                      torch.Size([896, 896])          False
 1396  model.vae_decoder.down_blocks.2.mlp.1.bias                                        torch.Size([896])               False
 1397  model.vae_decoder.down_blocks.2.mlp.3.weight                                      torch.Size([896, 896])          False
 1398  model.vae_decoder.down_blocks.2.mlp.3.bias                                        torch.Size([896])               False
 1399  model.vae_decoder.down_mlp.0.weight                                               torch.Size([896])               False
 1400  model.vae_decoder.down_mlp.0.bias                                                 torch.Size([896])               False
 1401  model.vae_decoder.down_mlp.1.weight                                               torch.Size([32, 896])           False
 1402  model.vae_decoder.down_mlp.1.bias                                                 torch.Size([32])                False
 1403  model.vae_decoder.down_mlp.3.weight                                               torch.Size([32, 32])            False
 1404  model.vae_decoder.down_mlp.3.bias                                                 torch.Size([32])                False
 1405  model.llm_connector.layers.0.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1406  model.llm_connector.layers.0.self_attn.q_proj.bias                                torch.Size([896])               True
 1407  model.llm_connector.layers.0.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1408  model.llm_connector.layers.0.self_attn.k_proj.bias                                torch.Size([128])               True
 1409  model.llm_connector.layers.0.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1410  model.llm_connector.layers.0.self_attn.v_proj.bias                                torch.Size([128])               True
 1411  model.llm_connector.layers.0.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1412  model.llm_connector.layers.0.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1413  model.llm_connector.layers.0.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1414  model.llm_connector.layers.0.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1415  model.llm_connector.layers.0.input_layernorm.weight                               torch.Size([896])               True
 1416  model.llm_connector.layers.0.post_attention_layernorm.weight                      torch.Size([896])               True
 1417  model.llm_connector.layers.1.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1418  model.llm_connector.layers.1.self_attn.q_proj.bias                                torch.Size([896])               True
 1419  model.llm_connector.layers.1.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1420  model.llm_connector.layers.1.self_attn.k_proj.bias                                torch.Size([128])               True
 1421  model.llm_connector.layers.1.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1422  model.llm_connector.layers.1.self_attn.v_proj.bias                                torch.Size([128])               True
 1423  model.llm_connector.layers.1.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1424  model.llm_connector.layers.1.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1425  model.llm_connector.layers.1.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1426  model.llm_connector.layers.1.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1427  model.llm_connector.layers.1.input_layernorm.weight                               torch.Size([896])               True
 1428  model.llm_connector.layers.1.post_attention_layernorm.weight                      torch.Size([896])               True
 1429  model.llm_connector.layers.2.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1430  model.llm_connector.layers.2.self_attn.q_proj.bias                                torch.Size([896])               True
 1431  model.llm_connector.layers.2.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1432  model.llm_connector.layers.2.self_attn.k_proj.bias                                torch.Size([128])               True
 1433  model.llm_connector.layers.2.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1434  model.llm_connector.layers.2.self_attn.v_proj.bias                                torch.Size([128])               True
 1435  model.llm_connector.layers.2.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1436  model.llm_connector.layers.2.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1437  model.llm_connector.layers.2.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1438  model.llm_connector.layers.2.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1439  model.llm_connector.layers.2.input_layernorm.weight                               torch.Size([896])               True
 1440  model.llm_connector.layers.2.post_attention_layernorm.weight                      torch.Size([896])               True
 1441  model.llm_connector.layers.3.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1442  model.llm_connector.layers.3.self_attn.q_proj.bias                                torch.Size([896])               True
 1443  model.llm_connector.layers.3.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1444  model.llm_connector.layers.3.self_attn.k_proj.bias                                torch.Size([128])               True
 1445  model.llm_connector.layers.3.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1446  model.llm_connector.layers.3.self_attn.v_proj.bias                                torch.Size([128])               True
 1447  model.llm_connector.layers.3.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1448  model.llm_connector.layers.3.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1449  model.llm_connector.layers.3.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1450  model.llm_connector.layers.3.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1451  model.llm_connector.layers.3.input_layernorm.weight                               torch.Size([896])               True
 1452  model.llm_connector.layers.3.post_attention_layernorm.weight                      torch.Size([896])               True
 1453  model.llm_connector.layers.4.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1454  model.llm_connector.layers.4.self_attn.q_proj.bias                                torch.Size([896])               True
 1455  model.llm_connector.layers.4.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1456  model.llm_connector.layers.4.self_attn.k_proj.bias                                torch.Size([128])               True
 1457  model.llm_connector.layers.4.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1458  model.llm_connector.layers.4.self_attn.v_proj.bias                                torch.Size([128])               True
 1459  model.llm_connector.layers.4.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1460  model.llm_connector.layers.4.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1461  model.llm_connector.layers.4.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1462  model.llm_connector.layers.4.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1463  model.llm_connector.layers.4.input_layernorm.weight                               torch.Size([896])               True
 1464  model.llm_connector.layers.4.post_attention_layernorm.weight                      torch.Size([896])               True
 1465  model.llm_connector.layers.5.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1466  model.llm_connector.layers.5.self_attn.q_proj.bias                                torch.Size([896])               True
 1467  model.llm_connector.layers.5.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1468  model.llm_connector.layers.5.self_attn.k_proj.bias                                torch.Size([128])               True
 1469  model.llm_connector.layers.5.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1470  model.llm_connector.layers.5.self_attn.v_proj.bias                                torch.Size([128])               True
 1471  model.llm_connector.layers.5.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1472  model.llm_connector.layers.5.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1473  model.llm_connector.layers.5.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1474  model.llm_connector.layers.5.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1475  model.llm_connector.layers.5.input_layernorm.weight                               torch.Size([896])               True
 1476  model.llm_connector.layers.5.post_attention_layernorm.weight                      torch.Size([896])               True
 1477  model.llm_connector.norm.weight                                                   torch.Size([896])               True
 1478  model.projector.weight                                                            torch.Size([2304, 896])         True
 1479  model.projector.bias                                                              torch.Size([2304])              True
 1480  model.action_dit.layers.0.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1481  model.action_dit.layers.0.self_attn.q_proj.bias                                   torch.Size([896])               True
 1482  model.action_dit.layers.0.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1483  model.action_dit.layers.0.self_attn.k_proj.bias                                   torch.Size([128])               True
 1484  model.action_dit.layers.0.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1485  model.action_dit.layers.0.self_attn.v_proj.bias                                   torch.Size([128])               True
 1486  model.action_dit.layers.0.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1487  model.action_dit.layers.0.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1488  model.action_dit.layers.0.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1489  model.action_dit.layers.0.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1490  model.action_dit.layers.0.input_layernorm.weight                                  torch.Size([896])               True
 1491  model.action_dit.layers.0.post_attention_layernorm.weight                         torch.Size([896])               True
 1492  model.action_dit.layers.1.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1493  model.action_dit.layers.1.self_attn.q_proj.bias                                   torch.Size([896])               True
 1494  model.action_dit.layers.1.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1495  model.action_dit.layers.1.self_attn.k_proj.bias                                   torch.Size([128])               True
 1496  model.action_dit.layers.1.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1497  model.action_dit.layers.1.self_attn.v_proj.bias                                   torch.Size([128])               True
 1498  model.action_dit.layers.1.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1499  model.action_dit.layers.1.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1500  model.action_dit.layers.1.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1501  model.action_dit.layers.1.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1502  model.action_dit.layers.1.input_layernorm.weight                                  torch.Size([896])               True
 1503  model.action_dit.layers.1.post_attention_layernorm.weight                         torch.Size([896])               True
 1504  model.action_dit.layers.2.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1505  model.action_dit.layers.2.self_attn.q_proj.bias                                   torch.Size([896])               True
 1506  model.action_dit.layers.2.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1507  model.action_dit.layers.2.self_attn.k_proj.bias                                   torch.Size([128])               True
 1508  model.action_dit.layers.2.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1509  model.action_dit.layers.2.self_attn.v_proj.bias                                   torch.Size([128])               True
 1510  model.action_dit.layers.2.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1511  model.action_dit.layers.2.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1512  model.action_dit.layers.2.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1513  model.action_dit.layers.2.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1514  model.action_dit.layers.2.input_layernorm.weight                                  torch.Size([896])               True
 1515  model.action_dit.layers.2.post_attention_layernorm.weight                         torch.Size([896])               True
 1516  model.action_dit.norm.weight                                                      torch.Size([896])               True
 1517  model.action_in_proj.weight                                                       torch.Size([896, 5])            True
 1518  model.action_in_proj.bias                                                         torch.Size([896])               True
 1519  model.time_mlp_in.weight                                                          torch.Size([896, 896])          True
 1520  model.time_mlp_in.bias                                                            torch.Size([896])               True
 1521  model.time_mlp_out.weight                                                         torch.Size([896, 896])          True
 1522  model.time_mlp_out.bias                                                           torch.Size([896])               True
 1523  model.action_out_proj.weight                                                      torch.Size([5, 896])            True
 1524  model.action_out_proj.bias                                                        torch.Size([5])                 True
 1525  lm_head.weight                                                                    torch.Size([151678, 896])       False - (2851716:train_csgo.py:1486)
2026-01-07 15:34:02 - INFO - total_loss: 8.016271591186523, masked_loc_loss: 7.361514568328857, masked_gen_loss: 0.6547572612762451 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:17 - INFO - total_loss: 9.722625732421875, masked_loc_loss: 9.213069915771484, masked_gen_loss: 0.5095553994178772 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:23 - INFO - total_loss: 7.696690082550049, masked_loc_loss: 7.052275657653809, masked_gen_loss: 0.6444143056869507 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:30 - INFO - total_loss: 6.830178260803223, masked_loc_loss: 6.1820173263549805, masked_gen_loss: 0.6481606960296631 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:42 - INFO - total_loss: 8.749103546142578, masked_loc_loss: 8.296618461608887, masked_gen_loss: 0.4524850845336914 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:49 - INFO - total_loss: 6.804914951324463, masked_loc_loss: 6.294888496398926, masked_gen_loss: 0.5100263357162476 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:01 - INFO - total_loss: 3.2083003520965576, masked_loc_loss: 2.593846559524536, masked_gen_loss: 0.6144537925720215 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:09 - INFO - total_loss: 2.7725884914398193, masked_loc_loss: 2.222085475921631, masked_gen_loss: 0.5505030155181885 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:21 - INFO - total_loss: 18.272518157958984, masked_loc_loss: 17.768247604370117, masked_gen_loss: 0.5042710304260254 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:27 - INFO - total_loss: 19.324588775634766, masked_loc_loss: 18.707304000854492, masked_gen_loss: 0.617285430431366 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:38 - INFO - total_loss: 17.88177490234375, masked_loc_loss: 17.31314468383789, masked_gen_loss: 0.5686293244361877 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:47 - INFO - total_loss: 39.53097152709961, masked_loc_loss: 39.037315368652344, masked_gen_loss: 0.4936579763889313 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:57 - INFO - total_loss: 40.92516326904297, masked_loc_loss: 40.44829559326172, masked_gen_loss: 0.47686630487442017 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:08 - INFO - total_loss: 29.910009384155273, masked_loc_loss: 29.375606536865234, masked_gen_loss: 0.53440260887146 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:19 - INFO - total_loss: 18.820985794067383, masked_loc_loss: 18.277297973632812, masked_gen_loss: 0.543688178062439 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:28 - INFO - total_loss: 9.599990844726562, masked_loc_loss: 9.05958366394043, masked_gen_loss: 0.5404070615768433 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:41 - INFO - total_loss: 4.315921783447266, masked_loc_loss: 3.8599987030029297, masked_gen_loss: 0.4559229016304016 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:50 - INFO - total_loss: 1.5126945972442627, masked_loc_loss: 1.0233421325683594, masked_gen_loss: 0.4893524646759033 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:03 - INFO - total_loss: 1.8733385801315308, masked_loc_loss: 1.3685787916183472, masked_gen_loss: 0.5047597885131836 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:13 - INFO - total_loss: 3.100478410720825, masked_loc_loss: 2.6367905139923096, masked_gen_loss: 0.4636879563331604 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:24 - INFO - total_loss: 3.171135187149048, masked_loc_loss: 2.7427608966827393, masked_gen_loss: 0.42837420105934143 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:36 - INFO - total_loss: 2.031878709793091, masked_loc_loss: 1.5450547933578491, masked_gen_loss: 0.4868238866329193 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:45 - INFO - total_loss: 1.1782290935516357, masked_loc_loss: 0.7576919198036194, masked_gen_loss: 0.42053720355033875 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:59 - INFO - total_loss: 1.06063711643219, masked_loc_loss: 0.6125694513320923, masked_gen_loss: 0.44806763529777527 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:09 - INFO - total_loss: 1.4384318590164185, masked_loc_loss: 0.9771848320960999, masked_gen_loss: 0.4612470269203186 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:20 - INFO - total_loss: 1.4708964824676514, masked_loc_loss: 1.0282992124557495, masked_gen_loss: 0.44259732961654663 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:32 - INFO - total_loss: 1.0785729885101318, masked_loc_loss: 0.6504788398742676, masked_gen_loss: 0.42809414863586426 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:42 - INFO - total_loss: 1.010493278503418, masked_loc_loss: 0.6176542639732361, masked_gen_loss: 0.39283907413482666 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:55 - INFO - total_loss: 1.2101881504058838, masked_loc_loss: 0.7878851890563965, masked_gen_loss: 0.42230290174484253 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:07 - INFO - total_loss: 1.0440510511398315, masked_loc_loss: 0.6329319477081299, masked_gen_loss: 0.41111910343170166 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:15 - INFO - total_loss: 1.0967867374420166, masked_loc_loss: 0.6997131109237671, masked_gen_loss: 0.3970736861228943 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:28 - INFO - total_loss: 0.972062885761261, masked_loc_loss: 0.5384132862091064, masked_gen_loss: 0.43364959955215454 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:38 - INFO - total_loss: 1.0658835172653198, masked_loc_loss: 0.669926643371582, masked_gen_loss: 0.3959568440914154 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:50 - INFO - total_loss: 0.9857978224754333, masked_loc_loss: 0.5629732608795166, masked_gen_loss: 0.42282456159591675 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:01 - INFO - total_loss: 1.1838369369506836, masked_loc_loss: 0.8660554885864258, masked_gen_loss: 0.3177814483642578 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:11 - INFO - total_loss: 1.0241844654083252, masked_loc_loss: 0.6367733478546143, masked_gen_loss: 0.38741111755371094 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:24 - INFO - total_loss: 0.9042630791664124, masked_loc_loss: 0.5108721852302551, masked_gen_loss: 0.3933908939361572 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:34 - INFO - total_loss: 0.980246901512146, masked_loc_loss: 0.6247038841247559, masked_gen_loss: 0.35554301738739014 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:45 - INFO - total_loss: 0.9187288880348206, masked_loc_loss: 0.4870193600654602, masked_gen_loss: 0.43170952796936035 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:57 - INFO - total_loss: 0.9796720743179321, masked_loc_loss: 0.6002588272094727, masked_gen_loss: 0.3794132471084595 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:06 - INFO - total_loss: 0.9314988851547241, masked_loc_loss: 0.5622368454933167, masked_gen_loss: 0.3692620098590851 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:19 - INFO - total_loss: 0.9968426823616028, masked_loc_loss: 0.6569497585296631, masked_gen_loss: 0.3398929238319397 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:29 - INFO - total_loss: 0.9527702927589417, masked_loc_loss: 0.6254793405532837, masked_gen_loss: 0.32729095220565796 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:40 - INFO - total_loss: 0.9816361665725708, masked_loc_loss: 0.5958126783370972, masked_gen_loss: 0.38582348823547363 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:52 - INFO - total_loss: 0.918677568435669, masked_loc_loss: 0.5497407913208008, masked_gen_loss: 0.36893677711486816 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:02 - INFO - total_loss: 0.8816906213760376, masked_loc_loss: 0.463595986366272, masked_gen_loss: 0.4180946350097656 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:15 - INFO - total_loss: 0.889488935470581, masked_loc_loss: 0.48919519782066345, masked_gen_loss: 0.4002937078475952 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:26 - INFO - total_loss: 0.9555476307868958, masked_loc_loss: 0.5440045595169067, masked_gen_loss: 0.411543071269989 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:36 - INFO - total_loss: 0.9566481709480286, masked_loc_loss: 0.5432437062263489, masked_gen_loss: 0.4134044647216797 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:48 - INFO - total_loss: 0.9589022397994995, masked_loc_loss: 0.536656379699707, masked_gen_loss: 0.42224588990211487 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:59 - INFO - total_loss: 1.0416765213012695, masked_loc_loss: 0.6308184266090393, masked_gen_loss: 0.4108580946922302 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:10 - INFO - total_loss: 0.929053544998169, masked_loc_loss: 0.5936538577079773, masked_gen_loss: 0.33539965748786926 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:17 - INFO - total_loss: 0.8553975820541382, masked_loc_loss: 0.4758182168006897, masked_gen_loss: 0.3795793354511261 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:24 - INFO - total_loss: 0.988168478012085, masked_loc_loss: 0.6427753567695618, masked_gen_loss: 0.3453930914402008 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:30 - INFO - total_loss: 0.9175273180007935, masked_loc_loss: 0.5296337604522705, masked_gen_loss: 0.38789352774620056 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:44 - INFO - total_loss: 0.8511490225791931, masked_loc_loss: 0.48346441984176636, masked_gen_loss: 0.36768460273742676 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:53 - INFO - total_loss: 0.8610892295837402, masked_loc_loss: 0.4727027714252472, masked_gen_loss: 0.38838648796081543 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:05 - INFO - total_loss: 0.8747653961181641, masked_loc_loss: 0.5386097431182861, masked_gen_loss: 0.3361556828022003 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:15 - INFO - total_loss: 0.8509731292724609, masked_loc_loss: 0.48420146107673645, masked_gen_loss: 0.3667716383934021 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:26 - INFO - total_loss: 0.8920724391937256, masked_loc_loss: 0.51666259765625, masked_gen_loss: 0.3754098117351532 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:37 - INFO - total_loss: 0.8575152158737183, masked_loc_loss: 0.4748331308364868, masked_gen_loss: 0.38268205523490906 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:47 - INFO - total_loss: 0.7901333570480347, masked_loc_loss: 0.38204678893089294, masked_gen_loss: 0.4080865979194641 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:58 - INFO - total_loss: 0.7802613973617554, masked_loc_loss: 0.3640895187854767, masked_gen_loss: 0.4161719083786011 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:08 - INFO - total_loss: 0.7698971033096313, masked_loc_loss: 0.4018065631389618, masked_gen_loss: 0.36809051036834717 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:22 - INFO - total_loss: 0.759792685508728, masked_loc_loss: 0.32827624678611755, masked_gen_loss: 0.43151646852493286 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:31 - INFO - total_loss: 0.7143786549568176, masked_loc_loss: 0.291808158159256, masked_gen_loss: 0.42257049679756165 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:43 - INFO - total_loss: 0.6745386123657227, masked_loc_loss: 0.27640169858932495, masked_gen_loss: 0.3981369137763977 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:56 - INFO - total_loss: 0.7365338802337646, masked_loc_loss: 0.3781032860279083, masked_gen_loss: 0.35843056440353394 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:07 - INFO - total_loss: 0.730156660079956, masked_loc_loss: 0.3594759702682495, masked_gen_loss: 0.37068068981170654 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:18 - INFO - total_loss: 0.7407436370849609, masked_loc_loss: 0.32750818133354187, masked_gen_loss: 0.41323548555374146 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:32 - INFO - total_loss: 0.6354633569717407, masked_loc_loss: 0.23147982358932495, masked_gen_loss: 0.4039835035800934 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:45 - INFO - total_loss: 0.6752666234970093, masked_loc_loss: 0.392080694437027, masked_gen_loss: 0.2831858992576599 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:57 - INFO - total_loss: 0.693514347076416, masked_loc_loss: 0.2680851221084595, masked_gen_loss: 0.42542925477027893 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:09 - INFO - total_loss: 0.6590217351913452, masked_loc_loss: 0.3462931215763092, masked_gen_loss: 0.3127285838127136 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:22 - INFO - total_loss: 0.5521767139434814, masked_loc_loss: 0.21239516139030457, masked_gen_loss: 0.33978158235549927 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:35 - INFO - total_loss: 0.6911600828170776, masked_loc_loss: 0.2944875955581665, masked_gen_loss: 0.39667248725891113 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:47 - INFO - total_loss: 0.675765335559845, masked_loc_loss: 0.2916218638420105, masked_gen_loss: 0.3841434717178345 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:00 - INFO - total_loss: 0.6079438924789429, masked_loc_loss: 0.18998101353645325, masked_gen_loss: 0.417962908744812 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:13 - INFO - total_loss: 0.5908324718475342, masked_loc_loss: 0.1433747410774231, masked_gen_loss: 0.4474577307701111 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:24 - INFO - total_loss: 0.6499042510986328, masked_loc_loss: 0.2126111090183258, masked_gen_loss: 0.4372931718826294 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:37 - INFO - total_loss: 0.5836480855941772, masked_loc_loss: 0.18972459435462952, masked_gen_loss: 0.3939235210418701 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:50 - INFO - total_loss: 0.5870954394340515, masked_loc_loss: 0.19486933946609497, masked_gen_loss: 0.39222609996795654 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:02 - INFO - total_loss: 0.585151195526123, masked_loc_loss: 0.1914023458957672, masked_gen_loss: 0.3937488794326782 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:14 - INFO - total_loss: 0.5701838731765747, masked_loc_loss: 0.2007368952035904, masked_gen_loss: 0.3694469928741455 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:27 - INFO - total_loss: 0.602001428604126, masked_loc_loss: 0.23115137219429016, masked_gen_loss: 0.3708500266075134 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:39 - INFO - total_loss: 0.572185218334198, masked_loc_loss: 0.19784751534461975, masked_gen_loss: 0.37433770298957825 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:51 - INFO - total_loss: 0.5220043659210205, masked_loc_loss: 0.1506148725748062, masked_gen_loss: 0.3713894784450531 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:02 - INFO - total_loss: 0.5679590106010437, masked_loc_loss: 0.17295849323272705, masked_gen_loss: 0.39500051736831665 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:14 - INFO - total_loss: 0.5851463079452515, masked_loc_loss: 0.17682477831840515, masked_gen_loss: 0.4083215594291687 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:25 - INFO - total_loss: 0.567401647567749, masked_loc_loss: 0.21764642000198364, masked_gen_loss: 0.3497552275657654 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:36 - INFO - total_loss: 0.5731192827224731, masked_loc_loss: 0.25171712040901184, masked_gen_loss: 0.3214021325111389 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:49 - INFO - total_loss: 0.5729994773864746, masked_loc_loss: 0.20901653170585632, masked_gen_loss: 0.3639829754829407 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:00 - INFO - total_loss: 0.5620468854904175, masked_loc_loss: 0.20256325602531433, masked_gen_loss: 0.35948359966278076 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:11 - INFO - total_loss: 0.5365746021270752, masked_loc_loss: 0.2019551396369934, masked_gen_loss: 0.3346194922924042 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:24 - INFO - total_loss: 0.5851313471794128, masked_loc_loss: 0.22318921983242035, masked_gen_loss: 0.3619421124458313 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:37 - INFO - total_loss: 0.580797553062439, masked_loc_loss: 0.17078396677970886, masked_gen_loss: 0.4100136160850525 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:47 - INFO - total_loss: 0.4825495779514313, masked_loc_loss: 0.1512508988380432, masked_gen_loss: 0.33129867911338806 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:59 - INFO - total_loss: 0.5877301692962646, masked_loc_loss: 0.25717127323150635, masked_gen_loss: 0.3305588960647583 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:11 - INFO - total_loss: 0.53230881690979, masked_loc_loss: 0.17125055193901062, masked_gen_loss: 0.3610582947731018 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:22 - INFO - total_loss: 0.5633912086486816, masked_loc_loss: 0.1442982256412506, masked_gen_loss: 0.4190930128097534 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:33 - INFO - total_loss: 0.5856370329856873, masked_loc_loss: 0.14292296767234802, masked_gen_loss: 0.44271406531333923 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:46 - INFO - total_loss: 0.5487132668495178, masked_loc_loss: 0.2312725931406021, masked_gen_loss: 0.3174406886100769 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:54 - INFO - total_loss: 0.5613369345664978, masked_loc_loss: 0.18468394875526428, masked_gen_loss: 0.3766529858112335 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:08 - INFO - total_loss: 0.5546656250953674, masked_loc_loss: 0.22184038162231445, masked_gen_loss: 0.332825243473053 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:19 - INFO - total_loss: 0.5997779965400696, masked_loc_loss: 0.15228696167469025, masked_gen_loss: 0.4474910497665405 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:30 - INFO - total_loss: 0.5649056434631348, masked_loc_loss: 0.11743810027837753, masked_gen_loss: 0.447467565536499 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:43 - INFO - total_loss: 0.583893895149231, masked_loc_loss: 0.15513744950294495, masked_gen_loss: 0.4287564754486084 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:55 - INFO - total_loss: 0.5411317348480225, masked_loc_loss: 0.17638921737670898, masked_gen_loss: 0.3647425174713135 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:06 - INFO - total_loss: 0.575588047504425, masked_loc_loss: 0.15518714487552643, masked_gen_loss: 0.4204009175300598 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:17 - INFO - total_loss: 0.573444128036499, masked_loc_loss: 0.190070241689682, masked_gen_loss: 0.38337385654449463 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:30 - INFO - total_loss: 0.5144233703613281, masked_loc_loss: 0.14437805116176605, masked_gen_loss: 0.37004533410072327 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:39 - INFO - total_loss: 0.5606657266616821, masked_loc_loss: 0.2181476652622223, masked_gen_loss: 0.34251806139945984 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:46 - INFO - total_loss: 0.589073121547699, masked_loc_loss: 0.27989912033081055, masked_gen_loss: 0.3091740012168884 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:52 - INFO - total_loss: 0.5858042240142822, masked_loc_loss: 0.19879913330078125, masked_gen_loss: 0.387005090713501 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:02 - INFO - total_loss: 0.625925600528717, masked_loc_loss: 0.23054926097393036, masked_gen_loss: 0.3953763246536255 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:14 - INFO - total_loss: 0.5995684862136841, masked_loc_loss: 0.1941753625869751, masked_gen_loss: 0.405393123626709 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:27 - INFO - total_loss: 0.5422455072402954, masked_loc_loss: 0.15603536367416382, masked_gen_loss: 0.386210173368454 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:40 - INFO - total_loss: 0.585620105266571, masked_loc_loss: 0.20430266857147217, masked_gen_loss: 0.3813174366950989 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:51 - INFO - total_loss: 0.5730152130126953, masked_loc_loss: 0.24628089368343353, masked_gen_loss: 0.326734334230423 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:04 - INFO - total_loss: 0.544284462928772, masked_loc_loss: 0.17755816876888275, masked_gen_loss: 0.3667263090610504 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:16 - INFO - total_loss: 0.470126748085022, masked_loc_loss: 0.17384690046310425, masked_gen_loss: 0.2962798476219177 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:27 - INFO - total_loss: 0.5407406091690063, masked_loc_loss: 0.19303055107593536, masked_gen_loss: 0.3477100729942322 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:39 - INFO - total_loss: 0.5263441205024719, masked_loc_loss: 0.17080850899219513, masked_gen_loss: 0.355535626411438 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:53 - INFO - total_loss: 0.5497598648071289, masked_loc_loss: 0.13837894797325134, masked_gen_loss: 0.4113808870315552 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:05 - INFO - total_loss: 0.5475261211395264, masked_loc_loss: 0.1553763747215271, masked_gen_loss: 0.3921497166156769 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:17 - INFO - total_loss: 0.5903117656707764, masked_loc_loss: 0.21922960877418518, masked_gen_loss: 0.3710821866989136 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:29 - INFO - total_loss: 0.5271329879760742, masked_loc_loss: 0.15434196591377258, masked_gen_loss: 0.37279099225997925 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:42 - INFO - total_loss: 0.528388500213623, masked_loc_loss: 0.15988153219223022, masked_gen_loss: 0.36850693821907043 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:55 - INFO - total_loss: 0.6256237030029297, masked_loc_loss: 0.24671334028244019, masked_gen_loss: 0.3789103329181671 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:06 - INFO - total_loss: 0.4641904830932617, masked_loc_loss: 0.17309188842773438, masked_gen_loss: 0.29109859466552734 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:18 - INFO - total_loss: 0.5281478762626648, masked_loc_loss: 0.17274807393550873, masked_gen_loss: 0.3553997874259949 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:30 - INFO - total_loss: 0.5523617267608643, masked_loc_loss: 0.16942539811134338, masked_gen_loss: 0.38293635845184326 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:43 - INFO - total_loss: 0.5171045064926147, masked_loc_loss: 0.12768298387527466, masked_gen_loss: 0.3894215226173401 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:53 - INFO - total_loss: 0.5007053017616272, masked_loc_loss: 0.13198509812355042, masked_gen_loss: 0.3687202036380768 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:05 - INFO - total_loss: 0.5372463464736938, masked_loc_loss: 0.15572723746299744, masked_gen_loss: 0.381519079208374 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:17 - INFO - total_loss: 0.5217506289482117, masked_loc_loss: 0.18655556440353394, masked_gen_loss: 0.33519506454467773 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:27 - INFO - total_loss: 0.5399538278579712, masked_loc_loss: 0.19302648305892944, masked_gen_loss: 0.34692734479904175 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:39 - INFO - total_loss: 0.5022497177124023, masked_loc_loss: 0.11649784445762634, masked_gen_loss: 0.3857519030570984 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:52 - INFO - total_loss: 0.5277716517448425, masked_loc_loss: 0.2127583622932434, masked_gen_loss: 0.3150132894515991 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:02 - INFO - total_loss: 0.47947412729263306, masked_loc_loss: 0.11375277489423752, masked_gen_loss: 0.36572134494781494 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:14 - INFO - total_loss: 0.5286718606948853, masked_loc_loss: 0.1553109884262085, masked_gen_loss: 0.37336087226867676 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:27 - INFO - total_loss: 0.48739001154899597, masked_loc_loss: 0.16257348656654358, masked_gen_loss: 0.3248165249824524 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:40 - INFO - total_loss: 0.5283247828483582, masked_loc_loss: 0.12835675477981567, masked_gen_loss: 0.3999680280685425 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:49 - INFO - total_loss: 0.49295729398727417, masked_loc_loss: 0.17276738584041595, masked_gen_loss: 0.320189893245697 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:56 - INFO - total_loss: 0.5477946996688843, masked_loc_loss: 0.18583035469055176, masked_gen_loss: 0.3619643449783325 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:02 - INFO - total_loss: 0.5009013414382935, masked_loc_loss: 0.13892433047294617, masked_gen_loss: 0.3619770109653473 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:09 - INFO - total_loss: 0.5042781233787537, masked_loc_loss: 0.13952279090881348, masked_gen_loss: 0.3647553324699402 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:15 - INFO - total_loss: 0.5337852835655212, masked_loc_loss: 0.13570386171340942, masked_gen_loss: 0.3980814218521118 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:22 - INFO - total_loss: 0.48446568846702576, masked_loc_loss: 0.1181158795952797, masked_gen_loss: 0.36634981632232666 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:28 - INFO - total_loss: 0.5536412000656128, masked_loc_loss: 0.15482285618782043, masked_gen_loss: 0.39881837368011475 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:35 - INFO - total_loss: 0.5886045694351196, masked_loc_loss: 0.2282428741455078, masked_gen_loss: 0.3603616952896118 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:41 - INFO - total_loss: 0.5588357448577881, masked_loc_loss: 0.1525830328464508, masked_gen_loss: 0.4062526822090149 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:48 - INFO - total_loss: 0.5710664987564087, masked_loc_loss: 0.144052654504776, masked_gen_loss: 0.4270138144493103 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:55 - INFO - total_loss: 0.5572311878204346, masked_loc_loss: 0.26325124502182007, masked_gen_loss: 0.2939799427986145 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:01 - INFO - total_loss: 0.5642334222793579, masked_loc_loss: 0.19979095458984375, masked_gen_loss: 0.36444249749183655 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:07 - INFO - total_loss: 0.5855553150177002, masked_loc_loss: 0.16679629683494568, masked_gen_loss: 0.41875898838043213 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:14 - INFO - total_loss: 0.6124187707901001, masked_loc_loss: 0.2188417911529541, masked_gen_loss: 0.3935769498348236 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:21 - INFO - total_loss: 0.5087532997131348, masked_loc_loss: 0.1941131055355072, masked_gen_loss: 0.31464019417762756 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:27 - INFO - total_loss: 0.5698677897453308, masked_loc_loss: 0.16280196607112885, masked_gen_loss: 0.40706583857536316 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:34 - INFO - total_loss: 0.5145767331123352, masked_loc_loss: 0.11891684681177139, masked_gen_loss: 0.3956598937511444 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:41 - INFO - total_loss: 0.5513286590576172, masked_loc_loss: 0.18707889318466187, masked_gen_loss: 0.3642497956752777 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:47 - INFO - total_loss: 0.6480720043182373, masked_loc_loss: 0.22367450594902039, masked_gen_loss: 0.42439746856689453 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:54 - INFO - total_loss: 0.5759050846099854, masked_loc_loss: 0.1938389241695404, masked_gen_loss: 0.38206613063812256 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:00 - INFO - total_loss: 0.5202974081039429, masked_loc_loss: 0.17072483897209167, masked_gen_loss: 0.3495725989341736 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:07 - INFO - total_loss: 0.5701712369918823, masked_loc_loss: 0.1883566677570343, masked_gen_loss: 0.3818145990371704 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:13 - INFO - total_loss: 0.5984981060028076, masked_loc_loss: 0.2790186107158661, masked_gen_loss: 0.3194795250892639 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:22 - INFO - total_loss: 0.5481686592102051, masked_loc_loss: 0.14582008123397827, masked_gen_loss: 0.4023485481739044 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:34 - INFO - total_loss: 0.5585312843322754, masked_loc_loss: 0.13224634528160095, masked_gen_loss: 0.4262849688529968 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:49 - INFO - total_loss: 0.5139871835708618, masked_loc_loss: 0.1563783884048462, masked_gen_loss: 0.3576087951660156 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:04 - INFO - total_loss: 0.550539493560791, masked_loc_loss: 0.1446644365787506, masked_gen_loss: 0.405875027179718 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:19 - INFO - total_loss: 0.5446695685386658, masked_loc_loss: 0.23828528821468353, masked_gen_loss: 0.30638426542282104 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:26 - INFO - total_loss: 0.5532515645027161, masked_loc_loss: 0.18610769510269165, masked_gen_loss: 0.3671438694000244 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:40 - INFO - total_loss: 0.5031219720840454, masked_loc_loss: 0.16370651125907898, masked_gen_loss: 0.3394154906272888 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:54 - INFO - total_loss: 0.5319768190383911, masked_loc_loss: 0.19479350745677948, masked_gen_loss: 0.33718329668045044 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:08 - INFO - total_loss: 0.49709030985832214, masked_loc_loss: 0.0930309072136879, masked_gen_loss: 0.40405941009521484 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:23 - INFO - total_loss: 0.516464352607727, masked_loc_loss: 0.16958695650100708, masked_gen_loss: 0.34687739610671997 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:30 - INFO - total_loss: 0.556049644947052, masked_loc_loss: 0.21189138293266296, masked_gen_loss: 0.34415826201438904 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:36 - INFO - total_loss: 0.5732380747795105, masked_loc_loss: 0.17146210372447968, masked_gen_loss: 0.40177595615386963 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:44 - INFO - total_loss: 0.491845965385437, masked_loc_loss: 0.16498875617980957, masked_gen_loss: 0.32685720920562744 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:59 - INFO - total_loss: 0.5532264709472656, masked_loc_loss: 0.18938520550727844, masked_gen_loss: 0.36384129524230957 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:13 - INFO - total_loss: 0.5719676613807678, masked_loc_loss: 0.13112539052963257, masked_gen_loss: 0.44084227085113525 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:28 - INFO - total_loss: 0.48255041241645813, masked_loc_loss: 0.09167853742837906, masked_gen_loss: 0.39087188243865967 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:40 - INFO - total_loss: 0.40261712670326233, masked_loc_loss: 0.10429232567548752, masked_gen_loss: 0.2983247935771942 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:47 - INFO - total_loss: 0.5276544690132141, masked_loc_loss: 0.12131219357252121, masked_gen_loss: 0.4063422977924347 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:57 - INFO - total_loss: 0.5556333065032959, masked_loc_loss: 0.16055791079998016, masked_gen_loss: 0.39507538080215454 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:08 - INFO - total_loss: 0.5113930702209473, masked_loc_loss: 0.14086781442165375, masked_gen_loss: 0.3705252707004547 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:19 - INFO - total_loss: 0.48269540071487427, masked_loc_loss: 0.14373713731765747, masked_gen_loss: 0.3389582633972168 - (2851716:unified_unilip.py:926)
