2026-01-07 15:31:49 - INFO - Loaded WandB API key from .wandb_api_key.txt - (2851716:train_csgo.py:1280)
2026-01-07 15:31:51 - INFO - model_args: ModelArguments(model_name_or_path='UniLIP-1B', version='internvl', freeze_backbone=True, tune_mm_mlp_adapter=False, vision_tower=None, gen_vision_tower=None, mm_vision_select_layer=-1, pretrain_mm_mlp_adapter=None, pretrain_gen_mlp_adapter=None, vision_tower_pretrained=None, mm_projector_type='linear', gen_projector_type='linear', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_patch_merge_type='flat', mm_vision_select_feature='patch', n_query=256, n_und_query=0, gen_pooling='all', unilip_path='', unilip_factor=10.6, weighting_scheme='logit_normal', fix_dit=False, fix_connect=False, fix_vit=True, fix_llm=True, connect_layer=6, mllm_path='', mllm_hf_path='OpenGVLab/InternVL3-1B-hf', vae_path='', dit_path='', action_dit_layer=3) - (2851716:train_csgo.py:1292)
2026-01-07 15:31:51 - INFO - data_args: DataArguments(csgo_config='csgo_configs/exp3.yaml', data_path=None, lazy_preprocess=True, is_multimodal=False, csgo_image_folder='data/preprocessed_data', shortcaption_image_folder=None, data_type='mix', image_aspect_ratio='square') - (2851716:train_csgo.py:1293)
2026-01-07 15:31:51 - INFO - training_args: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
bits=16,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=8,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=deepspeed_scripts/zero0.json,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
double_quant=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
freeze_mm_mlp_adapter=False,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
group_by_modality_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=outputs/csgo_1b/exp3/runs/Jan07_15-31-49_gpu-05,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=IntervalStrategy.STEPS,
lora_alpha=16,
lora_bias=none,
lora_dropout=0.05,
lora_enable=False,
lora_r=64,
lora_weight_path=,
lr_scheduler_kwargs={'min_lr': 1e-05},
lr_scheduler_type=SchedulerType.COSINE_WITH_MIN_LR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mm_projector_lr=None,
model_max_length=1024,
mp_parameters=,
mpt_attn_impl=triton,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=100.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=outputs/csgo_1b/exp3,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
pretrain_path=none,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
quant_type=nf4,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=5000,
save_strategy=SaveStrategy.STEPS,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.003,
warmup_steps=0,
weight_decay=0.0,
) - (2851716:train_csgo.py:1294)
2026-01-07 15:31:51 - INFO - csgo_config: {'debug': False, 'is_multi_task': True, 'data_dir': 'data/preprocessed_data', 'train_maps': ['de_dust2', 'de_nuke', 'de_ancient'], 'val_maps': ['de_dust2', 'de_nuke', 'de_ancient'], 'test_maps': ['de_dust2', 'de_nuke', 'de_ancient']} - (2851716:train_csgo.py:1295)
2026-01-07 15:31:52 - INFO - vision_select_layer: -1 - (2851716:configuration_internvl_chat.py:69)
2026-01-07 15:31:52 - INFO - ps_version: v2 - (2851716:configuration_internvl_chat.py:70)
2026-01-07 15:31:52 - INFO - min_dynamic_patch: 1 - (2851716:configuration_internvl_chat.py:71)
2026-01-07 15:31:52 - INFO - max_dynamic_patch: 12 - (2851716:configuration_internvl_chat.py:72)
2026-01-07 15:31:52 - INFO - vision_config is None. Initializing the InternVisionConfig with default values. - (2851716:configuration_internvl_chat.py:42)
2026-01-07 15:31:52 - INFO - llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`). - (2851716:configuration_internvl_chat.py:46)
2026-01-07 15:31:52 - INFO - vision_select_layer: -1 - (2851716:configuration_internvl_chat.py:69)
2026-01-07 15:31:52 - INFO - ps_version: v1 - (2851716:configuration_internvl_chat.py:70)
2026-01-07 15:31:52 - INFO - min_dynamic_patch: 1 - (2851716:configuration_internvl_chat.py:71)
2026-01-07 15:31:52 - INFO - max_dynamic_patch: 6 - (2851716:configuration_internvl_chat.py:72)
2026-01-07 15:31:52 - INFO - num_image_token: 256 - (2851716:modeling_internvl_chat.py:59)
2026-01-07 15:31:52 - INFO - ps_version: v2 - (2851716:modeling_internvl_chat.py:60)
2026-01-07 15:32:06 - INFO - Using conversation format: internvl - (2851716:train_csgo.py:1377)
2026-01-07 15:32:06 - INFO - fix connect False - (2851716:unified_unilip.py:183)
2026-01-07 15:32:06 - INFO - fix dit False - (2851716:unified_unilip.py:184)
2026-01-07 15:32:06 - INFO - unilip load from checkpoint!!! - (2851716:unified_unilip.py:251)
2026-01-07 15:32:06 - INFO - DiT load from checkpoint!!! - (2851716:unified_unilip.py:264)
2026-01-07 15:32:06 - INFO - Connector load from checkpoint!!! - (2851716:unified_unilip.py:285)
2026-01-07 15:32:06 - INFO - latent_queries load from checkpoint!!! - (2851716:unified_unilip.py:307)
2026-01-07 15:32:06 - INFO - Initializing Action Connector from OpenGVLab/InternVL3-1B-hf slice... - (2851716:unified_unilip.py:328)
2026-01-07 15:32:07 - INFO - Action DiT weights initialized successfully! - (2851716:unified_unilip.py:339)
2026-01-07 15:32:07 - INFO - Action VAE weights initialized successfully! - (2851716:unified_unilip.py:360)
2026-01-07 15:32:14 - INFO -      trainable params: model.latent_queries - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.patch_embed.proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.patch_embed.proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_1.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_1.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_2.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_2.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.linear.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.time_embed.linear.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_1.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_1.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_2.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_projection.linear_2.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.caption_norm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.scale_shift_table - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_q.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_q.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_k.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_k.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_v.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_v.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_out.0.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_out.0.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_inverted.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_inverted.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_depth.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_depth.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_point.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.proj_out.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.dit.proj_out.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.0.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.1.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.2.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.3.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.4.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.layers.5.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.llm_connector.norm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.projector.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.projector.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.0.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.1.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.q_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.q_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.k_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.k_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.v_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.v_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.o_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.gate_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.up_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.down_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.input_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.layers.2.post_attention_layernorm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_dit.norm.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_in_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_in_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_in.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_in.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_out.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.time_mlp_out.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_out_proj.weight - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO -      trainable params: model.action_out_proj.bias - (2851716:train_csgo.py:1422)
2026-01-07 15:32:14 - INFO - Total parameters: 1696253544 - (2851716:train_csgo.py:1424)
2026-01-07 15:32:14 - INFO - Trainable parameters: 729874469 - (2851716:train_csgo.py:1425)
2026-01-07 15:32:14 - INFO - trainable percent: 43.028619 % - (2851716:train_csgo.py:1426)
2026-01-07 15:32:14 - INFO -  Loading Multi-Task CS2 Dataset... - (2851716:unified_task_dataset.py:489)
2026-01-07 15:32:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_dust2/splits_20000_5000/train_split.json... - (2851716:unified_task_dataset.py:497)
2026-01-07 15:32:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_nuke/splits_20000_5000/train_split.json... - (2851716:unified_task_dataset.py:497)
2026-01-07 15:32:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_ancient/splits_20000_5000/train_split.json... - (2851716:unified_task_dataset.py:497)
2026-01-07 15:32:14 - INFO -  Total entries: 60000 - (2851716:unified_task_dataset.py:528)
2026-01-07 15:32:28 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -c /tmp/tmpe4z542uz/test.c -o /tmp/tmpe4z542uz/test.o - (2851716:spawn.py:77)
2026-01-07 15:32:28 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat /tmp/tmpe4z542uz/test.o -laio -o /tmp/tmpe4z542uz/a.out - (2851716:spawn.py:77)
2026-01-07 15:32:28 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -c /tmp/tmp9a9bgyly/test.c -o /tmp/tmp9a9bgyly/test.o - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat /tmp/tmp9a9bgyly/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp9a9bgyly/a.out - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -O2 -isystem /home/jiahao/miniconda3/envs/UniLIP/include -fPIC -c /tmp/tmpfs7_mcnw/test.c -o /tmp/tmpfs7_mcnw/test.o - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO - gcc -pthread -B /home/jiahao/miniconda3/envs/UniLIP/compiler_compat /tmp/tmpfs7_mcnw/test.o -laio -o /tmp/tmpfs7_mcnw/a.out - (2851716:spawn.py:77)
2026-01-07 15:32:29 - INFO -   idx  name                                                                              shape                           trainable
-----  --------------------------------------------------------------------------------  ------------------------------  -----------
    0  model.latent_queries                                                              torch.Size([1, 256, 896])       True
    1  model.vision_tower.embeddings.class_embedding                                     torch.Size([1, 1, 1024])        False
    2  model.vision_tower.embeddings.position_embedding                                  torch.Size([1, 1025, 1024])     False
    3  model.vision_tower.embeddings.patch_embedding.weight                              torch.Size([1024, 3, 14, 14])   False
    4  model.vision_tower.embeddings.patch_embedding.bias                                torch.Size([1024])              False
    5  model.vision_tower.encoder.layers.0.ls1                                           torch.Size([1024])              False
    6  model.vision_tower.encoder.layers.0.ls2                                           torch.Size([1024])              False
    7  model.vision_tower.encoder.layers.0.attn.qkv.weight                               torch.Size([3072, 1024])        False
    8  model.vision_tower.encoder.layers.0.attn.qkv.bias                                 torch.Size([3072])              False
    9  model.vision_tower.encoder.layers.0.attn.proj.weight                              torch.Size([1024, 1024])        False
   10  model.vision_tower.encoder.layers.0.attn.proj.bias                                torch.Size([1024])              False
   11  model.vision_tower.encoder.layers.0.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   12  model.vision_tower.encoder.layers.0.mlp.fc1.bias                                  torch.Size([4096])              False
   13  model.vision_tower.encoder.layers.0.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   14  model.vision_tower.encoder.layers.0.mlp.fc2.bias                                  torch.Size([1024])              False
   15  model.vision_tower.encoder.layers.0.norm1.weight                                  torch.Size([1024])              False
   16  model.vision_tower.encoder.layers.0.norm1.bias                                    torch.Size([1024])              False
   17  model.vision_tower.encoder.layers.0.norm2.weight                                  torch.Size([1024])              False
   18  model.vision_tower.encoder.layers.0.norm2.bias                                    torch.Size([1024])              False
   19  model.vision_tower.encoder.layers.1.ls1                                           torch.Size([1024])              False
   20  model.vision_tower.encoder.layers.1.ls2                                           torch.Size([1024])              False
   21  model.vision_tower.encoder.layers.1.attn.qkv.weight                               torch.Size([3072, 1024])        False
   22  model.vision_tower.encoder.layers.1.attn.qkv.bias                                 torch.Size([3072])              False
   23  model.vision_tower.encoder.layers.1.attn.proj.weight                              torch.Size([1024, 1024])        False
   24  model.vision_tower.encoder.layers.1.attn.proj.bias                                torch.Size([1024])              False
   25  model.vision_tower.encoder.layers.1.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   26  model.vision_tower.encoder.layers.1.mlp.fc1.bias                                  torch.Size([4096])              False
   27  model.vision_tower.encoder.layers.1.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   28  model.vision_tower.encoder.layers.1.mlp.fc2.bias                                  torch.Size([1024])              False
   29  model.vision_tower.encoder.layers.1.norm1.weight                                  torch.Size([1024])              False
   30  model.vision_tower.encoder.layers.1.norm1.bias                                    torch.Size([1024])              False
   31  model.vision_tower.encoder.layers.1.norm2.weight                                  torch.Size([1024])              False
   32  model.vision_tower.encoder.layers.1.norm2.bias                                    torch.Size([1024])              False
   33  model.vision_tower.encoder.layers.2.ls1                                           torch.Size([1024])              False
   34  model.vision_tower.encoder.layers.2.ls2                                           torch.Size([1024])              False
   35  model.vision_tower.encoder.layers.2.attn.qkv.weight                               torch.Size([3072, 1024])        False
   36  model.vision_tower.encoder.layers.2.attn.qkv.bias                                 torch.Size([3072])              False
   37  model.vision_tower.encoder.layers.2.attn.proj.weight                              torch.Size([1024, 1024])        False
   38  model.vision_tower.encoder.layers.2.attn.proj.bias                                torch.Size([1024])              False
   39  model.vision_tower.encoder.layers.2.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   40  model.vision_tower.encoder.layers.2.mlp.fc1.bias                                  torch.Size([4096])              False
   41  model.vision_tower.encoder.layers.2.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   42  model.vision_tower.encoder.layers.2.mlp.fc2.bias                                  torch.Size([1024])              False
   43  model.vision_tower.encoder.layers.2.norm1.weight                                  torch.Size([1024])              False
   44  model.vision_tower.encoder.layers.2.norm1.bias                                    torch.Size([1024])              False
   45  model.vision_tower.encoder.layers.2.norm2.weight                                  torch.Size([1024])              False
   46  model.vision_tower.encoder.layers.2.norm2.bias                                    torch.Size([1024])              False
   47  model.vision_tower.encoder.layers.3.ls1                                           torch.Size([1024])              False
   48  model.vision_tower.encoder.layers.3.ls2                                           torch.Size([1024])              False
   49  model.vision_tower.encoder.layers.3.attn.qkv.weight                               torch.Size([3072, 1024])        False
   50  model.vision_tower.encoder.layers.3.attn.qkv.bias                                 torch.Size([3072])              False
   51  model.vision_tower.encoder.layers.3.attn.proj.weight                              torch.Size([1024, 1024])        False
   52  model.vision_tower.encoder.layers.3.attn.proj.bias                                torch.Size([1024])              False
   53  model.vision_tower.encoder.layers.3.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   54  model.vision_tower.encoder.layers.3.mlp.fc1.bias                                  torch.Size([4096])              False
   55  model.vision_tower.encoder.layers.3.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   56  model.vision_tower.encoder.layers.3.mlp.fc2.bias                                  torch.Size([1024])              False
   57  model.vision_tower.encoder.layers.3.norm1.weight                                  torch.Size([1024])              False
   58  model.vision_tower.encoder.layers.3.norm1.bias                                    torch.Size([1024])              False
   59  model.vision_tower.encoder.layers.3.norm2.weight                                  torch.Size([1024])              False
   60  model.vision_tower.encoder.layers.3.norm2.bias                                    torch.Size([1024])              False
   61  model.vision_tower.encoder.layers.4.ls1                                           torch.Size([1024])              False
   62  model.vision_tower.encoder.layers.4.ls2                                           torch.Size([1024])              False
   63  model.vision_tower.encoder.layers.4.attn.qkv.weight                               torch.Size([3072, 1024])        False
   64  model.vision_tower.encoder.layers.4.attn.qkv.bias                                 torch.Size([3072])              False
   65  model.vision_tower.encoder.layers.4.attn.proj.weight                              torch.Size([1024, 1024])        False
   66  model.vision_tower.encoder.layers.4.attn.proj.bias                                torch.Size([1024])              False
   67  model.vision_tower.encoder.layers.4.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   68  model.vision_tower.encoder.layers.4.mlp.fc1.bias                                  torch.Size([4096])              False
   69  model.vision_tower.encoder.layers.4.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   70  model.vision_tower.encoder.layers.4.mlp.fc2.bias                                  torch.Size([1024])              False
   71  model.vision_tower.encoder.layers.4.norm1.weight                                  torch.Size([1024])              False
   72  model.vision_tower.encoder.layers.4.norm1.bias                                    torch.Size([1024])              False
   73  model.vision_tower.encoder.layers.4.norm2.weight                                  torch.Size([1024])              False
   74  model.vision_tower.encoder.layers.4.norm2.bias                                    torch.Size([1024])              False
   75  model.vision_tower.encoder.layers.5.ls1                                           torch.Size([1024])              False
   76  model.vision_tower.encoder.layers.5.ls2                                           torch.Size([1024])              False
   77  model.vision_tower.encoder.layers.5.attn.qkv.weight                               torch.Size([3072, 1024])        False
   78  model.vision_tower.encoder.layers.5.attn.qkv.bias                                 torch.Size([3072])              False
   79  model.vision_tower.encoder.layers.5.attn.proj.weight                              torch.Size([1024, 1024])        False
   80  model.vision_tower.encoder.layers.5.attn.proj.bias                                torch.Size([1024])              False
   81  model.vision_tower.encoder.layers.5.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   82  model.vision_tower.encoder.layers.5.mlp.fc1.bias                                  torch.Size([4096])              False
   83  model.vision_tower.encoder.layers.5.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   84  model.vision_tower.encoder.layers.5.mlp.fc2.bias                                  torch.Size([1024])              False
   85  model.vision_tower.encoder.layers.5.norm1.weight                                  torch.Size([1024])              False
   86  model.vision_tower.encoder.layers.5.norm1.bias                                    torch.Size([1024])              False
   87  model.vision_tower.encoder.layers.5.norm2.weight                                  torch.Size([1024])              False
   88  model.vision_tower.encoder.layers.5.norm2.bias                                    torch.Size([1024])              False
   89  model.vision_tower.encoder.layers.6.ls1                                           torch.Size([1024])              False
   90  model.vision_tower.encoder.layers.6.ls2                                           torch.Size([1024])              False
   91  model.vision_tower.encoder.layers.6.attn.qkv.weight                               torch.Size([3072, 1024])        False
   92  model.vision_tower.encoder.layers.6.attn.qkv.bias                                 torch.Size([3072])              False
   93  model.vision_tower.encoder.layers.6.attn.proj.weight                              torch.Size([1024, 1024])        False
   94  model.vision_tower.encoder.layers.6.attn.proj.bias                                torch.Size([1024])              False
   95  model.vision_tower.encoder.layers.6.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   96  model.vision_tower.encoder.layers.6.mlp.fc1.bias                                  torch.Size([4096])              False
   97  model.vision_tower.encoder.layers.6.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   98  model.vision_tower.encoder.layers.6.mlp.fc2.bias                                  torch.Size([1024])              False
   99  model.vision_tower.encoder.layers.6.norm1.weight                                  torch.Size([1024])              False
  100  model.vision_tower.encoder.layers.6.norm1.bias                                    torch.Size([1024])              False
  101  model.vision_tower.encoder.layers.6.norm2.weight                                  torch.Size([1024])              False
  102  model.vision_tower.encoder.layers.6.norm2.bias                                    torch.Size([1024])              False
  103  model.vision_tower.encoder.layers.7.ls1                                           torch.Size([1024])              False
  104  model.vision_tower.encoder.layers.7.ls2                                           torch.Size([1024])              False
  105  model.vision_tower.encoder.layers.7.attn.qkv.weight                               torch.Size([3072, 1024])        False
  106  model.vision_tower.encoder.layers.7.attn.qkv.bias                                 torch.Size([3072])              False
  107  model.vision_tower.encoder.layers.7.attn.proj.weight                              torch.Size([1024, 1024])        False
  108  model.vision_tower.encoder.layers.7.attn.proj.bias                                torch.Size([1024])              False
  109  model.vision_tower.encoder.layers.7.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  110  model.vision_tower.encoder.layers.7.mlp.fc1.bias                                  torch.Size([4096])              False
  111  model.vision_tower.encoder.layers.7.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  112  model.vision_tower.encoder.layers.7.mlp.fc2.bias                                  torch.Size([1024])              False
  113  model.vision_tower.encoder.layers.7.norm1.weight                                  torch.Size([1024])              False
  114  model.vision_tower.encoder.layers.7.norm1.bias                                    torch.Size([1024])              False
  115  model.vision_tower.encoder.layers.7.norm2.weight                                  torch.Size([1024])              False
  116  model.vision_tower.encoder.layers.7.norm2.bias                                    torch.Size([1024])              False
  117  model.vision_tower.encoder.layers.8.ls1                                           torch.Size([1024])              False
  118  model.vision_tower.encoder.layers.8.ls2                                           torch.Size([1024])              False
  119  model.vision_tower.encoder.layers.8.attn.qkv.weight                               torch.Size([3072, 1024])        False
  120  model.vision_tower.encoder.layers.8.attn.qkv.bias                                 torch.Size([3072])              False
  121  model.vision_tower.encoder.layers.8.attn.proj.weight                              torch.Size([1024, 1024])        False
  122  model.vision_tower.encoder.layers.8.attn.proj.bias                                torch.Size([1024])              False
  123  model.vision_tower.encoder.layers.8.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  124  model.vision_tower.encoder.layers.8.mlp.fc1.bias                                  torch.Size([4096])              False
  125  model.vision_tower.encoder.layers.8.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  126  model.vision_tower.encoder.layers.8.mlp.fc2.bias                                  torch.Size([1024])              False
  127  model.vision_tower.encoder.layers.8.norm1.weight                                  torch.Size([1024])              False
  128  model.vision_tower.encoder.layers.8.norm1.bias                                    torch.Size([1024])              False
  129  model.vision_tower.encoder.layers.8.norm2.weight                                  torch.Size([1024])              False
  130  model.vision_tower.encoder.layers.8.norm2.bias                                    torch.Size([1024])              False
  131  model.vision_tower.encoder.layers.9.ls1                                           torch.Size([1024])              False
  132  model.vision_tower.encoder.layers.9.ls2                                           torch.Size([1024])              False
  133  model.vision_tower.encoder.layers.9.attn.qkv.weight                               torch.Size([3072, 1024])        False
  134  model.vision_tower.encoder.layers.9.attn.qkv.bias                                 torch.Size([3072])              False
  135  model.vision_tower.encoder.layers.9.attn.proj.weight                              torch.Size([1024, 1024])        False
  136  model.vision_tower.encoder.layers.9.attn.proj.bias                                torch.Size([1024])              False
  137  model.vision_tower.encoder.layers.9.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  138  model.vision_tower.encoder.layers.9.mlp.fc1.bias                                  torch.Size([4096])              False
  139  model.vision_tower.encoder.layers.9.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  140  model.vision_tower.encoder.layers.9.mlp.fc2.bias                                  torch.Size([1024])              False
  141  model.vision_tower.encoder.layers.9.norm1.weight                                  torch.Size([1024])              False
  142  model.vision_tower.encoder.layers.9.norm1.bias                                    torch.Size([1024])              False
  143  model.vision_tower.encoder.layers.9.norm2.weight                                  torch.Size([1024])              False
  144  model.vision_tower.encoder.layers.9.norm2.bias                                    torch.Size([1024])              False
  145  model.vision_tower.encoder.layers.10.ls1                                          torch.Size([1024])              False
  146  model.vision_tower.encoder.layers.10.ls2                                          torch.Size([1024])              False
  147  model.vision_tower.encoder.layers.10.attn.qkv.weight                              torch.Size([3072, 1024])        False
  148  model.vision_tower.encoder.layers.10.attn.qkv.bias                                torch.Size([3072])              False
  149  model.vision_tower.encoder.layers.10.attn.proj.weight                             torch.Size([1024, 1024])        False
  150  model.vision_tower.encoder.layers.10.attn.proj.bias                               torch.Size([1024])              False
  151  model.vision_tower.encoder.layers.10.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  152  model.vision_tower.encoder.layers.10.mlp.fc1.bias                                 torch.Size([4096])              False
  153  model.vision_tower.encoder.layers.10.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  154  model.vision_tower.encoder.layers.10.mlp.fc2.bias                                 torch.Size([1024])              False
  155  model.vision_tower.encoder.layers.10.norm1.weight                                 torch.Size([1024])              False
  156  model.vision_tower.encoder.layers.10.norm1.bias                                   torch.Size([1024])              False
  157  model.vision_tower.encoder.layers.10.norm2.weight                                 torch.Size([1024])              False
  158  model.vision_tower.encoder.layers.10.norm2.bias                                   torch.Size([1024])              False
  159  model.vision_tower.encoder.layers.11.ls1                                          torch.Size([1024])              False
  160  model.vision_tower.encoder.layers.11.ls2                                          torch.Size([1024])              False
  161  model.vision_tower.encoder.layers.11.attn.qkv.weight                              torch.Size([3072, 1024])        False
  162  model.vision_tower.encoder.layers.11.attn.qkv.bias                                torch.Size([3072])              False
  163  model.vision_tower.encoder.layers.11.attn.proj.weight                             torch.Size([1024, 1024])        False
  164  model.vision_tower.encoder.layers.11.attn.proj.bias                               torch.Size([1024])              False
  165  model.vision_tower.encoder.layers.11.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  166  model.vision_tower.encoder.layers.11.mlp.fc1.bias                                 torch.Size([4096])              False
  167  model.vision_tower.encoder.layers.11.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  168  model.vision_tower.encoder.layers.11.mlp.fc2.bias                                 torch.Size([1024])              False
  169  model.vision_tower.encoder.layers.11.norm1.weight                                 torch.Size([1024])              False
  170  model.vision_tower.encoder.layers.11.norm1.bias                                   torch.Size([1024])              False
  171  model.vision_tower.encoder.layers.11.norm2.weight                                 torch.Size([1024])              False
  172  model.vision_tower.encoder.layers.11.norm2.bias                                   torch.Size([1024])              False
  173  model.vision_tower.encoder.layers.12.ls1                                          torch.Size([1024])              False
  174  model.vision_tower.encoder.layers.12.ls2                                          torch.Size([1024])              False
  175  model.vision_tower.encoder.layers.12.attn.qkv.weight                              torch.Size([3072, 1024])        False
  176  model.vision_tower.encoder.layers.12.attn.qkv.bias                                torch.Size([3072])              False
  177  model.vision_tower.encoder.layers.12.attn.proj.weight                             torch.Size([1024, 1024])        False
  178  model.vision_tower.encoder.layers.12.attn.proj.bias                               torch.Size([1024])              False
  179  model.vision_tower.encoder.layers.12.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  180  model.vision_tower.encoder.layers.12.mlp.fc1.bias                                 torch.Size([4096])              False
  181  model.vision_tower.encoder.layers.12.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  182  model.vision_tower.encoder.layers.12.mlp.fc2.bias                                 torch.Size([1024])              False
  183  model.vision_tower.encoder.layers.12.norm1.weight                                 torch.Size([1024])              False
  184  model.vision_tower.encoder.layers.12.norm1.bias                                   torch.Size([1024])              False
  185  model.vision_tower.encoder.layers.12.norm2.weight                                 torch.Size([1024])              False
  186  model.vision_tower.encoder.layers.12.norm2.bias                                   torch.Size([1024])              False
  187  model.vision_tower.encoder.layers.13.ls1                                          torch.Size([1024])              False
  188  model.vision_tower.encoder.layers.13.ls2                                          torch.Size([1024])              False
  189  model.vision_tower.encoder.layers.13.attn.qkv.weight                              torch.Size([3072, 1024])        False
  190  model.vision_tower.encoder.layers.13.attn.qkv.bias                                torch.Size([3072])              False
  191  model.vision_tower.encoder.layers.13.attn.proj.weight                             torch.Size([1024, 1024])        False
  192  model.vision_tower.encoder.layers.13.attn.proj.bias                               torch.Size([1024])              False
  193  model.vision_tower.encoder.layers.13.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  194  model.vision_tower.encoder.layers.13.mlp.fc1.bias                                 torch.Size([4096])              False
  195  model.vision_tower.encoder.layers.13.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  196  model.vision_tower.encoder.layers.13.mlp.fc2.bias                                 torch.Size([1024])              False
  197  model.vision_tower.encoder.layers.13.norm1.weight                                 torch.Size([1024])              False
  198  model.vision_tower.encoder.layers.13.norm1.bias                                   torch.Size([1024])              False
  199  model.vision_tower.encoder.layers.13.norm2.weight                                 torch.Size([1024])              False
  200  model.vision_tower.encoder.layers.13.norm2.bias                                   torch.Size([1024])              False
  201  model.vision_tower.encoder.layers.14.ls1                                          torch.Size([1024])              False
  202  model.vision_tower.encoder.layers.14.ls2                                          torch.Size([1024])              False
  203  model.vision_tower.encoder.layers.14.attn.qkv.weight                              torch.Size([3072, 1024])        False
  204  model.vision_tower.encoder.layers.14.attn.qkv.bias                                torch.Size([3072])              False
  205  model.vision_tower.encoder.layers.14.attn.proj.weight                             torch.Size([1024, 1024])        False
  206  model.vision_tower.encoder.layers.14.attn.proj.bias                               torch.Size([1024])              False
  207  model.vision_tower.encoder.layers.14.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  208  model.vision_tower.encoder.layers.14.mlp.fc1.bias                                 torch.Size([4096])              False
  209  model.vision_tower.encoder.layers.14.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  210  model.vision_tower.encoder.layers.14.mlp.fc2.bias                                 torch.Size([1024])              False
  211  model.vision_tower.encoder.layers.14.norm1.weight                                 torch.Size([1024])              False
  212  model.vision_tower.encoder.layers.14.norm1.bias                                   torch.Size([1024])              False
  213  model.vision_tower.encoder.layers.14.norm2.weight                                 torch.Size([1024])              False
  214  model.vision_tower.encoder.layers.14.norm2.bias                                   torch.Size([1024])              False
  215  model.vision_tower.encoder.layers.15.ls1                                          torch.Size([1024])              False
  216  model.vision_tower.encoder.layers.15.ls2                                          torch.Size([1024])              False
  217  model.vision_tower.encoder.layers.15.attn.qkv.weight                              torch.Size([3072, 1024])        False
  218  model.vision_tower.encoder.layers.15.attn.qkv.bias                                torch.Size([3072])              False
  219  model.vision_tower.encoder.layers.15.attn.proj.weight                             torch.Size([1024, 1024])        False
  220  model.vision_tower.encoder.layers.15.attn.proj.bias                               torch.Size([1024])              False
  221  model.vision_tower.encoder.layers.15.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  222  model.vision_tower.encoder.layers.15.mlp.fc1.bias                                 torch.Size([4096])              False
  223  model.vision_tower.encoder.layers.15.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  224  model.vision_tower.encoder.layers.15.mlp.fc2.bias                                 torch.Size([1024])              False
  225  model.vision_tower.encoder.layers.15.norm1.weight                                 torch.Size([1024])              False
  226  model.vision_tower.encoder.layers.15.norm1.bias                                   torch.Size([1024])              False
  227  model.vision_tower.encoder.layers.15.norm2.weight                                 torch.Size([1024])              False
  228  model.vision_tower.encoder.layers.15.norm2.bias                                   torch.Size([1024])              False
  229  model.vision_tower.encoder.layers.16.ls1                                          torch.Size([1024])              False
  230  model.vision_tower.encoder.layers.16.ls2                                          torch.Size([1024])              False
  231  model.vision_tower.encoder.layers.16.attn.qkv.weight                              torch.Size([3072, 1024])        False
  232  model.vision_tower.encoder.layers.16.attn.qkv.bias                                torch.Size([3072])              False
  233  model.vision_tower.encoder.layers.16.attn.proj.weight                             torch.Size([1024, 1024])        False
  234  model.vision_tower.encoder.layers.16.attn.proj.bias                               torch.Size([1024])              False
  235  model.vision_tower.encoder.layers.16.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  236  model.vision_tower.encoder.layers.16.mlp.fc1.bias                                 torch.Size([4096])              False
  237  model.vision_tower.encoder.layers.16.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  238  model.vision_tower.encoder.layers.16.mlp.fc2.bias                                 torch.Size([1024])              False
  239  model.vision_tower.encoder.layers.16.norm1.weight                                 torch.Size([1024])              False
  240  model.vision_tower.encoder.layers.16.norm1.bias                                   torch.Size([1024])              False
  241  model.vision_tower.encoder.layers.16.norm2.weight                                 torch.Size([1024])              False
  242  model.vision_tower.encoder.layers.16.norm2.bias                                   torch.Size([1024])              False
  243  model.vision_tower.encoder.layers.17.ls1                                          torch.Size([1024])              False
  244  model.vision_tower.encoder.layers.17.ls2                                          torch.Size([1024])              False
  245  model.vision_tower.encoder.layers.17.attn.qkv.weight                              torch.Size([3072, 1024])        False
  246  model.vision_tower.encoder.layers.17.attn.qkv.bias                                torch.Size([3072])              False
  247  model.vision_tower.encoder.layers.17.attn.proj.weight                             torch.Size([1024, 1024])        False
  248  model.vision_tower.encoder.layers.17.attn.proj.bias                               torch.Size([1024])              False
  249  model.vision_tower.encoder.layers.17.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  250  model.vision_tower.encoder.layers.17.mlp.fc1.bias                                 torch.Size([4096])              False
  251  model.vision_tower.encoder.layers.17.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  252  model.vision_tower.encoder.layers.17.mlp.fc2.bias                                 torch.Size([1024])              False
  253  model.vision_tower.encoder.layers.17.norm1.weight                                 torch.Size([1024])              False
  254  model.vision_tower.encoder.layers.17.norm1.bias                                   torch.Size([1024])              False
  255  model.vision_tower.encoder.layers.17.norm2.weight                                 torch.Size([1024])              False
  256  model.vision_tower.encoder.layers.17.norm2.bias                                   torch.Size([1024])              False
  257  model.vision_tower.encoder.layers.18.ls1                                          torch.Size([1024])              False
  258  model.vision_tower.encoder.layers.18.ls2                                          torch.Size([1024])              False
  259  model.vision_tower.encoder.layers.18.attn.qkv.weight                              torch.Size([3072, 1024])        False
  260  model.vision_tower.encoder.layers.18.attn.qkv.bias                                torch.Size([3072])              False
  261  model.vision_tower.encoder.layers.18.attn.proj.weight                             torch.Size([1024, 1024])        False
  262  model.vision_tower.encoder.layers.18.attn.proj.bias                               torch.Size([1024])              False
  263  model.vision_tower.encoder.layers.18.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  264  model.vision_tower.encoder.layers.18.mlp.fc1.bias                                 torch.Size([4096])              False
  265  model.vision_tower.encoder.layers.18.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  266  model.vision_tower.encoder.layers.18.mlp.fc2.bias                                 torch.Size([1024])              False
  267  model.vision_tower.encoder.layers.18.norm1.weight                                 torch.Size([1024])              False
  268  model.vision_tower.encoder.layers.18.norm1.bias                                   torch.Size([1024])              False
  269  model.vision_tower.encoder.layers.18.norm2.weight                                 torch.Size([1024])              False
  270  model.vision_tower.encoder.layers.18.norm2.bias                                   torch.Size([1024])              False
  271  model.vision_tower.encoder.layers.19.ls1                                          torch.Size([1024])              False
  272  model.vision_tower.encoder.layers.19.ls2                                          torch.Size([1024])              False
  273  model.vision_tower.encoder.layers.19.attn.qkv.weight                              torch.Size([3072, 1024])        False
  274  model.vision_tower.encoder.layers.19.attn.qkv.bias                                torch.Size([3072])              False
  275  model.vision_tower.encoder.layers.19.attn.proj.weight                             torch.Size([1024, 1024])        False
  276  model.vision_tower.encoder.layers.19.attn.proj.bias                               torch.Size([1024])              False
  277  model.vision_tower.encoder.layers.19.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  278  model.vision_tower.encoder.layers.19.mlp.fc1.bias                                 torch.Size([4096])              False
  279  model.vision_tower.encoder.layers.19.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  280  model.vision_tower.encoder.layers.19.mlp.fc2.bias                                 torch.Size([1024])              False
  281  model.vision_tower.encoder.layers.19.norm1.weight                                 torch.Size([1024])              False
  282  model.vision_tower.encoder.layers.19.norm1.bias                                   torch.Size([1024])              False
  283  model.vision_tower.encoder.layers.19.norm2.weight                                 torch.Size([1024])              False
  284  model.vision_tower.encoder.layers.19.norm2.bias                                   torch.Size([1024])              False
  285  model.vision_tower.encoder.layers.20.ls1                                          torch.Size([1024])              False
  286  model.vision_tower.encoder.layers.20.ls2                                          torch.Size([1024])              False
  287  model.vision_tower.encoder.layers.20.attn.qkv.weight                              torch.Size([3072, 1024])        False
  288  model.vision_tower.encoder.layers.20.attn.qkv.bias                                torch.Size([3072])              False
  289  model.vision_tower.encoder.layers.20.attn.proj.weight                             torch.Size([1024, 1024])        False
  290  model.vision_tower.encoder.layers.20.attn.proj.bias                               torch.Size([1024])              False
  291  model.vision_tower.encoder.layers.20.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  292  model.vision_tower.encoder.layers.20.mlp.fc1.bias                                 torch.Size([4096])              False
  293  model.vision_tower.encoder.layers.20.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  294  model.vision_tower.encoder.layers.20.mlp.fc2.bias                                 torch.Size([1024])              False
  295  model.vision_tower.encoder.layers.20.norm1.weight                                 torch.Size([1024])              False
  296  model.vision_tower.encoder.layers.20.norm1.bias                                   torch.Size([1024])              False
  297  model.vision_tower.encoder.layers.20.norm2.weight                                 torch.Size([1024])              False
  298  model.vision_tower.encoder.layers.20.norm2.bias                                   torch.Size([1024])              False
  299  model.vision_tower.encoder.layers.21.ls1                                          torch.Size([1024])              False
  300  model.vision_tower.encoder.layers.21.ls2                                          torch.Size([1024])              False
  301  model.vision_tower.encoder.layers.21.attn.qkv.weight                              torch.Size([3072, 1024])        False
  302  model.vision_tower.encoder.layers.21.attn.qkv.bias                                torch.Size([3072])              False
  303  model.vision_tower.encoder.layers.21.attn.proj.weight                             torch.Size([1024, 1024])        False
  304  model.vision_tower.encoder.layers.21.attn.proj.bias                               torch.Size([1024])              False
  305  model.vision_tower.encoder.layers.21.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  306  model.vision_tower.encoder.layers.21.mlp.fc1.bias                                 torch.Size([4096])              False
  307  model.vision_tower.encoder.layers.21.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  308  model.vision_tower.encoder.layers.21.mlp.fc2.bias                                 torch.Size([1024])              False
  309  model.vision_tower.encoder.layers.21.norm1.weight                                 torch.Size([1024])              False
  310  model.vision_tower.encoder.layers.21.norm1.bias                                   torch.Size([1024])              False
  311  model.vision_tower.encoder.layers.21.norm2.weight                                 torch.Size([1024])              False
  312  model.vision_tower.encoder.layers.21.norm2.bias                                   torch.Size([1024])              False
  313  model.vision_tower.encoder.layers.22.ls1                                          torch.Size([1024])              False
  314  model.vision_tower.encoder.layers.22.ls2                                          torch.Size([1024])              False
  315  model.vision_tower.encoder.layers.22.attn.qkv.weight                              torch.Size([3072, 1024])        False
  316  model.vision_tower.encoder.layers.22.attn.qkv.bias                                torch.Size([3072])              False
  317  model.vision_tower.encoder.layers.22.attn.proj.weight                             torch.Size([1024, 1024])        False
  318  model.vision_tower.encoder.layers.22.attn.proj.bias                               torch.Size([1024])              False
  319  model.vision_tower.encoder.layers.22.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  320  model.vision_tower.encoder.layers.22.mlp.fc1.bias                                 torch.Size([4096])              False
  321  model.vision_tower.encoder.layers.22.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  322  model.vision_tower.encoder.layers.22.mlp.fc2.bias                                 torch.Size([1024])              False
  323  model.vision_tower.encoder.layers.22.norm1.weight                                 torch.Size([1024])              False
  324  model.vision_tower.encoder.layers.22.norm1.bias                                   torch.Size([1024])              False
  325  model.vision_tower.encoder.layers.22.norm2.weight                                 torch.Size([1024])              False
  326  model.vision_tower.encoder.layers.22.norm2.bias                                   torch.Size([1024])              False
  327  model.vision_tower.encoder.layers.23.ls1                                          torch.Size([1024])              False
  328  model.vision_tower.encoder.layers.23.ls2                                          torch.Size([1024])              False
  329  model.vision_tower.encoder.layers.23.attn.qkv.weight                              torch.Size([3072, 1024])        False
  330  model.vision_tower.encoder.layers.23.attn.qkv.bias                                torch.Size([3072])              False
  331  model.vision_tower.encoder.layers.23.attn.proj.weight                             torch.Size([1024, 1024])        False
  332  model.vision_tower.encoder.layers.23.attn.proj.bias                               torch.Size([1024])              False
  333  model.vision_tower.encoder.layers.23.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  334  model.vision_tower.encoder.layers.23.mlp.fc1.bias                                 torch.Size([4096])              False
  335  model.vision_tower.encoder.layers.23.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  336  model.vision_tower.encoder.layers.23.mlp.fc2.bias                                 torch.Size([1024])              False
  337  model.vision_tower.encoder.layers.23.norm1.weight                                 torch.Size([1024])              False
  338  model.vision_tower.encoder.layers.23.norm1.bias                                   torch.Size([1024])              False
  339  model.vision_tower.encoder.layers.23.norm2.weight                                 torch.Size([1024])              False
  340  model.vision_tower.encoder.layers.23.norm2.bias                                   torch.Size([1024])              False
  341  model.multi_modal_projector.0.weight                                              torch.Size([4096])              False
  342  model.multi_modal_projector.0.bias                                                torch.Size([4096])              False
  343  model.multi_modal_projector.1.weight                                              torch.Size([896, 4096])         False
  344  model.multi_modal_projector.1.bias                                                torch.Size([896])               False
  345  model.multi_modal_projector.3.weight                                              torch.Size([896, 896])          False
  346  model.multi_modal_projector.3.bias                                                torch.Size([896])               False
  347  model.language_model.embed_tokens.weight                                          torch.Size([151678, 896])       False
  348  model.language_model.layers.0.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  349  model.language_model.layers.0.self_attn.q_proj.bias                               torch.Size([896])               False
  350  model.language_model.layers.0.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  351  model.language_model.layers.0.self_attn.k_proj.bias                               torch.Size([128])               False
  352  model.language_model.layers.0.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  353  model.language_model.layers.0.self_attn.v_proj.bias                               torch.Size([128])               False
  354  model.language_model.layers.0.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  355  model.language_model.layers.0.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  356  model.language_model.layers.0.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  357  model.language_model.layers.0.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  358  model.language_model.layers.0.input_layernorm.weight                              torch.Size([896])               False
  359  model.language_model.layers.0.post_attention_layernorm.weight                     torch.Size([896])               False
  360  model.language_model.layers.1.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  361  model.language_model.layers.1.self_attn.q_proj.bias                               torch.Size([896])               False
  362  model.language_model.layers.1.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  363  model.language_model.layers.1.self_attn.k_proj.bias                               torch.Size([128])               False
  364  model.language_model.layers.1.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  365  model.language_model.layers.1.self_attn.v_proj.bias                               torch.Size([128])               False
  366  model.language_model.layers.1.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  367  model.language_model.layers.1.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  368  model.language_model.layers.1.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  369  model.language_model.layers.1.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  370  model.language_model.layers.1.input_layernorm.weight                              torch.Size([896])               False
  371  model.language_model.layers.1.post_attention_layernorm.weight                     torch.Size([896])               False
  372  model.language_model.layers.2.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  373  model.language_model.layers.2.self_attn.q_proj.bias                               torch.Size([896])               False
  374  model.language_model.layers.2.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  375  model.language_model.layers.2.self_attn.k_proj.bias                               torch.Size([128])               False
  376  model.language_model.layers.2.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  377  model.language_model.layers.2.self_attn.v_proj.bias                               torch.Size([128])               False
  378  model.language_model.layers.2.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  379  model.language_model.layers.2.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  380  model.language_model.layers.2.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  381  model.language_model.layers.2.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  382  model.language_model.layers.2.input_layernorm.weight                              torch.Size([896])               False
  383  model.language_model.layers.2.post_attention_layernorm.weight                     torch.Size([896])               False
  384  model.language_model.layers.3.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  385  model.language_model.layers.3.self_attn.q_proj.bias                               torch.Size([896])               False
  386  model.language_model.layers.3.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  387  model.language_model.layers.3.self_attn.k_proj.bias                               torch.Size([128])               False
  388  model.language_model.layers.3.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  389  model.language_model.layers.3.self_attn.v_proj.bias                               torch.Size([128])               False
  390  model.language_model.layers.3.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  391  model.language_model.layers.3.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  392  model.language_model.layers.3.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  393  model.language_model.layers.3.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  394  model.language_model.layers.3.input_layernorm.weight                              torch.Size([896])               False
  395  model.language_model.layers.3.post_attention_layernorm.weight                     torch.Size([896])               False
  396  model.language_model.layers.4.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  397  model.language_model.layers.4.self_attn.q_proj.bias                               torch.Size([896])               False
  398  model.language_model.layers.4.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  399  model.language_model.layers.4.self_attn.k_proj.bias                               torch.Size([128])               False
  400  model.language_model.layers.4.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  401  model.language_model.layers.4.self_attn.v_proj.bias                               torch.Size([128])               False
  402  model.language_model.layers.4.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  403  model.language_model.layers.4.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  404  model.language_model.layers.4.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  405  model.language_model.layers.4.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  406  model.language_model.layers.4.input_layernorm.weight                              torch.Size([896])               False
  407  model.language_model.layers.4.post_attention_layernorm.weight                     torch.Size([896])               False
  408  model.language_model.layers.5.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  409  model.language_model.layers.5.self_attn.q_proj.bias                               torch.Size([896])               False
  410  model.language_model.layers.5.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  411  model.language_model.layers.5.self_attn.k_proj.bias                               torch.Size([128])               False
  412  model.language_model.layers.5.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  413  model.language_model.layers.5.self_attn.v_proj.bias                               torch.Size([128])               False
  414  model.language_model.layers.5.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  415  model.language_model.layers.5.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  416  model.language_model.layers.5.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  417  model.language_model.layers.5.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  418  model.language_model.layers.5.input_layernorm.weight                              torch.Size([896])               False
  419  model.language_model.layers.5.post_attention_layernorm.weight                     torch.Size([896])               False
  420  model.language_model.layers.6.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  421  model.language_model.layers.6.self_attn.q_proj.bias                               torch.Size([896])               False
  422  model.language_model.layers.6.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  423  model.language_model.layers.6.self_attn.k_proj.bias                               torch.Size([128])               False
  424  model.language_model.layers.6.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  425  model.language_model.layers.6.self_attn.v_proj.bias                               torch.Size([128])               False
  426  model.language_model.layers.6.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  427  model.language_model.layers.6.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  428  model.language_model.layers.6.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  429  model.language_model.layers.6.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  430  model.language_model.layers.6.input_layernorm.weight                              torch.Size([896])               False
  431  model.language_model.layers.6.post_attention_layernorm.weight                     torch.Size([896])               False
  432  model.language_model.layers.7.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  433  model.language_model.layers.7.self_attn.q_proj.bias                               torch.Size([896])               False
  434  model.language_model.layers.7.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  435  model.language_model.layers.7.self_attn.k_proj.bias                               torch.Size([128])               False
  436  model.language_model.layers.7.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  437  model.language_model.layers.7.self_attn.v_proj.bias                               torch.Size([128])               False
  438  model.language_model.layers.7.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  439  model.language_model.layers.7.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  440  model.language_model.layers.7.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  441  model.language_model.layers.7.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  442  model.language_model.layers.7.input_layernorm.weight                              torch.Size([896])               False
  443  model.language_model.layers.7.post_attention_layernorm.weight                     torch.Size([896])               False
  444  model.language_model.layers.8.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  445  model.language_model.layers.8.self_attn.q_proj.bias                               torch.Size([896])               False
  446  model.language_model.layers.8.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  447  model.language_model.layers.8.self_attn.k_proj.bias                               torch.Size([128])               False
  448  model.language_model.layers.8.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  449  model.language_model.layers.8.self_attn.v_proj.bias                               torch.Size([128])               False
  450  model.language_model.layers.8.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  451  model.language_model.layers.8.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  452  model.language_model.layers.8.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  453  model.language_model.layers.8.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  454  model.language_model.layers.8.input_layernorm.weight                              torch.Size([896])               False
  455  model.language_model.layers.8.post_attention_layernorm.weight                     torch.Size([896])               False
  456  model.language_model.layers.9.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  457  model.language_model.layers.9.self_attn.q_proj.bias                               torch.Size([896])               False
  458  model.language_model.layers.9.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  459  model.language_model.layers.9.self_attn.k_proj.bias                               torch.Size([128])               False
  460  model.language_model.layers.9.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  461  model.language_model.layers.9.self_attn.v_proj.bias                               torch.Size([128])               False
  462  model.language_model.layers.9.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  463  model.language_model.layers.9.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  464  model.language_model.layers.9.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  465  model.language_model.layers.9.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  466  model.language_model.layers.9.input_layernorm.weight                              torch.Size([896])               False
  467  model.language_model.layers.9.post_attention_layernorm.weight                     torch.Size([896])               False
  468  model.language_model.layers.10.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  469  model.language_model.layers.10.self_attn.q_proj.bias                              torch.Size([896])               False
  470  model.language_model.layers.10.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  471  model.language_model.layers.10.self_attn.k_proj.bias                              torch.Size([128])               False
  472  model.language_model.layers.10.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  473  model.language_model.layers.10.self_attn.v_proj.bias                              torch.Size([128])               False
  474  model.language_model.layers.10.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  475  model.language_model.layers.10.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  476  model.language_model.layers.10.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  477  model.language_model.layers.10.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  478  model.language_model.layers.10.input_layernorm.weight                             torch.Size([896])               False
  479  model.language_model.layers.10.post_attention_layernorm.weight                    torch.Size([896])               False
  480  model.language_model.layers.11.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  481  model.language_model.layers.11.self_attn.q_proj.bias                              torch.Size([896])               False
  482  model.language_model.layers.11.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  483  model.language_model.layers.11.self_attn.k_proj.bias                              torch.Size([128])               False
  484  model.language_model.layers.11.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  485  model.language_model.layers.11.self_attn.v_proj.bias                              torch.Size([128])               False
  486  model.language_model.layers.11.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  487  model.language_model.layers.11.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  488  model.language_model.layers.11.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  489  model.language_model.layers.11.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  490  model.language_model.layers.11.input_layernorm.weight                             torch.Size([896])               False
  491  model.language_model.layers.11.post_attention_layernorm.weight                    torch.Size([896])               False
  492  model.language_model.layers.12.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  493  model.language_model.layers.12.self_attn.q_proj.bias                              torch.Size([896])               False
  494  model.language_model.layers.12.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  495  model.language_model.layers.12.self_attn.k_proj.bias                              torch.Size([128])               False
  496  model.language_model.layers.12.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  497  model.language_model.layers.12.self_attn.v_proj.bias                              torch.Size([128])               False
  498  model.language_model.layers.12.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  499  model.language_model.layers.12.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  500  model.language_model.layers.12.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  501  model.language_model.layers.12.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  502  model.language_model.layers.12.input_layernorm.weight                             torch.Size([896])               False
  503  model.language_model.layers.12.post_attention_layernorm.weight                    torch.Size([896])               False
  504  model.language_model.layers.13.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  505  model.language_model.layers.13.self_attn.q_proj.bias                              torch.Size([896])               False
  506  model.language_model.layers.13.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  507  model.language_model.layers.13.self_attn.k_proj.bias                              torch.Size([128])               False
  508  model.language_model.layers.13.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  509  model.language_model.layers.13.self_attn.v_proj.bias                              torch.Size([128])               False
  510  model.language_model.layers.13.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  511  model.language_model.layers.13.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  512  model.language_model.layers.13.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  513  model.language_model.layers.13.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  514  model.language_model.layers.13.input_layernorm.weight                             torch.Size([896])               False
  515  model.language_model.layers.13.post_attention_layernorm.weight                    torch.Size([896])               False
  516  model.language_model.layers.14.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  517  model.language_model.layers.14.self_attn.q_proj.bias                              torch.Size([896])               False
  518  model.language_model.layers.14.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  519  model.language_model.layers.14.self_attn.k_proj.bias                              torch.Size([128])               False
  520  model.language_model.layers.14.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  521  model.language_model.layers.14.self_attn.v_proj.bias                              torch.Size([128])               False
  522  model.language_model.layers.14.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  523  model.language_model.layers.14.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  524  model.language_model.layers.14.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  525  model.language_model.layers.14.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  526  model.language_model.layers.14.input_layernorm.weight                             torch.Size([896])               False
  527  model.language_model.layers.14.post_attention_layernorm.weight                    torch.Size([896])               False
  528  model.language_model.layers.15.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  529  model.language_model.layers.15.self_attn.q_proj.bias                              torch.Size([896])               False
  530  model.language_model.layers.15.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  531  model.language_model.layers.15.self_attn.k_proj.bias                              torch.Size([128])               False
  532  model.language_model.layers.15.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  533  model.language_model.layers.15.self_attn.v_proj.bias                              torch.Size([128])               False
  534  model.language_model.layers.15.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  535  model.language_model.layers.15.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  536  model.language_model.layers.15.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  537  model.language_model.layers.15.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  538  model.language_model.layers.15.input_layernorm.weight                             torch.Size([896])               False
  539  model.language_model.layers.15.post_attention_layernorm.weight                    torch.Size([896])               False
  540  model.language_model.layers.16.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  541  model.language_model.layers.16.self_attn.q_proj.bias                              torch.Size([896])               False
  542  model.language_model.layers.16.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  543  model.language_model.layers.16.self_attn.k_proj.bias                              torch.Size([128])               False
  544  model.language_model.layers.16.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  545  model.language_model.layers.16.self_attn.v_proj.bias                              torch.Size([128])               False
  546  model.language_model.layers.16.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  547  model.language_model.layers.16.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  548  model.language_model.layers.16.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  549  model.language_model.layers.16.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  550  model.language_model.layers.16.input_layernorm.weight                             torch.Size([896])               False
  551  model.language_model.layers.16.post_attention_layernorm.weight                    torch.Size([896])               False
  552  model.language_model.layers.17.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  553  model.language_model.layers.17.self_attn.q_proj.bias                              torch.Size([896])               False
  554  model.language_model.layers.17.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  555  model.language_model.layers.17.self_attn.k_proj.bias                              torch.Size([128])               False
  556  model.language_model.layers.17.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  557  model.language_model.layers.17.self_attn.v_proj.bias                              torch.Size([128])               False
  558  model.language_model.layers.17.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  559  model.language_model.layers.17.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  560  model.language_model.layers.17.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  561  model.language_model.layers.17.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  562  model.language_model.layers.17.input_layernorm.weight                             torch.Size([896])               False
  563  model.language_model.layers.17.post_attention_layernorm.weight                    torch.Size([896])               False
  564  model.language_model.layers.18.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  565  model.language_model.layers.18.self_attn.q_proj.bias                              torch.Size([896])               False
  566  model.language_model.layers.18.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  567  model.language_model.layers.18.self_attn.k_proj.bias                              torch.Size([128])               False
  568  model.language_model.layers.18.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  569  model.language_model.layers.18.self_attn.v_proj.bias                              torch.Size([128])               False
  570  model.language_model.layers.18.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  571  model.language_model.layers.18.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  572  model.language_model.layers.18.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  573  model.language_model.layers.18.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  574  model.language_model.layers.18.input_layernorm.weight                             torch.Size([896])               False
  575  model.language_model.layers.18.post_attention_layernorm.weight                    torch.Size([896])               False
  576  model.language_model.layers.19.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  577  model.language_model.layers.19.self_attn.q_proj.bias                              torch.Size([896])               False
  578  model.language_model.layers.19.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  579  model.language_model.layers.19.self_attn.k_proj.bias                              torch.Size([128])               False
  580  model.language_model.layers.19.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  581  model.language_model.layers.19.self_attn.v_proj.bias                              torch.Size([128])               False
  582  model.language_model.layers.19.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  583  model.language_model.layers.19.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  584  model.language_model.layers.19.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  585  model.language_model.layers.19.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  586  model.language_model.layers.19.input_layernorm.weight                             torch.Size([896])               False
  587  model.language_model.layers.19.post_attention_layernorm.weight                    torch.Size([896])               False
  588  model.language_model.layers.20.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  589  model.language_model.layers.20.self_attn.q_proj.bias                              torch.Size([896])               False
  590  model.language_model.layers.20.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  591  model.language_model.layers.20.self_attn.k_proj.bias                              torch.Size([128])               False
  592  model.language_model.layers.20.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  593  model.language_model.layers.20.self_attn.v_proj.bias                              torch.Size([128])               False
  594  model.language_model.layers.20.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  595  model.language_model.layers.20.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  596  model.language_model.layers.20.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  597  model.language_model.layers.20.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  598  model.language_model.layers.20.input_layernorm.weight                             torch.Size([896])               False
  599  model.language_model.layers.20.post_attention_layernorm.weight                    torch.Size([896])               False
  600  model.language_model.layers.21.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  601  model.language_model.layers.21.self_attn.q_proj.bias                              torch.Size([896])               False
  602  model.language_model.layers.21.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  603  model.language_model.layers.21.self_attn.k_proj.bias                              torch.Size([128])               False
  604  model.language_model.layers.21.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  605  model.language_model.layers.21.self_attn.v_proj.bias                              torch.Size([128])               False
  606  model.language_model.layers.21.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  607  model.language_model.layers.21.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  608  model.language_model.layers.21.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  609  model.language_model.layers.21.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  610  model.language_model.layers.21.input_layernorm.weight                             torch.Size([896])               False
  611  model.language_model.layers.21.post_attention_layernorm.weight                    torch.Size([896])               False
  612  model.language_model.layers.22.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  613  model.language_model.layers.22.self_attn.q_proj.bias                              torch.Size([896])               False
  614  model.language_model.layers.22.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  615  model.language_model.layers.22.self_attn.k_proj.bias                              torch.Size([128])               False
  616  model.language_model.layers.22.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  617  model.language_model.layers.22.self_attn.v_proj.bias                              torch.Size([128])               False
  618  model.language_model.layers.22.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  619  model.language_model.layers.22.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  620  model.language_model.layers.22.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  621  model.language_model.layers.22.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  622  model.language_model.layers.22.input_layernorm.weight                             torch.Size([896])               False
  623  model.language_model.layers.22.post_attention_layernorm.weight                    torch.Size([896])               False
  624  model.language_model.layers.23.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  625  model.language_model.layers.23.self_attn.q_proj.bias                              torch.Size([896])               False
  626  model.language_model.layers.23.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  627  model.language_model.layers.23.self_attn.k_proj.bias                              torch.Size([128])               False
  628  model.language_model.layers.23.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  629  model.language_model.layers.23.self_attn.v_proj.bias                              torch.Size([128])               False
  630  model.language_model.layers.23.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  631  model.language_model.layers.23.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  632  model.language_model.layers.23.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  633  model.language_model.layers.23.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  634  model.language_model.layers.23.input_layernorm.weight                             torch.Size([896])               False
  635  model.language_model.layers.23.post_attention_layernorm.weight                    torch.Size([896])               False
  636  model.language_model.norm.weight                                                  torch.Size([896])               False
  637  model.dit.scale_shift_table                                                       torch.Size([2, 1152])           True
  638  model.dit.patch_embed.proj.weight                                                 torch.Size([1152, 32, 1, 1])    True
  639  model.dit.patch_embed.proj.bias                                                   torch.Size([1152])              True
  640  model.dit.time_embed.emb.timestep_embedder.linear_1.weight                        torch.Size([1152, 256])         True
  641  model.dit.time_embed.emb.timestep_embedder.linear_1.bias                          torch.Size([1152])              True
  642  model.dit.time_embed.emb.timestep_embedder.linear_2.weight                        torch.Size([1152, 1152])        True
  643  model.dit.time_embed.emb.timestep_embedder.linear_2.bias                          torch.Size([1152])              True
  644  model.dit.time_embed.linear.weight                                                torch.Size([6912, 1152])        True
  645  model.dit.time_embed.linear.bias                                                  torch.Size([6912])              True
  646  model.dit.caption_projection.linear_1.weight                                      torch.Size([1152, 2304])        True
  647  model.dit.caption_projection.linear_1.bias                                        torch.Size([1152])              True
  648  model.dit.caption_projection.linear_2.weight                                      torch.Size([1152, 1152])        True
  649  model.dit.caption_projection.linear_2.bias                                        torch.Size([1152])              True
  650  model.dit.caption_norm.weight                                                     torch.Size([1152])              True
  651  model.dit.transformer_blocks.0.scale_shift_table                                  torch.Size([6, 1152])           True
  652  model.dit.transformer_blocks.0.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  653  model.dit.transformer_blocks.0.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  654  model.dit.transformer_blocks.0.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  655  model.dit.transformer_blocks.0.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  656  model.dit.transformer_blocks.0.attn1.to_out.0.bias                                torch.Size([1152])              True
  657  model.dit.transformer_blocks.0.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  658  model.dit.transformer_blocks.0.attn2.to_q.bias                                    torch.Size([1152])              True
  659  model.dit.transformer_blocks.0.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  660  model.dit.transformer_blocks.0.attn2.to_k.bias                                    torch.Size([1152])              True
  661  model.dit.transformer_blocks.0.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  662  model.dit.transformer_blocks.0.attn2.to_v.bias                                    torch.Size([1152])              True
  663  model.dit.transformer_blocks.0.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  664  model.dit.transformer_blocks.0.attn2.to_out.0.bias                                torch.Size([1152])              True
  665  model.dit.transformer_blocks.0.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  666  model.dit.transformer_blocks.0.ff.conv_inverted.bias                              torch.Size([5760])              True
  667  model.dit.transformer_blocks.0.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  668  model.dit.transformer_blocks.0.ff.conv_depth.bias                                 torch.Size([5760])              True
  669  model.dit.transformer_blocks.0.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  670  model.dit.transformer_blocks.1.scale_shift_table                                  torch.Size([6, 1152])           True
  671  model.dit.transformer_blocks.1.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  672  model.dit.transformer_blocks.1.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  673  model.dit.transformer_blocks.1.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  674  model.dit.transformer_blocks.1.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  675  model.dit.transformer_blocks.1.attn1.to_out.0.bias                                torch.Size([1152])              True
  676  model.dit.transformer_blocks.1.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  677  model.dit.transformer_blocks.1.attn2.to_q.bias                                    torch.Size([1152])              True
  678  model.dit.transformer_blocks.1.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  679  model.dit.transformer_blocks.1.attn2.to_k.bias                                    torch.Size([1152])              True
  680  model.dit.transformer_blocks.1.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  681  model.dit.transformer_blocks.1.attn2.to_v.bias                                    torch.Size([1152])              True
  682  model.dit.transformer_blocks.1.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  683  model.dit.transformer_blocks.1.attn2.to_out.0.bias                                torch.Size([1152])              True
  684  model.dit.transformer_blocks.1.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  685  model.dit.transformer_blocks.1.ff.conv_inverted.bias                              torch.Size([5760])              True
  686  model.dit.transformer_blocks.1.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  687  model.dit.transformer_blocks.1.ff.conv_depth.bias                                 torch.Size([5760])              True
  688  model.dit.transformer_blocks.1.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  689  model.dit.transformer_blocks.2.scale_shift_table                                  torch.Size([6, 1152])           True
  690  model.dit.transformer_blocks.2.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  691  model.dit.transformer_blocks.2.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  692  model.dit.transformer_blocks.2.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  693  model.dit.transformer_blocks.2.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  694  model.dit.transformer_blocks.2.attn1.to_out.0.bias                                torch.Size([1152])              True
  695  model.dit.transformer_blocks.2.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  696  model.dit.transformer_blocks.2.attn2.to_q.bias                                    torch.Size([1152])              True
  697  model.dit.transformer_blocks.2.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  698  model.dit.transformer_blocks.2.attn2.to_k.bias                                    torch.Size([1152])              True
  699  model.dit.transformer_blocks.2.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  700  model.dit.transformer_blocks.2.attn2.to_v.bias                                    torch.Size([1152])              True
  701  model.dit.transformer_blocks.2.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  702  model.dit.transformer_blocks.2.attn2.to_out.0.bias                                torch.Size([1152])              True
  703  model.dit.transformer_blocks.2.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  704  model.dit.transformer_blocks.2.ff.conv_inverted.bias                              torch.Size([5760])              True
  705  model.dit.transformer_blocks.2.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  706  model.dit.transformer_blocks.2.ff.conv_depth.bias                                 torch.Size([5760])              True
  707  model.dit.transformer_blocks.2.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  708  model.dit.transformer_blocks.3.scale_shift_table                                  torch.Size([6, 1152])           True
  709  model.dit.transformer_blocks.3.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  710  model.dit.transformer_blocks.3.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  711  model.dit.transformer_blocks.3.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  712  model.dit.transformer_blocks.3.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  713  model.dit.transformer_blocks.3.attn1.to_out.0.bias                                torch.Size([1152])              True
  714  model.dit.transformer_blocks.3.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  715  model.dit.transformer_blocks.3.attn2.to_q.bias                                    torch.Size([1152])              True
  716  model.dit.transformer_blocks.3.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  717  model.dit.transformer_blocks.3.attn2.to_k.bias                                    torch.Size([1152])              True
  718  model.dit.transformer_blocks.3.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  719  model.dit.transformer_blocks.3.attn2.to_v.bias                                    torch.Size([1152])              True
  720  model.dit.transformer_blocks.3.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  721  model.dit.transformer_blocks.3.attn2.to_out.0.bias                                torch.Size([1152])              True
  722  model.dit.transformer_blocks.3.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  723  model.dit.transformer_blocks.3.ff.conv_inverted.bias                              torch.Size([5760])              True
  724  model.dit.transformer_blocks.3.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  725  model.dit.transformer_blocks.3.ff.conv_depth.bias                                 torch.Size([5760])              True
  726  model.dit.transformer_blocks.3.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  727  model.dit.transformer_blocks.4.scale_shift_table                                  torch.Size([6, 1152])           True
  728  model.dit.transformer_blocks.4.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  729  model.dit.transformer_blocks.4.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  730  model.dit.transformer_blocks.4.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  731  model.dit.transformer_blocks.4.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  732  model.dit.transformer_blocks.4.attn1.to_out.0.bias                                torch.Size([1152])              True
  733  model.dit.transformer_blocks.4.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  734  model.dit.transformer_blocks.4.attn2.to_q.bias                                    torch.Size([1152])              True
  735  model.dit.transformer_blocks.4.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  736  model.dit.transformer_blocks.4.attn2.to_k.bias                                    torch.Size([1152])              True
  737  model.dit.transformer_blocks.4.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  738  model.dit.transformer_blocks.4.attn2.to_v.bias                                    torch.Size([1152])              True
  739  model.dit.transformer_blocks.4.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  740  model.dit.transformer_blocks.4.attn2.to_out.0.bias                                torch.Size([1152])              True
  741  model.dit.transformer_blocks.4.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  742  model.dit.transformer_blocks.4.ff.conv_inverted.bias                              torch.Size([5760])              True
  743  model.dit.transformer_blocks.4.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  744  model.dit.transformer_blocks.4.ff.conv_depth.bias                                 torch.Size([5760])              True
  745  model.dit.transformer_blocks.4.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  746  model.dit.transformer_blocks.5.scale_shift_table                                  torch.Size([6, 1152])           True
  747  model.dit.transformer_blocks.5.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  748  model.dit.transformer_blocks.5.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  749  model.dit.transformer_blocks.5.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  750  model.dit.transformer_blocks.5.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  751  model.dit.transformer_blocks.5.attn1.to_out.0.bias                                torch.Size([1152])              True
  752  model.dit.transformer_blocks.5.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  753  model.dit.transformer_blocks.5.attn2.to_q.bias                                    torch.Size([1152])              True
  754  model.dit.transformer_blocks.5.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  755  model.dit.transformer_blocks.5.attn2.to_k.bias                                    torch.Size([1152])              True
  756  model.dit.transformer_blocks.5.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  757  model.dit.transformer_blocks.5.attn2.to_v.bias                                    torch.Size([1152])              True
  758  model.dit.transformer_blocks.5.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  759  model.dit.transformer_blocks.5.attn2.to_out.0.bias                                torch.Size([1152])              True
  760  model.dit.transformer_blocks.5.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  761  model.dit.transformer_blocks.5.ff.conv_inverted.bias                              torch.Size([5760])              True
  762  model.dit.transformer_blocks.5.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  763  model.dit.transformer_blocks.5.ff.conv_depth.bias                                 torch.Size([5760])              True
  764  model.dit.transformer_blocks.5.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  765  model.dit.transformer_blocks.6.scale_shift_table                                  torch.Size([6, 1152])           True
  766  model.dit.transformer_blocks.6.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  767  model.dit.transformer_blocks.6.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  768  model.dit.transformer_blocks.6.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  769  model.dit.transformer_blocks.6.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  770  model.dit.transformer_blocks.6.attn1.to_out.0.bias                                torch.Size([1152])              True
  771  model.dit.transformer_blocks.6.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  772  model.dit.transformer_blocks.6.attn2.to_q.bias                                    torch.Size([1152])              True
  773  model.dit.transformer_blocks.6.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  774  model.dit.transformer_blocks.6.attn2.to_k.bias                                    torch.Size([1152])              True
  775  model.dit.transformer_blocks.6.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  776  model.dit.transformer_blocks.6.attn2.to_v.bias                                    torch.Size([1152])              True
  777  model.dit.transformer_blocks.6.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  778  model.dit.transformer_blocks.6.attn2.to_out.0.bias                                torch.Size([1152])              True
  779  model.dit.transformer_blocks.6.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  780  model.dit.transformer_blocks.6.ff.conv_inverted.bias                              torch.Size([5760])              True
  781  model.dit.transformer_blocks.6.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  782  model.dit.transformer_blocks.6.ff.conv_depth.bias                                 torch.Size([5760])              True
  783  model.dit.transformer_blocks.6.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  784  model.dit.transformer_blocks.7.scale_shift_table                                  torch.Size([6, 1152])           True
  785  model.dit.transformer_blocks.7.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  786  model.dit.transformer_blocks.7.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  787  model.dit.transformer_blocks.7.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  788  model.dit.transformer_blocks.7.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  789  model.dit.transformer_blocks.7.attn1.to_out.0.bias                                torch.Size([1152])              True
  790  model.dit.transformer_blocks.7.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  791  model.dit.transformer_blocks.7.attn2.to_q.bias                                    torch.Size([1152])              True
  792  model.dit.transformer_blocks.7.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  793  model.dit.transformer_blocks.7.attn2.to_k.bias                                    torch.Size([1152])              True
  794  model.dit.transformer_blocks.7.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  795  model.dit.transformer_blocks.7.attn2.to_v.bias                                    torch.Size([1152])              True
  796  model.dit.transformer_blocks.7.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  797  model.dit.transformer_blocks.7.attn2.to_out.0.bias                                torch.Size([1152])              True
  798  model.dit.transformer_blocks.7.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  799  model.dit.transformer_blocks.7.ff.conv_inverted.bias                              torch.Size([5760])              True
  800  model.dit.transformer_blocks.7.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  801  model.dit.transformer_blocks.7.ff.conv_depth.bias                                 torch.Size([5760])              True
  802  model.dit.transformer_blocks.7.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  803  model.dit.transformer_blocks.8.scale_shift_table                                  torch.Size([6, 1152])           True
  804  model.dit.transformer_blocks.8.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  805  model.dit.transformer_blocks.8.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  806  model.dit.transformer_blocks.8.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  807  model.dit.transformer_blocks.8.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  808  model.dit.transformer_blocks.8.attn1.to_out.0.bias                                torch.Size([1152])              True
  809  model.dit.transformer_blocks.8.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  810  model.dit.transformer_blocks.8.attn2.to_q.bias                                    torch.Size([1152])              True
  811  model.dit.transformer_blocks.8.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  812  model.dit.transformer_blocks.8.attn2.to_k.bias                                    torch.Size([1152])              True
  813  model.dit.transformer_blocks.8.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  814  model.dit.transformer_blocks.8.attn2.to_v.bias                                    torch.Size([1152])              True
  815  model.dit.transformer_blocks.8.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  816  model.dit.transformer_blocks.8.attn2.to_out.0.bias                                torch.Size([1152])              True
  817  model.dit.transformer_blocks.8.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  818  model.dit.transformer_blocks.8.ff.conv_inverted.bias                              torch.Size([5760])              True
  819  model.dit.transformer_blocks.8.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  820  model.dit.transformer_blocks.8.ff.conv_depth.bias                                 torch.Size([5760])              True
  821  model.dit.transformer_blocks.8.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  822  model.dit.transformer_blocks.9.scale_shift_table                                  torch.Size([6, 1152])           True
  823  model.dit.transformer_blocks.9.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  824  model.dit.transformer_blocks.9.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  825  model.dit.transformer_blocks.9.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  826  model.dit.transformer_blocks.9.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  827  model.dit.transformer_blocks.9.attn1.to_out.0.bias                                torch.Size([1152])              True
  828  model.dit.transformer_blocks.9.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  829  model.dit.transformer_blocks.9.attn2.to_q.bias                                    torch.Size([1152])              True
  830  model.dit.transformer_blocks.9.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  831  model.dit.transformer_blocks.9.attn2.to_k.bias                                    torch.Size([1152])              True
  832  model.dit.transformer_blocks.9.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  833  model.dit.transformer_blocks.9.attn2.to_v.bias                                    torch.Size([1152])              True
  834  model.dit.transformer_blocks.9.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  835  model.dit.transformer_blocks.9.attn2.to_out.0.bias                                torch.Size([1152])              True
  836  model.dit.transformer_blocks.9.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  837  model.dit.transformer_blocks.9.ff.conv_inverted.bias                              torch.Size([5760])              True
  838  model.dit.transformer_blocks.9.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  839  model.dit.transformer_blocks.9.ff.conv_depth.bias                                 torch.Size([5760])              True
  840  model.dit.transformer_blocks.9.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  841  model.dit.transformer_blocks.10.scale_shift_table                                 torch.Size([6, 1152])           True
  842  model.dit.transformer_blocks.10.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  843  model.dit.transformer_blocks.10.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  844  model.dit.transformer_blocks.10.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  845  model.dit.transformer_blocks.10.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  846  model.dit.transformer_blocks.10.attn1.to_out.0.bias                               torch.Size([1152])              True
  847  model.dit.transformer_blocks.10.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  848  model.dit.transformer_blocks.10.attn2.to_q.bias                                   torch.Size([1152])              True
  849  model.dit.transformer_blocks.10.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  850  model.dit.transformer_blocks.10.attn2.to_k.bias                                   torch.Size([1152])              True
  851  model.dit.transformer_blocks.10.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  852  model.dit.transformer_blocks.10.attn2.to_v.bias                                   torch.Size([1152])              True
  853  model.dit.transformer_blocks.10.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  854  model.dit.transformer_blocks.10.attn2.to_out.0.bias                               torch.Size([1152])              True
  855  model.dit.transformer_blocks.10.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  856  model.dit.transformer_blocks.10.ff.conv_inverted.bias                             torch.Size([5760])              True
  857  model.dit.transformer_blocks.10.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  858  model.dit.transformer_blocks.10.ff.conv_depth.bias                                torch.Size([5760])              True
  859  model.dit.transformer_blocks.10.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  860  model.dit.transformer_blocks.11.scale_shift_table                                 torch.Size([6, 1152])           True
  861  model.dit.transformer_blocks.11.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  862  model.dit.transformer_blocks.11.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  863  model.dit.transformer_blocks.11.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  864  model.dit.transformer_blocks.11.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  865  model.dit.transformer_blocks.11.attn1.to_out.0.bias                               torch.Size([1152])              True
  866  model.dit.transformer_blocks.11.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  867  model.dit.transformer_blocks.11.attn2.to_q.bias                                   torch.Size([1152])              True
  868  model.dit.transformer_blocks.11.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  869  model.dit.transformer_blocks.11.attn2.to_k.bias                                   torch.Size([1152])              True
  870  model.dit.transformer_blocks.11.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  871  model.dit.transformer_blocks.11.attn2.to_v.bias                                   torch.Size([1152])              True
  872  model.dit.transformer_blocks.11.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  873  model.dit.transformer_blocks.11.attn2.to_out.0.bias                               torch.Size([1152])              True
  874  model.dit.transformer_blocks.11.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  875  model.dit.transformer_blocks.11.ff.conv_inverted.bias                             torch.Size([5760])              True
  876  model.dit.transformer_blocks.11.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  877  model.dit.transformer_blocks.11.ff.conv_depth.bias                                torch.Size([5760])              True
  878  model.dit.transformer_blocks.11.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  879  model.dit.transformer_blocks.12.scale_shift_table                                 torch.Size([6, 1152])           True
  880  model.dit.transformer_blocks.12.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  881  model.dit.transformer_blocks.12.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  882  model.dit.transformer_blocks.12.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  883  model.dit.transformer_blocks.12.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  884  model.dit.transformer_blocks.12.attn1.to_out.0.bias                               torch.Size([1152])              True
  885  model.dit.transformer_blocks.12.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  886  model.dit.transformer_blocks.12.attn2.to_q.bias                                   torch.Size([1152])              True
  887  model.dit.transformer_blocks.12.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  888  model.dit.transformer_blocks.12.attn2.to_k.bias                                   torch.Size([1152])              True
  889  model.dit.transformer_blocks.12.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  890  model.dit.transformer_blocks.12.attn2.to_v.bias                                   torch.Size([1152])              True
  891  model.dit.transformer_blocks.12.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  892  model.dit.transformer_blocks.12.attn2.to_out.0.bias                               torch.Size([1152])              True
  893  model.dit.transformer_blocks.12.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  894  model.dit.transformer_blocks.12.ff.conv_inverted.bias                             torch.Size([5760])              True
  895  model.dit.transformer_blocks.12.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  896  model.dit.transformer_blocks.12.ff.conv_depth.bias                                torch.Size([5760])              True
  897  model.dit.transformer_blocks.12.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  898  model.dit.transformer_blocks.13.scale_shift_table                                 torch.Size([6, 1152])           True
  899  model.dit.transformer_blocks.13.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  900  model.dit.transformer_blocks.13.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  901  model.dit.transformer_blocks.13.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  902  model.dit.transformer_blocks.13.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  903  model.dit.transformer_blocks.13.attn1.to_out.0.bias                               torch.Size([1152])              True
  904  model.dit.transformer_blocks.13.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  905  model.dit.transformer_blocks.13.attn2.to_q.bias                                   torch.Size([1152])              True
  906  model.dit.transformer_blocks.13.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  907  model.dit.transformer_blocks.13.attn2.to_k.bias                                   torch.Size([1152])              True
  908  model.dit.transformer_blocks.13.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  909  model.dit.transformer_blocks.13.attn2.to_v.bias                                   torch.Size([1152])              True
  910  model.dit.transformer_blocks.13.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  911  model.dit.transformer_blocks.13.attn2.to_out.0.bias                               torch.Size([1152])              True
  912  model.dit.transformer_blocks.13.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  913  model.dit.transformer_blocks.13.ff.conv_inverted.bias                             torch.Size([5760])              True
  914  model.dit.transformer_blocks.13.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  915  model.dit.transformer_blocks.13.ff.conv_depth.bias                                torch.Size([5760])              True
  916  model.dit.transformer_blocks.13.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  917  model.dit.transformer_blocks.14.scale_shift_table                                 torch.Size([6, 1152])           True
  918  model.dit.transformer_blocks.14.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  919  model.dit.transformer_blocks.14.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  920  model.dit.transformer_blocks.14.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  921  model.dit.transformer_blocks.14.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  922  model.dit.transformer_blocks.14.attn1.to_out.0.bias                               torch.Size([1152])              True
  923  model.dit.transformer_blocks.14.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  924  model.dit.transformer_blocks.14.attn2.to_q.bias                                   torch.Size([1152])              True
  925  model.dit.transformer_blocks.14.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  926  model.dit.transformer_blocks.14.attn2.to_k.bias                                   torch.Size([1152])              True
  927  model.dit.transformer_blocks.14.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  928  model.dit.transformer_blocks.14.attn2.to_v.bias                                   torch.Size([1152])              True
  929  model.dit.transformer_blocks.14.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  930  model.dit.transformer_blocks.14.attn2.to_out.0.bias                               torch.Size([1152])              True
  931  model.dit.transformer_blocks.14.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  932  model.dit.transformer_blocks.14.ff.conv_inverted.bias                             torch.Size([5760])              True
  933  model.dit.transformer_blocks.14.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  934  model.dit.transformer_blocks.14.ff.conv_depth.bias                                torch.Size([5760])              True
  935  model.dit.transformer_blocks.14.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  936  model.dit.transformer_blocks.15.scale_shift_table                                 torch.Size([6, 1152])           True
  937  model.dit.transformer_blocks.15.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  938  model.dit.transformer_blocks.15.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  939  model.dit.transformer_blocks.15.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  940  model.dit.transformer_blocks.15.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  941  model.dit.transformer_blocks.15.attn1.to_out.0.bias                               torch.Size([1152])              True
  942  model.dit.transformer_blocks.15.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  943  model.dit.transformer_blocks.15.attn2.to_q.bias                                   torch.Size([1152])              True
  944  model.dit.transformer_blocks.15.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  945  model.dit.transformer_blocks.15.attn2.to_k.bias                                   torch.Size([1152])              True
  946  model.dit.transformer_blocks.15.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  947  model.dit.transformer_blocks.15.attn2.to_v.bias                                   torch.Size([1152])              True
  948  model.dit.transformer_blocks.15.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  949  model.dit.transformer_blocks.15.attn2.to_out.0.bias                               torch.Size([1152])              True
  950  model.dit.transformer_blocks.15.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  951  model.dit.transformer_blocks.15.ff.conv_inverted.bias                             torch.Size([5760])              True
  952  model.dit.transformer_blocks.15.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  953  model.dit.transformer_blocks.15.ff.conv_depth.bias                                torch.Size([5760])              True
  954  model.dit.transformer_blocks.15.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  955  model.dit.transformer_blocks.16.scale_shift_table                                 torch.Size([6, 1152])           True
  956  model.dit.transformer_blocks.16.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  957  model.dit.transformer_blocks.16.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  958  model.dit.transformer_blocks.16.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  959  model.dit.transformer_blocks.16.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  960  model.dit.transformer_blocks.16.attn1.to_out.0.bias                               torch.Size([1152])              True
  961  model.dit.transformer_blocks.16.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  962  model.dit.transformer_blocks.16.attn2.to_q.bias                                   torch.Size([1152])              True
  963  model.dit.transformer_blocks.16.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  964  model.dit.transformer_blocks.16.attn2.to_k.bias                                   torch.Size([1152])              True
  965  model.dit.transformer_blocks.16.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  966  model.dit.transformer_blocks.16.attn2.to_v.bias                                   torch.Size([1152])              True
  967  model.dit.transformer_blocks.16.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  968  model.dit.transformer_blocks.16.attn2.to_out.0.bias                               torch.Size([1152])              True
  969  model.dit.transformer_blocks.16.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  970  model.dit.transformer_blocks.16.ff.conv_inverted.bias                             torch.Size([5760])              True
  971  model.dit.transformer_blocks.16.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  972  model.dit.transformer_blocks.16.ff.conv_depth.bias                                torch.Size([5760])              True
  973  model.dit.transformer_blocks.16.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  974  model.dit.transformer_blocks.17.scale_shift_table                                 torch.Size([6, 1152])           True
  975  model.dit.transformer_blocks.17.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  976  model.dit.transformer_blocks.17.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  977  model.dit.transformer_blocks.17.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  978  model.dit.transformer_blocks.17.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  979  model.dit.transformer_blocks.17.attn1.to_out.0.bias                               torch.Size([1152])              True
  980  model.dit.transformer_blocks.17.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  981  model.dit.transformer_blocks.17.attn2.to_q.bias                                   torch.Size([1152])              True
  982  model.dit.transformer_blocks.17.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  983  model.dit.transformer_blocks.17.attn2.to_k.bias                                   torch.Size([1152])              True
  984  model.dit.transformer_blocks.17.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  985  model.dit.transformer_blocks.17.attn2.to_v.bias                                   torch.Size([1152])              True
  986  model.dit.transformer_blocks.17.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  987  model.dit.transformer_blocks.17.attn2.to_out.0.bias                               torch.Size([1152])              True
  988  model.dit.transformer_blocks.17.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  989  model.dit.transformer_blocks.17.ff.conv_inverted.bias                             torch.Size([5760])              True
  990  model.dit.transformer_blocks.17.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  991  model.dit.transformer_blocks.17.ff.conv_depth.bias                                torch.Size([5760])              True
  992  model.dit.transformer_blocks.17.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  993  model.dit.transformer_blocks.18.scale_shift_table                                 torch.Size([6, 1152])           True
  994  model.dit.transformer_blocks.18.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  995  model.dit.transformer_blocks.18.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  996  model.dit.transformer_blocks.18.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  997  model.dit.transformer_blocks.18.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  998  model.dit.transformer_blocks.18.attn1.to_out.0.bias                               torch.Size([1152])              True
  999  model.dit.transformer_blocks.18.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1000  model.dit.transformer_blocks.18.attn2.to_q.bias                                   torch.Size([1152])              True
 1001  model.dit.transformer_blocks.18.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1002  model.dit.transformer_blocks.18.attn2.to_k.bias                                   torch.Size([1152])              True
 1003  model.dit.transformer_blocks.18.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1004  model.dit.transformer_blocks.18.attn2.to_v.bias                                   torch.Size([1152])              True
 1005  model.dit.transformer_blocks.18.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1006  model.dit.transformer_blocks.18.attn2.to_out.0.bias                               torch.Size([1152])              True
 1007  model.dit.transformer_blocks.18.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1008  model.dit.transformer_blocks.18.ff.conv_inverted.bias                             torch.Size([5760])              True
 1009  model.dit.transformer_blocks.18.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1010  model.dit.transformer_blocks.18.ff.conv_depth.bias                                torch.Size([5760])              True
 1011  model.dit.transformer_blocks.18.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1012  model.dit.transformer_blocks.19.scale_shift_table                                 torch.Size([6, 1152])           True
 1013  model.dit.transformer_blocks.19.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1014  model.dit.transformer_blocks.19.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1015  model.dit.transformer_blocks.19.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1016  model.dit.transformer_blocks.19.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1017  model.dit.transformer_blocks.19.attn1.to_out.0.bias                               torch.Size([1152])              True
 1018  model.dit.transformer_blocks.19.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1019  model.dit.transformer_blocks.19.attn2.to_q.bias                                   torch.Size([1152])              True
 1020  model.dit.transformer_blocks.19.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1021  model.dit.transformer_blocks.19.attn2.to_k.bias                                   torch.Size([1152])              True
 1022  model.dit.transformer_blocks.19.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1023  model.dit.transformer_blocks.19.attn2.to_v.bias                                   torch.Size([1152])              True
 1024  model.dit.transformer_blocks.19.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1025  model.dit.transformer_blocks.19.attn2.to_out.0.bias                               torch.Size([1152])              True
 1026  model.dit.transformer_blocks.19.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1027  model.dit.transformer_blocks.19.ff.conv_inverted.bias                             torch.Size([5760])              True
 1028  model.dit.transformer_blocks.19.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1029  model.dit.transformer_blocks.19.ff.conv_depth.bias                                torch.Size([5760])              True
 1030  model.dit.transformer_blocks.19.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1031  model.dit.transformer_blocks.20.scale_shift_table                                 torch.Size([6, 1152])           True
 1032  model.dit.transformer_blocks.20.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1033  model.dit.transformer_blocks.20.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1034  model.dit.transformer_blocks.20.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1035  model.dit.transformer_blocks.20.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1036  model.dit.transformer_blocks.20.attn1.to_out.0.bias                               torch.Size([1152])              True
 1037  model.dit.transformer_blocks.20.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1038  model.dit.transformer_blocks.20.attn2.to_q.bias                                   torch.Size([1152])              True
 1039  model.dit.transformer_blocks.20.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1040  model.dit.transformer_blocks.20.attn2.to_k.bias                                   torch.Size([1152])              True
 1041  model.dit.transformer_blocks.20.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1042  model.dit.transformer_blocks.20.attn2.to_v.bias                                   torch.Size([1152])              True
 1043  model.dit.transformer_blocks.20.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1044  model.dit.transformer_blocks.20.attn2.to_out.0.bias                               torch.Size([1152])              True
 1045  model.dit.transformer_blocks.20.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1046  model.dit.transformer_blocks.20.ff.conv_inverted.bias                             torch.Size([5760])              True
 1047  model.dit.transformer_blocks.20.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1048  model.dit.transformer_blocks.20.ff.conv_depth.bias                                torch.Size([5760])              True
 1049  model.dit.transformer_blocks.20.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1050  model.dit.transformer_blocks.21.scale_shift_table                                 torch.Size([6, 1152])           True
 1051  model.dit.transformer_blocks.21.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1052  model.dit.transformer_blocks.21.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1053  model.dit.transformer_blocks.21.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1054  model.dit.transformer_blocks.21.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1055  model.dit.transformer_blocks.21.attn1.to_out.0.bias                               torch.Size([1152])              True
 1056  model.dit.transformer_blocks.21.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1057  model.dit.transformer_blocks.21.attn2.to_q.bias                                   torch.Size([1152])              True
 1058  model.dit.transformer_blocks.21.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1059  model.dit.transformer_blocks.21.attn2.to_k.bias                                   torch.Size([1152])              True
 1060  model.dit.transformer_blocks.21.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1061  model.dit.transformer_blocks.21.attn2.to_v.bias                                   torch.Size([1152])              True
 1062  model.dit.transformer_blocks.21.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1063  model.dit.transformer_blocks.21.attn2.to_out.0.bias                               torch.Size([1152])              True
 1064  model.dit.transformer_blocks.21.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1065  model.dit.transformer_blocks.21.ff.conv_inverted.bias                             torch.Size([5760])              True
 1066  model.dit.transformer_blocks.21.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1067  model.dit.transformer_blocks.21.ff.conv_depth.bias                                torch.Size([5760])              True
 1068  model.dit.transformer_blocks.21.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1069  model.dit.transformer_blocks.22.scale_shift_table                                 torch.Size([6, 1152])           True
 1070  model.dit.transformer_blocks.22.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1071  model.dit.transformer_blocks.22.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1072  model.dit.transformer_blocks.22.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1073  model.dit.transformer_blocks.22.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1074  model.dit.transformer_blocks.22.attn1.to_out.0.bias                               torch.Size([1152])              True
 1075  model.dit.transformer_blocks.22.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1076  model.dit.transformer_blocks.22.attn2.to_q.bias                                   torch.Size([1152])              True
 1077  model.dit.transformer_blocks.22.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1078  model.dit.transformer_blocks.22.attn2.to_k.bias                                   torch.Size([1152])              True
 1079  model.dit.transformer_blocks.22.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1080  model.dit.transformer_blocks.22.attn2.to_v.bias                                   torch.Size([1152])              True
 1081  model.dit.transformer_blocks.22.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1082  model.dit.transformer_blocks.22.attn2.to_out.0.bias                               torch.Size([1152])              True
 1083  model.dit.transformer_blocks.22.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1084  model.dit.transformer_blocks.22.ff.conv_inverted.bias                             torch.Size([5760])              True
 1085  model.dit.transformer_blocks.22.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1086  model.dit.transformer_blocks.22.ff.conv_depth.bias                                torch.Size([5760])              True
 1087  model.dit.transformer_blocks.22.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1088  model.dit.transformer_blocks.23.scale_shift_table                                 torch.Size([6, 1152])           True
 1089  model.dit.transformer_blocks.23.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1090  model.dit.transformer_blocks.23.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1091  model.dit.transformer_blocks.23.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1092  model.dit.transformer_blocks.23.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1093  model.dit.transformer_blocks.23.attn1.to_out.0.bias                               torch.Size([1152])              True
 1094  model.dit.transformer_blocks.23.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1095  model.dit.transformer_blocks.23.attn2.to_q.bias                                   torch.Size([1152])              True
 1096  model.dit.transformer_blocks.23.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1097  model.dit.transformer_blocks.23.attn2.to_k.bias                                   torch.Size([1152])              True
 1098  model.dit.transformer_blocks.23.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1099  model.dit.transformer_blocks.23.attn2.to_v.bias                                   torch.Size([1152])              True
 1100  model.dit.transformer_blocks.23.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1101  model.dit.transformer_blocks.23.attn2.to_out.0.bias                               torch.Size([1152])              True
 1102  model.dit.transformer_blocks.23.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1103  model.dit.transformer_blocks.23.ff.conv_inverted.bias                             torch.Size([5760])              True
 1104  model.dit.transformer_blocks.23.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1105  model.dit.transformer_blocks.23.ff.conv_depth.bias                                torch.Size([5760])              True
 1106  model.dit.transformer_blocks.23.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1107  model.dit.transformer_blocks.24.scale_shift_table                                 torch.Size([6, 1152])           True
 1108  model.dit.transformer_blocks.24.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1109  model.dit.transformer_blocks.24.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1110  model.dit.transformer_blocks.24.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1111  model.dit.transformer_blocks.24.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1112  model.dit.transformer_blocks.24.attn1.to_out.0.bias                               torch.Size([1152])              True
 1113  model.dit.transformer_blocks.24.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1114  model.dit.transformer_blocks.24.attn2.to_q.bias                                   torch.Size([1152])              True
 1115  model.dit.transformer_blocks.24.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1116  model.dit.transformer_blocks.24.attn2.to_k.bias                                   torch.Size([1152])              True
 1117  model.dit.transformer_blocks.24.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1118  model.dit.transformer_blocks.24.attn2.to_v.bias                                   torch.Size([1152])              True
 1119  model.dit.transformer_blocks.24.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1120  model.dit.transformer_blocks.24.attn2.to_out.0.bias                               torch.Size([1152])              True
 1121  model.dit.transformer_blocks.24.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1122  model.dit.transformer_blocks.24.ff.conv_inverted.bias                             torch.Size([5760])              True
 1123  model.dit.transformer_blocks.24.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1124  model.dit.transformer_blocks.24.ff.conv_depth.bias                                torch.Size([5760])              True
 1125  model.dit.transformer_blocks.24.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1126  model.dit.transformer_blocks.25.scale_shift_table                                 torch.Size([6, 1152])           True
 1127  model.dit.transformer_blocks.25.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1128  model.dit.transformer_blocks.25.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1129  model.dit.transformer_blocks.25.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1130  model.dit.transformer_blocks.25.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1131  model.dit.transformer_blocks.25.attn1.to_out.0.bias                               torch.Size([1152])              True
 1132  model.dit.transformer_blocks.25.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1133  model.dit.transformer_blocks.25.attn2.to_q.bias                                   torch.Size([1152])              True
 1134  model.dit.transformer_blocks.25.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1135  model.dit.transformer_blocks.25.attn2.to_k.bias                                   torch.Size([1152])              True
 1136  model.dit.transformer_blocks.25.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1137  model.dit.transformer_blocks.25.attn2.to_v.bias                                   torch.Size([1152])              True
 1138  model.dit.transformer_blocks.25.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1139  model.dit.transformer_blocks.25.attn2.to_out.0.bias                               torch.Size([1152])              True
 1140  model.dit.transformer_blocks.25.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1141  model.dit.transformer_blocks.25.ff.conv_inverted.bias                             torch.Size([5760])              True
 1142  model.dit.transformer_blocks.25.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1143  model.dit.transformer_blocks.25.ff.conv_depth.bias                                torch.Size([5760])              True
 1144  model.dit.transformer_blocks.25.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1145  model.dit.transformer_blocks.26.scale_shift_table                                 torch.Size([6, 1152])           True
 1146  model.dit.transformer_blocks.26.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1147  model.dit.transformer_blocks.26.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1148  model.dit.transformer_blocks.26.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1149  model.dit.transformer_blocks.26.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1150  model.dit.transformer_blocks.26.attn1.to_out.0.bias                               torch.Size([1152])              True
 1151  model.dit.transformer_blocks.26.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1152  model.dit.transformer_blocks.26.attn2.to_q.bias                                   torch.Size([1152])              True
 1153  model.dit.transformer_blocks.26.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1154  model.dit.transformer_blocks.26.attn2.to_k.bias                                   torch.Size([1152])              True
 1155  model.dit.transformer_blocks.26.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1156  model.dit.transformer_blocks.26.attn2.to_v.bias                                   torch.Size([1152])              True
 1157  model.dit.transformer_blocks.26.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1158  model.dit.transformer_blocks.26.attn2.to_out.0.bias                               torch.Size([1152])              True
 1159  model.dit.transformer_blocks.26.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1160  model.dit.transformer_blocks.26.ff.conv_inverted.bias                             torch.Size([5760])              True
 1161  model.dit.transformer_blocks.26.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1162  model.dit.transformer_blocks.26.ff.conv_depth.bias                                torch.Size([5760])              True
 1163  model.dit.transformer_blocks.26.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1164  model.dit.transformer_blocks.27.scale_shift_table                                 torch.Size([6, 1152])           True
 1165  model.dit.transformer_blocks.27.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1166  model.dit.transformer_blocks.27.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1167  model.dit.transformer_blocks.27.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1168  model.dit.transformer_blocks.27.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1169  model.dit.transformer_blocks.27.attn1.to_out.0.bias                               torch.Size([1152])              True
 1170  model.dit.transformer_blocks.27.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1171  model.dit.transformer_blocks.27.attn2.to_q.bias                                   torch.Size([1152])              True
 1172  model.dit.transformer_blocks.27.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1173  model.dit.transformer_blocks.27.attn2.to_k.bias                                   torch.Size([1152])              True
 1174  model.dit.transformer_blocks.27.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1175  model.dit.transformer_blocks.27.attn2.to_v.bias                                   torch.Size([1152])              True
 1176  model.dit.transformer_blocks.27.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1177  model.dit.transformer_blocks.27.attn2.to_out.0.bias                               torch.Size([1152])              True
 1178  model.dit.transformer_blocks.27.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1179  model.dit.transformer_blocks.27.ff.conv_inverted.bias                             torch.Size([5760])              True
 1180  model.dit.transformer_blocks.27.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1181  model.dit.transformer_blocks.27.ff.conv_depth.bias                                torch.Size([5760])              True
 1182  model.dit.transformer_blocks.27.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1183  model.dit.proj_out.weight                                                         torch.Size([32, 1152])          True
 1184  model.dit.proj_out.bias                                                           torch.Size([32])                True
 1185  model.vae_decoder.decoder.conv_in.weight                                          torch.Size([1024, 32, 3, 3])    False
 1186  model.vae_decoder.decoder.conv_in.bias                                            torch.Size([1024])              False
 1187  model.vae_decoder.decoder.up_blocks.0.0.conv.weight                               torch.Size([128, 256, 3, 3])    False
 1188  model.vae_decoder.decoder.up_blocks.0.0.conv.bias                                 torch.Size([128])               False
 1189  model.vae_decoder.decoder.up_blocks.0.1.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1190  model.vae_decoder.decoder.up_blocks.0.1.conv1.bias                                torch.Size([128])               False
 1191  model.vae_decoder.decoder.up_blocks.0.1.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1192  model.vae_decoder.decoder.up_blocks.0.1.norm.weight                               torch.Size([128])               False
 1193  model.vae_decoder.decoder.up_blocks.0.1.norm.bias                                 torch.Size([128])               False
 1194  model.vae_decoder.decoder.up_blocks.0.2.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1195  model.vae_decoder.decoder.up_blocks.0.2.conv1.bias                                torch.Size([128])               False
 1196  model.vae_decoder.decoder.up_blocks.0.2.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1197  model.vae_decoder.decoder.up_blocks.0.2.norm.weight                               torch.Size([128])               False
 1198  model.vae_decoder.decoder.up_blocks.0.2.norm.bias                                 torch.Size([128])               False
 1199  model.vae_decoder.decoder.up_blocks.0.3.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1200  model.vae_decoder.decoder.up_blocks.0.3.conv1.bias                                torch.Size([128])               False
 1201  model.vae_decoder.decoder.up_blocks.0.3.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1202  model.vae_decoder.decoder.up_blocks.0.3.norm.weight                               torch.Size([128])               False
 1203  model.vae_decoder.decoder.up_blocks.0.3.norm.bias                                 torch.Size([128])               False
 1204  model.vae_decoder.decoder.up_blocks.1.0.conv.weight                               torch.Size([256, 512, 3, 3])    False
 1205  model.vae_decoder.decoder.up_blocks.1.0.conv.bias                                 torch.Size([256])               False
 1206  model.vae_decoder.decoder.up_blocks.1.1.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1207  model.vae_decoder.decoder.up_blocks.1.1.conv1.bias                                torch.Size([256])               False
 1208  model.vae_decoder.decoder.up_blocks.1.1.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1209  model.vae_decoder.decoder.up_blocks.1.1.norm.weight                               torch.Size([256])               False
 1210  model.vae_decoder.decoder.up_blocks.1.1.norm.bias                                 torch.Size([256])               False
 1211  model.vae_decoder.decoder.up_blocks.1.2.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1212  model.vae_decoder.decoder.up_blocks.1.2.conv1.bias                                torch.Size([256])               False
 1213  model.vae_decoder.decoder.up_blocks.1.2.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1214  model.vae_decoder.decoder.up_blocks.1.2.norm.weight                               torch.Size([256])               False
 1215  model.vae_decoder.decoder.up_blocks.1.2.norm.bias                                 torch.Size([256])               False
 1216  model.vae_decoder.decoder.up_blocks.1.3.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1217  model.vae_decoder.decoder.up_blocks.1.3.conv1.bias                                torch.Size([256])               False
 1218  model.vae_decoder.decoder.up_blocks.1.3.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1219  model.vae_decoder.decoder.up_blocks.1.3.norm.weight                               torch.Size([256])               False
 1220  model.vae_decoder.decoder.up_blocks.1.3.norm.bias                                 torch.Size([256])               False
 1221  model.vae_decoder.decoder.up_blocks.2.0.conv.weight                               torch.Size([512, 512, 3, 3])    False
 1222  model.vae_decoder.decoder.up_blocks.2.0.conv.bias                                 torch.Size([512])               False
 1223  model.vae_decoder.decoder.up_blocks.2.1.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1224  model.vae_decoder.decoder.up_blocks.2.1.conv1.bias                                torch.Size([512])               False
 1225  model.vae_decoder.decoder.up_blocks.2.1.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1226  model.vae_decoder.decoder.up_blocks.2.1.norm.weight                               torch.Size([512])               False
 1227  model.vae_decoder.decoder.up_blocks.2.1.norm.bias                                 torch.Size([512])               False
 1228  model.vae_decoder.decoder.up_blocks.2.2.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1229  model.vae_decoder.decoder.up_blocks.2.2.conv1.bias                                torch.Size([512])               False
 1230  model.vae_decoder.decoder.up_blocks.2.2.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1231  model.vae_decoder.decoder.up_blocks.2.2.norm.weight                               torch.Size([512])               False
 1232  model.vae_decoder.decoder.up_blocks.2.2.norm.bias                                 torch.Size([512])               False
 1233  model.vae_decoder.decoder.up_blocks.2.3.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1234  model.vae_decoder.decoder.up_blocks.2.3.conv1.bias                                torch.Size([512])               False
 1235  model.vae_decoder.decoder.up_blocks.2.3.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1236  model.vae_decoder.decoder.up_blocks.2.3.norm.weight                               torch.Size([512])               False
 1237  model.vae_decoder.decoder.up_blocks.2.3.norm.bias                                 torch.Size([512])               False
 1238  model.vae_decoder.decoder.up_blocks.3.0.conv.weight                               torch.Size([512, 1024, 3, 3])   False
 1239  model.vae_decoder.decoder.up_blocks.3.0.conv.bias                                 torch.Size([512])               False
 1240  model.vae_decoder.decoder.up_blocks.3.1.attn.to_q.weight                          torch.Size([512, 512])          False
 1241  model.vae_decoder.decoder.up_blocks.3.1.attn.to_k.weight                          torch.Size([512, 512])          False
 1242  model.vae_decoder.decoder.up_blocks.3.1.attn.to_v.weight                          torch.Size([512, 512])          False
 1243  model.vae_decoder.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1244  model.vae_decoder.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1245  model.vae_decoder.decoder.up_blocks.3.1.attn.to_out.weight                        torch.Size([512, 1024])         False
 1246  model.vae_decoder.decoder.up_blocks.3.1.attn.norm_out.weight                      torch.Size([512])               False
 1247  model.vae_decoder.decoder.up_blocks.3.1.attn.norm_out.bias                        torch.Size([512])               False
 1248  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1249  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1250  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1251  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1252  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1253  model.vae_decoder.decoder.up_blocks.3.1.conv_out.norm.weight                      torch.Size([512])               False
 1254  model.vae_decoder.decoder.up_blocks.3.1.conv_out.norm.bias                        torch.Size([512])               False
 1255  model.vae_decoder.decoder.up_blocks.3.2.attn.to_q.weight                          torch.Size([512, 512])          False
 1256  model.vae_decoder.decoder.up_blocks.3.2.attn.to_k.weight                          torch.Size([512, 512])          False
 1257  model.vae_decoder.decoder.up_blocks.3.2.attn.to_v.weight                          torch.Size([512, 512])          False
 1258  model.vae_decoder.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1259  model.vae_decoder.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1260  model.vae_decoder.decoder.up_blocks.3.2.attn.to_out.weight                        torch.Size([512, 1024])         False
 1261  model.vae_decoder.decoder.up_blocks.3.2.attn.norm_out.weight                      torch.Size([512])               False
 1262  model.vae_decoder.decoder.up_blocks.3.2.attn.norm_out.bias                        torch.Size([512])               False
 1263  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1264  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1265  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1266  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1267  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1268  model.vae_decoder.decoder.up_blocks.3.2.conv_out.norm.weight                      torch.Size([512])               False
 1269  model.vae_decoder.decoder.up_blocks.3.2.conv_out.norm.bias                        torch.Size([512])               False
 1270  model.vae_decoder.decoder.up_blocks.3.3.attn.to_q.weight                          torch.Size([512, 512])          False
 1271  model.vae_decoder.decoder.up_blocks.3.3.attn.to_k.weight                          torch.Size([512, 512])          False
 1272  model.vae_decoder.decoder.up_blocks.3.3.attn.to_v.weight                          torch.Size([512, 512])          False
 1273  model.vae_decoder.decoder.up_blocks.3.3.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1274  model.vae_decoder.decoder.up_blocks.3.3.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1275  model.vae_decoder.decoder.up_blocks.3.3.attn.to_out.weight                        torch.Size([512, 1024])         False
 1276  model.vae_decoder.decoder.up_blocks.3.3.attn.norm_out.weight                      torch.Size([512])               False
 1277  model.vae_decoder.decoder.up_blocks.3.3.attn.norm_out.bias                        torch.Size([512])               False
 1278  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1279  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1280  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1281  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1282  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1283  model.vae_decoder.decoder.up_blocks.3.3.conv_out.norm.weight                      torch.Size([512])               False
 1284  model.vae_decoder.decoder.up_blocks.3.3.conv_out.norm.bias                        torch.Size([512])               False
 1285  model.vae_decoder.decoder.up_blocks.4.0.conv.weight                               torch.Size([1024, 1024, 3, 3])  False
 1286  model.vae_decoder.decoder.up_blocks.4.0.conv.bias                                 torch.Size([1024])              False
 1287  model.vae_decoder.decoder.up_blocks.4.1.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1288  model.vae_decoder.decoder.up_blocks.4.1.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1289  model.vae_decoder.decoder.up_blocks.4.1.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1290  model.vae_decoder.decoder.up_blocks.4.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1291  model.vae_decoder.decoder.up_blocks.4.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1292  model.vae_decoder.decoder.up_blocks.4.1.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1293  model.vae_decoder.decoder.up_blocks.4.1.attn.norm_out.weight                      torch.Size([1024])              False
 1294  model.vae_decoder.decoder.up_blocks.4.1.attn.norm_out.bias                        torch.Size([1024])              False
 1295  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1296  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1297  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1298  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1299  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1300  model.vae_decoder.decoder.up_blocks.4.1.conv_out.norm.weight                      torch.Size([1024])              False
 1301  model.vae_decoder.decoder.up_blocks.4.1.conv_out.norm.bias                        torch.Size([1024])              False
 1302  model.vae_decoder.decoder.up_blocks.4.2.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1303  model.vae_decoder.decoder.up_blocks.4.2.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1304  model.vae_decoder.decoder.up_blocks.4.2.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1305  model.vae_decoder.decoder.up_blocks.4.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1306  model.vae_decoder.decoder.up_blocks.4.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1307  model.vae_decoder.decoder.up_blocks.4.2.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1308  model.vae_decoder.decoder.up_blocks.4.2.attn.norm_out.weight                      torch.Size([1024])              False
 1309  model.vae_decoder.decoder.up_blocks.4.2.attn.norm_out.bias                        torch.Size([1024])              False
 1310  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1311  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1312  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1313  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1314  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1315  model.vae_decoder.decoder.up_blocks.4.2.conv_out.norm.weight                      torch.Size([1024])              False
 1316  model.vae_decoder.decoder.up_blocks.4.2.conv_out.norm.bias                        torch.Size([1024])              False
 1317  model.vae_decoder.decoder.up_blocks.4.3.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1318  model.vae_decoder.decoder.up_blocks.4.3.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1319  model.vae_decoder.decoder.up_blocks.4.3.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1320  model.vae_decoder.decoder.up_blocks.4.3.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1321  model.vae_decoder.decoder.up_blocks.4.3.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1322  model.vae_decoder.decoder.up_blocks.4.3.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1323  model.vae_decoder.decoder.up_blocks.4.3.attn.norm_out.weight                      torch.Size([1024])              False
 1324  model.vae_decoder.decoder.up_blocks.4.3.attn.norm_out.bias                        torch.Size([1024])              False
 1325  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1326  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1327  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1328  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1329  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1330  model.vae_decoder.decoder.up_blocks.4.3.conv_out.norm.weight                      torch.Size([1024])              False
 1331  model.vae_decoder.decoder.up_blocks.4.3.conv_out.norm.bias                        torch.Size([1024])              False
 1332  model.vae_decoder.decoder.up_blocks.5.0.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1333  model.vae_decoder.decoder.up_blocks.5.0.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1334  model.vae_decoder.decoder.up_blocks.5.0.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1335  model.vae_decoder.decoder.up_blocks.5.0.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1336  model.vae_decoder.decoder.up_blocks.5.0.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1337  model.vae_decoder.decoder.up_blocks.5.0.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1338  model.vae_decoder.decoder.up_blocks.5.0.attn.norm_out.weight                      torch.Size([1024])              False
 1339  model.vae_decoder.decoder.up_blocks.5.0.attn.norm_out.bias                        torch.Size([1024])              False
 1340  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1341  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1342  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1343  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1344  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1345  model.vae_decoder.decoder.up_blocks.5.0.conv_out.norm.weight                      torch.Size([1024])              False
 1346  model.vae_decoder.decoder.up_blocks.5.0.conv_out.norm.bias                        torch.Size([1024])              False
 1347  model.vae_decoder.decoder.up_blocks.5.1.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1348  model.vae_decoder.decoder.up_blocks.5.1.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1349  model.vae_decoder.decoder.up_blocks.5.1.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1350  model.vae_decoder.decoder.up_blocks.5.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1351  model.vae_decoder.decoder.up_blocks.5.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1352  model.vae_decoder.decoder.up_blocks.5.1.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1353  model.vae_decoder.decoder.up_blocks.5.1.attn.norm_out.weight                      torch.Size([1024])              False
 1354  model.vae_decoder.decoder.up_blocks.5.1.attn.norm_out.bias                        torch.Size([1024])              False
 1355  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1356  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1357  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1358  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1359  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1360  model.vae_decoder.decoder.up_blocks.5.1.conv_out.norm.weight                      torch.Size([1024])              False
 1361  model.vae_decoder.decoder.up_blocks.5.1.conv_out.norm.bias                        torch.Size([1024])              False
 1362  model.vae_decoder.decoder.up_blocks.5.2.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1363  model.vae_decoder.decoder.up_blocks.5.2.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1364  model.vae_decoder.decoder.up_blocks.5.2.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1365  model.vae_decoder.decoder.up_blocks.5.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1366  model.vae_decoder.decoder.up_blocks.5.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1367  model.vae_decoder.decoder.up_blocks.5.2.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1368  model.vae_decoder.decoder.up_blocks.5.2.attn.norm_out.weight                      torch.Size([1024])              False
 1369  model.vae_decoder.decoder.up_blocks.5.2.attn.norm_out.bias                        torch.Size([1024])              False
 1370  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1371  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1372  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1373  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1374  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1375  model.vae_decoder.decoder.up_blocks.5.2.conv_out.norm.weight                      torch.Size([1024])              False
 1376  model.vae_decoder.decoder.up_blocks.5.2.conv_out.norm.bias                        torch.Size([1024])              False
 1377  model.vae_decoder.decoder.norm_out.weight                                         torch.Size([128])               False
 1378  model.vae_decoder.decoder.norm_out.bias                                           torch.Size([128])               False
 1379  model.vae_decoder.decoder.conv_out.weight                                         torch.Size([3, 128, 3, 3])      False
 1380  model.vae_decoder.decoder.conv_out.bias                                           torch.Size([3])                 False
 1381  model.vae_decoder.down_blocks.0.mlp.0.weight                                      torch.Size([896])               False
 1382  model.vae_decoder.down_blocks.0.mlp.0.bias                                        torch.Size([896])               False
 1383  model.vae_decoder.down_blocks.0.mlp.1.weight                                      torch.Size([896, 896])          False
 1384  model.vae_decoder.down_blocks.0.mlp.1.bias                                        torch.Size([896])               False
 1385  model.vae_decoder.down_blocks.0.mlp.3.weight                                      torch.Size([896, 896])          False
 1386  model.vae_decoder.down_blocks.0.mlp.3.bias                                        torch.Size([896])               False
 1387  model.vae_decoder.down_blocks.1.mlp.0.weight                                      torch.Size([896])               False
 1388  model.vae_decoder.down_blocks.1.mlp.0.bias                                        torch.Size([896])               False
 1389  model.vae_decoder.down_blocks.1.mlp.1.weight                                      torch.Size([896, 896])          False
 1390  model.vae_decoder.down_blocks.1.mlp.1.bias                                        torch.Size([896])               False
 1391  model.vae_decoder.down_blocks.1.mlp.3.weight                                      torch.Size([896, 896])          False
 1392  model.vae_decoder.down_blocks.1.mlp.3.bias                                        torch.Size([896])               False
 1393  model.vae_decoder.down_blocks.2.mlp.0.weight                                      torch.Size([896])               False
 1394  model.vae_decoder.down_blocks.2.mlp.0.bias                                        torch.Size([896])               False
 1395  model.vae_decoder.down_blocks.2.mlp.1.weight                                      torch.Size([896, 896])          False
 1396  model.vae_decoder.down_blocks.2.mlp.1.bias                                        torch.Size([896])               False
 1397  model.vae_decoder.down_blocks.2.mlp.3.weight                                      torch.Size([896, 896])          False
 1398  model.vae_decoder.down_blocks.2.mlp.3.bias                                        torch.Size([896])               False
 1399  model.vae_decoder.down_mlp.0.weight                                               torch.Size([896])               False
 1400  model.vae_decoder.down_mlp.0.bias                                                 torch.Size([896])               False
 1401  model.vae_decoder.down_mlp.1.weight                                               torch.Size([32, 896])           False
 1402  model.vae_decoder.down_mlp.1.bias                                                 torch.Size([32])                False
 1403  model.vae_decoder.down_mlp.3.weight                                               torch.Size([32, 32])            False
 1404  model.vae_decoder.down_mlp.3.bias                                                 torch.Size([32])                False
 1405  model.llm_connector.layers.0.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1406  model.llm_connector.layers.0.self_attn.q_proj.bias                                torch.Size([896])               True
 1407  model.llm_connector.layers.0.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1408  model.llm_connector.layers.0.self_attn.k_proj.bias                                torch.Size([128])               True
 1409  model.llm_connector.layers.0.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1410  model.llm_connector.layers.0.self_attn.v_proj.bias                                torch.Size([128])               True
 1411  model.llm_connector.layers.0.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1412  model.llm_connector.layers.0.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1413  model.llm_connector.layers.0.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1414  model.llm_connector.layers.0.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1415  model.llm_connector.layers.0.input_layernorm.weight                               torch.Size([896])               True
 1416  model.llm_connector.layers.0.post_attention_layernorm.weight                      torch.Size([896])               True
 1417  model.llm_connector.layers.1.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1418  model.llm_connector.layers.1.self_attn.q_proj.bias                                torch.Size([896])               True
 1419  model.llm_connector.layers.1.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1420  model.llm_connector.layers.1.self_attn.k_proj.bias                                torch.Size([128])               True
 1421  model.llm_connector.layers.1.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1422  model.llm_connector.layers.1.self_attn.v_proj.bias                                torch.Size([128])               True
 1423  model.llm_connector.layers.1.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1424  model.llm_connector.layers.1.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1425  model.llm_connector.layers.1.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1426  model.llm_connector.layers.1.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1427  model.llm_connector.layers.1.input_layernorm.weight                               torch.Size([896])               True
 1428  model.llm_connector.layers.1.post_attention_layernorm.weight                      torch.Size([896])               True
 1429  model.llm_connector.layers.2.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1430  model.llm_connector.layers.2.self_attn.q_proj.bias                                torch.Size([896])               True
 1431  model.llm_connector.layers.2.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1432  model.llm_connector.layers.2.self_attn.k_proj.bias                                torch.Size([128])               True
 1433  model.llm_connector.layers.2.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1434  model.llm_connector.layers.2.self_attn.v_proj.bias                                torch.Size([128])               True
 1435  model.llm_connector.layers.2.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1436  model.llm_connector.layers.2.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1437  model.llm_connector.layers.2.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1438  model.llm_connector.layers.2.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1439  model.llm_connector.layers.2.input_layernorm.weight                               torch.Size([896])               True
 1440  model.llm_connector.layers.2.post_attention_layernorm.weight                      torch.Size([896])               True
 1441  model.llm_connector.layers.3.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1442  model.llm_connector.layers.3.self_attn.q_proj.bias                                torch.Size([896])               True
 1443  model.llm_connector.layers.3.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1444  model.llm_connector.layers.3.self_attn.k_proj.bias                                torch.Size([128])               True
 1445  model.llm_connector.layers.3.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1446  model.llm_connector.layers.3.self_attn.v_proj.bias                                torch.Size([128])               True
 1447  model.llm_connector.layers.3.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1448  model.llm_connector.layers.3.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1449  model.llm_connector.layers.3.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1450  model.llm_connector.layers.3.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1451  model.llm_connector.layers.3.input_layernorm.weight                               torch.Size([896])               True
 1452  model.llm_connector.layers.3.post_attention_layernorm.weight                      torch.Size([896])               True
 1453  model.llm_connector.layers.4.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1454  model.llm_connector.layers.4.self_attn.q_proj.bias                                torch.Size([896])               True
 1455  model.llm_connector.layers.4.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1456  model.llm_connector.layers.4.self_attn.k_proj.bias                                torch.Size([128])               True
 1457  model.llm_connector.layers.4.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1458  model.llm_connector.layers.4.self_attn.v_proj.bias                                torch.Size([128])               True
 1459  model.llm_connector.layers.4.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1460  model.llm_connector.layers.4.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1461  model.llm_connector.layers.4.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1462  model.llm_connector.layers.4.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1463  model.llm_connector.layers.4.input_layernorm.weight                               torch.Size([896])               True
 1464  model.llm_connector.layers.4.post_attention_layernorm.weight                      torch.Size([896])               True
 1465  model.llm_connector.layers.5.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1466  model.llm_connector.layers.5.self_attn.q_proj.bias                                torch.Size([896])               True
 1467  model.llm_connector.layers.5.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1468  model.llm_connector.layers.5.self_attn.k_proj.bias                                torch.Size([128])               True
 1469  model.llm_connector.layers.5.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1470  model.llm_connector.layers.5.self_attn.v_proj.bias                                torch.Size([128])               True
 1471  model.llm_connector.layers.5.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1472  model.llm_connector.layers.5.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1473  model.llm_connector.layers.5.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1474  model.llm_connector.layers.5.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1475  model.llm_connector.layers.5.input_layernorm.weight                               torch.Size([896])               True
 1476  model.llm_connector.layers.5.post_attention_layernorm.weight                      torch.Size([896])               True
 1477  model.llm_connector.norm.weight                                                   torch.Size([896])               True
 1478  model.projector.weight                                                            torch.Size([2304, 896])         True
 1479  model.projector.bias                                                              torch.Size([2304])              True
 1480  model.action_dit.layers.0.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1481  model.action_dit.layers.0.self_attn.q_proj.bias                                   torch.Size([896])               True
 1482  model.action_dit.layers.0.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1483  model.action_dit.layers.0.self_attn.k_proj.bias                                   torch.Size([128])               True
 1484  model.action_dit.layers.0.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1485  model.action_dit.layers.0.self_attn.v_proj.bias                                   torch.Size([128])               True
 1486  model.action_dit.layers.0.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1487  model.action_dit.layers.0.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1488  model.action_dit.layers.0.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1489  model.action_dit.layers.0.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1490  model.action_dit.layers.0.input_layernorm.weight                                  torch.Size([896])               True
 1491  model.action_dit.layers.0.post_attention_layernorm.weight                         torch.Size([896])               True
 1492  model.action_dit.layers.1.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1493  model.action_dit.layers.1.self_attn.q_proj.bias                                   torch.Size([896])               True
 1494  model.action_dit.layers.1.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1495  model.action_dit.layers.1.self_attn.k_proj.bias                                   torch.Size([128])               True
 1496  model.action_dit.layers.1.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1497  model.action_dit.layers.1.self_attn.v_proj.bias                                   torch.Size([128])               True
 1498  model.action_dit.layers.1.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1499  model.action_dit.layers.1.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1500  model.action_dit.layers.1.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1501  model.action_dit.layers.1.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1502  model.action_dit.layers.1.input_layernorm.weight                                  torch.Size([896])               True
 1503  model.action_dit.layers.1.post_attention_layernorm.weight                         torch.Size([896])               True
 1504  model.action_dit.layers.2.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1505  model.action_dit.layers.2.self_attn.q_proj.bias                                   torch.Size([896])               True
 1506  model.action_dit.layers.2.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1507  model.action_dit.layers.2.self_attn.k_proj.bias                                   torch.Size([128])               True
 1508  model.action_dit.layers.2.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1509  model.action_dit.layers.2.self_attn.v_proj.bias                                   torch.Size([128])               True
 1510  model.action_dit.layers.2.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1511  model.action_dit.layers.2.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1512  model.action_dit.layers.2.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1513  model.action_dit.layers.2.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1514  model.action_dit.layers.2.input_layernorm.weight                                  torch.Size([896])               True
 1515  model.action_dit.layers.2.post_attention_layernorm.weight                         torch.Size([896])               True
 1516  model.action_dit.norm.weight                                                      torch.Size([896])               True
 1517  model.action_in_proj.weight                                                       torch.Size([896, 5])            True
 1518  model.action_in_proj.bias                                                         torch.Size([896])               True
 1519  model.time_mlp_in.weight                                                          torch.Size([896, 896])          True
 1520  model.time_mlp_in.bias                                                            torch.Size([896])               True
 1521  model.time_mlp_out.weight                                                         torch.Size([896, 896])          True
 1522  model.time_mlp_out.bias                                                           torch.Size([896])               True
 1523  model.action_out_proj.weight                                                      torch.Size([5, 896])            True
 1524  model.action_out_proj.bias                                                        torch.Size([5])                 True
 1525  lm_head.weight                                                                    torch.Size([151678, 896])       False - (2851716:train_csgo.py:1486)
2026-01-07 15:34:02 - INFO - total_loss: 8.016271591186523, masked_loc_loss: 7.361514568328857, masked_gen_loss: 0.6547572612762451 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:17 - INFO - total_loss: 9.722625732421875, masked_loc_loss: 9.213069915771484, masked_gen_loss: 0.5095553994178772 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:23 - INFO - total_loss: 7.696690082550049, masked_loc_loss: 7.052275657653809, masked_gen_loss: 0.6444143056869507 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:30 - INFO - total_loss: 6.830178260803223, masked_loc_loss: 6.1820173263549805, masked_gen_loss: 0.6481606960296631 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:42 - INFO - total_loss: 8.749103546142578, masked_loc_loss: 8.296618461608887, masked_gen_loss: 0.4524850845336914 - (2851716:unified_unilip.py:926)
2026-01-07 15:34:49 - INFO - total_loss: 6.804914951324463, masked_loc_loss: 6.294888496398926, masked_gen_loss: 0.5100263357162476 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:01 - INFO - total_loss: 3.2083003520965576, masked_loc_loss: 2.593846559524536, masked_gen_loss: 0.6144537925720215 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:09 - INFO - total_loss: 2.7725884914398193, masked_loc_loss: 2.222085475921631, masked_gen_loss: 0.5505030155181885 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:21 - INFO - total_loss: 18.272518157958984, masked_loc_loss: 17.768247604370117, masked_gen_loss: 0.5042710304260254 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:27 - INFO - total_loss: 19.324588775634766, masked_loc_loss: 18.707304000854492, masked_gen_loss: 0.617285430431366 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:38 - INFO - total_loss: 17.88177490234375, masked_loc_loss: 17.31314468383789, masked_gen_loss: 0.5686293244361877 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:47 - INFO - total_loss: 39.53097152709961, masked_loc_loss: 39.037315368652344, masked_gen_loss: 0.4936579763889313 - (2851716:unified_unilip.py:926)
2026-01-07 15:35:57 - INFO - total_loss: 40.92516326904297, masked_loc_loss: 40.44829559326172, masked_gen_loss: 0.47686630487442017 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:08 - INFO - total_loss: 29.910009384155273, masked_loc_loss: 29.375606536865234, masked_gen_loss: 0.53440260887146 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:19 - INFO - total_loss: 18.820985794067383, masked_loc_loss: 18.277297973632812, masked_gen_loss: 0.543688178062439 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:28 - INFO - total_loss: 9.599990844726562, masked_loc_loss: 9.05958366394043, masked_gen_loss: 0.5404070615768433 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:41 - INFO - total_loss: 4.315921783447266, masked_loc_loss: 3.8599987030029297, masked_gen_loss: 0.4559229016304016 - (2851716:unified_unilip.py:926)
2026-01-07 15:36:50 - INFO - total_loss: 1.5126945972442627, masked_loc_loss: 1.0233421325683594, masked_gen_loss: 0.4893524646759033 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:03 - INFO - total_loss: 1.8733385801315308, masked_loc_loss: 1.3685787916183472, masked_gen_loss: 0.5047597885131836 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:13 - INFO - total_loss: 3.100478410720825, masked_loc_loss: 2.6367905139923096, masked_gen_loss: 0.4636879563331604 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:24 - INFO - total_loss: 3.171135187149048, masked_loc_loss: 2.7427608966827393, masked_gen_loss: 0.42837420105934143 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:36 - INFO - total_loss: 2.031878709793091, masked_loc_loss: 1.5450547933578491, masked_gen_loss: 0.4868238866329193 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:45 - INFO - total_loss: 1.1782290935516357, masked_loc_loss: 0.7576919198036194, masked_gen_loss: 0.42053720355033875 - (2851716:unified_unilip.py:926)
2026-01-07 15:37:59 - INFO - total_loss: 1.06063711643219, masked_loc_loss: 0.6125694513320923, masked_gen_loss: 0.44806763529777527 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:09 - INFO - total_loss: 1.4384318590164185, masked_loc_loss: 0.9771848320960999, masked_gen_loss: 0.4612470269203186 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:20 - INFO - total_loss: 1.4708964824676514, masked_loc_loss: 1.0282992124557495, masked_gen_loss: 0.44259732961654663 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:32 - INFO - total_loss: 1.0785729885101318, masked_loc_loss: 0.6504788398742676, masked_gen_loss: 0.42809414863586426 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:42 - INFO - total_loss: 1.010493278503418, masked_loc_loss: 0.6176542639732361, masked_gen_loss: 0.39283907413482666 - (2851716:unified_unilip.py:926)
2026-01-07 15:38:55 - INFO - total_loss: 1.2101881504058838, masked_loc_loss: 0.7878851890563965, masked_gen_loss: 0.42230290174484253 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:07 - INFO - total_loss: 1.0440510511398315, masked_loc_loss: 0.6329319477081299, masked_gen_loss: 0.41111910343170166 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:15 - INFO - total_loss: 1.0967867374420166, masked_loc_loss: 0.6997131109237671, masked_gen_loss: 0.3970736861228943 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:28 - INFO - total_loss: 0.972062885761261, masked_loc_loss: 0.5384132862091064, masked_gen_loss: 0.43364959955215454 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:38 - INFO - total_loss: 1.0658835172653198, masked_loc_loss: 0.669926643371582, masked_gen_loss: 0.3959568440914154 - (2851716:unified_unilip.py:926)
2026-01-07 15:39:50 - INFO - total_loss: 0.9857978224754333, masked_loc_loss: 0.5629732608795166, masked_gen_loss: 0.42282456159591675 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:01 - INFO - total_loss: 1.1838369369506836, masked_loc_loss: 0.8660554885864258, masked_gen_loss: 0.3177814483642578 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:11 - INFO - total_loss: 1.0241844654083252, masked_loc_loss: 0.6367733478546143, masked_gen_loss: 0.38741111755371094 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:24 - INFO - total_loss: 0.9042630791664124, masked_loc_loss: 0.5108721852302551, masked_gen_loss: 0.3933908939361572 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:34 - INFO - total_loss: 0.980246901512146, masked_loc_loss: 0.6247038841247559, masked_gen_loss: 0.35554301738739014 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:45 - INFO - total_loss: 0.9187288880348206, masked_loc_loss: 0.4870193600654602, masked_gen_loss: 0.43170952796936035 - (2851716:unified_unilip.py:926)
2026-01-07 15:40:57 - INFO - total_loss: 0.9796720743179321, masked_loc_loss: 0.6002588272094727, masked_gen_loss: 0.3794132471084595 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:06 - INFO - total_loss: 0.9314988851547241, masked_loc_loss: 0.5622368454933167, masked_gen_loss: 0.3692620098590851 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:19 - INFO - total_loss: 0.9968426823616028, masked_loc_loss: 0.6569497585296631, masked_gen_loss: 0.3398929238319397 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:29 - INFO - total_loss: 0.9527702927589417, masked_loc_loss: 0.6254793405532837, masked_gen_loss: 0.32729095220565796 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:40 - INFO - total_loss: 0.9816361665725708, masked_loc_loss: 0.5958126783370972, masked_gen_loss: 0.38582348823547363 - (2851716:unified_unilip.py:926)
2026-01-07 15:41:52 - INFO - total_loss: 0.918677568435669, masked_loc_loss: 0.5497407913208008, masked_gen_loss: 0.36893677711486816 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:02 - INFO - total_loss: 0.8816906213760376, masked_loc_loss: 0.463595986366272, masked_gen_loss: 0.4180946350097656 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:15 - INFO - total_loss: 0.889488935470581, masked_loc_loss: 0.48919519782066345, masked_gen_loss: 0.4002937078475952 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:26 - INFO - total_loss: 0.9555476307868958, masked_loc_loss: 0.5440045595169067, masked_gen_loss: 0.411543071269989 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:36 - INFO - total_loss: 0.9566481709480286, masked_loc_loss: 0.5432437062263489, masked_gen_loss: 0.4134044647216797 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:48 - INFO - total_loss: 0.9589022397994995, masked_loc_loss: 0.536656379699707, masked_gen_loss: 0.42224588990211487 - (2851716:unified_unilip.py:926)
2026-01-07 15:42:59 - INFO - total_loss: 1.0416765213012695, masked_loc_loss: 0.6308184266090393, masked_gen_loss: 0.4108580946922302 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:10 - INFO - total_loss: 0.929053544998169, masked_loc_loss: 0.5936538577079773, masked_gen_loss: 0.33539965748786926 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:17 - INFO - total_loss: 0.8553975820541382, masked_loc_loss: 0.4758182168006897, masked_gen_loss: 0.3795793354511261 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:24 - INFO - total_loss: 0.988168478012085, masked_loc_loss: 0.6427753567695618, masked_gen_loss: 0.3453930914402008 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:30 - INFO - total_loss: 0.9175273180007935, masked_loc_loss: 0.5296337604522705, masked_gen_loss: 0.38789352774620056 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:44 - INFO - total_loss: 0.8511490225791931, masked_loc_loss: 0.48346441984176636, masked_gen_loss: 0.36768460273742676 - (2851716:unified_unilip.py:926)
2026-01-07 15:43:53 - INFO - total_loss: 0.8610892295837402, masked_loc_loss: 0.4727027714252472, masked_gen_loss: 0.38838648796081543 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:05 - INFO - total_loss: 0.8747653961181641, masked_loc_loss: 0.5386097431182861, masked_gen_loss: 0.3361556828022003 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:15 - INFO - total_loss: 0.8509731292724609, masked_loc_loss: 0.48420146107673645, masked_gen_loss: 0.3667716383934021 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:26 - INFO - total_loss: 0.8920724391937256, masked_loc_loss: 0.51666259765625, masked_gen_loss: 0.3754098117351532 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:37 - INFO - total_loss: 0.8575152158737183, masked_loc_loss: 0.4748331308364868, masked_gen_loss: 0.38268205523490906 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:47 - INFO - total_loss: 0.7901333570480347, masked_loc_loss: 0.38204678893089294, masked_gen_loss: 0.4080865979194641 - (2851716:unified_unilip.py:926)
2026-01-07 15:44:58 - INFO - total_loss: 0.7802613973617554, masked_loc_loss: 0.3640895187854767, masked_gen_loss: 0.4161719083786011 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:08 - INFO - total_loss: 0.7698971033096313, masked_loc_loss: 0.4018065631389618, masked_gen_loss: 0.36809051036834717 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:22 - INFO - total_loss: 0.759792685508728, masked_loc_loss: 0.32827624678611755, masked_gen_loss: 0.43151646852493286 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:31 - INFO - total_loss: 0.7143786549568176, masked_loc_loss: 0.291808158159256, masked_gen_loss: 0.42257049679756165 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:43 - INFO - total_loss: 0.6745386123657227, masked_loc_loss: 0.27640169858932495, masked_gen_loss: 0.3981369137763977 - (2851716:unified_unilip.py:926)
2026-01-07 15:45:56 - INFO - total_loss: 0.7365338802337646, masked_loc_loss: 0.3781032860279083, masked_gen_loss: 0.35843056440353394 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:07 - INFO - total_loss: 0.730156660079956, masked_loc_loss: 0.3594759702682495, masked_gen_loss: 0.37068068981170654 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:18 - INFO - total_loss: 0.7407436370849609, masked_loc_loss: 0.32750818133354187, masked_gen_loss: 0.41323548555374146 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:32 - INFO - total_loss: 0.6354633569717407, masked_loc_loss: 0.23147982358932495, masked_gen_loss: 0.4039835035800934 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:45 - INFO - total_loss: 0.6752666234970093, masked_loc_loss: 0.392080694437027, masked_gen_loss: 0.2831858992576599 - (2851716:unified_unilip.py:926)
2026-01-07 15:46:57 - INFO - total_loss: 0.693514347076416, masked_loc_loss: 0.2680851221084595, masked_gen_loss: 0.42542925477027893 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:09 - INFO - total_loss: 0.6590217351913452, masked_loc_loss: 0.3462931215763092, masked_gen_loss: 0.3127285838127136 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:22 - INFO - total_loss: 0.5521767139434814, masked_loc_loss: 0.21239516139030457, masked_gen_loss: 0.33978158235549927 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:35 - INFO - total_loss: 0.6911600828170776, masked_loc_loss: 0.2944875955581665, masked_gen_loss: 0.39667248725891113 - (2851716:unified_unilip.py:926)
2026-01-07 15:47:47 - INFO - total_loss: 0.675765335559845, masked_loc_loss: 0.2916218638420105, masked_gen_loss: 0.3841434717178345 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:00 - INFO - total_loss: 0.6079438924789429, masked_loc_loss: 0.18998101353645325, masked_gen_loss: 0.417962908744812 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:13 - INFO - total_loss: 0.5908324718475342, masked_loc_loss: 0.1433747410774231, masked_gen_loss: 0.4474577307701111 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:24 - INFO - total_loss: 0.6499042510986328, masked_loc_loss: 0.2126111090183258, masked_gen_loss: 0.4372931718826294 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:37 - INFO - total_loss: 0.5836480855941772, masked_loc_loss: 0.18972459435462952, masked_gen_loss: 0.3939235210418701 - (2851716:unified_unilip.py:926)
2026-01-07 15:48:50 - INFO - total_loss: 0.5870954394340515, masked_loc_loss: 0.19486933946609497, masked_gen_loss: 0.39222609996795654 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:02 - INFO - total_loss: 0.585151195526123, masked_loc_loss: 0.1914023458957672, masked_gen_loss: 0.3937488794326782 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:14 - INFO - total_loss: 0.5701838731765747, masked_loc_loss: 0.2007368952035904, masked_gen_loss: 0.3694469928741455 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:27 - INFO - total_loss: 0.602001428604126, masked_loc_loss: 0.23115137219429016, masked_gen_loss: 0.3708500266075134 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:39 - INFO - total_loss: 0.572185218334198, masked_loc_loss: 0.19784751534461975, masked_gen_loss: 0.37433770298957825 - (2851716:unified_unilip.py:926)
2026-01-07 15:49:51 - INFO - total_loss: 0.5220043659210205, masked_loc_loss: 0.1506148725748062, masked_gen_loss: 0.3713894784450531 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:02 - INFO - total_loss: 0.5679590106010437, masked_loc_loss: 0.17295849323272705, masked_gen_loss: 0.39500051736831665 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:14 - INFO - total_loss: 0.5851463079452515, masked_loc_loss: 0.17682477831840515, masked_gen_loss: 0.4083215594291687 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:25 - INFO - total_loss: 0.567401647567749, masked_loc_loss: 0.21764642000198364, masked_gen_loss: 0.3497552275657654 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:36 - INFO - total_loss: 0.5731192827224731, masked_loc_loss: 0.25171712040901184, masked_gen_loss: 0.3214021325111389 - (2851716:unified_unilip.py:926)
2026-01-07 15:50:49 - INFO - total_loss: 0.5729994773864746, masked_loc_loss: 0.20901653170585632, masked_gen_loss: 0.3639829754829407 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:00 - INFO - total_loss: 0.5620468854904175, masked_loc_loss: 0.20256325602531433, masked_gen_loss: 0.35948359966278076 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:11 - INFO - total_loss: 0.5365746021270752, masked_loc_loss: 0.2019551396369934, masked_gen_loss: 0.3346194922924042 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:24 - INFO - total_loss: 0.5851313471794128, masked_loc_loss: 0.22318921983242035, masked_gen_loss: 0.3619421124458313 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:37 - INFO - total_loss: 0.580797553062439, masked_loc_loss: 0.17078396677970886, masked_gen_loss: 0.4100136160850525 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:47 - INFO - total_loss: 0.4825495779514313, masked_loc_loss: 0.1512508988380432, masked_gen_loss: 0.33129867911338806 - (2851716:unified_unilip.py:926)
2026-01-07 15:51:59 - INFO - total_loss: 0.5877301692962646, masked_loc_loss: 0.25717127323150635, masked_gen_loss: 0.3305588960647583 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:11 - INFO - total_loss: 0.53230881690979, masked_loc_loss: 0.17125055193901062, masked_gen_loss: 0.3610582947731018 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:22 - INFO - total_loss: 0.5633912086486816, masked_loc_loss: 0.1442982256412506, masked_gen_loss: 0.4190930128097534 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:33 - INFO - total_loss: 0.5856370329856873, masked_loc_loss: 0.14292296767234802, masked_gen_loss: 0.44271406531333923 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:46 - INFO - total_loss: 0.5487132668495178, masked_loc_loss: 0.2312725931406021, masked_gen_loss: 0.3174406886100769 - (2851716:unified_unilip.py:926)
2026-01-07 15:52:54 - INFO - total_loss: 0.5613369345664978, masked_loc_loss: 0.18468394875526428, masked_gen_loss: 0.3766529858112335 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:08 - INFO - total_loss: 0.5546656250953674, masked_loc_loss: 0.22184038162231445, masked_gen_loss: 0.332825243473053 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:19 - INFO - total_loss: 0.5997779965400696, masked_loc_loss: 0.15228696167469025, masked_gen_loss: 0.4474910497665405 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:30 - INFO - total_loss: 0.5649056434631348, masked_loc_loss: 0.11743810027837753, masked_gen_loss: 0.447467565536499 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:43 - INFO - total_loss: 0.583893895149231, masked_loc_loss: 0.15513744950294495, masked_gen_loss: 0.4287564754486084 - (2851716:unified_unilip.py:926)
2026-01-07 15:53:55 - INFO - total_loss: 0.5411317348480225, masked_loc_loss: 0.17638921737670898, masked_gen_loss: 0.3647425174713135 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:06 - INFO - total_loss: 0.575588047504425, masked_loc_loss: 0.15518714487552643, masked_gen_loss: 0.4204009175300598 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:17 - INFO - total_loss: 0.573444128036499, masked_loc_loss: 0.190070241689682, masked_gen_loss: 0.38337385654449463 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:30 - INFO - total_loss: 0.5144233703613281, masked_loc_loss: 0.14437805116176605, masked_gen_loss: 0.37004533410072327 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:39 - INFO - total_loss: 0.5606657266616821, masked_loc_loss: 0.2181476652622223, masked_gen_loss: 0.34251806139945984 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:46 - INFO - total_loss: 0.589073121547699, masked_loc_loss: 0.27989912033081055, masked_gen_loss: 0.3091740012168884 - (2851716:unified_unilip.py:926)
2026-01-07 15:54:52 - INFO - total_loss: 0.5858042240142822, masked_loc_loss: 0.19879913330078125, masked_gen_loss: 0.387005090713501 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:02 - INFO - total_loss: 0.625925600528717, masked_loc_loss: 0.23054926097393036, masked_gen_loss: 0.3953763246536255 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:14 - INFO - total_loss: 0.5995684862136841, masked_loc_loss: 0.1941753625869751, masked_gen_loss: 0.405393123626709 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:27 - INFO - total_loss: 0.5422455072402954, masked_loc_loss: 0.15603536367416382, masked_gen_loss: 0.386210173368454 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:40 - INFO - total_loss: 0.585620105266571, masked_loc_loss: 0.20430266857147217, masked_gen_loss: 0.3813174366950989 - (2851716:unified_unilip.py:926)
2026-01-07 15:55:51 - INFO - total_loss: 0.5730152130126953, masked_loc_loss: 0.24628089368343353, masked_gen_loss: 0.326734334230423 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:04 - INFO - total_loss: 0.544284462928772, masked_loc_loss: 0.17755816876888275, masked_gen_loss: 0.3667263090610504 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:16 - INFO - total_loss: 0.470126748085022, masked_loc_loss: 0.17384690046310425, masked_gen_loss: 0.2962798476219177 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:27 - INFO - total_loss: 0.5407406091690063, masked_loc_loss: 0.19303055107593536, masked_gen_loss: 0.3477100729942322 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:39 - INFO - total_loss: 0.5263441205024719, masked_loc_loss: 0.17080850899219513, masked_gen_loss: 0.355535626411438 - (2851716:unified_unilip.py:926)
2026-01-07 15:56:53 - INFO - total_loss: 0.5497598648071289, masked_loc_loss: 0.13837894797325134, masked_gen_loss: 0.4113808870315552 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:05 - INFO - total_loss: 0.5475261211395264, masked_loc_loss: 0.1553763747215271, masked_gen_loss: 0.3921497166156769 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:17 - INFO - total_loss: 0.5903117656707764, masked_loc_loss: 0.21922960877418518, masked_gen_loss: 0.3710821866989136 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:29 - INFO - total_loss: 0.5271329879760742, masked_loc_loss: 0.15434196591377258, masked_gen_loss: 0.37279099225997925 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:42 - INFO - total_loss: 0.528388500213623, masked_loc_loss: 0.15988153219223022, masked_gen_loss: 0.36850693821907043 - (2851716:unified_unilip.py:926)
2026-01-07 15:57:55 - INFO - total_loss: 0.6256237030029297, masked_loc_loss: 0.24671334028244019, masked_gen_loss: 0.3789103329181671 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:06 - INFO - total_loss: 0.4641904830932617, masked_loc_loss: 0.17309188842773438, masked_gen_loss: 0.29109859466552734 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:18 - INFO - total_loss: 0.5281478762626648, masked_loc_loss: 0.17274807393550873, masked_gen_loss: 0.3553997874259949 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:30 - INFO - total_loss: 0.5523617267608643, masked_loc_loss: 0.16942539811134338, masked_gen_loss: 0.38293635845184326 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:43 - INFO - total_loss: 0.5171045064926147, masked_loc_loss: 0.12768298387527466, masked_gen_loss: 0.3894215226173401 - (2851716:unified_unilip.py:926)
2026-01-07 15:58:53 - INFO - total_loss: 0.5007053017616272, masked_loc_loss: 0.13198509812355042, masked_gen_loss: 0.3687202036380768 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:05 - INFO - total_loss: 0.5372463464736938, masked_loc_loss: 0.15572723746299744, masked_gen_loss: 0.381519079208374 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:17 - INFO - total_loss: 0.5217506289482117, masked_loc_loss: 0.18655556440353394, masked_gen_loss: 0.33519506454467773 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:27 - INFO - total_loss: 0.5399538278579712, masked_loc_loss: 0.19302648305892944, masked_gen_loss: 0.34692734479904175 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:39 - INFO - total_loss: 0.5022497177124023, masked_loc_loss: 0.11649784445762634, masked_gen_loss: 0.3857519030570984 - (2851716:unified_unilip.py:926)
2026-01-07 15:59:52 - INFO - total_loss: 0.5277716517448425, masked_loc_loss: 0.2127583622932434, masked_gen_loss: 0.3150132894515991 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:02 - INFO - total_loss: 0.47947412729263306, masked_loc_loss: 0.11375277489423752, masked_gen_loss: 0.36572134494781494 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:14 - INFO - total_loss: 0.5286718606948853, masked_loc_loss: 0.1553109884262085, masked_gen_loss: 0.37336087226867676 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:27 - INFO - total_loss: 0.48739001154899597, masked_loc_loss: 0.16257348656654358, masked_gen_loss: 0.3248165249824524 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:40 - INFO - total_loss: 0.5283247828483582, masked_loc_loss: 0.12835675477981567, masked_gen_loss: 0.3999680280685425 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:49 - INFO - total_loss: 0.49295729398727417, masked_loc_loss: 0.17276738584041595, masked_gen_loss: 0.320189893245697 - (2851716:unified_unilip.py:926)
2026-01-07 16:00:56 - INFO - total_loss: 0.5477946996688843, masked_loc_loss: 0.18583035469055176, masked_gen_loss: 0.3619643449783325 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:02 - INFO - total_loss: 0.5009013414382935, masked_loc_loss: 0.13892433047294617, masked_gen_loss: 0.3619770109653473 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:09 - INFO - total_loss: 0.5042781233787537, masked_loc_loss: 0.13952279090881348, masked_gen_loss: 0.3647553324699402 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:15 - INFO - total_loss: 0.5337852835655212, masked_loc_loss: 0.13570386171340942, masked_gen_loss: 0.3980814218521118 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:22 - INFO - total_loss: 0.48446568846702576, masked_loc_loss: 0.1181158795952797, masked_gen_loss: 0.36634981632232666 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:28 - INFO - total_loss: 0.5536412000656128, masked_loc_loss: 0.15482285618782043, masked_gen_loss: 0.39881837368011475 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:35 - INFO - total_loss: 0.5886045694351196, masked_loc_loss: 0.2282428741455078, masked_gen_loss: 0.3603616952896118 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:41 - INFO - total_loss: 0.5588357448577881, masked_loc_loss: 0.1525830328464508, masked_gen_loss: 0.4062526822090149 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:48 - INFO - total_loss: 0.5710664987564087, masked_loc_loss: 0.144052654504776, masked_gen_loss: 0.4270138144493103 - (2851716:unified_unilip.py:926)
2026-01-07 16:01:55 - INFO - total_loss: 0.5572311878204346, masked_loc_loss: 0.26325124502182007, masked_gen_loss: 0.2939799427986145 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:01 - INFO - total_loss: 0.5642334222793579, masked_loc_loss: 0.19979095458984375, masked_gen_loss: 0.36444249749183655 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:07 - INFO - total_loss: 0.5855553150177002, masked_loc_loss: 0.16679629683494568, masked_gen_loss: 0.41875898838043213 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:14 - INFO - total_loss: 0.6124187707901001, masked_loc_loss: 0.2188417911529541, masked_gen_loss: 0.3935769498348236 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:21 - INFO - total_loss: 0.5087532997131348, masked_loc_loss: 0.1941131055355072, masked_gen_loss: 0.31464019417762756 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:27 - INFO - total_loss: 0.5698677897453308, masked_loc_loss: 0.16280196607112885, masked_gen_loss: 0.40706583857536316 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:34 - INFO - total_loss: 0.5145767331123352, masked_loc_loss: 0.11891684681177139, masked_gen_loss: 0.3956598937511444 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:41 - INFO - total_loss: 0.5513286590576172, masked_loc_loss: 0.18707889318466187, masked_gen_loss: 0.3642497956752777 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:47 - INFO - total_loss: 0.6480720043182373, masked_loc_loss: 0.22367450594902039, masked_gen_loss: 0.42439746856689453 - (2851716:unified_unilip.py:926)
2026-01-07 16:02:54 - INFO - total_loss: 0.5759050846099854, masked_loc_loss: 0.1938389241695404, masked_gen_loss: 0.38206613063812256 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:00 - INFO - total_loss: 0.5202974081039429, masked_loc_loss: 0.17072483897209167, masked_gen_loss: 0.3495725989341736 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:07 - INFO - total_loss: 0.5701712369918823, masked_loc_loss: 0.1883566677570343, masked_gen_loss: 0.3818145990371704 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:13 - INFO - total_loss: 0.5984981060028076, masked_loc_loss: 0.2790186107158661, masked_gen_loss: 0.3194795250892639 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:22 - INFO - total_loss: 0.5481686592102051, masked_loc_loss: 0.14582008123397827, masked_gen_loss: 0.4023485481739044 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:34 - INFO - total_loss: 0.5585312843322754, masked_loc_loss: 0.13224634528160095, masked_gen_loss: 0.4262849688529968 - (2851716:unified_unilip.py:926)
2026-01-07 16:03:49 - INFO - total_loss: 0.5139871835708618, masked_loc_loss: 0.1563783884048462, masked_gen_loss: 0.3576087951660156 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:04 - INFO - total_loss: 0.550539493560791, masked_loc_loss: 0.1446644365787506, masked_gen_loss: 0.405875027179718 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:19 - INFO - total_loss: 0.5446695685386658, masked_loc_loss: 0.23828528821468353, masked_gen_loss: 0.30638426542282104 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:26 - INFO - total_loss: 0.5532515645027161, masked_loc_loss: 0.18610769510269165, masked_gen_loss: 0.3671438694000244 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:40 - INFO - total_loss: 0.5031219720840454, masked_loc_loss: 0.16370651125907898, masked_gen_loss: 0.3394154906272888 - (2851716:unified_unilip.py:926)
2026-01-07 16:04:54 - INFO - total_loss: 0.5319768190383911, masked_loc_loss: 0.19479350745677948, masked_gen_loss: 0.33718329668045044 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:08 - INFO - total_loss: 0.49709030985832214, masked_loc_loss: 0.0930309072136879, masked_gen_loss: 0.40405941009521484 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:23 - INFO - total_loss: 0.516464352607727, masked_loc_loss: 0.16958695650100708, masked_gen_loss: 0.34687739610671997 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:30 - INFO - total_loss: 0.556049644947052, masked_loc_loss: 0.21189138293266296, masked_gen_loss: 0.34415826201438904 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:36 - INFO - total_loss: 0.5732380747795105, masked_loc_loss: 0.17146210372447968, masked_gen_loss: 0.40177595615386963 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:44 - INFO - total_loss: 0.491845965385437, masked_loc_loss: 0.16498875617980957, masked_gen_loss: 0.32685720920562744 - (2851716:unified_unilip.py:926)
2026-01-07 16:05:59 - INFO - total_loss: 0.5532264709472656, masked_loc_loss: 0.18938520550727844, masked_gen_loss: 0.36384129524230957 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:13 - INFO - total_loss: 0.5719676613807678, masked_loc_loss: 0.13112539052963257, masked_gen_loss: 0.44084227085113525 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:28 - INFO - total_loss: 0.48255041241645813, masked_loc_loss: 0.09167853742837906, masked_gen_loss: 0.39087188243865967 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:40 - INFO - total_loss: 0.40261712670326233, masked_loc_loss: 0.10429232567548752, masked_gen_loss: 0.2983247935771942 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:47 - INFO - total_loss: 0.5276544690132141, masked_loc_loss: 0.12131219357252121, masked_gen_loss: 0.4063422977924347 - (2851716:unified_unilip.py:926)
2026-01-07 16:06:57 - INFO - total_loss: 0.5556333065032959, masked_loc_loss: 0.16055791079998016, masked_gen_loss: 0.39507538080215454 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:08 - INFO - total_loss: 0.5113930702209473, masked_loc_loss: 0.14086781442165375, masked_gen_loss: 0.3705252707004547 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:19 - INFO - total_loss: 0.48269540071487427, masked_loc_loss: 0.14373713731765747, masked_gen_loss: 0.3389582633972168 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:34 - INFO - total_loss: 0.4596278667449951, masked_loc_loss: 0.13812386989593506, masked_gen_loss: 0.32150399684906006 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:48 - INFO - total_loss: 0.5141823291778564, masked_loc_loss: 0.1673683524131775, masked_gen_loss: 0.34681400656700134 - (2851716:unified_unilip.py:926)
2026-01-07 16:07:57 - INFO - total_loss: 0.5436035394668579, masked_loc_loss: 0.12105326354503632, masked_gen_loss: 0.4225502610206604 - (2851716:unified_unilip.py:926)
2026-01-07 16:08:12 - INFO - total_loss: 0.5010995268821716, masked_loc_loss: 0.13599719107151031, masked_gen_loss: 0.3651023507118225 - (2851716:unified_unilip.py:926)
2026-01-07 16:08:18 - INFO - total_loss: 0.5879802703857422, masked_loc_loss: 0.19320988655090332, masked_gen_loss: 0.39477038383483887 - (2851716:unified_unilip.py:926)
2026-01-07 16:08:25 - INFO - total_loss: 0.4698032736778259, masked_loc_loss: 0.14276961982250214, masked_gen_loss: 0.3270336389541626 - (2851716:unified_unilip.py:926)
2026-01-07 16:08:39 - INFO - total_loss: 0.4978593587875366, masked_loc_loss: 0.10752137005329132, masked_gen_loss: 0.3903380036354065 - (2851716:unified_unilip.py:926)
2026-01-07 16:08:53 - INFO - total_loss: 0.5571324825286865, masked_loc_loss: 0.13503935933113098, masked_gen_loss: 0.42209309339523315 - (2851716:unified_unilip.py:926)
2026-01-07 16:09:08 - INFO - total_loss: 0.47448599338531494, masked_loc_loss: 0.09083530306816101, masked_gen_loss: 0.38365069031715393 - (2851716:unified_unilip.py:926)
2026-01-07 16:09:22 - INFO - total_loss: 0.4493311643600464, masked_loc_loss: 0.08663403242826462, masked_gen_loss: 0.36269712448120117 - (2851716:unified_unilip.py:926)
2026-01-07 16:09:29 - INFO - total_loss: 0.5485672354698181, masked_loc_loss: 0.15080775320529938, masked_gen_loss: 0.39775949716567993 - (2851716:unified_unilip.py:926)
2026-01-07 16:09:36 - INFO - total_loss: 0.5260075330734253, masked_loc_loss: 0.13294818997383118, masked_gen_loss: 0.3930593729019165 - (2851716:unified_unilip.py:926)
2026-01-07 16:09:45 - INFO - total_loss: 0.4654175937175751, masked_loc_loss: 0.14770540595054626, masked_gen_loss: 0.3177121877670288 - (2851716:unified_unilip.py:926)
2026-01-07 16:10:00 - INFO - total_loss: 0.512291669845581, masked_loc_loss: 0.11870388686656952, masked_gen_loss: 0.39358779788017273 - (2851716:unified_unilip.py:926)
2026-01-07 16:10:15 - INFO - total_loss: 0.5104113817214966, masked_loc_loss: 0.14766570925712585, masked_gen_loss: 0.36274564266204834 - (2851716:unified_unilip.py:926)
2026-01-07 16:10:29 - INFO - total_loss: 0.5476998090744019, masked_loc_loss: 0.16748371720314026, masked_gen_loss: 0.3802160918712616 - (2851716:unified_unilip.py:926)
2026-01-07 16:10:41 - INFO - total_loss: 0.4822896718978882, masked_loc_loss: 0.1772027611732483, masked_gen_loss: 0.3050869107246399 - (2851716:unified_unilip.py:926)
2026-01-07 16:10:48 - INFO - total_loss: 0.5575157403945923, masked_loc_loss: 0.16260235011577606, masked_gen_loss: 0.39491337537765503 - (2851716:unified_unilip.py:926)
2026-01-07 16:10:56 - INFO - total_loss: 0.53591388463974, masked_loc_loss: 0.12212447822093964, masked_gen_loss: 0.41378939151763916 - (2851716:unified_unilip.py:926)
2026-01-07 16:11:11 - INFO - total_loss: 0.5331219434738159, masked_loc_loss: 0.14064732193946838, masked_gen_loss: 0.39247462153434753 - (2851716:unified_unilip.py:926)
2026-01-07 16:11:26 - INFO - total_loss: 0.5334436297416687, masked_loc_loss: 0.14783687889575958, masked_gen_loss: 0.3856067657470703 - (2851716:unified_unilip.py:926)
2026-01-07 16:11:40 - INFO - total_loss: 0.5265220999717712, masked_loc_loss: 0.14585691690444946, masked_gen_loss: 0.3806651830673218 - (2851716:unified_unilip.py:926)
2026-01-07 16:11:53 - INFO - total_loss: 0.5446648001670837, masked_loc_loss: 0.13063572347164154, masked_gen_loss: 0.414029061794281 - (2851716:unified_unilip.py:926)
2026-01-07 16:11:59 - INFO - total_loss: 0.49497151374816895, masked_loc_loss: 0.11068134009838104, masked_gen_loss: 0.3842901587486267 - (2851716:unified_unilip.py:926)
2026-01-07 16:12:06 - INFO - total_loss: 0.5528518557548523, masked_loc_loss: 0.07812666147947311, masked_gen_loss: 0.4747251868247986 - (2851716:unified_unilip.py:926)
2026-01-07 16:12:19 - INFO - total_loss: 0.5023143887519836, masked_loc_loss: 0.10002521425485611, masked_gen_loss: 0.40228915214538574 - (2851716:unified_unilip.py:926)
2026-01-07 16:12:34 - INFO - total_loss: 0.5664466619491577, masked_loc_loss: 0.15302440524101257, masked_gen_loss: 0.41342222690582275 - (2851716:unified_unilip.py:926)
2026-01-07 16:12:48 - INFO - total_loss: 0.523594081401825, masked_loc_loss: 0.090886689722538, masked_gen_loss: 0.43270736932754517 - (2851716:unified_unilip.py:926)
2026-01-07 16:13:03 - INFO - total_loss: 0.44282266497612, masked_loc_loss: 0.09523579478263855, masked_gen_loss: 0.34758687019348145 - (2851716:unified_unilip.py:926)
2026-01-07 16:13:09 - INFO - total_loss: 0.5150612592697144, masked_loc_loss: 0.11287830024957657, masked_gen_loss: 0.402182936668396 - (2851716:unified_unilip.py:926)
2026-01-07 16:13:16 - INFO - total_loss: 0.5331443548202515, masked_loc_loss: 0.1225561574101448, masked_gen_loss: 0.41058817505836487 - (2851716:unified_unilip.py:926)
2026-01-07 16:13:24 - INFO - total_loss: 0.5417677164077759, masked_loc_loss: 0.09649951010942459, masked_gen_loss: 0.4452682137489319 - (2851716:unified_unilip.py:926)
2026-01-07 16:13:38 - INFO - total_loss: 0.4998858571052551, masked_loc_loss: 0.15748511254787445, masked_gen_loss: 0.3424007296562195 - (2851716:unified_unilip.py:926)
2026-01-07 16:13:53 - INFO - total_loss: 0.4956624209880829, masked_loc_loss: 0.135534405708313, masked_gen_loss: 0.3601280152797699 - (2851716:unified_unilip.py:926)
2026-01-07 16:14:07 - INFO - total_loss: 0.5403838753700256, masked_loc_loss: 0.20739834010601044, masked_gen_loss: 0.3329855501651764 - (2851716:unified_unilip.py:926)
2026-01-07 16:14:20 - INFO - total_loss: 0.5386649370193481, masked_loc_loss: 0.20309296250343323, masked_gen_loss: 0.33557194471359253 - (2851716:unified_unilip.py:926)
2026-01-07 16:14:26 - INFO - total_loss: 0.4939623475074768, masked_loc_loss: 0.1288348138332367, masked_gen_loss: 0.3651275336742401 - (2851716:unified_unilip.py:926)
2026-01-07 16:14:38 - INFO - total_loss: 0.4787489175796509, masked_loc_loss: 0.15103720128536224, masked_gen_loss: 0.32771170139312744 - (2851716:unified_unilip.py:926)
2026-01-07 16:14:52 - INFO - total_loss: 0.5146913528442383, masked_loc_loss: 0.17963072657585144, masked_gen_loss: 0.33506062626838684 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:01 - INFO - total_loss: 0.4801768660545349, masked_loc_loss: 0.11837597191333771, masked_gen_loss: 0.3618009090423584 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:08 - INFO - total_loss: 0.4584062397480011, masked_loc_loss: 0.12154991179704666, masked_gen_loss: 0.33685633540153503 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:14 - INFO - total_loss: 0.535983145236969, masked_loc_loss: 0.14044882357120514, masked_gen_loss: 0.39553430676460266 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:21 - INFO - total_loss: 0.4864616096019745, masked_loc_loss: 0.14186030626296997, masked_gen_loss: 0.3446013033390045 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:27 - INFO - total_loss: 0.4625016152858734, masked_loc_loss: 0.13822415471076965, masked_gen_loss: 0.32427746057510376 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:34 - INFO - total_loss: 0.5020164251327515, masked_loc_loss: 0.12065504491329193, masked_gen_loss: 0.38136136531829834 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:41 - INFO - total_loss: 0.44699549674987793, masked_loc_loss: 0.12310950458049774, masked_gen_loss: 0.3238860070705414 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:48 - INFO - total_loss: 0.47891032695770264, masked_loc_loss: 0.151664137840271, masked_gen_loss: 0.32724618911743164 - (2851716:unified_unilip.py:926)
2026-01-07 16:15:54 - INFO - total_loss: 0.48976048827171326, masked_loc_loss: 0.08349145203828812, masked_gen_loss: 0.40626904368400574 - (2851716:unified_unilip.py:926)
2026-01-07 16:16:01 - INFO - total_loss: 0.533229410648346, masked_loc_loss: 0.1863652765750885, masked_gen_loss: 0.34686413407325745 - (2851716:unified_unilip.py:926)
2026-01-07 16:16:07 - INFO - total_loss: 0.5623519420623779, masked_loc_loss: 0.27259257435798645, masked_gen_loss: 0.2897593379020691 - (2851716:unified_unilip.py:926)
2026-01-07 16:16:21 - INFO - total_loss: 0.5484541654586792, masked_loc_loss: 0.17789900302886963, masked_gen_loss: 0.37055519223213196 - (2851716:unified_unilip.py:926)
2026-01-07 16:16:37 - INFO - total_loss: 0.48086875677108765, masked_loc_loss: 0.11226028949022293, masked_gen_loss: 0.3686084747314453 - (2851716:unified_unilip.py:926)
2026-01-07 16:16:51 - INFO - total_loss: 0.5778258442878723, masked_loc_loss: 0.18334107100963593, masked_gen_loss: 0.3944847881793976 - (2851716:unified_unilip.py:926)
2026-01-07 16:17:06 - INFO - total_loss: 0.49248215556144714, masked_loc_loss: 0.10367076843976974, masked_gen_loss: 0.3888113796710968 - (2851716:unified_unilip.py:926)
2026-01-07 16:17:12 - INFO - total_loss: 0.47300806641578674, masked_loc_loss: 0.11677101254463196, masked_gen_loss: 0.3562370538711548 - (2851716:unified_unilip.py:926)
2026-01-07 16:17:23 - INFO - total_loss: 0.5536908507347107, masked_loc_loss: 0.1428322196006775, masked_gen_loss: 0.4108586311340332 - (2851716:unified_unilip.py:926)
2026-01-07 16:17:37 - INFO - total_loss: 0.5221868753433228, masked_loc_loss: 0.17893287539482117, masked_gen_loss: 0.343254029750824 - (2851716:unified_unilip.py:926)
2026-01-07 16:17:52 - INFO - total_loss: 0.551217794418335, masked_loc_loss: 0.14350536465644836, masked_gen_loss: 0.407712459564209 - (2851716:unified_unilip.py:926)
2026-01-07 16:18:07 - INFO - total_loss: 0.5160288214683533, masked_loc_loss: 0.12782222032546997, masked_gen_loss: 0.3882066011428833 - (2851716:unified_unilip.py:926)
2026-01-07 16:18:18 - INFO - total_loss: 0.42430922389030457, masked_loc_loss: 0.12562400102615356, masked_gen_loss: 0.298685222864151 - (2851716:unified_unilip.py:926)
2026-01-07 16:18:31 - INFO - total_loss: 0.46066391468048096, masked_loc_loss: 0.11428088694810867, masked_gen_loss: 0.3463830351829529 - (2851716:unified_unilip.py:926)
2026-01-07 16:18:45 - INFO - total_loss: 0.5236027836799622, masked_loc_loss: 0.13102667033672333, masked_gen_loss: 0.39257609844207764 - (2851716:unified_unilip.py:926)
2026-01-07 16:19:00 - INFO - total_loss: 0.4783911406993866, masked_loc_loss: 0.15075942873954773, masked_gen_loss: 0.32763171195983887 - (2851716:unified_unilip.py:926)
2026-01-07 16:19:14 - INFO - total_loss: 0.5119186639785767, masked_loc_loss: 0.1326855719089508, masked_gen_loss: 0.37923312187194824 - (2851716:unified_unilip.py:926)
2026-01-07 16:19:22 - INFO - total_loss: 0.4780285358428955, masked_loc_loss: 0.16374589502811432, masked_gen_loss: 0.31428262591362 - (2851716:unified_unilip.py:926)
2026-01-07 16:19:35 - INFO - total_loss: 0.5188654065132141, masked_loc_loss: 0.13331764936447144, masked_gen_loss: 0.3855477571487427 - (2851716:unified_unilip.py:926)
2026-01-07 16:19:42 - INFO - total_loss: 0.42807960510253906, masked_loc_loss: 0.09512700140476227, masked_gen_loss: 0.3329525887966156 - (2851716:unified_unilip.py:926)
2026-01-07 16:19:56 - INFO - total_loss: 0.4669341444969177, masked_loc_loss: 0.13475565612316132, masked_gen_loss: 0.3321785032749176 - (2851716:unified_unilip.py:926)
2026-01-07 16:20:10 - INFO - total_loss: 0.5698515176773071, masked_loc_loss: 0.22226744890213013, masked_gen_loss: 0.347584068775177 - (2851716:unified_unilip.py:926)
2026-01-07 16:20:25 - INFO - total_loss: 0.5456662178039551, masked_loc_loss: 0.10926884412765503, masked_gen_loss: 0.43639740347862244 - (2851716:unified_unilip.py:926)
2026-01-07 16:20:39 - INFO - total_loss: 0.46233004331588745, masked_loc_loss: 0.141356959939003, masked_gen_loss: 0.32097306847572327 - (2851716:unified_unilip.py:926)
2026-01-07 16:20:46 - INFO - total_loss: 0.5219046473503113, masked_loc_loss: 0.14360640943050385, masked_gen_loss: 0.37829822301864624 - (2851716:unified_unilip.py:926)
2026-01-07 16:20:54 - INFO - total_loss: 0.6938862800598145, masked_loc_loss: 0.3175210952758789, masked_gen_loss: 0.37636518478393555 - (2851716:unified_unilip.py:926)
2026-01-07 16:21:08 - INFO - total_loss: 0.5682820081710815, masked_loc_loss: 0.21003377437591553, masked_gen_loss: 0.358248233795166 - (2851716:unified_unilip.py:926)
2026-01-07 16:21:23 - INFO - total_loss: 0.505577802658081, masked_loc_loss: 0.12663733959197998, masked_gen_loss: 0.3789404332637787 - (2851716:unified_unilip.py:926)
2026-01-07 16:21:37 - INFO - total_loss: 0.5547363758087158, masked_loc_loss: 0.17303693294525146, masked_gen_loss: 0.38169944286346436 - (2851716:unified_unilip.py:926)
2026-01-07 16:21:50 - INFO - total_loss: 0.49242648482322693, masked_loc_loss: 0.1338219940662384, masked_gen_loss: 0.3586044907569885 - (2851716:unified_unilip.py:926)
2026-01-07 16:21:57 - INFO - total_loss: 0.506462574005127, masked_loc_loss: 0.16712212562561035, masked_gen_loss: 0.339340478181839 - (2851716:unified_unilip.py:926)
2026-01-07 16:22:06 - INFO - total_loss: 0.47942572832107544, masked_loc_loss: 0.13665318489074707, masked_gen_loss: 0.34277254343032837 - (2851716:unified_unilip.py:926)
2026-01-07 16:22:20 - INFO - total_loss: 0.5140264630317688, masked_loc_loss: 0.14696019887924194, masked_gen_loss: 0.36706626415252686 - (2851716:unified_unilip.py:926)
2026-01-07 16:22:35 - INFO - total_loss: 0.5409680604934692, masked_loc_loss: 0.15255343914031982, masked_gen_loss: 0.388414591550827 - (2851716:unified_unilip.py:926)
2026-01-07 16:22:52 - INFO - total_loss: 0.5198606252670288, masked_loc_loss: 0.2096748650074005, masked_gen_loss: 0.3101857304573059 - (2851716:unified_unilip.py:926)
2026-01-07 16:23:01 - INFO - total_loss: 0.4819609820842743, masked_loc_loss: 0.11388649791479111, masked_gen_loss: 0.3680744767189026 - (2851716:unified_unilip.py:926)
2026-01-07 16:23:07 - INFO - total_loss: 0.5181030631065369, masked_loc_loss: 0.12893939018249512, masked_gen_loss: 0.38916367292404175 - (2851716:unified_unilip.py:926)
2026-01-07 16:23:19 - INFO - total_loss: 0.5226902961730957, masked_loc_loss: 0.14761516451835632, masked_gen_loss: 0.37507516145706177 - (2851716:unified_unilip.py:926)
2026-01-07 16:23:34 - INFO - total_loss: 0.45923715829849243, masked_loc_loss: 0.1052776500582695, masked_gen_loss: 0.35395950078964233 - (2851716:unified_unilip.py:926)
2026-01-07 16:23:49 - INFO - total_loss: 0.48951491713523865, masked_loc_loss: 0.1544412076473236, masked_gen_loss: 0.33507370948791504 - (2851716:unified_unilip.py:926)
2026-01-07 16:24:04 - INFO - total_loss: 0.4619942307472229, masked_loc_loss: 0.19864951074123383, masked_gen_loss: 0.2633447051048279 - (2851716:unified_unilip.py:926)
2026-01-07 16:24:12 - INFO - total_loss: 0.5009833574295044, masked_loc_loss: 0.15897411108016968, masked_gen_loss: 0.3420092463493347 - (2851716:unified_unilip.py:926)
2026-01-07 16:24:18 - INFO - total_loss: 0.5257925391197205, masked_loc_loss: 0.14797666668891907, masked_gen_loss: 0.3778158724308014 - (2851716:unified_unilip.py:926)
2026-01-07 16:24:32 - INFO - total_loss: 0.48536524176597595, masked_loc_loss: 0.1200181245803833, masked_gen_loss: 0.36534711718559265 - (2851716:unified_unilip.py:926)
2026-01-07 16:24:47 - INFO - total_loss: 0.5090922713279724, masked_loc_loss: 0.11805742233991623, masked_gen_loss: 0.3910348415374756 - (2851716:unified_unilip.py:926)
2026-01-07 16:25:02 - INFO - total_loss: 0.4540823996067047, masked_loc_loss: 0.11428558826446533, masked_gen_loss: 0.3397968113422394 - (2851716:unified_unilip.py:926)
2026-01-07 16:25:16 - INFO - total_loss: 0.4778454005718231, masked_loc_loss: 0.10161778330802917, masked_gen_loss: 0.37622761726379395 - (2851716:unified_unilip.py:926)
2026-01-07 16:25:22 - INFO - total_loss: 0.4951621890068054, masked_loc_loss: 0.12706486880779266, masked_gen_loss: 0.36809730529785156 - (2851716:unified_unilip.py:926)
2026-01-07 16:25:28 - INFO - total_loss: 0.4962030351161957, masked_loc_loss: 0.14018645882606506, masked_gen_loss: 0.3560165762901306 - (2851716:unified_unilip.py:926)
2026-01-07 16:25:43 - INFO - total_loss: 0.4775160551071167, masked_loc_loss: 0.08219924569129944, masked_gen_loss: 0.39531680941581726 - (2851716:unified_unilip.py:926)
2026-01-07 16:25:57 - INFO - total_loss: 0.48327985405921936, masked_loc_loss: 0.11208173632621765, masked_gen_loss: 0.3711981177330017 - (2851716:unified_unilip.py:926)
2026-01-07 16:26:11 - INFO - total_loss: 0.4977487027645111, masked_loc_loss: 0.13458523154258728, masked_gen_loss: 0.36316347122192383 - (2851716:unified_unilip.py:926)
2026-01-07 16:26:25 - INFO - total_loss: 0.4817606508731842, masked_loc_loss: 0.09687767177820206, masked_gen_loss: 0.38488298654556274 - (2851716:unified_unilip.py:926)
2026-01-07 16:26:32 - INFO - total_loss: 0.49976322054862976, masked_loc_loss: 0.1104174554347992, masked_gen_loss: 0.38934576511383057 - (2851716:unified_unilip.py:926)
2026-01-07 16:26:45 - INFO - total_loss: 0.479543536901474, masked_loc_loss: 0.13287997245788574, masked_gen_loss: 0.34666356444358826 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:00 - INFO - total_loss: 0.5123955011367798, masked_loc_loss: 0.11053451895713806, masked_gen_loss: 0.4018609821796417 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:07 - INFO - total_loss: 0.4738539755344391, masked_loc_loss: 0.09889348596334457, masked_gen_loss: 0.3749604821205139 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:14 - INFO - total_loss: 0.493810772895813, masked_loc_loss: 0.14423313736915588, masked_gen_loss: 0.3495776355266571 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:20 - INFO - total_loss: 0.5207293033599854, masked_loc_loss: 0.09387337416410446, masked_gen_loss: 0.4268559515476227 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:27 - INFO - total_loss: 0.4483039081096649, masked_loc_loss: 0.1339680254459381, masked_gen_loss: 0.3143358826637268 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:33 - INFO - total_loss: 0.4428060054779053, masked_loc_loss: 0.12084836512804031, masked_gen_loss: 0.32195764780044556 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:40 - INFO - total_loss: 0.4344087243080139, masked_loc_loss: 0.11328329145908356, masked_gen_loss: 0.32112544775009155 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:46 - INFO - total_loss: 0.46194204688072205, masked_loc_loss: 0.09087467938661575, masked_gen_loss: 0.3710673749446869 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:53 - INFO - total_loss: 0.4799244999885559, masked_loc_loss: 0.13600416481494904, masked_gen_loss: 0.34392035007476807 - (2851716:unified_unilip.py:926)
2026-01-07 16:27:59 - INFO - total_loss: 0.37011954188346863, masked_loc_loss: 0.13270987570285797, masked_gen_loss: 0.23740966618061066 - (2851716:unified_unilip.py:926)
2026-01-07 16:28:06 - INFO - total_loss: 0.4798648953437805, masked_loc_loss: 0.11941473931074142, masked_gen_loss: 0.3604501485824585 - (2851716:unified_unilip.py:926)
2026-01-07 16:28:13 - INFO - total_loss: 0.5431301593780518, masked_loc_loss: 0.09817235916852951, masked_gen_loss: 0.44495779275894165 - (2851716:unified_unilip.py:926)
2026-01-07 16:28:25 - INFO - total_loss: 0.4814794659614563, masked_loc_loss: 0.1230216771364212, masked_gen_loss: 0.3584578037261963 - (2851716:unified_unilip.py:926)
2026-01-07 16:28:39 - INFO - total_loss: 0.4608035683631897, masked_loc_loss: 0.08522242307662964, masked_gen_loss: 0.37558114528656006 - (2851716:unified_unilip.py:926)
2026-01-07 16:28:54 - INFO - total_loss: 0.4577205777168274, masked_loc_loss: 0.13198643922805786, masked_gen_loss: 0.32573413848876953 - (2851716:unified_unilip.py:926)
2026-01-07 16:29:09 - INFO - total_loss: 0.440434992313385, masked_loc_loss: 0.09761007130146027, masked_gen_loss: 0.34282493591308594 - (2851716:unified_unilip.py:926)
2026-01-07 16:29:17 - INFO - total_loss: 0.46368420124053955, masked_loc_loss: 0.0784556195139885, masked_gen_loss: 0.38522857427597046 - (2851716:unified_unilip.py:926)
2026-01-07 16:29:24 - INFO - total_loss: 0.4799223244190216, masked_loc_loss: 0.15289297699928284, masked_gen_loss: 0.32702934741973877 - (2851716:unified_unilip.py:926)
2026-01-07 16:29:33 - INFO - total_loss: 0.4317433834075928, masked_loc_loss: 0.10573367774486542, masked_gen_loss: 0.32600969076156616 - (2851716:unified_unilip.py:926)
2026-01-07 16:29:47 - INFO - total_loss: 0.4257112145423889, masked_loc_loss: 0.1342342495918274, masked_gen_loss: 0.2914769649505615 - (2851716:unified_unilip.py:926)
2026-01-07 16:30:02 - INFO - total_loss: 0.4713265895843506, masked_loc_loss: 0.1313895434141159, masked_gen_loss: 0.3399370312690735 - (2851716:unified_unilip.py:926)
2026-01-07 16:30:17 - INFO - total_loss: 0.5087453722953796, masked_loc_loss: 0.12827546894550323, masked_gen_loss: 0.3804698884487152 - (2851716:unified_unilip.py:926)
2026-01-07 16:30:29 - INFO - total_loss: 0.500253438949585, masked_loc_loss: 0.14202341437339783, masked_gen_loss: 0.35822999477386475 - (2851716:unified_unilip.py:926)
2026-01-07 16:30:36 - INFO - total_loss: 0.5017052292823792, masked_loc_loss: 0.1288660615682602, masked_gen_loss: 0.37283918261528015 - (2851716:unified_unilip.py:926)
2026-01-07 16:30:45 - INFO - total_loss: 0.49810394644737244, masked_loc_loss: 0.11437284201383591, masked_gen_loss: 0.38373109698295593 - (2851716:unified_unilip.py:926)
2026-01-07 16:30:59 - INFO - total_loss: 0.5083504915237427, masked_loc_loss: 0.11294476687908173, masked_gen_loss: 0.39540570974349976 - (2851716:unified_unilip.py:926)
2026-01-07 16:31:14 - INFO - total_loss: 0.53232342004776, masked_loc_loss: 0.16646799445152283, masked_gen_loss: 0.3658554255962372 - (2851716:unified_unilip.py:926)
2026-01-07 16:31:28 - INFO - total_loss: 0.5310708284378052, masked_loc_loss: 0.10666509717702866, masked_gen_loss: 0.4244057536125183 - (2851716:unified_unilip.py:926)
2026-01-07 16:31:40 - INFO - total_loss: 0.5060766935348511, masked_loc_loss: 0.11595304310321808, masked_gen_loss: 0.3901236653327942 - (2851716:unified_unilip.py:926)
2026-01-07 16:31:46 - INFO - total_loss: 0.4337758719921112, masked_loc_loss: 0.12068427354097366, masked_gen_loss: 0.31309160590171814 - (2851716:unified_unilip.py:926)
2026-01-07 16:31:56 - INFO - total_loss: 0.5176323652267456, masked_loc_loss: 0.1570768654346466, masked_gen_loss: 0.3605555295944214 - (2851716:unified_unilip.py:926)
2026-01-07 16:32:11 - INFO - total_loss: 0.4342721700668335, masked_loc_loss: 0.10276350378990173, masked_gen_loss: 0.33150866627693176 - (2851716:unified_unilip.py:926)
2026-01-07 16:32:25 - INFO - total_loss: 0.5100946426391602, masked_loc_loss: 0.11934155225753784, masked_gen_loss: 0.3907530605792999 - (2851716:unified_unilip.py:926)
2026-01-07 16:32:39 - INFO - total_loss: 0.478760302066803, masked_loc_loss: 0.21742881834506989, masked_gen_loss: 0.2613314986228943 - (2851716:unified_unilip.py:926)
2026-01-07 16:32:50 - INFO - total_loss: 0.48806050419807434, masked_loc_loss: 0.09746673703193665, masked_gen_loss: 0.3905937671661377 - (2851716:unified_unilip.py:926)
2026-01-07 16:32:56 - INFO - total_loss: 0.4552467167377472, masked_loc_loss: 0.0895552933216095, masked_gen_loss: 0.3656914234161377 - (2851716:unified_unilip.py:926)
2026-01-07 16:33:10 - INFO - total_loss: 0.42418867349624634, masked_loc_loss: 0.07843751460313797, masked_gen_loss: 0.34575116634368896 - (2851716:unified_unilip.py:926)
2026-01-07 16:33:24 - INFO - total_loss: 0.484287828207016, masked_loc_loss: 0.09646178036928177, masked_gen_loss: 0.3878260552883148 - (2851716:unified_unilip.py:926)
2026-01-07 16:33:39 - INFO - total_loss: 0.4775587320327759, masked_loc_loss: 0.12362659722566605, masked_gen_loss: 0.35393214225769043 - (2851716:unified_unilip.py:926)
2026-01-07 16:33:53 - INFO - total_loss: 0.46970605850219727, masked_loc_loss: 0.1332370787858963, masked_gen_loss: 0.33646899461746216 - (2851716:unified_unilip.py:926)
2026-01-07 16:34:00 - INFO - total_loss: 0.5356252193450928, masked_loc_loss: 0.11686655879020691, masked_gen_loss: 0.4187586307525635 - (2851716:unified_unilip.py:926)
2026-01-07 16:34:09 - INFO - total_loss: 0.4491856098175049, masked_loc_loss: 0.15857475996017456, masked_gen_loss: 0.2906108498573303 - (2851716:unified_unilip.py:926)
2026-01-07 16:34:23 - INFO - total_loss: 0.4680519104003906, masked_loc_loss: 0.08983822166919708, masked_gen_loss: 0.37821367383003235 - (2851716:unified_unilip.py:926)
2026-01-07 16:34:37 - INFO - total_loss: 0.46497172117233276, masked_loc_loss: 0.10769467055797577, masked_gen_loss: 0.3572770357131958 - (2851716:unified_unilip.py:926)
2026-01-07 16:34:51 - INFO - total_loss: 0.45917513966560364, masked_loc_loss: 0.1599784791469574, masked_gen_loss: 0.29919666051864624 - (2851716:unified_unilip.py:926)
2026-01-07 16:35:05 - INFO - total_loss: 0.48732084035873413, masked_loc_loss: 0.1257171630859375, masked_gen_loss: 0.36160367727279663 - (2851716:unified_unilip.py:926)
2026-01-07 16:35:11 - INFO - total_loss: 0.5176910161972046, masked_loc_loss: 0.08178621530532837, masked_gen_loss: 0.4359048306941986 - (2851716:unified_unilip.py:926)
2026-01-07 16:35:22 - INFO - total_loss: 0.43784064054489136, masked_loc_loss: 0.08834677934646606, masked_gen_loss: 0.3494938611984253 - (2851716:unified_unilip.py:926)
2026-01-07 16:35:37 - INFO - total_loss: 0.5421121120452881, masked_loc_loss: 0.15988478064537048, masked_gen_loss: 0.38222736120224 - (2851716:unified_unilip.py:926)
2026-01-07 16:35:51 - INFO - total_loss: 0.4625212550163269, masked_loc_loss: 0.14472244679927826, masked_gen_loss: 0.31779879331588745 - (2851716:unified_unilip.py:926)
2026-01-07 16:36:06 - INFO - total_loss: 0.4716781675815582, masked_loc_loss: 0.12580791115760803, masked_gen_loss: 0.3458702564239502 - (2851716:unified_unilip.py:926)
2026-01-07 16:36:16 - INFO - total_loss: 0.4515959322452545, masked_loc_loss: 0.09065423160791397, masked_gen_loss: 0.36094170808792114 - (2851716:unified_unilip.py:926)
2026-01-07 16:36:23 - INFO - total_loss: 0.4443930387496948, masked_loc_loss: 0.160990372300148, masked_gen_loss: 0.2834026515483856 - (2851716:unified_unilip.py:926)
2026-01-07 16:36:35 - INFO - total_loss: 0.47743815183639526, masked_loc_loss: 0.13247981667518616, masked_gen_loss: 0.3449583351612091 - (2851716:unified_unilip.py:926)
2026-01-07 16:36:50 - INFO - total_loss: 0.48723480105400085, masked_loc_loss: 0.15781432390213013, masked_gen_loss: 0.3294204771518707 - (2851716:unified_unilip.py:926)
2026-01-07 16:37:04 - INFO - total_loss: 0.45971381664276123, masked_loc_loss: 0.13316737115383148, masked_gen_loss: 0.32654646039009094 - (2851716:unified_unilip.py:926)
2026-01-07 16:37:18 - INFO - total_loss: 0.4944702684879303, masked_loc_loss: 0.12988224625587463, masked_gen_loss: 0.36458802223205566 - (2851716:unified_unilip.py:926)
2026-01-07 16:37:27 - INFO - total_loss: 0.5201637148857117, masked_loc_loss: 0.10160036385059357, masked_gen_loss: 0.4185633361339569 - (2851716:unified_unilip.py:926)
2026-01-07 16:37:36 - INFO - total_loss: 0.458562433719635, masked_loc_loss: 0.11892502009868622, masked_gen_loss: 0.33963742852211 - (2851716:unified_unilip.py:926)
2026-01-07 16:37:50 - INFO - total_loss: 0.5341084003448486, masked_loc_loss: 0.13158230483531952, masked_gen_loss: 0.4025261104106903 - (2851716:unified_unilip.py:926)
2026-01-07 16:38:04 - INFO - total_loss: 0.46852511167526245, masked_loc_loss: 0.11690406501293182, masked_gen_loss: 0.35162103176116943 - (2851716:unified_unilip.py:926)
2026-01-07 16:38:19 - INFO - total_loss: 0.4825366139411926, masked_loc_loss: 0.1346578598022461, masked_gen_loss: 0.34787875413894653 - (2851716:unified_unilip.py:926)
2026-01-07 16:38:30 - INFO - total_loss: 0.4661233127117157, masked_loc_loss: 0.14546063542366028, masked_gen_loss: 0.3206626772880554 - (2851716:unified_unilip.py:926)
2026-01-07 16:38:40 - INFO - total_loss: 0.5195607542991638, masked_loc_loss: 0.1071547418832779, masked_gen_loss: 0.41240599751472473 - (2851716:unified_unilip.py:926)
2026-01-07 16:38:54 - INFO - total_loss: 0.47765231132507324, masked_loc_loss: 0.09616312384605408, masked_gen_loss: 0.38148918747901917 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:08 - INFO - total_loss: 0.41224122047424316, masked_loc_loss: 0.0953444093465805, masked_gen_loss: 0.31689679622650146 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:20 - INFO - total_loss: 0.4502505660057068, masked_loc_loss: 0.08818356692790985, masked_gen_loss: 0.36206698417663574 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:26 - INFO - total_loss: 0.4601644277572632, masked_loc_loss: 0.09103565663099289, masked_gen_loss: 0.3691287636756897 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:32 - INFO - total_loss: 0.4828048050403595, masked_loc_loss: 0.10548757761716843, masked_gen_loss: 0.3773172199726105 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:39 - INFO - total_loss: 0.4167327880859375, masked_loc_loss: 0.07522965967655182, masked_gen_loss: 0.3415031433105469 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:45 - INFO - total_loss: 0.4858068525791168, masked_loc_loss: 0.07862033694982529, masked_gen_loss: 0.40718650817871094 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:52 - INFO - total_loss: 0.4072810709476471, masked_loc_loss: 0.1236015260219574, masked_gen_loss: 0.2836795449256897 - (2851716:unified_unilip.py:926)
2026-01-07 16:39:58 - INFO - total_loss: 0.4204311668872833, masked_loc_loss: 0.11004239320755005, masked_gen_loss: 0.3103887736797333 - (2851716:unified_unilip.py:926)
2026-01-07 16:40:05 - INFO - total_loss: 0.5198290348052979, masked_loc_loss: 0.11458411812782288, masked_gen_loss: 0.40524494647979736 - (2851716:unified_unilip.py:926)
2026-01-07 16:40:12 - INFO - total_loss: 0.4361794590950012, masked_loc_loss: 0.09538052976131439, masked_gen_loss: 0.34079891443252563 - (2851716:unified_unilip.py:926)
2026-01-07 16:40:18 - INFO - total_loss: 0.5124064087867737, masked_loc_loss: 0.11909106373786926, masked_gen_loss: 0.3933153450489044 - (2851716:unified_unilip.py:926)
2026-01-07 16:40:24 - INFO - total_loss: 0.4612434506416321, masked_loc_loss: 0.09086215496063232, masked_gen_loss: 0.37038129568099976 - (2851716:unified_unilip.py:926)
2026-01-07 16:40:37 - INFO - total_loss: 0.484682559967041, masked_loc_loss: 0.16571734845638275, masked_gen_loss: 0.31896519660949707 - (2851716:unified_unilip.py:926)
2026-01-07 16:40:51 - INFO - total_loss: 0.5628257393836975, masked_loc_loss: 0.11425796896219254, masked_gen_loss: 0.44856777787208557 - (2851716:unified_unilip.py:926)
2026-01-07 16:41:06 - INFO - total_loss: 0.4443258047103882, masked_loc_loss: 0.08986727893352509, masked_gen_loss: 0.3544585108757019 - (2851716:unified_unilip.py:926)
2026-01-07 16:41:21 - INFO - total_loss: 0.4049049913883209, masked_loc_loss: 0.08392509818077087, masked_gen_loss: 0.32097989320755005 - (2851716:unified_unilip.py:926)
2026-01-07 16:41:29 - INFO - total_loss: 0.5009922981262207, masked_loc_loss: 0.15617594122886658, masked_gen_loss: 0.3448163866996765 - (2851716:unified_unilip.py:926)
2026-01-07 16:41:35 - INFO - total_loss: 0.5122766494750977, masked_loc_loss: 0.09931190311908722, masked_gen_loss: 0.41296476125717163 - (2851716:unified_unilip.py:926)
2026-01-07 16:41:45 - INFO - total_loss: 0.44870930910110474, masked_loc_loss: 0.10968001186847687, masked_gen_loss: 0.33902931213378906 - (2851716:unified_unilip.py:926)
2026-01-07 16:42:01 - INFO - total_loss: 0.4168982207775116, masked_loc_loss: 0.08499967306852341, masked_gen_loss: 0.3318985402584076 - (2851716:unified_unilip.py:926)
2026-01-07 16:42:15 - INFO - total_loss: 0.49836665391921997, masked_loc_loss: 0.10848654806613922, masked_gen_loss: 0.38988009095191956 - (2851716:unified_unilip.py:926)
2026-01-07 16:42:30 - INFO - total_loss: 0.4886237382888794, masked_loc_loss: 0.09903348982334137, masked_gen_loss: 0.3895902633666992 - (2851716:unified_unilip.py:926)
2026-01-07 16:42:41 - INFO - total_loss: 0.4342484474182129, masked_loc_loss: 0.11880858987569809, masked_gen_loss: 0.3154398500919342 - (2851716:unified_unilip.py:926)
2026-01-07 16:42:48 - INFO - total_loss: 0.4721081554889679, masked_loc_loss: 0.10312382131814957, masked_gen_loss: 0.3689843416213989 - (2851716:unified_unilip.py:926)
2026-01-07 16:43:00 - INFO - total_loss: 0.47836777567863464, masked_loc_loss: 0.07938683778047562, masked_gen_loss: 0.3989809453487396 - (2851716:unified_unilip.py:926)
2026-01-07 16:43:15 - INFO - total_loss: 0.4334096908569336, masked_loc_loss: 0.08009769022464752, masked_gen_loss: 0.3533119857311249 - (2851716:unified_unilip.py:926)
2026-01-07 16:43:29 - INFO - total_loss: 0.424663782119751, masked_loc_loss: 0.0709572583436966, masked_gen_loss: 0.3537065088748932 - (2851716:unified_unilip.py:926)
2026-01-07 16:43:44 - INFO - total_loss: 0.49478209018707275, masked_loc_loss: 0.07349815219640732, masked_gen_loss: 0.42128393054008484 - (2851716:unified_unilip.py:926)
2026-01-07 16:43:52 - INFO - total_loss: 0.43991580605506897, masked_loc_loss: 0.09123704582452774, masked_gen_loss: 0.3486787676811218 - (2851716:unified_unilip.py:926)
2026-01-07 16:44:01 - INFO - total_loss: 0.44878512620925903, masked_loc_loss: 0.06856445968151093, masked_gen_loss: 0.3802206814289093 - (2851716:unified_unilip.py:926)
2026-01-07 16:44:15 - INFO - total_loss: 0.45613187551498413, masked_loc_loss: 0.13369588553905487, masked_gen_loss: 0.32243597507476807 - (2851716:unified_unilip.py:926)
2026-01-07 16:44:30 - INFO - total_loss: 0.4195331037044525, masked_loc_loss: 0.13717833161354065, masked_gen_loss: 0.28235477209091187 - (2851716:unified_unilip.py:926)
2026-01-07 16:44:44 - INFO - total_loss: 0.45540207624435425, masked_loc_loss: 0.11312058568000793, masked_gen_loss: 0.3422814905643463 - (2851716:unified_unilip.py:926)
2026-01-07 16:44:56 - INFO - total_loss: 0.4465208649635315, masked_loc_loss: 0.09519901871681213, masked_gen_loss: 0.35132184624671936 - (2851716:unified_unilip.py:926)
2026-01-07 16:45:02 - INFO - total_loss: 0.4514595866203308, masked_loc_loss: 0.1228732019662857, masked_gen_loss: 0.3285863697528839 - (2851716:unified_unilip.py:926)
2026-01-07 16:45:13 - INFO - total_loss: 0.4483892321586609, masked_loc_loss: 0.047669634222984314, masked_gen_loss: 0.4007195830345154 - (2851716:unified_unilip.py:926)
2026-01-07 16:45:27 - INFO - total_loss: 0.4625505208969116, masked_loc_loss: 0.0945848673582077, masked_gen_loss: 0.3679656386375427 - (2851716:unified_unilip.py:926)
2026-01-07 16:45:41 - INFO - total_loss: 0.4033604860305786, masked_loc_loss: 0.09783339500427246, masked_gen_loss: 0.30552709102630615 - (2851716:unified_unilip.py:926)
2026-01-07 16:45:56 - INFO - total_loss: 0.4706825017929077, masked_loc_loss: 0.06229931116104126, masked_gen_loss: 0.40838319063186646 - (2851716:unified_unilip.py:926)
2026-01-07 16:46:06 - INFO - total_loss: 0.42057183384895325, masked_loc_loss: 0.05698615312576294, masked_gen_loss: 0.3635856807231903 - (2851716:unified_unilip.py:926)
2026-01-07 16:46:14 - INFO - total_loss: 0.3585702180862427, masked_loc_loss: 0.08848094940185547, masked_gen_loss: 0.2700892686843872 - (2851716:unified_unilip.py:926)
2026-01-07 16:46:29 - INFO - total_loss: 0.43717387318611145, masked_loc_loss: 0.07278820127248764, masked_gen_loss: 0.3643856644630432 - (2851716:unified_unilip.py:926)
2026-01-07 16:46:43 - INFO - total_loss: 0.46505802869796753, masked_loc_loss: 0.10468005388975143, masked_gen_loss: 0.3603779673576355 - (2851716:unified_unilip.py:926)
2026-01-07 16:46:58 - INFO - total_loss: 0.4790363907814026, masked_loc_loss: 0.08620254695415497, masked_gen_loss: 0.3928338289260864 - (2851716:unified_unilip.py:926)
2026-01-07 16:47:10 - INFO - total_loss: 0.42863792181015015, masked_loc_loss: 0.0798480361700058, masked_gen_loss: 0.34878987073898315 - (2851716:unified_unilip.py:926)
2026-01-07 16:47:17 - INFO - total_loss: 0.45018061995506287, masked_loc_loss: 0.1192028820514679, masked_gen_loss: 0.33097773790359497 - (2851716:unified_unilip.py:926)
2026-01-07 16:47:32 - INFO - total_loss: 0.48730170726776123, masked_loc_loss: 0.11987597495317459, masked_gen_loss: 0.36742573976516724 - (2851716:unified_unilip.py:926)
2026-01-07 16:47:46 - INFO - total_loss: 0.4370894432067871, masked_loc_loss: 0.06995320320129395, masked_gen_loss: 0.36713624000549316 - (2851716:unified_unilip.py:926)
2026-01-07 16:48:01 - INFO - total_loss: 0.48717957735061646, masked_loc_loss: 0.11511630564928055, masked_gen_loss: 0.3720632791519165 - (2851716:unified_unilip.py:926)
2026-01-07 16:48:15 - INFO - total_loss: 0.4831314980983734, masked_loc_loss: 0.07510551810264587, masked_gen_loss: 0.40802597999572754 - (2851716:unified_unilip.py:926)
2026-01-07 16:48:25 - INFO - total_loss: 0.4661845266819, masked_loc_loss: 0.11192851513624191, masked_gen_loss: 0.3542560040950775 - (2851716:unified_unilip.py:926)
2026-01-07 16:48:40 - INFO - total_loss: 0.4365323781967163, masked_loc_loss: 0.1195264607667923, masked_gen_loss: 0.3170059323310852 - (2851716:unified_unilip.py:926)
2026-01-07 16:48:54 - INFO - total_loss: 0.3927956819534302, masked_loc_loss: 0.10278797149658203, masked_gen_loss: 0.29000771045684814 - (2851716:unified_unilip.py:926)
2026-01-07 16:49:09 - INFO - total_loss: 0.4905509054660797, masked_loc_loss: 0.1042834222316742, masked_gen_loss: 0.3862674832344055 - (2851716:unified_unilip.py:926)
2026-01-07 16:49:20 - INFO - total_loss: 0.4515119791030884, masked_loc_loss: 0.09655754268169403, masked_gen_loss: 0.35495442152023315 - (2851716:unified_unilip.py:926)
2026-01-07 16:49:32 - INFO - total_loss: 0.515307605266571, masked_loc_loss: 0.08974211663007736, masked_gen_loss: 0.4255654811859131 - (2851716:unified_unilip.py:926)
2026-01-07 16:49:46 - INFO - total_loss: 0.4625566899776459, masked_loc_loss: 0.12173064798116684, masked_gen_loss: 0.34082603454589844 - (2851716:unified_unilip.py:926)
2026-01-07 16:50:01 - INFO - total_loss: 0.4293692111968994, masked_loc_loss: 0.09311217814683914, masked_gen_loss: 0.33625704050064087 - (2851716:unified_unilip.py:926)
2026-01-07 16:50:16 - INFO - total_loss: 0.48391056060791016, masked_loc_loss: 0.15857374668121338, masked_gen_loss: 0.3253368139266968 - (2851716:unified_unilip.py:926)
2026-01-07 16:50:29 - INFO - total_loss: 0.47992414236068726, masked_loc_loss: 0.11087781935930252, masked_gen_loss: 0.36904633045196533 - (2851716:unified_unilip.py:926)
2026-01-07 16:50:42 - INFO - total_loss: 0.4860984981060028, masked_loc_loss: 0.11184743791818619, masked_gen_loss: 0.3742510676383972 - (2851716:unified_unilip.py:926)
2026-01-07 16:50:56 - INFO - total_loss: 0.42309725284576416, masked_loc_loss: 0.10663080960512161, masked_gen_loss: 0.31646645069122314 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:06 - INFO - total_loss: 0.5140310525894165, masked_loc_loss: 0.10110007226467133, masked_gen_loss: 0.41293099522590637 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:12 - INFO - total_loss: 0.4748148024082184, masked_loc_loss: 0.09768877178430557, masked_gen_loss: 0.3771260380744934 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:19 - INFO - total_loss: 0.4595436453819275, masked_loc_loss: 0.11404983699321747, masked_gen_loss: 0.34549379348754883 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:25 - INFO - total_loss: 0.41213056445121765, masked_loc_loss: 0.09217511862516403, masked_gen_loss: 0.319955438375473 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:32 - INFO - total_loss: 0.4735493063926697, masked_loc_loss: 0.09741362929344177, masked_gen_loss: 0.3761356770992279 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:38 - INFO - total_loss: 0.42196232080459595, masked_loc_loss: 0.10890169441699982, masked_gen_loss: 0.3130606412887573 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:45 - INFO - total_loss: 0.3538792133331299, masked_loc_loss: 0.08782444894313812, masked_gen_loss: 0.26605474948883057 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:51 - INFO - total_loss: 0.44227689504623413, masked_loc_loss: 0.07274657487869263, masked_gen_loss: 0.3695303201675415 - (2851716:unified_unilip.py:926)
2026-01-07 16:51:58 - INFO - total_loss: 0.4656122326850891, masked_loc_loss: 0.08788993954658508, masked_gen_loss: 0.37772229313850403 - (2851716:unified_unilip.py:926)
2026-01-07 16:52:04 - INFO - total_loss: 0.47377797961235046, masked_loc_loss: 0.12697961926460266, masked_gen_loss: 0.3467983603477478 - (2851716:unified_unilip.py:926)
2026-01-07 16:52:10 - INFO - total_loss: 0.4703871011734009, masked_loc_loss: 0.116726353764534, masked_gen_loss: 0.3536607325077057 - (2851716:unified_unilip.py:926)
2026-01-07 16:52:23 - INFO - total_loss: 0.4567890167236328, masked_loc_loss: 0.1258358508348465, masked_gen_loss: 0.3309531807899475 - (2851716:unified_unilip.py:926)
2026-01-07 16:52:38 - INFO - total_loss: 0.49549275636672974, masked_loc_loss: 0.08723454177379608, masked_gen_loss: 0.40825822949409485 - (2851716:unified_unilip.py:926)
2026-01-07 16:52:53 - INFO - total_loss: 0.45707738399505615, masked_loc_loss: 0.07362343370914459, masked_gen_loss: 0.38345393538475037 - (2851716:unified_unilip.py:926)
2026-01-07 16:53:07 - INFO - total_loss: 0.524982213973999, masked_loc_loss: 0.15162765979766846, masked_gen_loss: 0.37335455417633057 - (2851716:unified_unilip.py:926)
2026-01-07 16:53:14 - INFO - total_loss: 0.49457651376724243, masked_loc_loss: 0.1459694504737854, masked_gen_loss: 0.34860706329345703 - (2851716:unified_unilip.py:926)
2026-01-07 16:53:21 - INFO - total_loss: 0.5027266144752502, masked_loc_loss: 0.10701756179332733, masked_gen_loss: 0.3957090377807617 - (2851716:unified_unilip.py:926)
2026-01-07 16:53:34 - INFO - total_loss: 0.46485817432403564, masked_loc_loss: 0.08353529870510101, masked_gen_loss: 0.3813228905200958 - (2851716:unified_unilip.py:926)
2026-01-07 16:53:49 - INFO - total_loss: 0.42710819840431213, masked_loc_loss: 0.1138756275177002, masked_gen_loss: 0.31323257088661194 - (2851716:unified_unilip.py:926)
2026-01-07 16:54:04 - INFO - total_loss: 0.43857187032699585, masked_loc_loss: 0.08153767883777618, masked_gen_loss: 0.35703420639038086 - (2851716:unified_unilip.py:926)
2026-01-07 16:54:18 - INFO - total_loss: 0.4796973466873169, masked_loc_loss: 0.09184671938419342, masked_gen_loss: 0.38785064220428467 - (2851716:unified_unilip.py:926)
2026-01-07 16:54:25 - INFO - total_loss: 0.4620816707611084, masked_loc_loss: 0.068524070084095, masked_gen_loss: 0.393557608127594 - (2851716:unified_unilip.py:926)
2026-01-07 16:54:35 - INFO - total_loss: 0.47065919637680054, masked_loc_loss: 0.09939207136631012, masked_gen_loss: 0.3712671101093292 - (2851716:unified_unilip.py:926)
2026-01-07 16:54:50 - INFO - total_loss: 0.4218243360519409, masked_loc_loss: 0.0775783509016037, masked_gen_loss: 0.3442460000514984 - (2851716:unified_unilip.py:926)
2026-01-07 16:55:04 - INFO - total_loss: 0.4553602933883667, masked_loc_loss: 0.08066868782043457, masked_gen_loss: 0.37469160556793213 - (2851716:unified_unilip.py:926)
2026-01-07 16:55:19 - INFO - total_loss: 0.47355926036834717, masked_loc_loss: 0.07316890358924866, masked_gen_loss: 0.4003903567790985 - (2851716:unified_unilip.py:926)
2026-01-07 16:55:30 - INFO - total_loss: 0.3946375846862793, masked_loc_loss: 0.09371988475322723, masked_gen_loss: 0.30091771483421326 - (2851716:unified_unilip.py:926)
2026-01-07 16:55:39 - INFO - total_loss: 0.478361576795578, masked_loc_loss: 0.10063519328832626, masked_gen_loss: 0.37772637605667114 - (2851716:unified_unilip.py:926)
2026-01-07 16:55:53 - INFO - total_loss: 0.4502755403518677, masked_loc_loss: 0.12439032644033432, masked_gen_loss: 0.32588520646095276 - (2851716:unified_unilip.py:926)
2026-01-07 16:56:08 - INFO - total_loss: 0.4629879295825958, masked_loc_loss: 0.09969460964202881, masked_gen_loss: 0.363293319940567 - (2851716:unified_unilip.py:926)
2026-01-07 16:56:22 - INFO - total_loss: 0.4428623914718628, masked_loc_loss: 0.07986246049404144, masked_gen_loss: 0.36299991607666016 - (2851716:unified_unilip.py:926)
2026-01-07 16:56:34 - INFO - total_loss: 0.4403032660484314, masked_loc_loss: 0.07238533347845078, masked_gen_loss: 0.3679179251194 - (2851716:unified_unilip.py:926)
2026-01-07 16:56:42 - INFO - total_loss: 0.45806798338890076, masked_loc_loss: 0.11884506791830063, masked_gen_loss: 0.33922290802001953 - (2851716:unified_unilip.py:926)
2026-01-07 16:56:56 - INFO - total_loss: 0.48525211215019226, masked_loc_loss: 0.06961938738822937, masked_gen_loss: 0.4156327247619629 - (2851716:unified_unilip.py:926)
2026-01-07 16:57:11 - INFO - total_loss: 0.42379021644592285, masked_loc_loss: 0.09527009725570679, masked_gen_loss: 0.32852011919021606 - (2851716:unified_unilip.py:926)
2026-01-07 16:57:23 - INFO - total_loss: 0.3874685764312744, masked_loc_loss: 0.08738069236278534, masked_gen_loss: 0.30008789896965027 - (2851716:unified_unilip.py:926)
2026-01-07 16:57:35 - INFO - total_loss: 0.48420020937919617, masked_loc_loss: 0.15191400051116943, masked_gen_loss: 0.33228620886802673 - (2851716:unified_unilip.py:926)
2026-01-07 16:57:43 - INFO - total_loss: 0.42262744903564453, masked_loc_loss: 0.06533735990524292, masked_gen_loss: 0.3572900891304016 - (2851716:unified_unilip.py:926)
2026-01-07 16:57:58 - INFO - total_loss: 0.4517704248428345, masked_loc_loss: 0.08298022300004959, masked_gen_loss: 0.3687902092933655 - (2851716:unified_unilip.py:926)
2026-01-07 16:58:12 - INFO - total_loss: 0.41472044587135315, masked_loc_loss: 0.08745023608207703, masked_gen_loss: 0.3272702097892761 - (2851716:unified_unilip.py:926)
2026-01-07 16:58:26 - INFO - total_loss: 0.4259922206401825, masked_loc_loss: 0.062393784523010254, masked_gen_loss: 0.36359843611717224 - (2851716:unified_unilip.py:926)
2026-01-07 16:58:33 - INFO - total_loss: 0.43070748448371887, masked_loc_loss: 0.07786145806312561, masked_gen_loss: 0.35284602642059326 - (2851716:unified_unilip.py:926)
2026-01-07 16:58:47 - INFO - total_loss: 0.5364871025085449, masked_loc_loss: 0.1546652764081955, masked_gen_loss: 0.38182181119918823 - (2851716:unified_unilip.py:926)
2026-01-07 16:59:01 - INFO - total_loss: 0.5586750507354736, masked_loc_loss: 0.19976374506950378, masked_gen_loss: 0.35891127586364746 - (2851716:unified_unilip.py:926)
2026-01-07 16:59:15 - INFO - total_loss: 0.44473186135292053, masked_loc_loss: 0.10362478345632553, masked_gen_loss: 0.3411070704460144 - (2851716:unified_unilip.py:926)
2026-01-07 16:59:29 - INFO - total_loss: 0.43052393198013306, masked_loc_loss: 0.10615890473127365, masked_gen_loss: 0.3243650197982788 - (2851716:unified_unilip.py:926)
2026-01-07 16:59:40 - INFO - total_loss: 0.4327223300933838, masked_loc_loss: 0.09014739096164703, masked_gen_loss: 0.34257492423057556 - (2851716:unified_unilip.py:926)
2026-01-07 16:59:54 - INFO - total_loss: 0.4855763912200928, masked_loc_loss: 0.1365702599287033, masked_gen_loss: 0.34900611639022827 - (2851716:unified_unilip.py:926)
2026-01-07 17:00:08 - INFO - total_loss: 0.47356170415878296, masked_loc_loss: 0.11118648946285248, masked_gen_loss: 0.3623751997947693 - (2851716:unified_unilip.py:926)
2026-01-07 17:00:23 - INFO - total_loss: 0.4738268256187439, masked_loc_loss: 0.10685387998819351, masked_gen_loss: 0.366972953081131 - (2851716:unified_unilip.py:926)
2026-01-07 17:00:33 - INFO - total_loss: 0.4656296670436859, masked_loc_loss: 0.0963602364063263, masked_gen_loss: 0.3692694306373596 - (2851716:unified_unilip.py:926)
2026-01-07 17:00:44 - INFO - total_loss: 0.4546908736228943, masked_loc_loss: 0.10867096483707428, masked_gen_loss: 0.3460199236869812 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:14 - INFO - total_loss: 0.4697265625, masked_loc_loss: 0.09606610983610153, masked_gen_loss: 0.37366044521331787 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:20 - INFO - total_loss: 0.4046119749546051, masked_loc_loss: 0.15326407551765442, masked_gen_loss: 0.2513478994369507 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:26 - INFO - total_loss: 0.48622560501098633, masked_loc_loss: 0.08953563868999481, masked_gen_loss: 0.3966899514198303 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:32 - INFO - total_loss: 0.48616823554039, masked_loc_loss: 0.11408547312021255, masked_gen_loss: 0.37208276987075806 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:38 - INFO - total_loss: 0.48584336042404175, masked_loc_loss: 0.08980582654476166, masked_gen_loss: 0.3960375189781189 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:45 - INFO - total_loss: 0.46174466609954834, masked_loc_loss: 0.07923531532287598, masked_gen_loss: 0.38250935077667236 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:51 - INFO - total_loss: 0.44008952379226685, masked_loc_loss: 0.10484088957309723, masked_gen_loss: 0.3352486491203308 - (2851716:unified_unilip.py:926)
2026-01-07 17:02:57 - INFO - total_loss: 0.43496671319007874, masked_loc_loss: 0.09100355952978134, masked_gen_loss: 0.3439631462097168 - (2851716:unified_unilip.py:926)
2026-01-07 17:03:19 - INFO - total_loss: 0.4386254847049713, masked_loc_loss: 0.08271049708127975, masked_gen_loss: 0.35591498017311096 - (2851716:unified_unilip.py:926)
2026-01-07 17:03:25 - INFO - total_loss: 0.47234126925468445, masked_loc_loss: 0.14226451516151428, masked_gen_loss: 0.33007675409317017 - (2851716:unified_unilip.py:926)
2026-01-07 17:03:34 - INFO - total_loss: 0.483700156211853, masked_loc_loss: 0.06293556094169617, masked_gen_loss: 0.42076459527015686 - (2851716:unified_unilip.py:926)
2026-01-07 17:03:47 - INFO - total_loss: 0.4892357587814331, masked_loc_loss: 0.11333119869232178, masked_gen_loss: 0.37590456008911133 - (2851716:unified_unilip.py:926)
2026-01-07 17:04:01 - INFO - total_loss: 0.3982696533203125, masked_loc_loss: 0.0887497067451477, masked_gen_loss: 0.3095199465751648 - (2851716:unified_unilip.py:926)
2026-01-07 17:04:15 - INFO - total_loss: 0.4797665476799011, masked_loc_loss: 0.09324895590543747, masked_gen_loss: 0.38651758432388306 - (2851716:unified_unilip.py:926)
2026-01-07 17:04:26 - INFO - total_loss: 0.5037343502044678, masked_loc_loss: 0.1219971626996994, masked_gen_loss: 0.3817371726036072 - (2851716:unified_unilip.py:926)
2026-01-07 17:04:33 - INFO - total_loss: 0.48494529724121094, masked_loc_loss: 0.1001337319612503, masked_gen_loss: 0.3848115801811218 - (2851716:unified_unilip.py:926)
2026-01-07 17:04:39 - INFO - total_loss: 0.4355349540710449, masked_loc_loss: 0.11442547291517258, masked_gen_loss: 0.32110947370529175 - (2851716:unified_unilip.py:926)
2026-01-07 17:04:52 - INFO - total_loss: 0.45439213514328003, masked_loc_loss: 0.0710550844669342, masked_gen_loss: 0.3833370506763458 - (2851716:unified_unilip.py:926)
2026-01-07 17:05:07 - INFO - total_loss: 0.42391088604927063, masked_loc_loss: 0.09885817766189575, masked_gen_loss: 0.3250527083873749 - (2851716:unified_unilip.py:926)
2026-01-07 17:05:21 - INFO - total_loss: 0.45008525252342224, masked_loc_loss: 0.07505879551172256, masked_gen_loss: 0.3750264644622803 - (2851716:unified_unilip.py:926)
2026-01-07 17:05:35 - INFO - total_loss: 0.39909666776657104, masked_loc_loss: 0.07725869864225388, masked_gen_loss: 0.3218379616737366 - (2851716:unified_unilip.py:926)
2026-01-07 17:05:43 - INFO - total_loss: 0.4425733983516693, masked_loc_loss: 0.07021433115005493, masked_gen_loss: 0.3723590672016144 - (2851716:unified_unilip.py:926)
2026-01-07 17:05:49 - INFO - total_loss: 0.43950024247169495, masked_loc_loss: 0.10477005690336227, masked_gen_loss: 0.3347301781177521 - (2851716:unified_unilip.py:926)
2026-01-07 17:06:03 - INFO - total_loss: 0.4464309811592102, masked_loc_loss: 0.10150282084941864, masked_gen_loss: 0.34492817521095276 - (2851716:unified_unilip.py:926)
2026-01-07 17:06:18 - INFO - total_loss: 0.3924509882926941, masked_loc_loss: 0.10195983946323395, masked_gen_loss: 0.29049116373062134 - (2851716:unified_unilip.py:926)
2026-01-07 17:06:32 - INFO - total_loss: 0.4870995581150055, masked_loc_loss: 0.06716945767402649, masked_gen_loss: 0.419930100440979 - (2851716:unified_unilip.py:926)
2026-01-07 17:06:47 - INFO - total_loss: 0.45993661880493164, masked_loc_loss: 0.08375322073698044, masked_gen_loss: 0.3761833906173706 - (2851716:unified_unilip.py:926)
2026-01-07 17:06:54 - INFO - total_loss: 0.40353089570999146, masked_loc_loss: 0.06829284876585007, masked_gen_loss: 0.3352380394935608 - (2851716:unified_unilip.py:926)
2026-01-07 17:07:04 - INFO - total_loss: 0.5006425976753235, masked_loc_loss: 0.11350191384553909, masked_gen_loss: 0.387140691280365 - (2851716:unified_unilip.py:926)
2026-01-07 17:07:19 - INFO - total_loss: 0.4772375822067261, masked_loc_loss: 0.07442677021026611, masked_gen_loss: 0.40281081199645996 - (2851716:unified_unilip.py:926)
2026-01-07 17:07:34 - INFO - total_loss: 0.46159258484840393, masked_loc_loss: 0.0765438973903656, masked_gen_loss: 0.38504868745803833 - (2851716:unified_unilip.py:926)
2026-01-07 17:07:48 - INFO - total_loss: 0.3935686945915222, masked_loc_loss: 0.085345059633255, masked_gen_loss: 0.3082236349582672 - (2851716:unified_unilip.py:926)
2026-01-07 17:07:59 - INFO - total_loss: 0.39824241399765015, masked_loc_loss: 0.10351159423589706, masked_gen_loss: 0.2947308123111725 - (2851716:unified_unilip.py:926)
2026-01-07 17:08:08 - INFO - total_loss: 0.46127092838287354, masked_loc_loss: 0.07587341964244843, masked_gen_loss: 0.3853974938392639 - (2851716:unified_unilip.py:926)
2026-01-07 17:08:23 - INFO - total_loss: 0.45158159732818604, masked_loc_loss: 0.07395738363265991, masked_gen_loss: 0.3776242136955261 - (2851716:unified_unilip.py:926)
2026-01-07 17:08:38 - INFO - total_loss: 0.41411393880844116, masked_loc_loss: 0.09958589822053909, masked_gen_loss: 0.31452804803848267 - (2851716:unified_unilip.py:926)
2026-01-07 17:08:52 - INFO - total_loss: 0.38930580019950867, masked_loc_loss: 0.0947350561618805, masked_gen_loss: 0.2945707440376282 - (2851716:unified_unilip.py:926)
2026-01-07 17:09:03 - INFO - total_loss: 0.46145981550216675, masked_loc_loss: 0.09229649603366852, masked_gen_loss: 0.3691633343696594 - (2851716:unified_unilip.py:926)
2026-01-07 17:09:13 - INFO - total_loss: 0.4878392815589905, masked_loc_loss: 0.07409346103668213, masked_gen_loss: 0.41374582052230835 - (2851716:unified_unilip.py:926)
2026-01-07 17:09:28 - INFO - total_loss: 0.4219837784767151, masked_loc_loss: 0.06931115686893463, masked_gen_loss: 0.35267260670661926 - (2851716:unified_unilip.py:926)
2026-01-07 17:09:42 - INFO - total_loss: 0.42385759949684143, masked_loc_loss: 0.07319138199090958, masked_gen_loss: 0.35066622495651245 - (2851716:unified_unilip.py:926)
2026-01-07 17:09:56 - INFO - total_loss: 0.42355433106422424, masked_loc_loss: 0.10739290714263916, masked_gen_loss: 0.3161614239215851 - (2851716:unified_unilip.py:926)
2026-01-07 17:10:08 - INFO - total_loss: 0.4285980761051178, masked_loc_loss: 0.08976832032203674, masked_gen_loss: 0.33882975578308105 - (2851716:unified_unilip.py:926)
2026-01-07 17:10:19 - INFO - total_loss: 0.4832708537578583, masked_loc_loss: 0.11979803442955017, masked_gen_loss: 0.3634728193283081 - (2851716:unified_unilip.py:926)
2026-01-07 17:10:34 - INFO - total_loss: 0.507803201675415, masked_loc_loss: 0.08585628867149353, masked_gen_loss: 0.4219468832015991 - (2851716:unified_unilip.py:926)
2026-01-07 17:10:48 - INFO - total_loss: 0.47568410634994507, masked_loc_loss: 0.07768629491329193, masked_gen_loss: 0.39799779653549194 - (2851716:unified_unilip.py:926)
2026-01-07 17:11:02 - INFO - total_loss: 0.43814539909362793, masked_loc_loss: 0.06481923162937164, masked_gen_loss: 0.3733261823654175 - (2851716:unified_unilip.py:926)
2026-01-07 17:11:11 - INFO - total_loss: 0.4492173492908478, masked_loc_loss: 0.0761953815817833, masked_gen_loss: 0.3730219602584839 - (2851716:unified_unilip.py:926)
2026-01-07 17:11:20 - INFO - total_loss: 0.4451114535331726, masked_loc_loss: 0.11954957246780396, masked_gen_loss: 0.32556188106536865 - (2851716:unified_unilip.py:926)
2026-01-07 17:11:34 - INFO - total_loss: 0.54111647605896, masked_loc_loss: 0.15923261642456055, masked_gen_loss: 0.3818838894367218 - (2851716:unified_unilip.py:926)
2026-01-07 17:11:48 - INFO - total_loss: 0.48477238416671753, masked_loc_loss: 0.07126882672309875, masked_gen_loss: 0.4135035574436188 - (2851716:unified_unilip.py:926)
2026-01-07 17:12:03 - INFO - total_loss: 0.4576995372772217, masked_loc_loss: 0.06229091435670853, masked_gen_loss: 0.39540863037109375 - (2851716:unified_unilip.py:926)
2026-01-07 17:12:15 - INFO - total_loss: 0.38994771242141724, masked_loc_loss: 0.09444360435009003, masked_gen_loss: 0.295504093170166 - (2851716:unified_unilip.py:926)
2026-01-07 17:12:24 - INFO - total_loss: 0.532458484172821, masked_loc_loss: 0.13071344792842865, masked_gen_loss: 0.4017450213432312 - (2851716:unified_unilip.py:926)
2026-01-07 17:12:38 - INFO - total_loss: 0.4537147879600525, masked_loc_loss: 0.09996799379587173, masked_gen_loss: 0.35374680161476135 - (2851716:unified_unilip.py:926)
2026-01-07 17:12:53 - INFO - total_loss: 0.40869027376174927, masked_loc_loss: 0.0590081661939621, masked_gen_loss: 0.349682092666626 - (2851716:unified_unilip.py:926)
2026-01-07 17:13:07 - INFO - total_loss: 0.4622999131679535, masked_loc_loss: 0.05871295556426048, masked_gen_loss: 0.4035869538784027 - (2851716:unified_unilip.py:926)
2026-01-07 17:13:20 - INFO - total_loss: 0.4864043593406677, masked_loc_loss: 0.1353967785835266, masked_gen_loss: 0.3510075807571411 - (2851716:unified_unilip.py:926)
2026-01-07 17:13:32 - INFO - total_loss: 0.44356733560562134, masked_loc_loss: 0.1091211587190628, masked_gen_loss: 0.3344461917877197 - (2851716:unified_unilip.py:926)
2026-01-07 17:13:46 - INFO - total_loss: 0.4281712472438812, masked_loc_loss: 0.0477038249373436, masked_gen_loss: 0.38046741485595703 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:01 - INFO - total_loss: 0.5061982274055481, masked_loc_loss: 0.09989231079816818, masked_gen_loss: 0.4063059389591217 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:09 - INFO - total_loss: 0.42813122272491455, masked_loc_loss: 0.08158820122480392, masked_gen_loss: 0.34654301404953003 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:16 - INFO - total_loss: 0.39753448963165283, masked_loc_loss: 0.0884428471326828, masked_gen_loss: 0.30909162759780884 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:22 - INFO - total_loss: 0.46408241987228394, masked_loc_loss: 0.07221828401088715, masked_gen_loss: 0.3918641209602356 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:29 - INFO - total_loss: 0.4080502390861511, masked_loc_loss: 0.0957791805267334, masked_gen_loss: 0.3122710585594177 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:35 - INFO - total_loss: 0.44855475425720215, masked_loc_loss: 0.07574194669723511, masked_gen_loss: 0.37281280755996704 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:42 - INFO - total_loss: 0.462368369102478, masked_loc_loss: 0.07295971363782883, masked_gen_loss: 0.3894086480140686 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:48 - INFO - total_loss: 0.45874327421188354, masked_loc_loss: 0.10905839502811432, masked_gen_loss: 0.34968486428260803 - (2851716:unified_unilip.py:926)
2026-01-07 17:14:55 - INFO - total_loss: 0.48365893959999084, masked_loc_loss: 0.10420771688222885, masked_gen_loss: 0.3794512152671814 - (2851716:unified_unilip.py:926)
2026-01-07 17:15:01 - INFO - total_loss: 0.45840033888816833, masked_loc_loss: 0.06274231523275375, masked_gen_loss: 0.395658016204834 - (2851716:unified_unilip.py:926)
2026-01-07 17:15:08 - INFO - total_loss: 0.4312467575073242, masked_loc_loss: 0.10453516244888306, masked_gen_loss: 0.32671159505844116 - (2851716:unified_unilip.py:926)
2026-01-07 17:15:14 - INFO - total_loss: 0.44864422082901, masked_loc_loss: 0.08658947050571442, masked_gen_loss: 0.3620547652244568 - (2851716:unified_unilip.py:926)
2026-01-07 17:15:29 - INFO - total_loss: 0.49744880199432373, masked_loc_loss: 0.09648662805557251, masked_gen_loss: 0.4009621739387512 - (2851716:unified_unilip.py:926)
2026-01-07 17:15:44 - INFO - total_loss: 0.42854124307632446, masked_loc_loss: 0.05307544767856598, masked_gen_loss: 0.3754657804965973 - (2851716:unified_unilip.py:926)
2026-01-07 17:15:58 - INFO - total_loss: 0.44686806201934814, masked_loc_loss: 0.09558647125959396, masked_gen_loss: 0.3512815833091736 - (2851716:unified_unilip.py:926)
2026-01-07 17:16:12 - INFO - total_loss: 0.4476834535598755, masked_loc_loss: 0.05993373692035675, masked_gen_loss: 0.38774970173835754 - (2851716:unified_unilip.py:926)
2026-01-07 17:16:18 - INFO - total_loss: 0.4495985507965088, masked_loc_loss: 0.07949918508529663, masked_gen_loss: 0.37009936571121216 - (2851716:unified_unilip.py:926)
2026-01-07 17:16:25 - INFO - total_loss: 0.3887138366699219, masked_loc_loss: 0.08924025297164917, masked_gen_loss: 0.2994735836982727 - (2851716:unified_unilip.py:926)
2026-01-07 17:16:40 - INFO - total_loss: 0.4175521731376648, masked_loc_loss: 0.07558590918779373, masked_gen_loss: 0.34196627140045166 - (2851716:unified_unilip.py:926)
2026-01-07 17:16:54 - INFO - total_loss: 0.445416122674942, masked_loc_loss: 0.09501617401838303, masked_gen_loss: 0.3503999412059784 - (2851716:unified_unilip.py:926)
2026-01-07 17:17:08 - INFO - total_loss: 0.46814966201782227, masked_loc_loss: 0.13784754276275635, masked_gen_loss: 0.3303021192550659 - (2851716:unified_unilip.py:926)
2026-01-07 17:17:22 - INFO - total_loss: 0.45721614360809326, masked_loc_loss: 0.06942710280418396, masked_gen_loss: 0.3877890408039093 - (2851716:unified_unilip.py:926)
2026-01-07 17:17:28 - INFO - total_loss: 0.454736590385437, masked_loc_loss: 0.07985120266675949, masked_gen_loss: 0.3748853802680969 - (2851716:unified_unilip.py:926)
2026-01-07 17:17:40 - INFO - total_loss: 0.4822748005390167, masked_loc_loss: 0.12189680337905884, masked_gen_loss: 0.3603779971599579 - (2851716:unified_unilip.py:926)
2026-01-07 17:17:54 - INFO - total_loss: 0.4260316491127014, masked_loc_loss: 0.09455301612615585, masked_gen_loss: 0.33147862553596497 - (2851716:unified_unilip.py:926)
2026-01-07 17:18:09 - INFO - total_loss: 0.41318145394325256, masked_loc_loss: 0.08534201234579086, masked_gen_loss: 0.3278394341468811 - (2851716:unified_unilip.py:926)
2026-01-07 17:18:23 - INFO - total_loss: 0.40461957454681396, masked_loc_loss: 0.08715211600065231, masked_gen_loss: 0.31746745109558105 - (2851716:unified_unilip.py:926)
2026-01-07 17:18:32 - INFO - total_loss: 0.4471326768398285, masked_loc_loss: 0.07718035578727722, masked_gen_loss: 0.36995232105255127 - (2851716:unified_unilip.py:926)
2026-01-07 17:18:42 - INFO - total_loss: 0.4946090579032898, masked_loc_loss: 0.13107088208198547, masked_gen_loss: 0.3635381758213043 - (2851716:unified_unilip.py:926)
2026-01-07 17:18:57 - INFO - total_loss: 0.4268251955509186, masked_loc_loss: 0.0591835081577301, masked_gen_loss: 0.3676416873931885 - (2851716:unified_unilip.py:926)
2026-01-07 17:19:11 - INFO - total_loss: 0.4176643490791321, masked_loc_loss: 0.0886748731136322, masked_gen_loss: 0.3289894759654999 - (2851716:unified_unilip.py:926)
2026-01-07 17:19:26 - INFO - total_loss: 0.49342963099479675, masked_loc_loss: 0.10613176226615906, masked_gen_loss: 0.3872978687286377 - (2851716:unified_unilip.py:926)
2026-01-07 17:19:37 - INFO - total_loss: 0.48080286383628845, masked_loc_loss: 0.14015033841133118, masked_gen_loss: 0.3406525254249573 - (2851716:unified_unilip.py:926)
2026-01-07 17:19:46 - INFO - total_loss: 0.49191033840179443, masked_loc_loss: 0.0865219384431839, masked_gen_loss: 0.40538841485977173 - (2851716:unified_unilip.py:926)
2026-01-07 17:20:01 - INFO - total_loss: 0.440343976020813, masked_loc_loss: 0.10611326992511749, masked_gen_loss: 0.3342306911945343 - (2851716:unified_unilip.py:926)
2026-01-07 17:20:15 - INFO - total_loss: 0.416289746761322, masked_loc_loss: 0.07759792357683182, masked_gen_loss: 0.3386918306350708 - (2851716:unified_unilip.py:926)
2026-01-07 17:20:30 - INFO - total_loss: 0.416517972946167, masked_loc_loss: 0.05730476230382919, masked_gen_loss: 0.3592132031917572 - (2851716:unified_unilip.py:926)
2026-01-07 17:20:41 - INFO - total_loss: 0.43822991847991943, masked_loc_loss: 0.08478547632694244, masked_gen_loss: 0.3534444272518158 - (2851716:unified_unilip.py:926)
2026-01-07 17:20:50 - INFO - total_loss: 0.4513736963272095, masked_loc_loss: 0.10331683605909348, masked_gen_loss: 0.3480568528175354 - (2851716:unified_unilip.py:926)
2026-01-07 17:21:05 - INFO - total_loss: 0.4199475646018982, masked_loc_loss: 0.054069701582193375, masked_gen_loss: 0.3658778667449951 - (2851716:unified_unilip.py:926)
2026-01-07 17:21:19 - INFO - total_loss: 0.45487380027770996, masked_loc_loss: 0.06744872778654099, masked_gen_loss: 0.3874250650405884 - (2851716:unified_unilip.py:926)
2026-01-07 17:21:34 - INFO - total_loss: 0.40813249349594116, masked_loc_loss: 0.08893992751836777, masked_gen_loss: 0.3191925585269928 - (2851716:unified_unilip.py:926)
2026-01-07 17:21:45 - INFO - total_loss: 0.4669492542743683, masked_loc_loss: 0.07490274310112, masked_gen_loss: 0.3920465111732483 - (2851716:unified_unilip.py:926)
2026-01-07 17:21:52 - INFO - total_loss: 0.39416515827178955, masked_loc_loss: 0.08979173004627228, masked_gen_loss: 0.3043734133243561 - (2851716:unified_unilip.py:926)
2026-01-07 17:22:07 - INFO - total_loss: 0.4322874844074249, masked_loc_loss: 0.06261763721704483, masked_gen_loss: 0.3696698546409607 - (2851716:unified_unilip.py:926)
2026-01-07 17:22:21 - INFO - total_loss: 0.43710026144981384, masked_loc_loss: 0.08281873911619186, masked_gen_loss: 0.3542815148830414 - (2851716:unified_unilip.py:926)
2026-01-07 17:22:35 - INFO - total_loss: 0.41478291153907776, masked_loc_loss: 0.08066356182098389, masked_gen_loss: 0.33411934971809387 - (2851716:unified_unilip.py:926)
2026-01-07 17:22:49 - INFO - total_loss: 0.45597174763679504, masked_loc_loss: 0.06827005743980408, masked_gen_loss: 0.38770169019699097 - (2851716:unified_unilip.py:926)
2026-01-07 17:22:55 - INFO - total_loss: 0.44349849224090576, masked_loc_loss: 0.07905833423137665, masked_gen_loss: 0.3644401729106903 - (2851716:unified_unilip.py:926)
2026-01-07 17:23:09 - INFO - total_loss: 0.41876161098480225, masked_loc_loss: 0.06963131576776505, masked_gen_loss: 0.3491303026676178 - (2851716:unified_unilip.py:926)
2026-01-07 17:23:23 - INFO - total_loss: 0.3905053436756134, masked_loc_loss: 0.07300397008657455, masked_gen_loss: 0.31750136613845825 - (2851716:unified_unilip.py:926)
2026-01-07 17:23:37 - INFO - total_loss: 0.45410943031311035, masked_loc_loss: 0.1123848482966423, masked_gen_loss: 0.34172457456588745 - (2851716:unified_unilip.py:926)
2026-01-07 17:23:52 - INFO - total_loss: 0.37877339124679565, masked_loc_loss: 0.07501907646656036, masked_gen_loss: 0.3037543296813965 - (2851716:unified_unilip.py:926)
2026-01-07 17:23:58 - INFO - total_loss: 0.4042842984199524, masked_loc_loss: 0.09543313086032867, masked_gen_loss: 0.3088511824607849 - (2851716:unified_unilip.py:926)
2026-01-07 17:24:09 - INFO - total_loss: 0.43140411376953125, masked_loc_loss: 0.0646454393863678, masked_gen_loss: 0.36675867438316345 - (2851716:unified_unilip.py:926)
2026-01-07 17:24:23 - INFO - total_loss: 0.43581753969192505, masked_loc_loss: 0.1161273866891861, masked_gen_loss: 0.31969016790390015 - (2851716:unified_unilip.py:926)
2026-01-07 17:24:38 - INFO - total_loss: 0.426220178604126, masked_loc_loss: 0.07121580839157104, masked_gen_loss: 0.35500437021255493 - (2851716:unified_unilip.py:926)
2026-01-07 17:24:52 - INFO - total_loss: 0.47628384828567505, masked_loc_loss: 0.07867829501628876, masked_gen_loss: 0.3976055383682251 - (2851716:unified_unilip.py:926)
2026-01-07 17:25:02 - INFO - total_loss: 0.40415769815444946, masked_loc_loss: 0.07898586988449097, masked_gen_loss: 0.3251718282699585 - (2851716:unified_unilip.py:926)
2026-01-07 17:25:16 - INFO - total_loss: 0.4488334357738495, masked_loc_loss: 0.10766714066267014, masked_gen_loss: 0.34116628766059875 - (2851716:unified_unilip.py:926)
2026-01-07 17:25:31 - INFO - total_loss: 0.4041716754436493, masked_loc_loss: 0.06383320689201355, masked_gen_loss: 0.34033846855163574 - (2851716:unified_unilip.py:926)
2026-01-07 17:25:45 - INFO - total_loss: 0.40193837881088257, masked_loc_loss: 0.06765198707580566, masked_gen_loss: 0.3342863917350769 - (2851716:unified_unilip.py:926)
2026-01-07 17:25:52 - INFO - total_loss: 0.37310126423835754, masked_loc_loss: 0.05946243554353714, masked_gen_loss: 0.313638836145401 - (2851716:unified_unilip.py:926)
2026-01-07 17:25:59 - INFO - total_loss: 0.4477415978908539, masked_loc_loss: 0.08425088971853256, masked_gen_loss: 0.3634907007217407 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:05 - INFO - total_loss: 0.4228558838367462, masked_loc_loss: 0.062057703733444214, masked_gen_loss: 0.360798180103302 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:12 - INFO - total_loss: 0.42166295647621155, masked_loc_loss: 0.05720921978354454, masked_gen_loss: 0.3644537329673767 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:18 - INFO - total_loss: 0.44912245869636536, masked_loc_loss: 0.06808217614889145, masked_gen_loss: 0.3810402750968933 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:25 - INFO - total_loss: 0.3826255202293396, masked_loc_loss: 0.0751049667596817, masked_gen_loss: 0.3075205683708191 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:31 - INFO - total_loss: 0.3992854356765747, masked_loc_loss: 0.07526348531246185, masked_gen_loss: 0.32402193546295166 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:38 - INFO - total_loss: 0.4929687976837158, masked_loc_loss: 0.10001735389232635, masked_gen_loss: 0.39295142889022827 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:44 - INFO - total_loss: 0.43388301134109497, masked_loc_loss: 0.09234738349914551, masked_gen_loss: 0.34153562784194946 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:51 - INFO - total_loss: 0.46007999777793884, masked_loc_loss: 0.09956356883049011, masked_gen_loss: 0.36051642894744873 - (2851716:unified_unilip.py:926)
2026-01-07 17:26:57 - INFO - total_loss: 0.4140859842300415, masked_loc_loss: 0.07507002353668213, masked_gen_loss: 0.3390159606933594 - (2851716:unified_unilip.py:926)
2026-01-07 17:27:12 - INFO - total_loss: 0.4867703914642334, masked_loc_loss: 0.11818218231201172, masked_gen_loss: 0.3685882091522217 - (2851716:unified_unilip.py:926)
2026-01-07 17:27:26 - INFO - total_loss: 0.42849329113960266, masked_loc_loss: 0.06350555270910263, masked_gen_loss: 0.36498773097991943 - (2851716:unified_unilip.py:926)
2026-01-07 17:27:41 - INFO - total_loss: 0.42865169048309326, masked_loc_loss: 0.06234323978424072, masked_gen_loss: 0.36630845069885254 - (2851716:unified_unilip.py:926)
2026-01-07 17:27:55 - INFO - total_loss: 0.42982855439186096, masked_loc_loss: 0.12037926912307739, masked_gen_loss: 0.30944928526878357 - (2851716:unified_unilip.py:926)
2026-01-07 17:28:01 - INFO - total_loss: 0.4518539309501648, masked_loc_loss: 0.12808167934417725, masked_gen_loss: 0.32377225160598755 - (2851716:unified_unilip.py:926)
2026-01-07 17:28:08 - INFO - total_loss: 0.45886725187301636, masked_loc_loss: 0.11135423183441162, masked_gen_loss: 0.34751302003860474 - (2851716:unified_unilip.py:926)
2026-01-07 17:28:20 - INFO - total_loss: 0.43690723180770874, masked_loc_loss: 0.09524232149124146, masked_gen_loss: 0.3416649103164673 - (2851716:unified_unilip.py:926)
2026-01-07 17:28:34 - INFO - total_loss: 0.41269442439079285, masked_loc_loss: 0.0746302604675293, masked_gen_loss: 0.33806416392326355 - (2851716:unified_unilip.py:926)
2026-01-07 17:28:49 - INFO - total_loss: 0.4124872088432312, masked_loc_loss: 0.07675673067569733, masked_gen_loss: 0.3357304632663727 - (2851716:unified_unilip.py:926)
2026-01-07 17:29:03 - INFO - total_loss: 0.492762953042984, masked_loc_loss: 0.15184327960014343, masked_gen_loss: 0.3409196734428406 - (2851716:unified_unilip.py:926)
2026-01-07 17:29:11 - INFO - total_loss: 0.445263147354126, masked_loc_loss: 0.0847214013338089, masked_gen_loss: 0.36054176092147827 - (2851716:unified_unilip.py:926)
2026-01-07 17:29:20 - INFO - total_loss: 0.4146933853626251, masked_loc_loss: 0.05494886636734009, masked_gen_loss: 0.35974451899528503 - (2851716:unified_unilip.py:926)
2026-01-07 17:29:35 - INFO - total_loss: 0.4468674063682556, masked_loc_loss: 0.07158411294221878, masked_gen_loss: 0.37528330087661743 - (2851716:unified_unilip.py:926)
2026-01-07 17:29:49 - INFO - total_loss: 0.47931206226348877, masked_loc_loss: 0.05619090795516968, masked_gen_loss: 0.4231211543083191 - (2851716:unified_unilip.py:926)
2026-01-07 17:30:03 - INFO - total_loss: 0.4177629351615906, masked_loc_loss: 0.07450425624847412, masked_gen_loss: 0.34325867891311646 - (2851716:unified_unilip.py:926)
2026-01-07 17:30:15 - INFO - total_loss: 0.4394289255142212, masked_loc_loss: 0.06621253490447998, masked_gen_loss: 0.3732163906097412 - (2851716:unified_unilip.py:926)
2026-01-07 17:30:21 - INFO - total_loss: 0.4651109576225281, masked_loc_loss: 0.08607904613018036, masked_gen_loss: 0.3790318965911865 - (2851716:unified_unilip.py:926)
2026-01-07 17:30:36 - INFO - total_loss: 0.4211338460445404, masked_loc_loss: 0.07405039668083191, masked_gen_loss: 0.3470834493637085 - (2851716:unified_unilip.py:926)
2026-01-07 17:30:50 - INFO - total_loss: 0.4834630787372589, masked_loc_loss: 0.09732935577630997, masked_gen_loss: 0.38613373041152954 - (2851716:unified_unilip.py:926)
2026-01-07 17:31:04 - INFO - total_loss: 0.40732115507125854, masked_loc_loss: 0.11193305999040604, masked_gen_loss: 0.2953881025314331 - (2851716:unified_unilip.py:926)
2026-01-07 17:31:18 - INFO - total_loss: 0.3933601975440979, masked_loc_loss: 0.09342031925916672, masked_gen_loss: 0.2999398708343506 - (2851716:unified_unilip.py:926)
2026-01-07 17:31:27 - INFO - total_loss: 0.4048198163509369, masked_loc_loss: 0.08428528904914856, masked_gen_loss: 0.32053452730178833 - (2851716:unified_unilip.py:926)
2026-01-07 17:31:42 - INFO - total_loss: 0.4716283082962036, masked_loc_loss: 0.07275199890136719, masked_gen_loss: 0.3988763093948364 - (2851716:unified_unilip.py:926)
2026-01-07 17:31:56 - INFO - total_loss: 0.45273226499557495, masked_loc_loss: 0.08775575459003448, masked_gen_loss: 0.36497652530670166 - (2851716:unified_unilip.py:926)
2026-01-07 17:32:11 - INFO - total_loss: 0.44291019439697266, masked_loc_loss: 0.05670899525284767, masked_gen_loss: 0.3862012028694153 - (2851716:unified_unilip.py:926)
2026-01-07 17:32:23 - INFO - total_loss: 0.41969138383865356, masked_loc_loss: 0.08591455221176147, masked_gen_loss: 0.3337768316268921 - (2851716:unified_unilip.py:926)
2026-01-07 17:32:32 - INFO - total_loss: 0.38972151279449463, masked_loc_loss: 0.07822006940841675, masked_gen_loss: 0.3115014433860779 - (2851716:unified_unilip.py:926)
2026-01-07 17:32:47 - INFO - total_loss: 0.3917433023452759, masked_loc_loss: 0.06910018622875214, masked_gen_loss: 0.32264310121536255 - (2851716:unified_unilip.py:926)
2026-01-07 17:33:01 - INFO - total_loss: 0.3867940902709961, masked_loc_loss: 0.05982686206698418, masked_gen_loss: 0.3269672393798828 - (2851716:unified_unilip.py:926)
2026-01-07 17:33:16 - INFO - total_loss: 0.3947586119174957, masked_loc_loss: 0.09771856665611267, masked_gen_loss: 0.29704004526138306 - (2851716:unified_unilip.py:926)
2026-01-07 17:33:27 - INFO - total_loss: 0.40289926528930664, masked_loc_loss: 0.06900164484977722, masked_gen_loss: 0.3338976204395294 - (2851716:unified_unilip.py:926)
2026-01-07 17:33:35 - INFO - total_loss: 0.377372145652771, masked_loc_loss: 0.07909183204174042, masked_gen_loss: 0.2982802987098694 - (2851716:unified_unilip.py:926)
2026-01-07 17:33:49 - INFO - total_loss: 0.4367668628692627, masked_loc_loss: 0.05708428472280502, masked_gen_loss: 0.3796825706958771 - (2851716:unified_unilip.py:926)
2026-01-07 17:34:04 - INFO - total_loss: 0.4152100682258606, masked_loc_loss: 0.07690942287445068, masked_gen_loss: 0.3383006453514099 - (2851716:unified_unilip.py:926)
2026-01-07 17:34:18 - INFO - total_loss: 0.4933112859725952, masked_loc_loss: 0.04419882223010063, masked_gen_loss: 0.4491124749183655 - (2851716:unified_unilip.py:926)
2026-01-07 17:34:31 - INFO - total_loss: 0.43046802282333374, masked_loc_loss: 0.06443513929843903, masked_gen_loss: 0.3660328984260559 - (2851716:unified_unilip.py:926)
2026-01-07 17:34:40 - INFO - total_loss: 0.3928356468677521, masked_loc_loss: 0.06941822171211243, masked_gen_loss: 0.32341742515563965 - (2851716:unified_unilip.py:926)
2026-01-07 17:34:54 - INFO - total_loss: 0.4609779715538025, masked_loc_loss: 0.04329068213701248, masked_gen_loss: 0.4176872968673706 - (2851716:unified_unilip.py:926)
2026-01-07 17:35:09 - INFO - total_loss: 0.41499605774879456, masked_loc_loss: 0.08466598391532898, masked_gen_loss: 0.3303300738334656 - (2851716:unified_unilip.py:926)
2026-01-07 17:35:23 - INFO - total_loss: 0.39072781801223755, masked_loc_loss: 0.09342683106660843, masked_gen_loss: 0.2973009943962097 - (2851716:unified_unilip.py:926)
2026-01-07 17:35:34 - INFO - total_loss: 0.44816142320632935, masked_loc_loss: 0.12114281952381134, masked_gen_loss: 0.3270186185836792 - (2851716:unified_unilip.py:926)
2026-01-07 17:35:42 - INFO - total_loss: 0.4032766819000244, masked_loc_loss: 0.06372585892677307, masked_gen_loss: 0.33955082297325134 - (2851716:unified_unilip.py:926)
2026-01-07 17:35:57 - INFO - total_loss: 0.4244130253791809, masked_loc_loss: 0.07124905288219452, masked_gen_loss: 0.3531639873981476 - (2851716:unified_unilip.py:926)
2026-01-07 17:36:11 - INFO - total_loss: 0.44380539655685425, masked_loc_loss: 0.11102165281772614, masked_gen_loss: 0.3327837586402893 - (2851716:unified_unilip.py:926)
2026-01-07 17:36:25 - INFO - total_loss: 0.4197603762149811, masked_loc_loss: 0.06359957903623581, masked_gen_loss: 0.3561607897281647 - (2851716:unified_unilip.py:926)
2026-01-07 17:36:38 - INFO - total_loss: 0.36279940605163574, masked_loc_loss: 0.06432296335697174, masked_gen_loss: 0.2984764277935028 - (2851716:unified_unilip.py:926)
2026-01-07 17:36:50 - INFO - total_loss: 0.47250398993492126, masked_loc_loss: 0.07637449353933334, masked_gen_loss: 0.3961294889450073 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:04 - INFO - total_loss: 0.4739331603050232, masked_loc_loss: 0.06529875099658966, masked_gen_loss: 0.40863439440727234 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:19 - INFO - total_loss: 0.4345758855342865, masked_loc_loss: 0.06871569156646729, masked_gen_loss: 0.3658601939678192 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:27 - INFO - total_loss: 0.39291587471961975, masked_loc_loss: 0.09458041191101074, masked_gen_loss: 0.298335462808609 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:33 - INFO - total_loss: 0.4680168926715851, masked_loc_loss: 0.07979518175125122, masked_gen_loss: 0.38822171092033386 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:40 - INFO - total_loss: 0.47051316499710083, masked_loc_loss: 0.07900089025497437, masked_gen_loss: 0.39151227474212646 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:46 - INFO - total_loss: 0.4251424968242645, masked_loc_loss: 0.0692535936832428, masked_gen_loss: 0.35588890314102173 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:53 - INFO - total_loss: 0.45564740896224976, masked_loc_loss: 0.08141590654850006, masked_gen_loss: 0.3742315173149109 - (2851716:unified_unilip.py:926)
2026-01-07 17:37:59 - INFO - total_loss: 0.3319268822669983, masked_loc_loss: 0.07381881773471832, masked_gen_loss: 0.25810807943344116 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:06 - INFO - total_loss: 0.41493627429008484, masked_loc_loss: 0.09100764989852905, masked_gen_loss: 0.3239286243915558 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:12 - INFO - total_loss: 0.40145811438560486, masked_loc_loss: 0.07312434166669846, masked_gen_loss: 0.3283337652683258 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:19 - INFO - total_loss: 0.42714571952819824, masked_loc_loss: 0.06846658885478973, masked_gen_loss: 0.3586791455745697 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:25 - INFO - total_loss: 0.4360606074333191, masked_loc_loss: 0.09004761278629303, masked_gen_loss: 0.34601300954818726 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:32 - INFO - total_loss: 0.4194221496582031, masked_loc_loss: 0.06744213402271271, masked_gen_loss: 0.3519800305366516 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:41 - INFO - total_loss: 0.41225874423980713, masked_loc_loss: 0.07805881649255753, masked_gen_loss: 0.3341999351978302 - (2851716:unified_unilip.py:926)
2026-01-07 17:38:55 - INFO - total_loss: 0.4316968619823456, masked_loc_loss: 0.09264284372329712, masked_gen_loss: 0.33905401825904846 - (2851716:unified_unilip.py:926)
2026-01-07 17:39:10 - INFO - total_loss: 0.44344303011894226, masked_loc_loss: 0.05847575515508652, masked_gen_loss: 0.38496726751327515 - (2851716:unified_unilip.py:926)
2026-01-07 17:39:25 - INFO - total_loss: 0.4041288197040558, masked_loc_loss: 0.047247231006622314, masked_gen_loss: 0.35688158869743347 - (2851716:unified_unilip.py:926)
2026-01-07 17:39:37 - INFO - total_loss: 0.4552435874938965, masked_loc_loss: 0.0622684583067894, masked_gen_loss: 0.3929751217365265 - (2851716:unified_unilip.py:926)
2026-01-07 17:39:43 - INFO - total_loss: 0.512927234172821, masked_loc_loss: 0.10850786417722702, masked_gen_loss: 0.4044193923473358 - (2851716:unified_unilip.py:926)
2026-01-07 17:39:55 - INFO - total_loss: 0.4568589925765991, masked_loc_loss: 0.059858184307813644, masked_gen_loss: 0.39700081944465637 - (2851716:unified_unilip.py:926)
2026-01-07 17:40:10 - INFO - total_loss: 0.47878193855285645, masked_loc_loss: 0.10411764681339264, masked_gen_loss: 0.3746642768383026 - (2851716:unified_unilip.py:926)
2026-01-07 17:40:25 - INFO - total_loss: 0.3924674391746521, masked_loc_loss: 0.05332396924495697, masked_gen_loss: 0.3391434848308563 - (2851716:unified_unilip.py:926)
2026-01-07 17:40:40 - INFO - total_loss: 0.42716318368911743, masked_loc_loss: 0.08194851130247116, masked_gen_loss: 0.3452146649360657 - (2851716:unified_unilip.py:926)
2026-01-07 17:40:47 - INFO - total_loss: 0.4533037543296814, masked_loc_loss: 0.06556491553783417, masked_gen_loss: 0.38773882389068604 - (2851716:unified_unilip.py:926)
2026-01-07 17:41:01 - INFO - total_loss: 0.3995094895362854, masked_loc_loss: 0.07180732488632202, masked_gen_loss: 0.3277021646499634 - (2851716:unified_unilip.py:926)
2026-01-07 17:41:15 - INFO - total_loss: 0.4152945876121521, masked_loc_loss: 0.06887757033109665, masked_gen_loss: 0.34641700983047485 - (2851716:unified_unilip.py:926)
2026-01-07 17:41:30 - INFO - total_loss: 0.41984397172927856, masked_loc_loss: 0.09033478796482086, masked_gen_loss: 0.3295091688632965 - (2851716:unified_unilip.py:926)
2026-01-07 17:41:44 - INFO - total_loss: 0.46243351697921753, masked_loc_loss: 0.08150056004524231, masked_gen_loss: 0.3809329569339752 - (2851716:unified_unilip.py:926)
2026-01-07 17:41:52 - INFO - total_loss: 0.43462082743644714, masked_loc_loss: 0.051572877913713455, masked_gen_loss: 0.3830479383468628 - (2851716:unified_unilip.py:926)
2026-01-07 17:42:06 - INFO - total_loss: 0.3991472125053406, masked_loc_loss: 0.09662620723247528, masked_gen_loss: 0.3025209903717041 - (2851716:unified_unilip.py:926)
2026-01-07 17:42:19 - INFO - total_loss: 0.4286061227321625, masked_loc_loss: 0.09029662609100342, masked_gen_loss: 0.33830949664115906 - (2851716:unified_unilip.py:926)
2026-01-07 17:42:33 - INFO - total_loss: 0.3941788673400879, masked_loc_loss: 0.08141423761844635, masked_gen_loss: 0.31276461482048035 - (2851716:unified_unilip.py:926)
2026-01-07 17:42:47 - INFO - total_loss: 0.3942963480949402, masked_loc_loss: 0.06804351508617401, masked_gen_loss: 0.326252818107605 - (2851716:unified_unilip.py:926)
2026-01-07 17:42:58 - INFO - total_loss: 0.4118882417678833, masked_loc_loss: 0.04116456210613251, masked_gen_loss: 0.3707236647605896 - (2851716:unified_unilip.py:926)
2026-01-07 17:43:09 - INFO - total_loss: 0.44451552629470825, masked_loc_loss: 0.06724736094474792, masked_gen_loss: 0.3772681653499603 - (2851716:unified_unilip.py:926)
2026-01-07 17:43:23 - INFO - total_loss: 0.40907394886016846, masked_loc_loss: 0.045633669942617416, masked_gen_loss: 0.36344027519226074 - (2851716:unified_unilip.py:926)
2026-01-07 17:43:37 - INFO - total_loss: 0.43470025062561035, masked_loc_loss: 0.07204477488994598, masked_gen_loss: 0.3626554608345032 - (2851716:unified_unilip.py:926)
2026-01-07 17:43:51 - INFO - total_loss: 0.4340677857398987, masked_loc_loss: 0.07622049748897552, masked_gen_loss: 0.35784727334976196 - (2851716:unified_unilip.py:926)
2026-01-07 17:44:05 - INFO - total_loss: 0.46565836668014526, masked_loc_loss: 0.05003438889980316, masked_gen_loss: 0.4156239628791809 - (2851716:unified_unilip.py:926)
2026-01-07 17:44:12 - INFO - total_loss: 0.3938136696815491, masked_loc_loss: 0.07021492719650269, masked_gen_loss: 0.3235987424850464 - (2851716:unified_unilip.py:926)
2026-01-07 17:44:26 - INFO - total_loss: 0.411817342042923, masked_loc_loss: 0.08185752481222153, masked_gen_loss: 0.32995980978012085 - (2851716:unified_unilip.py:926)
2026-01-07 17:44:41 - INFO - total_loss: 0.49100831151008606, masked_loc_loss: 0.10187879204750061, masked_gen_loss: 0.38912951946258545 - (2851716:unified_unilip.py:926)
2026-01-07 17:44:55 - INFO - total_loss: 0.4310378134250641, masked_loc_loss: 0.07845822721719742, masked_gen_loss: 0.35257959365844727 - (2851716:unified_unilip.py:926)
2026-01-07 17:45:10 - INFO - total_loss: 0.36473801732063293, masked_loc_loss: 0.06405410915613174, masked_gen_loss: 0.3006839156150818 - (2851716:unified_unilip.py:926)
2026-01-07 17:45:16 - INFO - total_loss: 0.42225223779678345, masked_loc_loss: 0.051433660089969635, masked_gen_loss: 0.3708185851573944 - (2851716:unified_unilip.py:926)
2026-01-07 17:45:30 - INFO - total_loss: 0.4691199064254761, masked_loc_loss: 0.10529559850692749, masked_gen_loss: 0.3638243079185486 - (2851716:unified_unilip.py:926)
2026-01-07 17:45:44 - INFO - total_loss: 0.44203758239746094, masked_loc_loss: 0.06249496340751648, masked_gen_loss: 0.37954261898994446 - (2851716:unified_unilip.py:926)
2026-01-07 17:45:59 - INFO - total_loss: 0.43945908546447754, masked_loc_loss: 0.07786191999912262, masked_gen_loss: 0.3615971505641937 - (2851716:unified_unilip.py:926)
2026-01-07 17:46:14 - INFO - total_loss: 0.43750542402267456, masked_loc_loss: 0.11161956936120987, masked_gen_loss: 0.3258858621120453 - (2851716:unified_unilip.py:926)
2026-01-07 17:46:20 - INFO - total_loss: 0.42140674591064453, masked_loc_loss: 0.058377671986818314, masked_gen_loss: 0.3630290627479553 - (2851716:unified_unilip.py:926)
2026-01-07 17:46:32 - INFO - total_loss: 0.42681246995925903, masked_loc_loss: 0.07474516332149506, masked_gen_loss: 0.3520672917366028 - (2851716:unified_unilip.py:926)
2026-01-07 17:46:47 - INFO - total_loss: 0.4762110710144043, masked_loc_loss: 0.06271712481975555, masked_gen_loss: 0.41349393129348755 - (2851716:unified_unilip.py:926)
2026-01-07 17:47:01 - INFO - total_loss: 0.3964022696018219, masked_loc_loss: 0.05254598706960678, masked_gen_loss: 0.3438562750816345 - (2851716:unified_unilip.py:926)
2026-01-07 17:47:15 - INFO - total_loss: 0.4359340965747833, masked_loc_loss: 0.058185894042253494, masked_gen_loss: 0.37774819135665894 - (2851716:unified_unilip.py:926)
2026-01-07 17:47:24 - INFO - total_loss: 0.4113007187843323, masked_loc_loss: 0.08503781259059906, masked_gen_loss: 0.326262891292572 - (2851716:unified_unilip.py:926)
2026-01-07 17:47:36 - INFO - total_loss: 0.3302726745605469, masked_loc_loss: 0.08173263072967529, masked_gen_loss: 0.24854004383087158 - (2851716:unified_unilip.py:926)
2026-01-07 17:47:50 - INFO - total_loss: 0.42936834692955017, masked_loc_loss: 0.05694493651390076, masked_gen_loss: 0.3724234104156494 - (2851716:unified_unilip.py:926)
2026-01-07 17:48:04 - INFO - total_loss: 0.4175703525543213, masked_loc_loss: 0.12435869872570038, masked_gen_loss: 0.2932116389274597 - (2851716:unified_unilip.py:926)
2026-01-07 17:48:18 - INFO - total_loss: 0.40909600257873535, masked_loc_loss: 0.09665024280548096, masked_gen_loss: 0.3124457597732544 - (2851716:unified_unilip.py:926)
2026-01-07 17:48:27 - INFO - total_loss: 0.36853668093681335, masked_loc_loss: 0.050918109714984894, masked_gen_loss: 0.31761857867240906 - (2851716:unified_unilip.py:926)
2026-01-07 17:48:41 - INFO - total_loss: 0.4397217631340027, masked_loc_loss: 0.10050280392169952, masked_gen_loss: 0.33921894431114197 - (2851716:unified_unilip.py:926)
2026-01-07 17:48:55 - INFO - total_loss: 0.4450317323207855, masked_loc_loss: 0.08778800815343857, masked_gen_loss: 0.35724371671676636 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:02 - INFO - total_loss: 0.4492250382900238, masked_loc_loss: 0.06867179274559021, masked_gen_loss: 0.3805532455444336 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:08 - INFO - total_loss: 0.3918437957763672, masked_loc_loss: 0.049398720264434814, masked_gen_loss: 0.3424450755119324 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:15 - INFO - total_loss: 0.48693710565567017, masked_loc_loss: 0.08807589113712311, masked_gen_loss: 0.39886122941970825 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:21 - INFO - total_loss: 0.475386381149292, masked_loc_loss: 0.047062695026397705, masked_gen_loss: 0.4283236861228943 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:28 - INFO - total_loss: 0.40388351678848267, masked_loc_loss: 0.06191297620534897, masked_gen_loss: 0.3419705331325531 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:34 - INFO - total_loss: 0.39639919996261597, masked_loc_loss: 0.07764965295791626, masked_gen_loss: 0.3187495470046997 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:41 - INFO - total_loss: 0.4145957827568054, masked_loc_loss: 0.053391799330711365, masked_gen_loss: 0.36120396852493286 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:47 - INFO - total_loss: 0.4466749429702759, masked_loc_loss: 0.05250043794512749, masked_gen_loss: 0.3941745162010193 - (2851716:unified_unilip.py:926)
2026-01-07 17:49:53 - INFO - total_loss: 0.36861205101013184, masked_loc_loss: 0.05707605183124542, masked_gen_loss: 0.3115360140800476 - (2851716:unified_unilip.py:926)
2026-01-07 17:50:00 - INFO - total_loss: 0.4127095341682434, masked_loc_loss: 0.0769248753786087, masked_gen_loss: 0.3357846736907959 - (2851716:unified_unilip.py:926)
2026-01-07 17:50:07 - INFO - total_loss: 0.39733749628067017, masked_loc_loss: 0.07112863659858704, masked_gen_loss: 0.32620885968208313 - (2851716:unified_unilip.py:926)
2026-01-07 17:50:17 - INFO - total_loss: 0.3423352837562561, masked_loc_loss: 0.09969380497932434, masked_gen_loss: 0.24264147877693176 - (2851716:unified_unilip.py:926)
2026-01-07 17:50:31 - INFO - total_loss: 0.4135221242904663, masked_loc_loss: 0.05745500326156616, masked_gen_loss: 0.35606712102890015 - (2851716:unified_unilip.py:926)
2026-01-07 17:50:46 - INFO - total_loss: 0.4876197278499603, masked_loc_loss: 0.060965023934841156, masked_gen_loss: 0.4266546964645386 - (2851716:unified_unilip.py:926)
2026-01-07 17:51:00 - INFO - total_loss: 0.41627737879753113, masked_loc_loss: 0.05511663481593132, masked_gen_loss: 0.3611607551574707 - (2851716:unified_unilip.py:926)
2026-01-07 17:51:11 - INFO - total_loss: 0.42893776297569275, masked_loc_loss: 0.07641228288412094, masked_gen_loss: 0.3525254726409912 - (2851716:unified_unilip.py:926)
2026-01-07 17:51:18 - INFO - total_loss: 0.4646686315536499, masked_loc_loss: 0.1154514029622078, masked_gen_loss: 0.3492172360420227 - (2851716:unified_unilip.py:926)
2026-01-07 17:51:29 - INFO - total_loss: 0.4148598611354828, masked_loc_loss: 0.029651153832674026, masked_gen_loss: 0.38520869612693787 - (2851716:unified_unilip.py:926)
2026-01-07 17:51:44 - INFO - total_loss: 0.3720862865447998, masked_loc_loss: 0.06120537221431732, masked_gen_loss: 0.3108808994293213 - (2851716:unified_unilip.py:926)
2026-01-07 17:51:58 - INFO - total_loss: 0.4462216794490814, masked_loc_loss: 0.08718821406364441, masked_gen_loss: 0.359033465385437 - (2851716:unified_unilip.py:926)
2026-01-07 17:52:13 - INFO - total_loss: 0.41790807247161865, masked_loc_loss: 0.07495653629302979, masked_gen_loss: 0.34295153617858887 - (2851716:unified_unilip.py:926)
2026-01-07 17:52:22 - INFO - total_loss: 0.38808465003967285, masked_loc_loss: 0.07557916641235352, masked_gen_loss: 0.31250548362731934 - (2851716:unified_unilip.py:926)
2026-01-07 17:52:29 - INFO - total_loss: 0.3911309838294983, masked_loc_loss: 0.06790849566459656, masked_gen_loss: 0.32322248816490173 - (2851716:unified_unilip.py:926)
2026-01-07 17:52:43 - INFO - total_loss: 0.36677515506744385, masked_loc_loss: 0.06430507451295853, masked_gen_loss: 0.3024700880050659 - (2851716:unified_unilip.py:926)
2026-01-07 17:52:58 - INFO - total_loss: 0.46046948432922363, masked_loc_loss: 0.06692434102296829, masked_gen_loss: 0.39354515075683594 - (2851716:unified_unilip.py:926)
2026-01-07 17:53:12 - INFO - total_loss: 0.4133265018463135, masked_loc_loss: 0.056998781859874725, masked_gen_loss: 0.35632771253585815 - (2851716:unified_unilip.py:926)
2026-01-07 17:53:26 - INFO - total_loss: 0.43330124020576477, masked_loc_loss: 0.06265845894813538, masked_gen_loss: 0.3706427812576294 - (2851716:unified_unilip.py:926)
2026-01-07 17:53:32 - INFO - total_loss: 0.4009808897972107, masked_loc_loss: 0.07892443239688873, masked_gen_loss: 0.32205647230148315 - (2851716:unified_unilip.py:926)
2026-01-07 17:53:45 - INFO - total_loss: 0.39951881766319275, masked_loc_loss: 0.06790795922279358, masked_gen_loss: 0.33161085844039917 - (2851716:unified_unilip.py:926)
2026-01-07 17:53:59 - INFO - total_loss: 0.41180336475372314, masked_loc_loss: 0.04662816971540451, masked_gen_loss: 0.36517518758773804 - (2851716:unified_unilip.py:926)
2026-01-07 17:54:14 - INFO - total_loss: 0.43195223808288574, masked_loc_loss: 0.06814305484294891, masked_gen_loss: 0.36380916833877563 - (2851716:unified_unilip.py:926)
2026-01-07 17:54:28 - INFO - total_loss: 0.3859269917011261, masked_loc_loss: 0.05938407778739929, masked_gen_loss: 0.3265429139137268 - (2851716:unified_unilip.py:926)
2026-01-07 17:54:35 - INFO - total_loss: 0.40207770466804504, masked_loc_loss: 0.05508764460682869, masked_gen_loss: 0.34699004888534546 - (2851716:unified_unilip.py:926)
2026-01-07 17:54:45 - INFO - total_loss: 0.381041556596756, masked_loc_loss: 0.07615649700164795, masked_gen_loss: 0.30488505959510803 - (2851716:unified_unilip.py:926)
2026-01-07 17:54:59 - INFO - total_loss: 0.3473777174949646, masked_loc_loss: 0.05638544261455536, masked_gen_loss: 0.29099225997924805 - (2851716:unified_unilip.py:926)
2026-01-07 17:55:13 - INFO - total_loss: 0.3772267699241638, masked_loc_loss: 0.06766735017299652, masked_gen_loss: 0.3095594048500061 - (2851716:unified_unilip.py:926)
2026-01-07 17:55:28 - INFO - total_loss: 0.47380882501602173, masked_loc_loss: 0.09845799207687378, masked_gen_loss: 0.37535083293914795 - (2851716:unified_unilip.py:926)
2026-01-07 17:55:39 - INFO - total_loss: 0.3777206242084503, masked_loc_loss: 0.06144227832555771, masked_gen_loss: 0.316278338432312 - (2851716:unified_unilip.py:926)
2026-01-07 17:55:45 - INFO - total_loss: 0.49241217970848083, masked_loc_loss: 0.10282603651285172, masked_gen_loss: 0.3895861506462097 - (2851716:unified_unilip.py:926)
2026-01-07 17:55:58 - INFO - total_loss: 0.35598307847976685, masked_loc_loss: 0.07036562263965607, masked_gen_loss: 0.285617470741272 - (2851716:unified_unilip.py:926)
2026-01-07 17:56:13 - INFO - total_loss: 0.4517945647239685, masked_loc_loss: 0.06254015862941742, masked_gen_loss: 0.3892544209957123 - (2851716:unified_unilip.py:926)
2026-01-07 17:56:27 - INFO - total_loss: 0.38268768787384033, masked_loc_loss: 0.08160306513309479, masked_gen_loss: 0.30108460783958435 - (2851716:unified_unilip.py:926)
2026-01-07 17:56:42 - INFO - total_loss: 0.48299384117126465, masked_loc_loss: 0.09977516531944275, masked_gen_loss: 0.3832186758518219 - (2851716:unified_unilip.py:926)
2026-01-07 17:56:49 - INFO - total_loss: 0.4154791533946991, masked_loc_loss: 0.05280103161931038, masked_gen_loss: 0.3626781105995178 - (2851716:unified_unilip.py:926)
2026-01-07 17:56:59 - INFO - total_loss: 0.42045697569847107, masked_loc_loss: 0.0520295575261116, masked_gen_loss: 0.36842742562294006 - (2851716:unified_unilip.py:926)
2026-01-07 17:57:14 - INFO - total_loss: 0.4201686382293701, masked_loc_loss: 0.0594489686191082, masked_gen_loss: 0.3607196807861328 - (2851716:unified_unilip.py:926)
2026-01-07 17:57:28 - INFO - total_loss: 0.39222702383995056, masked_loc_loss: 0.05530659481883049, masked_gen_loss: 0.33692044019699097 - (2851716:unified_unilip.py:926)
2026-01-07 17:57:43 - INFO - total_loss: 0.4224521219730377, masked_loc_loss: 0.07056669145822525, masked_gen_loss: 0.35188543796539307 - (2851716:unified_unilip.py:926)
2026-01-07 17:57:53 - INFO - total_loss: 0.3954664468765259, masked_loc_loss: 0.0600411593914032, masked_gen_loss: 0.3354252874851227 - (2851716:unified_unilip.py:926)
2026-01-07 17:58:03 - INFO - total_loss: 0.4590053856372833, masked_loc_loss: 0.07631838321685791, masked_gen_loss: 0.3826870024204254 - (2851716:unified_unilip.py:926)
2026-01-07 17:58:18 - INFO - total_loss: 0.44053035974502563, masked_loc_loss: 0.04273151606321335, masked_gen_loss: 0.3977988362312317 - (2851716:unified_unilip.py:926)
2026-01-07 17:58:32 - INFO - total_loss: 0.42350074648857117, masked_loc_loss: 0.07551100850105286, masked_gen_loss: 0.3479897379875183 - (2851716:unified_unilip.py:926)
2026-01-07 17:58:46 - INFO - total_loss: 0.3575756549835205, masked_loc_loss: 0.07174251228570938, masked_gen_loss: 0.2858331501483917 - (2851716:unified_unilip.py:926)
2026-01-07 17:58:58 - INFO - total_loss: 0.43840640783309937, masked_loc_loss: 0.054928794503211975, masked_gen_loss: 0.3834776282310486 - (2851716:unified_unilip.py:926)
2026-01-07 17:59:06 - INFO - total_loss: 0.40502169728279114, masked_loc_loss: 0.07923111319541931, masked_gen_loss: 0.3257905840873718 - (2851716:unified_unilip.py:926)
2026-01-07 17:59:21 - INFO - total_loss: 0.400913268327713, masked_loc_loss: 0.09751401096582413, masked_gen_loss: 0.3033992648124695 - (2851716:unified_unilip.py:926)
2026-01-07 17:59:35 - INFO - total_loss: 0.40204066038131714, masked_loc_loss: 0.07627135515213013, masked_gen_loss: 0.325769305229187 - (2851716:unified_unilip.py:926)
2026-01-07 17:59:49 - INFO - total_loss: 0.40744203329086304, masked_loc_loss: 0.058736469596624374, masked_gen_loss: 0.34870555996894836 - (2851716:unified_unilip.py:926)
2026-01-07 18:00:02 - INFO - total_loss: 0.4207887649536133, masked_loc_loss: 0.04070120304822922, masked_gen_loss: 0.38008755445480347 - (2851716:unified_unilip.py:926)
2026-01-07 18:00:14 - INFO - total_loss: 0.37737083435058594, masked_loc_loss: 0.055250152945518494, masked_gen_loss: 0.32212066650390625 - (2851716:unified_unilip.py:926)
2026-01-07 18:00:28 - INFO - total_loss: 0.4748848080635071, masked_loc_loss: 0.07073789834976196, masked_gen_loss: 0.4041469097137451 - (2851716:unified_unilip.py:926)
2026-01-07 18:00:42 - INFO - total_loss: 0.41623884439468384, masked_loc_loss: 0.09718960523605347, masked_gen_loss: 0.31904923915863037 - (2851716:unified_unilip.py:926)
2026-01-07 18:00:51 - INFO - total_loss: 0.38989442586898804, masked_loc_loss: 0.048197612166404724, masked_gen_loss: 0.3416968286037445 - (2851716:unified_unilip.py:926)
2026-01-07 18:00:57 - INFO - total_loss: 0.42032748460769653, masked_loc_loss: 0.0795697420835495, masked_gen_loss: 0.34075772762298584 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:04 - INFO - total_loss: 0.36309757828712463, masked_loc_loss: 0.04926910251379013, masked_gen_loss: 0.3138284683227539 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:10 - INFO - total_loss: 0.3652520477771759, masked_loc_loss: 0.07983972877264023, masked_gen_loss: 0.2854123115539551 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:17 - INFO - total_loss: 0.4896864891052246, masked_loc_loss: 0.07186831533908844, masked_gen_loss: 0.41781818866729736 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:23 - INFO - total_loss: 0.36598870158195496, masked_loc_loss: 0.06641208380460739, masked_gen_loss: 0.29957661032676697 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:30 - INFO - total_loss: 0.42524924874305725, masked_loc_loss: 0.05458458140492439, masked_gen_loss: 0.37066465616226196 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:36 - INFO - total_loss: 0.4231918156147003, masked_loc_loss: 0.067020945250988, masked_gen_loss: 0.3561708629131317 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:42 - INFO - total_loss: 0.38620346784591675, masked_loc_loss: 0.06435614079236984, masked_gen_loss: 0.3218473196029663 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:49 - INFO - total_loss: 0.39159703254699707, masked_loc_loss: 0.04010344296693802, masked_gen_loss: 0.35149359703063965 - (2851716:unified_unilip.py:926)
2026-01-07 18:01:55 - INFO - total_loss: 0.42232102155685425, masked_loc_loss: 0.0735650360584259, masked_gen_loss: 0.34875598549842834 - (2851716:unified_unilip.py:926)
2026-01-07 18:02:02 - INFO - total_loss: 0.4203653335571289, masked_loc_loss: 0.04402659088373184, masked_gen_loss: 0.37633875012397766 - (2851716:unified_unilip.py:926)
2026-01-07 18:02:15 - INFO - total_loss: 0.3756820559501648, masked_loc_loss: 0.05651446431875229, masked_gen_loss: 0.3191675841808319 - (2851716:unified_unilip.py:926)
2026-01-07 18:02:30 - INFO - total_loss: 0.38698309659957886, masked_loc_loss: 0.05602012574672699, masked_gen_loss: 0.3309629559516907 - (2851716:unified_unilip.py:926)
2026-01-07 18:02:44 - INFO - total_loss: 0.4036495089530945, masked_loc_loss: 0.07305539399385452, masked_gen_loss: 0.33059412240982056 - (2851716:unified_unilip.py:926)
2026-01-07 18:02:59 - INFO - total_loss: 0.4302518963813782, masked_loc_loss: 0.03652406111359596, masked_gen_loss: 0.3937278389930725 - (2851716:unified_unilip.py:926)
2026-01-07 18:03:06 - INFO - total_loss: 0.42061474919319153, masked_loc_loss: 0.08547702431678772, masked_gen_loss: 0.3351377248764038 - (2851716:unified_unilip.py:926)
2026-01-07 18:03:12 - INFO - total_loss: 0.37874487042427063, masked_loc_loss: 0.06714335083961487, masked_gen_loss: 0.31160151958465576 - (2851716:unified_unilip.py:926)
2026-01-07 18:03:23 - INFO - total_loss: 0.43024611473083496, masked_loc_loss: 0.06944611668586731, masked_gen_loss: 0.36079999804496765 - (2851716:unified_unilip.py:926)
2026-01-07 18:03:37 - INFO - total_loss: 0.4614567756652832, masked_loc_loss: 0.08082057535648346, masked_gen_loss: 0.38063618540763855 - (2851716:unified_unilip.py:926)
2026-01-07 18:03:52 - INFO - total_loss: 0.38548246026039124, masked_loc_loss: 0.047027260065078735, masked_gen_loss: 0.3384552001953125 - (2851716:unified_unilip.py:926)
2026-01-07 18:04:06 - INFO - total_loss: 0.4146028161048889, masked_loc_loss: 0.05696854367852211, masked_gen_loss: 0.3576342761516571 - (2851716:unified_unilip.py:926)
2026-01-07 18:04:17 - INFO - total_loss: 0.4381750524044037, masked_loc_loss: 0.058735765516757965, masked_gen_loss: 0.3794392943382263 - (2851716:unified_unilip.py:926)
2026-01-07 18:04:24 - INFO - total_loss: 0.4282449781894684, masked_loc_loss: 0.08662080764770508, masked_gen_loss: 0.3416241705417633 - (2851716:unified_unilip.py:926)
2026-01-07 18:04:38 - INFO - total_loss: 0.4726816415786743, masked_loc_loss: 0.06570343673229218, masked_gen_loss: 0.40697818994522095 - (2851716:unified_unilip.py:926)
2026-01-07 18:04:53 - INFO - total_loss: 0.34859153628349304, masked_loc_loss: 0.08775537461042404, masked_gen_loss: 0.2608361542224884 - (2851716:unified_unilip.py:926)
2026-01-07 18:05:07 - INFO - total_loss: 0.41062629222869873, masked_loc_loss: 0.08326013386249542, masked_gen_loss: 0.3273661732673645 - (2851716:unified_unilip.py:926)
2026-01-07 18:05:21 - INFO - total_loss: 0.4599999785423279, masked_loc_loss: 0.06198374181985855, masked_gen_loss: 0.3980162441730499 - (2851716:unified_unilip.py:926)
2026-01-07 18:05:28 - INFO - total_loss: 0.42854753136634827, masked_loc_loss: 0.07978101819753647, masked_gen_loss: 0.3487665057182312 - (2851716:unified_unilip.py:926)
2026-01-07 18:05:41 - INFO - total_loss: 0.38225191831588745, masked_loc_loss: 0.049709416925907135, masked_gen_loss: 0.3325425088405609 - (2851716:unified_unilip.py:926)
2026-01-07 18:05:56 - INFO - total_loss: 0.4382573664188385, masked_loc_loss: 0.05164217948913574, masked_gen_loss: 0.38661518692970276 - (2851716:unified_unilip.py:926)
2026-01-07 18:06:10 - INFO - total_loss: 0.4026397466659546, masked_loc_loss: 0.09003768861293793, masked_gen_loss: 0.31260204315185547 - (2851716:unified_unilip.py:926)
2026-01-07 18:06:24 - INFO - total_loss: 0.39443129301071167, masked_loc_loss: 0.08986762911081314, masked_gen_loss: 0.3045636713504791 - (2851716:unified_unilip.py:926)
2026-01-07 18:06:32 - INFO - total_loss: 0.42150256037712097, masked_loc_loss: 0.052767716348171234, masked_gen_loss: 0.36873483657836914 - (2851716:unified_unilip.py:926)
2026-01-07 18:06:41 - INFO - total_loss: 0.35579726099967957, masked_loc_loss: 0.04900693893432617, masked_gen_loss: 0.3067903220653534 - (2851716:unified_unilip.py:926)
2026-01-07 18:06:55 - INFO - total_loss: 0.3383256196975708, masked_loc_loss: 0.04094093665480614, masked_gen_loss: 0.29738467931747437 - (2851716:unified_unilip.py:926)
2026-01-07 18:07:09 - INFO - total_loss: 0.4321470856666565, masked_loc_loss: 0.06960225105285645, masked_gen_loss: 0.36254483461380005 - (2851716:unified_unilip.py:926)
2026-01-07 18:07:24 - INFO - total_loss: 0.40864887833595276, masked_loc_loss: 0.07834931463003159, masked_gen_loss: 0.3302995562553406 - (2851716:unified_unilip.py:926)
2026-01-07 18:07:35 - INFO - total_loss: 0.38555821776390076, masked_loc_loss: 0.04818322882056236, masked_gen_loss: 0.3373749852180481 - (2851716:unified_unilip.py:926)
2026-01-07 18:07:41 - INFO - total_loss: 0.429627001285553, masked_loc_loss: 0.07675760984420776, masked_gen_loss: 0.3528693914413452 - (2851716:unified_unilip.py:926)
2026-01-07 18:07:55 - INFO - total_loss: 0.46819183230400085, masked_loc_loss: 0.06613442301750183, masked_gen_loss: 0.402057409286499 - (2851716:unified_unilip.py:926)
2026-01-07 18:08:09 - INFO - total_loss: 0.4348770081996918, masked_loc_loss: 0.052077263593673706, masked_gen_loss: 0.38279974460601807 - (2851716:unified_unilip.py:926)
2026-01-07 18:08:24 - INFO - total_loss: 0.4015713036060333, masked_loc_loss: 0.06407196074724197, masked_gen_loss: 0.33749935030937195 - (2851716:unified_unilip.py:926)
2026-01-07 18:08:38 - INFO - total_loss: 0.4154277443885803, masked_loc_loss: 0.10072613507509232, masked_gen_loss: 0.3147016167640686 - (2851716:unified_unilip.py:926)
2026-01-07 18:08:45 - INFO - total_loss: 0.38541465997695923, masked_loc_loss: 0.05774698778986931, masked_gen_loss: 0.3276676833629608 - (2851716:unified_unilip.py:926)
2026-01-07 18:08:56 - INFO - total_loss: 0.39770612120628357, masked_loc_loss: 0.07533737272024155, masked_gen_loss: 0.3223687410354614 - (2851716:unified_unilip.py:926)
2026-01-07 18:09:10 - INFO - total_loss: 0.4311838150024414, masked_loc_loss: 0.04757152870297432, masked_gen_loss: 0.3836122751235962 - (2851716:unified_unilip.py:926)
2026-01-07 18:09:24 - INFO - total_loss: 0.4328642785549164, masked_loc_loss: 0.0661872923374176, masked_gen_loss: 0.3666769862174988 - (2851716:unified_unilip.py:926)
2026-01-07 18:09:38 - INFO - total_loss: 0.379011332988739, masked_loc_loss: 0.04046284779906273, masked_gen_loss: 0.338548481464386 - (2851716:unified_unilip.py:926)
2026-01-07 18:09:49 - INFO - total_loss: 0.3859277367591858, masked_loc_loss: 0.05147174000740051, masked_gen_loss: 0.3344559967517853 - (2851716:unified_unilip.py:926)
2026-01-07 18:09:58 - INFO - total_loss: 0.42627134919166565, masked_loc_loss: 0.06263499706983566, masked_gen_loss: 0.3636363446712494 - (2851716:unified_unilip.py:926)
2026-01-07 18:10:12 - INFO - total_loss: 0.4498828053474426, masked_loc_loss: 0.06394904851913452, masked_gen_loss: 0.3859337568283081 - (2851716:unified_unilip.py:926)
2026-01-07 18:10:27 - INFO - total_loss: 0.3789095878601074, masked_loc_loss: 0.0631028488278389, masked_gen_loss: 0.3158067464828491 - (2851716:unified_unilip.py:926)
2026-01-07 18:10:41 - INFO - total_loss: 0.45700931549072266, masked_loc_loss: 0.06826390326023102, masked_gen_loss: 0.38874542713165283 - (2851716:unified_unilip.py:926)
2026-01-07 18:10:53 - INFO - total_loss: 0.43189728260040283, masked_loc_loss: 0.06681578606367111, masked_gen_loss: 0.3650814890861511 - (2851716:unified_unilip.py:926)
2026-01-07 18:11:01 - INFO - total_loss: 0.4707716405391693, masked_loc_loss: 0.08623304963111877, masked_gen_loss: 0.38453859090805054 - (2851716:unified_unilip.py:926)
2026-01-07 18:11:16 - INFO - total_loss: 0.39979279041290283, masked_loc_loss: 0.07088880240917206, masked_gen_loss: 0.3289039731025696 - (2851716:unified_unilip.py:926)
2026-01-07 18:11:30 - INFO - total_loss: 0.4587007462978363, masked_loc_loss: 0.04430059343576431, masked_gen_loss: 0.4144001603126526 - (2851716:unified_unilip.py:926)
2026-01-07 18:11:45 - INFO - total_loss: 0.4803284704685211, masked_loc_loss: 0.08222880214452744, masked_gen_loss: 0.3980996608734131 - (2851716:unified_unilip.py:926)
2026-01-07 18:11:58 - INFO - total_loss: 0.4022796154022217, masked_loc_loss: 0.07281112670898438, masked_gen_loss: 0.3294684886932373 - (2851716:unified_unilip.py:926)
2026-01-07 18:12:12 - INFO - total_loss: 0.4397176504135132, masked_loc_loss: 0.050002411007881165, masked_gen_loss: 0.3897152245044708 - (2851716:unified_unilip.py:926)
2026-01-07 18:12:27 - INFO - total_loss: 0.3689820468425751, masked_loc_loss: 0.052135564386844635, masked_gen_loss: 0.31684648990631104 - (2851716:unified_unilip.py:926)
2026-01-07 18:12:40 - INFO - total_loss: 0.4257197082042694, masked_loc_loss: 0.054686691612005234, masked_gen_loss: 0.3710330128669739 - (2851716:unified_unilip.py:926)
2026-01-07 18:12:47 - INFO - total_loss: 0.4339725375175476, masked_loc_loss: 0.06539787352085114, masked_gen_loss: 0.3685746490955353 - (2851716:unified_unilip.py:926)
2026-01-07 18:12:53 - INFO - total_loss: 0.41721951961517334, masked_loc_loss: 0.07823837548494339, masked_gen_loss: 0.33898115158081055 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:00 - INFO - total_loss: 0.4553620517253876, masked_loc_loss: 0.05128565803170204, masked_gen_loss: 0.40407639741897583 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:06 - INFO - total_loss: 0.46914470195770264, masked_loc_loss: 0.0843925029039383, masked_gen_loss: 0.38475221395492554 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:13 - INFO - total_loss: 0.44163963198661804, masked_loc_loss: 0.06180825084447861, masked_gen_loss: 0.37983137369155884 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:19 - INFO - total_loss: 0.4336024224758148, masked_loc_loss: 0.05377183482050896, masked_gen_loss: 0.37983059883117676 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:26 - INFO - total_loss: 0.3463258147239685, masked_loc_loss: 0.060602448880672455, masked_gen_loss: 0.28572335839271545 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:32 - INFO - total_loss: 0.33748382329940796, masked_loc_loss: 0.053400155156850815, masked_gen_loss: 0.28408366441726685 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:39 - INFO - total_loss: 0.4596879780292511, masked_loc_loss: 0.05504339188337326, masked_gen_loss: 0.40464457869529724 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:45 - INFO - total_loss: 0.422346293926239, masked_loc_loss: 0.09871600568294525, masked_gen_loss: 0.32363030314445496 - (2851716:unified_unilip.py:926)
2026-01-07 18:13:56 - INFO - total_loss: 0.46830084919929504, masked_loc_loss: 0.06839275360107422, masked_gen_loss: 0.3999080955982208 - (2851716:unified_unilip.py:926)
2026-01-07 18:14:10 - INFO - total_loss: 0.39415213465690613, masked_loc_loss: 0.042981505393981934, masked_gen_loss: 0.3511706292629242 - (2851716:unified_unilip.py:926)
2026-01-07 18:14:24 - INFO - total_loss: 0.4258023798465729, masked_loc_loss: 0.06041499227285385, masked_gen_loss: 0.3653873801231384 - (2851716:unified_unilip.py:926)
2026-01-07 18:14:38 - INFO - total_loss: 0.42770957946777344, masked_loc_loss: 0.0803016871213913, masked_gen_loss: 0.34740790724754333 - (2851716:unified_unilip.py:926)
2026-01-07 18:14:49 - INFO - total_loss: 0.3892520070075989, masked_loc_loss: 0.05729876458644867, masked_gen_loss: 0.331953227519989 - (2851716:unified_unilip.py:926)
2026-01-07 18:14:55 - INFO - total_loss: 0.3802638351917267, masked_loc_loss: 0.0748836100101471, masked_gen_loss: 0.3053802251815796 - (2851716:unified_unilip.py:926)
2026-01-07 18:15:07 - INFO - total_loss: 0.40086832642555237, masked_loc_loss: 0.047639150172472, masked_gen_loss: 0.3532291650772095 - (2851716:unified_unilip.py:926)
2026-01-07 18:15:21 - INFO - total_loss: 0.3799394965171814, masked_loc_loss: 0.07291218638420105, masked_gen_loss: 0.30702731013298035 - (2851716:unified_unilip.py:926)
2026-01-07 18:15:36 - INFO - total_loss: 0.4234538674354553, masked_loc_loss: 0.10756666958332062, masked_gen_loss: 0.3158872127532959 - (2851716:unified_unilip.py:926)
2026-01-07 18:15:50 - INFO - total_loss: 0.4307492673397064, masked_loc_loss: 0.08409461379051208, masked_gen_loss: 0.34665465354919434 - (2851716:unified_unilip.py:926)
2026-01-07 18:15:59 - INFO - total_loss: 0.4432467818260193, masked_loc_loss: 0.056664932519197464, masked_gen_loss: 0.3865818381309509 - (2851716:unified_unilip.py:926)
2026-01-07 18:16:07 - INFO - total_loss: 0.38896623253822327, masked_loc_loss: 0.04582247883081436, masked_gen_loss: 0.3431437611579895 - (2851716:unified_unilip.py:926)
2026-01-07 18:16:21 - INFO - total_loss: 0.36840173602104187, masked_loc_loss: 0.056276556104421616, masked_gen_loss: 0.31212517619132996 - (2851716:unified_unilip.py:926)
2026-01-07 18:16:36 - INFO - total_loss: 0.4013451039791107, masked_loc_loss: 0.09906706213951111, masked_gen_loss: 0.3022780418395996 - (2851716:unified_unilip.py:926)
2026-01-07 18:16:50 - INFO - total_loss: 0.4144509434700012, masked_loc_loss: 0.082964226603508, masked_gen_loss: 0.3314867317676544 - (2851716:unified_unilip.py:926)
2026-01-07 18:17:03 - INFO - total_loss: 0.45065245032310486, masked_loc_loss: 0.07222083956003189, masked_gen_loss: 0.37843161821365356 - (2851716:unified_unilip.py:926)
2026-01-07 18:17:10 - INFO - total_loss: 0.39333751797676086, masked_loc_loss: 0.05543830245733261, masked_gen_loss: 0.33789920806884766 - (2851716:unified_unilip.py:926)
2026-01-07 18:17:24 - INFO - total_loss: 0.4034038782119751, masked_loc_loss: 0.04103410989046097, masked_gen_loss: 0.3623697757720947 - (2851716:unified_unilip.py:926)
2026-01-07 18:17:39 - INFO - total_loss: 0.4074351191520691, masked_loc_loss: 0.04447993263602257, masked_gen_loss: 0.3629551827907562 - (2851716:unified_unilip.py:926)
2026-01-07 18:17:53 - INFO - total_loss: 0.43156832456588745, masked_loc_loss: 0.08533147722482681, masked_gen_loss: 0.34623685479164124 - (2851716:unified_unilip.py:926)
2026-01-07 18:18:07 - INFO - total_loss: 0.40002578496932983, masked_loc_loss: 0.06428884714841843, masked_gen_loss: 0.3357369303703308 - (2851716:unified_unilip.py:926)
2026-01-07 18:18:17 - INFO - total_loss: 0.4373461604118347, masked_loc_loss: 0.05484987050294876, masked_gen_loss: 0.38249629735946655 - (2851716:unified_unilip.py:926)
2026-01-07 18:18:31 - INFO - total_loss: 0.427103728055954, masked_loc_loss: 0.05569431930780411, masked_gen_loss: 0.37140941619873047 - (2851716:unified_unilip.py:926)
2026-01-07 18:18:45 - INFO - total_loss: 0.3977961242198944, masked_loc_loss: 0.07870909571647644, masked_gen_loss: 0.31908702850341797 - (2851716:unified_unilip.py:926)
2026-01-07 18:19:00 - INFO - total_loss: 0.3621978759765625, masked_loc_loss: 0.07471670210361481, masked_gen_loss: 0.2874811887741089 - (2851716:unified_unilip.py:926)
2026-01-07 18:19:12 - INFO - total_loss: 0.43327996134757996, masked_loc_loss: 0.030295509845018387, masked_gen_loss: 0.4029844403266907 - (2851716:unified_unilip.py:926)
2026-01-07 18:19:22 - INFO - total_loss: 0.437110036611557, masked_loc_loss: 0.0748198851943016, masked_gen_loss: 0.3622901439666748 - (2851716:unified_unilip.py:926)
2026-01-07 18:19:36 - INFO - total_loss: 0.44774049520492554, masked_loc_loss: 0.06626919656991959, masked_gen_loss: 0.38147130608558655 - (2851716:unified_unilip.py:926)
2026-01-07 18:19:51 - INFO - total_loss: 0.432033509016037, masked_loc_loss: 0.10601475834846497, masked_gen_loss: 0.326018750667572 - (2851716:unified_unilip.py:926)
2026-01-07 18:20:05 - INFO - total_loss: 0.4034639596939087, masked_loc_loss: 0.07852528989315033, masked_gen_loss: 0.32493868470191956 - (2851716:unified_unilip.py:926)
2026-01-07 18:20:16 - INFO - total_loss: 0.3857339918613434, masked_loc_loss: 0.0623878613114357, masked_gen_loss: 0.3233461380004883 - (2851716:unified_unilip.py:926)
2026-01-07 18:20:26 - INFO - total_loss: 0.3885779082775116, masked_loc_loss: 0.081623375415802, masked_gen_loss: 0.3069545328617096 - (2851716:unified_unilip.py:926)
2026-01-07 18:20:40 - INFO - total_loss: 0.38045212626457214, masked_loc_loss: 0.04480745643377304, masked_gen_loss: 0.3356446623802185 - (2851716:unified_unilip.py:926)
2026-01-07 18:20:54 - INFO - total_loss: 0.38141733407974243, masked_loc_loss: 0.026545923203229904, masked_gen_loss: 0.3548714220523834 - (2851716:unified_unilip.py:926)
2026-01-07 18:21:08 - INFO - total_loss: 0.402097225189209, masked_loc_loss: 0.06193162500858307, masked_gen_loss: 0.3401656150817871 - (2851716:unified_unilip.py:926)
2026-01-07 18:21:19 - INFO - total_loss: 0.41358262300491333, masked_loc_loss: 0.05271867290139198, masked_gen_loss: 0.36086395382881165 - (2851716:unified_unilip.py:926)
2026-01-07 18:21:29 - INFO - total_loss: 0.38876256346702576, masked_loc_loss: 0.04725583270192146, masked_gen_loss: 0.3415067195892334 - (2851716:unified_unilip.py:926)
2026-01-07 18:21:43 - INFO - total_loss: 0.3978738784790039, masked_loc_loss: 0.03847304731607437, masked_gen_loss: 0.35940083861351013 - (2851716:unified_unilip.py:926)
2026-01-07 18:21:58 - INFO - total_loss: 0.38719627261161804, masked_loc_loss: 0.04836573451757431, masked_gen_loss: 0.33883053064346313 - (2851716:unified_unilip.py:926)
2026-01-07 18:22:12 - INFO - total_loss: 0.41667652130126953, masked_loc_loss: 0.0711064264178276, masked_gen_loss: 0.34557008743286133 - (2851716:unified_unilip.py:926)
2026-01-07 18:22:23 - INFO - total_loss: 0.3379485309123993, masked_loc_loss: 0.07632333040237427, masked_gen_loss: 0.261625200510025 - (2851716:unified_unilip.py:926)
2026-01-07 18:22:33 - INFO - total_loss: 0.40302222967147827, masked_loc_loss: 0.0532107800245285, masked_gen_loss: 0.3498114347457886 - (2851716:unified_unilip.py:926)
2026-01-07 18:22:48 - INFO - total_loss: 0.3762029707431793, masked_loc_loss: 0.0434744730591774, masked_gen_loss: 0.3327285051345825 - (2851716:unified_unilip.py:926)
2026-01-07 18:23:02 - INFO - total_loss: 0.3571435213088989, masked_loc_loss: 0.06267042458057404, masked_gen_loss: 0.2944731116294861 - (2851716:unified_unilip.py:926)
2026-01-07 18:23:16 - INFO - total_loss: 0.3712809085845947, masked_loc_loss: 0.04659498110413551, masked_gen_loss: 0.3246859312057495 - (2851716:unified_unilip.py:926)
2026-01-07 18:23:29 - INFO - total_loss: 0.43632832169532776, masked_loc_loss: 0.05925625562667847, masked_gen_loss: 0.3770720660686493 - (2851716:unified_unilip.py:926)
2026-01-07 18:23:44 - INFO - total_loss: 0.476982057094574, masked_loc_loss: 0.05076746642589569, masked_gen_loss: 0.4262145757675171 - (2851716:unified_unilip.py:926)
2026-01-07 18:23:58 - INFO - total_loss: 0.4115819036960602, masked_loc_loss: 0.10711804032325745, masked_gen_loss: 0.30446386337280273 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:10 - INFO - total_loss: 0.4089377820491791, masked_loc_loss: 0.05570080876350403, masked_gen_loss: 0.35323697328567505 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:17 - INFO - total_loss: 0.3922833800315857, masked_loc_loss: 0.07443785667419434, masked_gen_loss: 0.31784552335739136 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:23 - INFO - total_loss: 0.42112112045288086, masked_loc_loss: 0.07001914083957672, masked_gen_loss: 0.35110199451446533 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:30 - INFO - total_loss: 0.4411877393722534, masked_loc_loss: 0.051794491708278656, masked_gen_loss: 0.38939324021339417 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:36 - INFO - total_loss: 0.36494672298431396, masked_loc_loss: 0.05236268416047096, masked_gen_loss: 0.3125840425491333 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:43 - INFO - total_loss: 0.4389980435371399, masked_loc_loss: 0.07109421491622925, masked_gen_loss: 0.36790382862091064 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:50 - INFO - total_loss: 0.44168686866760254, masked_loc_loss: 0.07039820402860641, masked_gen_loss: 0.3712886571884155 - (2851716:unified_unilip.py:926)
2026-01-07 18:24:56 - INFO - total_loss: 0.37658214569091797, masked_loc_loss: 0.06619474291801453, masked_gen_loss: 0.31038740277290344 - (2851716:unified_unilip.py:926)
2026-01-07 18:25:03 - INFO - total_loss: 0.47043412923812866, masked_loc_loss: 0.0753931924700737, masked_gen_loss: 0.39504092931747437 - (2851716:unified_unilip.py:926)
2026-01-07 18:25:09 - INFO - total_loss: 0.4121692180633545, masked_loc_loss: 0.07553254812955856, masked_gen_loss: 0.33663666248321533 - (2851716:unified_unilip.py:926)
2026-01-07 18:25:16 - INFO - total_loss: 0.4403042495250702, masked_loc_loss: 0.11091411113739014, masked_gen_loss: 0.32939013838768005 - (2851716:unified_unilip.py:926)
2026-01-07 18:25:30 - INFO - total_loss: 0.44914543628692627, masked_loc_loss: 0.06474383175373077, masked_gen_loss: 0.3844015896320343 - (2851716:unified_unilip.py:926)
2026-01-07 18:25:45 - INFO - total_loss: 0.4312993288040161, masked_loc_loss: 0.060261908918619156, masked_gen_loss: 0.37103742361068726 - (2851716:unified_unilip.py:926)
2026-01-07 18:25:59 - INFO - total_loss: 0.41980332136154175, masked_loc_loss: 0.0758257657289505, masked_gen_loss: 0.34397757053375244 - (2851716:unified_unilip.py:926)
2026-01-07 18:26:14 - INFO - total_loss: 0.39618292450904846, masked_loc_loss: 0.07576948404312134, masked_gen_loss: 0.3204134404659271 - (2851716:unified_unilip.py:926)
2026-01-07 18:26:20 - INFO - total_loss: 0.38807958364486694, masked_loc_loss: 0.044493548572063446, masked_gen_loss: 0.3435860276222229 - (2851716:unified_unilip.py:926)
2026-01-07 18:26:33 - INFO - total_loss: 0.3769632577896118, masked_loc_loss: 0.07915611565113068, masked_gen_loss: 0.29780712723731995 - (2851716:unified_unilip.py:926)
2026-01-07 18:26:47 - INFO - total_loss: 0.4379773437976837, masked_loc_loss: 0.05977226048707962, masked_gen_loss: 0.3782050907611847 - (2851716:unified_unilip.py:926)
2026-01-07 18:27:02 - INFO - total_loss: 0.38187694549560547, masked_loc_loss: 0.05307002365589142, masked_gen_loss: 0.32880690693855286 - (2851716:unified_unilip.py:926)
2026-01-07 18:27:16 - INFO - total_loss: 0.3617907762527466, masked_loc_loss: 0.06388884782791138, masked_gen_loss: 0.2979019284248352 - (2851716:unified_unilip.py:926)
2026-01-07 18:27:23 - INFO - total_loss: 0.39468052983283997, masked_loc_loss: 0.04710322618484497, masked_gen_loss: 0.347577303647995 - (2851716:unified_unilip.py:926)
2026-01-07 18:27:35 - INFO - total_loss: 0.40970849990844727, masked_loc_loss: 0.040869951248168945, masked_gen_loss: 0.3688385486602783 - (2851716:unified_unilip.py:926)
2026-01-07 18:27:49 - INFO - total_loss: 0.4649866819381714, masked_loc_loss: 0.049111973494291306, masked_gen_loss: 0.415874719619751 - (2851716:unified_unilip.py:926)
2026-01-07 18:28:04 - INFO - total_loss: 0.38338106870651245, masked_loc_loss: 0.04981261491775513, masked_gen_loss: 0.3335684537887573 - (2851716:unified_unilip.py:926)
2026-01-07 18:28:18 - INFO - total_loss: 0.4794623851776123, masked_loc_loss: 0.07500185072422028, masked_gen_loss: 0.4044605493545532 - (2851716:unified_unilip.py:926)
2026-01-07 18:28:27 - INFO - total_loss: 0.38098156452178955, masked_loc_loss: 0.0903177410364151, masked_gen_loss: 0.29066383838653564 - (2851716:unified_unilip.py:926)
2026-01-07 18:28:36 - INFO - total_loss: 0.40400582551956177, masked_loc_loss: 0.05874865502119064, masked_gen_loss: 0.3452571630477905 - (2851716:unified_unilip.py:926)
2026-01-07 18:28:50 - INFO - total_loss: 0.38796892762184143, masked_loc_loss: 0.06411311030387878, masked_gen_loss: 0.32385581731796265 - (2851716:unified_unilip.py:926)
2026-01-07 18:29:05 - INFO - total_loss: 0.3981211185455322, masked_loc_loss: 0.03716888278722763, masked_gen_loss: 0.360952228307724 - (2851716:unified_unilip.py:926)
2026-01-07 18:29:19 - INFO - total_loss: 0.44644707441329956, masked_loc_loss: 0.07727302610874176, masked_gen_loss: 0.369174063205719 - (2851716:unified_unilip.py:926)
2026-01-07 18:29:31 - INFO - total_loss: 0.4451450705528259, masked_loc_loss: 0.04524745047092438, masked_gen_loss: 0.39989763498306274 - (2851716:unified_unilip.py:926)
2026-01-07 18:29:44 - INFO - total_loss: 0.4159049093723297, masked_loc_loss: 0.06581106781959534, masked_gen_loss: 0.3500938415527344 - (2851716:unified_unilip.py:926)
2026-01-07 18:29:58 - INFO - total_loss: 0.40660983324050903, masked_loc_loss: 0.05131939798593521, masked_gen_loss: 0.3552904427051544 - (2851716:unified_unilip.py:926)
2026-01-07 18:30:13 - INFO - total_loss: 0.41568678617477417, masked_loc_loss: 0.05426231026649475, masked_gen_loss: 0.3614244759082794 - (2851716:unified_unilip.py:926)
2026-01-07 18:30:27 - INFO - total_loss: 0.4171648621559143, masked_loc_loss: 0.09305079281330109, masked_gen_loss: 0.3241140842437744 - (2851716:unified_unilip.py:926)
2026-01-07 18:30:37 - INFO - total_loss: 0.4250011444091797, masked_loc_loss: 0.09933613240718842, masked_gen_loss: 0.32566502690315247 - (2851716:unified_unilip.py:926)
2026-01-07 18:30:52 - INFO - total_loss: 0.4126037061214447, masked_loc_loss: 0.10455366969108582, masked_gen_loss: 0.3080500364303589 - (2851716:unified_unilip.py:926)
2026-01-07 18:31:06 - INFO - total_loss: 0.4461755156517029, masked_loc_loss: 0.10535752773284912, masked_gen_loss: 0.34081798791885376 - (2851716:unified_unilip.py:926)
2026-01-07 18:31:21 - INFO - total_loss: 0.410653293132782, masked_loc_loss: 0.09111565351486206, masked_gen_loss: 0.3195376396179199 - (2851716:unified_unilip.py:926)
2026-01-07 18:31:34 - INFO - total_loss: 0.42712169885635376, masked_loc_loss: 0.05889284610748291, masked_gen_loss: 0.36822885274887085 - (2851716:unified_unilip.py:926)
2026-01-07 18:31:49 - INFO - total_loss: 0.4807228147983551, masked_loc_loss: 0.16247311234474182, masked_gen_loss: 0.3182497024536133 - (2851716:unified_unilip.py:926)
2026-01-07 18:32:03 - INFO - total_loss: 0.5149523615837097, masked_loc_loss: 0.14199264347553253, masked_gen_loss: 0.3729597330093384 - (2851716:unified_unilip.py:926)
2026-01-07 18:32:17 - INFO - total_loss: 0.42447593808174133, masked_loc_loss: 0.06325548142194748, masked_gen_loss: 0.36122044920921326 - (2851716:unified_unilip.py:926)
2026-01-07 18:33:45 - INFO - total_loss: 0.4451580345630646, masked_loc_loss: 0.0618416890501976, masked_gen_loss: 0.3833163380622864 - (2851716:unified_unilip.py:926)
2026-01-07 18:33:58 - INFO - total_loss: 0.41273853182792664, masked_loc_loss: 0.06678102165460587, masked_gen_loss: 0.34595751762390137 - (2851716:unified_unilip.py:926)
2026-01-07 18:34:12 - INFO - total_loss: 0.44371360540390015, masked_loc_loss: 0.08646641671657562, masked_gen_loss: 0.35724717378616333 - (2851716:unified_unilip.py:926)
2026-01-07 18:34:25 - INFO - total_loss: 0.44210222363471985, masked_loc_loss: 0.09585187584161758, masked_gen_loss: 0.34625035524368286 - (2851716:unified_unilip.py:926)
2026-01-07 18:34:31 - INFO - total_loss: 0.505911111831665, masked_loc_loss: 0.06902691721916199, masked_gen_loss: 0.43688419461250305 - (2851716:unified_unilip.py:926)
2026-01-07 18:34:37 - INFO - total_loss: 0.4167593717575073, masked_loc_loss: 0.08111566305160522, masked_gen_loss: 0.3356437087059021 - (2851716:unified_unilip.py:926)
2026-01-07 18:34:47 - INFO - total_loss: 0.3927975594997406, masked_loc_loss: 0.0439552403986454, masked_gen_loss: 0.3488423228263855 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:00 - INFO - total_loss: 0.3881491422653198, masked_loc_loss: 0.09180689603090286, masked_gen_loss: 0.29634225368499756 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:15 - INFO - total_loss: 0.4376840591430664, masked_loc_loss: 0.08836480975151062, masked_gen_loss: 0.3493192493915558 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:25 - INFO - total_loss: 0.3803001642227173, masked_loc_loss: 0.03957037627696991, masked_gen_loss: 0.34072980284690857 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:31 - INFO - total_loss: 0.43119844794273376, masked_loc_loss: 0.05627616494894028, masked_gen_loss: 0.3749222755432129 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:38 - INFO - total_loss: 0.401215523481369, masked_loc_loss: 0.07781801372766495, masked_gen_loss: 0.32339751720428467 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:44 - INFO - total_loss: 0.4426952600479126, masked_loc_loss: 0.09712740778923035, masked_gen_loss: 0.34556785225868225 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:51 - INFO - total_loss: 0.3892335295677185, masked_loc_loss: 0.08182241022586823, masked_gen_loss: 0.3074111342430115 - (2851716:unified_unilip.py:926)
2026-01-07 18:35:57 - INFO - total_loss: 0.4276447892189026, masked_loc_loss: 0.06653980910778046, masked_gen_loss: 0.36110496520996094 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:04 - INFO - total_loss: 0.4442915916442871, masked_loc_loss: 0.04964312165975571, masked_gen_loss: 0.3946484625339508 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:10 - INFO - total_loss: 0.4405531585216522, masked_loc_loss: 0.0692208930850029, masked_gen_loss: 0.3713322579860687 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:17 - INFO - total_loss: 0.39622730016708374, masked_loc_loss: 0.07715918123722076, masked_gen_loss: 0.31906813383102417 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:23 - INFO - total_loss: 0.4098273515701294, masked_loc_loss: 0.051718950271606445, masked_gen_loss: 0.35810840129852295 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:30 - INFO - total_loss: 0.4602283835411072, masked_loc_loss: 0.0675240159034729, masked_gen_loss: 0.3927043676376343 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:36 - INFO - total_loss: 0.44279393553733826, masked_loc_loss: 0.07549632340669632, masked_gen_loss: 0.36729761958122253 - (2851716:unified_unilip.py:926)
2026-01-07 18:36:48 - INFO - total_loss: 0.3929450511932373, masked_loc_loss: 0.06563127785921097, masked_gen_loss: 0.32731378078460693 - (2851716:unified_unilip.py:926)
2026-01-07 18:37:03 - INFO - total_loss: 0.3904365599155426, masked_loc_loss: 0.040648482739925385, masked_gen_loss: 0.3497880697250366 - (2851716:unified_unilip.py:926)
2026-01-07 18:37:18 - INFO - total_loss: 0.43252047896385193, masked_loc_loss: 0.0809466540813446, masked_gen_loss: 0.3515738248825073 - (2851716:unified_unilip.py:926)
2026-01-07 18:37:32 - INFO - total_loss: 0.3996104598045349, masked_loc_loss: 0.043030545115470886, masked_gen_loss: 0.35657989978790283 - (2851716:unified_unilip.py:926)
2026-01-07 18:37:41 - INFO - total_loss: 0.4399816393852234, masked_loc_loss: 0.04818810150027275, masked_gen_loss: 0.39179354906082153 - (2851716:unified_unilip.py:926)
2026-01-07 18:37:48 - INFO - total_loss: 0.4107438325881958, masked_loc_loss: 0.04239581525325775, masked_gen_loss: 0.36834800243377686 - (2851716:unified_unilip.py:926)
2026-01-07 18:38:02 - INFO - total_loss: 0.39170897006988525, masked_loc_loss: 0.03729507327079773, masked_gen_loss: 0.3544138967990875 - (2851716:unified_unilip.py:926)
2026-01-07 18:38:16 - INFO - total_loss: 0.38962656259536743, masked_loc_loss: 0.03605757653713226, masked_gen_loss: 0.35356900095939636 - (2851716:unified_unilip.py:926)
2026-01-07 18:38:31 - INFO - total_loss: 0.4378697872161865, masked_loc_loss: 0.05576172471046448, masked_gen_loss: 0.38210806250572205 - (2851716:unified_unilip.py:926)
2026-01-07 18:38:45 - INFO - total_loss: 0.4163745045661926, masked_loc_loss: 0.08708776533603668, masked_gen_loss: 0.32928675413131714 - (2851716:unified_unilip.py:926)
2026-01-07 18:38:52 - INFO - total_loss: 0.4115341603755951, masked_loc_loss: 0.035371653735637665, masked_gen_loss: 0.37616249918937683 - (2851716:unified_unilip.py:926)
2026-01-07 18:39:01 - INFO - total_loss: 0.38339096307754517, masked_loc_loss: 0.04606080427765846, masked_gen_loss: 0.337330162525177 - (2851716:unified_unilip.py:926)
2026-01-07 18:39:15 - INFO - total_loss: 0.37192368507385254, masked_loc_loss: 0.04112768918275833, masked_gen_loss: 0.3307960033416748 - (2851716:unified_unilip.py:926)
2026-01-07 18:39:30 - INFO - total_loss: 0.40786466002464294, masked_loc_loss: 0.0518404021859169, masked_gen_loss: 0.35602426528930664 - (2851716:unified_unilip.py:926)
2026-01-07 18:39:44 - INFO - total_loss: 0.3503004014492035, masked_loc_loss: 0.06668057292699814, masked_gen_loss: 0.28361982107162476 - (2851716:unified_unilip.py:926)
2026-01-07 18:39:55 - INFO - total_loss: 0.3604680895805359, masked_loc_loss: 0.05259533226490021, masked_gen_loss: 0.3078727722167969 - (2851716:unified_unilip.py:926)
2026-01-07 18:40:03 - INFO - total_loss: 0.40243345499038696, masked_loc_loss: 0.04247592017054558, masked_gen_loss: 0.3599575459957123 - (2851716:unified_unilip.py:926)
2026-01-07 18:40:18 - INFO - total_loss: 0.4083254039287567, masked_loc_loss: 0.07495489716529846, masked_gen_loss: 0.33337050676345825 - (2851716:unified_unilip.py:926)
2026-01-07 18:40:32 - INFO - total_loss: 0.4261853098869324, masked_loc_loss: 0.07775186002254486, masked_gen_loss: 0.3484334349632263 - (2851716:unified_unilip.py:926)
2026-01-07 18:40:46 - INFO - total_loss: 0.42158377170562744, masked_loc_loss: 0.03518156707286835, masked_gen_loss: 0.3864021897315979 - (2851716:unified_unilip.py:926)
2026-01-07 18:40:59 - INFO - total_loss: 0.37636834383010864, masked_loc_loss: 0.06269097328186035, masked_gen_loss: 0.3136773705482483 - (2851716:unified_unilip.py:926)
2026-01-07 18:41:05 - INFO - total_loss: 0.4219699203968048, masked_loc_loss: 0.05360349267721176, masked_gen_loss: 0.36836642026901245 - (2851716:unified_unilip.py:926)
2026-01-07 18:41:19 - INFO - total_loss: 0.43312159180641174, masked_loc_loss: 0.05732759088277817, masked_gen_loss: 0.375793993473053 - (2851716:unified_unilip.py:926)
2026-01-07 18:41:33 - INFO - total_loss: 0.43306899070739746, masked_loc_loss: 0.07879026979207993, masked_gen_loss: 0.35427871346473694 - (2851716:unified_unilip.py:926)
2026-01-07 18:41:48 - INFO - total_loss: 0.4102952182292938, masked_loc_loss: 0.04903135448694229, masked_gen_loss: 0.36126387119293213 - (2851716:unified_unilip.py:926)
2026-01-07 18:42:02 - INFO - total_loss: 0.38182246685028076, masked_loc_loss: 0.04670923203229904, masked_gen_loss: 0.3351132273674011 - (2851716:unified_unilip.py:926)
2026-01-07 18:42:09 - INFO - total_loss: 0.4040174186229706, masked_loc_loss: 0.051863886415958405, masked_gen_loss: 0.3521535396575928 - (2851716:unified_unilip.py:926)
2026-01-07 18:42:22 - INFO - total_loss: 0.427212655544281, masked_loc_loss: 0.05623556673526764, masked_gen_loss: 0.3709770739078522 - (2851716:unified_unilip.py:926)
2026-01-07 18:42:37 - INFO - total_loss: 0.3806653618812561, masked_loc_loss: 0.08475492894649506, masked_gen_loss: 0.29591041803359985 - (2851716:unified_unilip.py:926)
2026-01-07 18:42:52 - INFO - total_loss: 0.3945804536342621, masked_loc_loss: 0.07426586747169495, masked_gen_loss: 0.32031458616256714 - (2851716:unified_unilip.py:926)
2026-01-07 18:43:07 - INFO - total_loss: 0.3813152313232422, masked_loc_loss: 0.02680147811770439, masked_gen_loss: 0.3545137643814087 - (2851716:unified_unilip.py:926)
2026-01-07 18:43:13 - INFO - total_loss: 0.39994075894355774, masked_loc_loss: 0.05800333246588707, masked_gen_loss: 0.34193742275238037 - (2851716:unified_unilip.py:926)
2026-01-07 18:43:28 - INFO - total_loss: 0.44721755385398865, masked_loc_loss: 0.07169893383979797, masked_gen_loss: 0.3755186200141907 - (2851716:unified_unilip.py:926)
2026-01-07 18:43:42 - INFO - total_loss: 0.3981269896030426, masked_loc_loss: 0.0453178845345974, masked_gen_loss: 0.3528091013431549 - (2851716:unified_unilip.py:926)
2026-01-07 18:43:57 - INFO - total_loss: 0.39450952410697937, masked_loc_loss: 0.05111631006002426, masked_gen_loss: 0.3433932065963745 - (2851716:unified_unilip.py:926)
2026-01-07 18:44:11 - INFO - total_loss: 0.36488813161849976, masked_loc_loss: 0.05600672960281372, masked_gen_loss: 0.30888140201568604 - (2851716:unified_unilip.py:926)
2026-01-07 18:44:19 - INFO - total_loss: 0.39538171887397766, masked_loc_loss: 0.08108016848564148, masked_gen_loss: 0.3143015503883362 - (2851716:unified_unilip.py:926)
2026-01-07 18:44:33 - INFO - total_loss: 0.36397796869277954, masked_loc_loss: 0.04158353433012962, masked_gen_loss: 0.3223944306373596 - (2851716:unified_unilip.py:926)
2026-01-07 18:44:48 - INFO - total_loss: 0.3937397599220276, masked_loc_loss: 0.06726452708244324, masked_gen_loss: 0.32647523283958435 - (2851716:unified_unilip.py:926)
2026-01-07 18:45:02 - INFO - total_loss: 0.37218835949897766, masked_loc_loss: 0.04664399474859238, masked_gen_loss: 0.3255443572998047 - (2851716:unified_unilip.py:926)
2026-01-07 18:45:16 - INFO - total_loss: 0.42242833971977234, masked_loc_loss: 0.06792179495096207, masked_gen_loss: 0.35450655221939087 - (2851716:unified_unilip.py:926)
2026-01-07 18:45:25 - INFO - total_loss: 0.3625248670578003, masked_loc_loss: 0.03493250906467438, masked_gen_loss: 0.3275923728942871 - (2851716:unified_unilip.py:926)
2026-01-07 18:45:39 - INFO - total_loss: 0.3954477310180664, masked_loc_loss: 0.05696164071559906, masked_gen_loss: 0.33848610520362854 - (2851716:unified_unilip.py:926)
2026-01-07 18:45:54 - INFO - total_loss: 0.3616310954093933, masked_loc_loss: 0.04474732279777527, masked_gen_loss: 0.31688377261161804 - (2851716:unified_unilip.py:926)
2026-01-07 18:46:08 - INFO - total_loss: 0.4153618812561035, masked_loc_loss: 0.05970995873212814, masked_gen_loss: 0.3556519150733948 - (2851716:unified_unilip.py:926)
2026-01-07 18:46:20 - INFO - total_loss: 0.43858271837234497, masked_loc_loss: 0.0718776062130928, masked_gen_loss: 0.36670511960983276 - (2851716:unified_unilip.py:926)
2026-01-07 18:46:34 - INFO - total_loss: 0.40329959988594055, masked_loc_loss: 0.06202498823404312, masked_gen_loss: 0.341274619102478 - (2851716:unified_unilip.py:926)
2026-01-07 18:46:48 - INFO - total_loss: 0.4953961968421936, masked_loc_loss: 0.06556002795696259, masked_gen_loss: 0.4298361539840698 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:03 - INFO - total_loss: 0.3690485656261444, masked_loc_loss: 0.048756975680589676, masked_gen_loss: 0.32029157876968384 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:10 - INFO - total_loss: 0.39160269498825073, masked_loc_loss: 0.07380540668964386, masked_gen_loss: 0.31779730319976807 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:16 - INFO - total_loss: 0.4390788674354553, masked_loc_loss: 0.050095513463020325, masked_gen_loss: 0.3889833390712738 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:23 - INFO - total_loss: 0.37075313925743103, masked_loc_loss: 0.05603322759270668, masked_gen_loss: 0.31471991539001465 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:29 - INFO - total_loss: 0.4115145206451416, masked_loc_loss: 0.058338820934295654, masked_gen_loss: 0.35317569971084595 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:36 - INFO - total_loss: 0.4174168109893799, masked_loc_loss: 0.076197549700737, masked_gen_loss: 0.3412192761898041 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:42 - INFO - total_loss: 0.392734169960022, masked_loc_loss: 0.04752969741821289, masked_gen_loss: 0.3452044725418091 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:49 - INFO - total_loss: 0.44290393590927124, masked_loc_loss: 0.06860168278217316, masked_gen_loss: 0.3743022382259369 - (2851716:unified_unilip.py:926)
2026-01-07 18:47:55 - INFO - total_loss: 0.44319626688957214, masked_loc_loss: 0.052393339574337006, masked_gen_loss: 0.39080291986465454 - (2851716:unified_unilip.py:926)
2026-01-07 18:48:02 - INFO - total_loss: 0.40455496311187744, masked_loc_loss: 0.06824292242527008, masked_gen_loss: 0.33631205558776855 - (2851716:unified_unilip.py:926)
2026-01-07 18:48:08 - INFO - total_loss: 0.38937753438949585, masked_loc_loss: 0.05879771709442139, masked_gen_loss: 0.33057981729507446 - (2851716:unified_unilip.py:926)
2026-01-07 18:48:15 - INFO - total_loss: 0.3942136764526367, masked_loc_loss: 0.06723806262016296, masked_gen_loss: 0.32697561383247375 - (2851716:unified_unilip.py:926)
2026-01-07 18:48:23 - INFO - total_loss: 0.41858360171318054, masked_loc_loss: 0.062227215617895126, masked_gen_loss: 0.3563563823699951 - (2851716:unified_unilip.py:926)
2026-01-07 18:48:38 - INFO - total_loss: 0.4053628146648407, masked_loc_loss: 0.033161841332912445, masked_gen_loss: 0.37220096588134766 - (2851716:unified_unilip.py:926)
2026-01-07 18:48:52 - INFO - total_loss: 0.41155147552490234, masked_loc_loss: 0.09587894380092621, masked_gen_loss: 0.31567251682281494 - (2851716:unified_unilip.py:926)
2026-01-07 18:49:07 - INFO - total_loss: 0.40634042024612427, masked_loc_loss: 0.07008804380893707, masked_gen_loss: 0.3362523913383484 - (2851716:unified_unilip.py:926)
2026-01-07 18:49:20 - INFO - total_loss: 0.39913812279701233, masked_loc_loss: 0.0530456118285656, masked_gen_loss: 0.3460925221443176 - (2851716:unified_unilip.py:926)
2026-01-07 18:49:26 - INFO - total_loss: 0.34650683403015137, masked_loc_loss: 0.05374819412827492, masked_gen_loss: 0.29275864362716675 - (2851716:unified_unilip.py:926)
2026-01-07 18:49:35 - INFO - total_loss: 0.3549238443374634, masked_loc_loss: 0.07471078634262085, masked_gen_loss: 0.28021305799484253 - (2851716:unified_unilip.py:926)
2026-01-07 18:49:50 - INFO - total_loss: 0.38523873686790466, masked_loc_loss: 0.08023673295974731, masked_gen_loss: 0.30500200390815735 - (2851716:unified_unilip.py:926)
2026-01-07 18:50:04 - INFO - total_loss: 0.42092421650886536, masked_loc_loss: 0.04457726329565048, masked_gen_loss: 0.3763469457626343 - (2851716:unified_unilip.py:926)
2026-01-07 18:50:19 - INFO - total_loss: 0.3848799765110016, masked_loc_loss: 0.0610312856733799, masked_gen_loss: 0.323848694562912 - (2851716:unified_unilip.py:926)
2026-01-07 18:50:31 - INFO - total_loss: 0.4010348320007324, masked_loc_loss: 0.048660747706890106, masked_gen_loss: 0.3523740768432617 - (2851716:unified_unilip.py:926)
2026-01-07 18:50:38 - INFO - total_loss: 0.41999295353889465, masked_loc_loss: 0.061123814433813095, masked_gen_loss: 0.35886913537979126 - (2851716:unified_unilip.py:926)
2026-01-07 18:50:53 - INFO - total_loss: 0.39614108204841614, masked_loc_loss: 0.0656837448477745, masked_gen_loss: 0.33045732975006104 - (2851716:unified_unilip.py:926)
2026-01-07 18:51:07 - INFO - total_loss: 0.4020105302333832, masked_loc_loss: 0.05418948084115982, masked_gen_loss: 0.34782105684280396 - (2851716:unified_unilip.py:926)
2026-01-07 18:51:22 - INFO - total_loss: 0.37255674600601196, masked_loc_loss: 0.062021031975746155, masked_gen_loss: 0.310535728931427 - (2851716:unified_unilip.py:926)
2026-01-07 18:51:36 - INFO - total_loss: 0.36036404967308044, masked_loc_loss: 0.04474342614412308, masked_gen_loss: 0.31562063097953796 - (2851716:unified_unilip.py:926)
2026-01-07 18:51:43 - INFO - total_loss: 0.39330029487609863, masked_loc_loss: 0.04440097510814667, masked_gen_loss: 0.34889930486679077 - (2851716:unified_unilip.py:926)
2026-01-07 18:51:57 - INFO - total_loss: 0.38210704922676086, masked_loc_loss: 0.06098601222038269, masked_gen_loss: 0.3211210370063782 - (2851716:unified_unilip.py:926)
2026-01-07 18:52:11 - INFO - total_loss: 0.4049259424209595, masked_loc_loss: 0.09072443842887878, masked_gen_loss: 0.3142015039920807 - (2851716:unified_unilip.py:926)
2026-01-07 18:52:26 - INFO - total_loss: 0.41481223702430725, masked_loc_loss: 0.08575093746185303, masked_gen_loss: 0.3290612995624542 - (2851716:unified_unilip.py:926)
2026-01-07 18:52:39 - INFO - total_loss: 0.41319504380226135, masked_loc_loss: 0.06902357935905457, masked_gen_loss: 0.3441714644432068 - (2851716:unified_unilip.py:926)
2026-01-07 18:52:48 - INFO - total_loss: 0.4093037247657776, masked_loc_loss: 0.06014186143875122, masked_gen_loss: 0.34916186332702637 - (2851716:unified_unilip.py:926)
2026-01-07 18:53:03 - INFO - total_loss: 0.3627130389213562, masked_loc_loss: 0.04036973416805267, masked_gen_loss: 0.32234328985214233 - (2851716:unified_unilip.py:926)
2026-01-07 18:53:17 - INFO - total_loss: 0.3836398720741272, masked_loc_loss: 0.06812483072280884, masked_gen_loss: 0.31551504135131836 - (2851716:unified_unilip.py:926)
2026-01-07 18:53:31 - INFO - total_loss: 0.3791744112968445, masked_loc_loss: 0.08338756859302521, masked_gen_loss: 0.29578685760498047 - (2851716:unified_unilip.py:926)
2026-01-07 18:53:43 - INFO - total_loss: 0.3961944282054901, masked_loc_loss: 0.053314827382564545, masked_gen_loss: 0.34287959337234497 - (2851716:unified_unilip.py:926)
2026-01-07 18:53:53 - INFO - total_loss: 0.39606815576553345, masked_loc_loss: 0.08101843297481537, masked_gen_loss: 0.3150497078895569 - (2851716:unified_unilip.py:926)
2026-01-07 18:54:07 - INFO - total_loss: 0.4170534610748291, masked_loc_loss: 0.06549146771430969, masked_gen_loss: 0.3515619933605194 - (2851716:unified_unilip.py:926)
2026-01-07 18:54:22 - INFO - total_loss: 0.3789359927177429, masked_loc_loss: 0.06876617670059204, masked_gen_loss: 0.3101698160171509 - (2851716:unified_unilip.py:926)
2026-01-07 18:54:36 - INFO - total_loss: 0.40660956501960754, masked_loc_loss: 0.0870678722858429, masked_gen_loss: 0.31954169273376465 - (2851716:unified_unilip.py:926)
2026-01-07 18:54:47 - INFO - total_loss: 0.4530380368232727, masked_loc_loss: 0.06303268671035767, masked_gen_loss: 0.39000535011291504 - (2851716:unified_unilip.py:926)
2026-01-07 18:55:01 - INFO - total_loss: 0.3715324103832245, masked_loc_loss: 0.051281530410051346, masked_gen_loss: 0.32025086879730225 - (2851716:unified_unilip.py:926)
2026-01-07 18:55:16 - INFO - total_loss: 0.3711469769477844, masked_loc_loss: 0.061553314328193665, masked_gen_loss: 0.30959367752075195 - (2851716:unified_unilip.py:926)
2026-01-07 18:55:30 - INFO - total_loss: 0.4636334776878357, masked_loc_loss: 0.06573587656021118, masked_gen_loss: 0.3978976011276245 - (2851716:unified_unilip.py:926)
2026-01-07 18:55:45 - INFO - total_loss: 0.41850781440734863, masked_loc_loss: 0.04131554067134857, masked_gen_loss: 0.37719225883483887 - (2851716:unified_unilip.py:926)
2026-01-07 18:55:52 - INFO - total_loss: 0.3811330199241638, masked_loc_loss: 0.06892711669206619, masked_gen_loss: 0.3122059106826782 - (2851716:unified_unilip.py:926)
2026-01-07 18:56:06 - INFO - total_loss: 0.3845219612121582, masked_loc_loss: 0.04542357474565506, masked_gen_loss: 0.33909839391708374 - (2851716:unified_unilip.py:926)
2026-01-07 18:56:21 - INFO - total_loss: 0.3853297531604767, masked_loc_loss: 0.05650123581290245, masked_gen_loss: 0.32882851362228394 - (2851716:unified_unilip.py:926)
2026-01-07 18:56:35 - INFO - total_loss: 0.40321117639541626, masked_loc_loss: 0.04908956587314606, masked_gen_loss: 0.3541216254234314 - (2851716:unified_unilip.py:926)
2026-01-07 18:56:50 - INFO - total_loss: 0.379749596118927, masked_loc_loss: 0.05261052027344704, masked_gen_loss: 0.32713907957077026 - (2851716:unified_unilip.py:926)
2026-01-07 18:57:00 - INFO - total_loss: 0.3987899422645569, masked_loc_loss: 0.05525653064250946, masked_gen_loss: 0.34353339672088623 - (2851716:unified_unilip.py:926)
2026-01-07 18:57:14 - INFO - total_loss: 0.37901002168655396, masked_loc_loss: 0.05081825330853462, masked_gen_loss: 0.32819175720214844 - (2851716:unified_unilip.py:926)
2026-01-07 18:57:29 - INFO - total_loss: 0.32784178853034973, masked_loc_loss: 0.04054494947195053, masked_gen_loss: 0.2872968316078186 - (2851716:unified_unilip.py:926)
2026-01-07 18:57:43 - INFO - total_loss: 0.36306941509246826, masked_loc_loss: 0.061864301562309265, masked_gen_loss: 0.3012050986289978 - (2851716:unified_unilip.py:926)
2026-01-07 18:57:54 - INFO - total_loss: 0.39994949102401733, masked_loc_loss: 0.056453630328178406, masked_gen_loss: 0.34349584579467773 - (2851716:unified_unilip.py:926)
2026-01-07 18:58:04 - INFO - total_loss: 0.4445602595806122, masked_loc_loss: 0.03350735083222389, masked_gen_loss: 0.4110529124736786 - (2851716:unified_unilip.py:926)
2026-01-07 18:58:19 - INFO - total_loss: 0.39525800943374634, masked_loc_loss: 0.029502257704734802, masked_gen_loss: 0.36575576663017273 - (2851716:unified_unilip.py:926)
2026-01-07 18:58:33 - INFO - total_loss: 0.3521908223628998, masked_loc_loss: 0.04144106060266495, masked_gen_loss: 0.31074976921081543 - (2851716:unified_unilip.py:926)
2026-01-07 18:58:43 - INFO - total_loss: 0.3564969599246979, masked_loc_loss: 0.05296161770820618, masked_gen_loss: 0.3035353422164917 - (2851716:unified_unilip.py:926)
2026-01-07 18:58:50 - INFO - total_loss: 0.39356765151023865, masked_loc_loss: 0.04346355050802231, masked_gen_loss: 0.35010409355163574 - (2851716:unified_unilip.py:926)
2026-01-07 18:58:56 - INFO - total_loss: 0.35281407833099365, masked_loc_loss: 0.07547830045223236, masked_gen_loss: 0.2773357927799225 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:03 - INFO - total_loss: 0.4416099786758423, masked_loc_loss: 0.04661811888217926, masked_gen_loss: 0.3949918746948242 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:09 - INFO - total_loss: 0.3701242208480835, masked_loc_loss: 0.06421424448490143, masked_gen_loss: 0.30590999126434326 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:16 - INFO - total_loss: 0.397012323141098, masked_loc_loss: 0.06698581576347351, masked_gen_loss: 0.3300265073776245 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:22 - INFO - total_loss: 0.4488212466239929, masked_loc_loss: 0.05153914541006088, masked_gen_loss: 0.39728209376335144 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:28 - INFO - total_loss: 0.4229591190814972, masked_loc_loss: 0.048928938806056976, masked_gen_loss: 0.3740301728248596 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:35 - INFO - total_loss: 0.3597710430622101, masked_loc_loss: 0.0679219663143158, masked_gen_loss: 0.2918490767478943 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:41 - INFO - total_loss: 0.4304825961589813, masked_loc_loss: 0.03277859836816788, masked_gen_loss: 0.39770400524139404 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:48 - INFO - total_loss: 0.39022934436798096, masked_loc_loss: 0.06223322078585625, masked_gen_loss: 0.3279961347579956 - (2851716:unified_unilip.py:926)
2026-01-07 18:59:57 - INFO - total_loss: 0.4333079755306244, masked_loc_loss: 0.08211329579353333, masked_gen_loss: 0.35119467973709106 - (2851716:unified_unilip.py:926)
2026-01-07 19:00:11 - INFO - total_loss: 0.40395858883857727, masked_loc_loss: 0.06104743108153343, masked_gen_loss: 0.34291115403175354 - (2851716:unified_unilip.py:926)
2026-01-07 19:00:26 - INFO - total_loss: 0.4926251471042633, masked_loc_loss: 0.06408116221427917, masked_gen_loss: 0.42854398488998413 - (2851716:unified_unilip.py:926)
2026-01-07 19:00:40 - INFO - total_loss: 0.34672674536705017, masked_loc_loss: 0.045853666961193085, masked_gen_loss: 0.3008730709552765 - (2851716:unified_unilip.py:926)
2026-01-07 19:00:52 - INFO - total_loss: 0.33521953225135803, masked_loc_loss: 0.053345631808042526, masked_gen_loss: 0.2818739116191864 - (2851716:unified_unilip.py:926)
2026-01-07 19:00:58 - INFO - total_loss: 0.43185102939605713, masked_loc_loss: 0.06447009742259979, masked_gen_loss: 0.36738094687461853 - (2851716:unified_unilip.py:926)
2026-01-07 19:01:09 - INFO - total_loss: 0.3890724182128906, masked_loc_loss: 0.03539682924747467, masked_gen_loss: 0.35367560386657715 - (2851716:unified_unilip.py:926)
2026-01-07 19:01:23 - INFO - total_loss: 0.42748087644577026, masked_loc_loss: 0.10103209316730499, masked_gen_loss: 0.32644879817962646 - (2851716:unified_unilip.py:926)
2026-01-07 19:01:38 - INFO - total_loss: 0.4511505961418152, masked_loc_loss: 0.05745873600244522, masked_gen_loss: 0.39369186758995056 - (2851716:unified_unilip.py:926)
2026-01-07 19:01:52 - INFO - total_loss: 0.43545663356781006, masked_loc_loss: 0.08037859201431274, masked_gen_loss: 0.3550780415534973 - (2851716:unified_unilip.py:926)
2026-01-07 19:02:03 - INFO - total_loss: 0.4381988048553467, masked_loc_loss: 0.0618470162153244, masked_gen_loss: 0.3763517737388611 - (2851716:unified_unilip.py:926)
2026-01-07 19:02:11 - INFO - total_loss: 0.36597299575805664, masked_loc_loss: 0.04037756845355034, masked_gen_loss: 0.3255954384803772 - (2851716:unified_unilip.py:926)
2026-01-07 19:02:25 - INFO - total_loss: 0.4704208970069885, masked_loc_loss: 0.06755892187356949, masked_gen_loss: 0.40286198258399963 - (2851716:unified_unilip.py:926)
2026-01-07 19:02:40 - INFO - total_loss: 0.407220721244812, masked_loc_loss: 0.04146628454327583, masked_gen_loss: 0.3657544255256653 - (2851716:unified_unilip.py:926)
2026-01-07 19:02:55 - INFO - total_loss: 0.38569462299346924, masked_loc_loss: 0.06002969294786453, masked_gen_loss: 0.3256649374961853 - (2851716:unified_unilip.py:926)
2026-01-07 19:03:07 - INFO - total_loss: 0.4208712577819824, masked_loc_loss: 0.08201808482408524, masked_gen_loss: 0.3388531804084778 - (2851716:unified_unilip.py:926)
2026-01-07 19:03:16 - INFO - total_loss: 0.389916330575943, masked_loc_loss: 0.05418331176042557, masked_gen_loss: 0.335733026266098 - (2851716:unified_unilip.py:926)
2026-01-07 19:03:31 - INFO - total_loss: 0.42532414197921753, masked_loc_loss: 0.05836586654186249, masked_gen_loss: 0.36695826053619385 - (2851716:unified_unilip.py:926)
2026-01-07 19:03:45 - INFO - total_loss: 0.385587215423584, masked_loc_loss: 0.05629891902208328, masked_gen_loss: 0.3292883038520813 - (2851716:unified_unilip.py:926)
2026-01-07 19:03:59 - INFO - total_loss: 0.41182973980903625, masked_loc_loss: 0.062283892184495926, masked_gen_loss: 0.34954583644866943 - (2851716:unified_unilip.py:926)
2026-01-07 19:04:11 - INFO - total_loss: 0.415671169757843, masked_loc_loss: 0.058009520173072815, masked_gen_loss: 0.3576616644859314 - (2851716:unified_unilip.py:926)
2026-01-07 19:04:21 - INFO - total_loss: 0.4590384066104889, masked_loc_loss: 0.09655299782752991, masked_gen_loss: 0.362485408782959 - (2851716:unified_unilip.py:926)
2026-01-07 19:04:36 - INFO - total_loss: 0.4236031174659729, masked_loc_loss: 0.062113285064697266, masked_gen_loss: 0.36148983240127563 - (2851716:unified_unilip.py:926)
2026-01-07 19:04:50 - INFO - total_loss: 0.428913414478302, masked_loc_loss: 0.06678824871778488, masked_gen_loss: 0.3621251583099365 - (2851716:unified_unilip.py:926)
2026-01-07 19:05:05 - INFO - total_loss: 0.37946271896362305, masked_loc_loss: 0.032354485243558884, masked_gen_loss: 0.34710824489593506 - (2851716:unified_unilip.py:926)
2026-01-07 19:05:15 - INFO - total_loss: 0.4172646999359131, masked_loc_loss: 0.07385982573032379, masked_gen_loss: 0.3434048593044281 - (2851716:unified_unilip.py:926)
2026-01-07 19:05:25 - INFO - total_loss: 0.43600794672966003, masked_loc_loss: 0.07104411721229553, masked_gen_loss: 0.3649638295173645 - (2851716:unified_unilip.py:926)
2026-01-07 19:05:39 - INFO - total_loss: 0.4078057110309601, masked_loc_loss: 0.05052492022514343, masked_gen_loss: 0.35728079080581665 - (2851716:unified_unilip.py:926)
2026-01-07 19:05:54 - INFO - total_loss: 0.3995307683944702, masked_loc_loss: 0.04649728909134865, masked_gen_loss: 0.35303348302841187 - (2851716:unified_unilip.py:926)
2026-01-07 19:06:08 - INFO - total_loss: 0.3830634653568268, masked_loc_loss: 0.04566212743520737, masked_gen_loss: 0.3374013304710388 - (2851716:unified_unilip.py:926)
2026-01-07 19:06:19 - INFO - total_loss: 0.4549773931503296, masked_loc_loss: 0.03763730823993683, masked_gen_loss: 0.41734009981155396 - (2851716:unified_unilip.py:926)
2026-01-07 19:06:25 - INFO - total_loss: 0.3959673345088959, masked_loc_loss: 0.04689464718103409, masked_gen_loss: 0.3490726947784424 - (2851716:unified_unilip.py:926)
2026-01-07 19:06:35 - INFO - total_loss: 0.39352947473526, masked_loc_loss: 0.047781746834516525, masked_gen_loss: 0.3457477390766144 - (2851716:unified_unilip.py:926)
2026-01-07 19:06:49 - INFO - total_loss: 0.43729063868522644, masked_loc_loss: 0.03915092349052429, masked_gen_loss: 0.39813971519470215 - (2851716:unified_unilip.py:926)
2026-01-07 19:07:03 - INFO - total_loss: 0.3514902591705322, masked_loc_loss: 0.04379623755812645, masked_gen_loss: 0.3076940178871155 - (2851716:unified_unilip.py:926)
2026-01-07 19:07:18 - INFO - total_loss: 0.4005272090435028, masked_loc_loss: 0.04349388927221298, masked_gen_loss: 0.35703331232070923 - (2851716:unified_unilip.py:926)
2026-01-07 19:07:29 - INFO - total_loss: 0.41740682721138, masked_loc_loss: 0.05896473303437233, masked_gen_loss: 0.358442097902298 - (2851716:unified_unilip.py:926)
2026-01-07 19:07:36 - INFO - total_loss: 0.4461269974708557, masked_loc_loss: 0.06269556283950806, masked_gen_loss: 0.38343143463134766 - (2851716:unified_unilip.py:926)
2026-01-07 19:07:50 - INFO - total_loss: 0.4230167865753174, masked_loc_loss: 0.03318113833665848, masked_gen_loss: 0.3898356556892395 - (2851716:unified_unilip.py:926)
2026-01-07 19:08:04 - INFO - total_loss: 0.4293522536754608, masked_loc_loss: 0.04093656688928604, masked_gen_loss: 0.38841569423675537 - (2851716:unified_unilip.py:926)
2026-01-07 19:08:19 - INFO - total_loss: 0.39834433794021606, masked_loc_loss: 0.06231468543410301, masked_gen_loss: 0.33602964878082275 - (2851716:unified_unilip.py:926)
2026-01-07 19:08:33 - INFO - total_loss: 0.4188057780265808, masked_loc_loss: 0.056633543223142624, masked_gen_loss: 0.3621722459793091 - (2851716:unified_unilip.py:926)
2026-01-07 19:08:40 - INFO - total_loss: 0.33476555347442627, masked_loc_loss: 0.05272609740495682, masked_gen_loss: 0.28203946352005005 - (2851716:unified_unilip.py:926)
2026-01-07 19:08:54 - INFO - total_loss: 0.4128795266151428, masked_loc_loss: 0.05768148601055145, masked_gen_loss: 0.35519805550575256 - (2851716:unified_unilip.py:926)
2026-01-07 19:09:08 - INFO - total_loss: 0.43912163376808167, masked_loc_loss: 0.041259147226810455, masked_gen_loss: 0.3978624939918518 - (2851716:unified_unilip.py:926)
2026-01-07 19:09:23 - INFO - total_loss: 0.365848183631897, masked_loc_loss: 0.05928780883550644, masked_gen_loss: 0.30656036734580994 - (2851716:unified_unilip.py:926)
2026-01-07 19:09:38 - INFO - total_loss: 0.4445340633392334, masked_loc_loss: 0.04484260454773903, masked_gen_loss: 0.39969146251678467 - (2851716:unified_unilip.py:926)
2026-01-07 19:09:51 - INFO - total_loss: 0.35342732071876526, masked_loc_loss: 0.038808681070804596, masked_gen_loss: 0.31461864709854126 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:02 - INFO - total_loss: 0.37117835879325867, masked_loc_loss: 0.04896954447031021, masked_gen_loss: 0.32220882177352905 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:17 - INFO - total_loss: 0.39366787672042847, masked_loc_loss: 0.049966391175985336, masked_gen_loss: 0.34370148181915283 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:27 - INFO - total_loss: 0.41334012150764465, masked_loc_loss: 0.04384150356054306, masked_gen_loss: 0.369498610496521 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:33 - INFO - total_loss: 0.3714660704135895, masked_loc_loss: 0.09484973549842834, masked_gen_loss: 0.27661633491516113 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:40 - INFO - total_loss: 0.4135923683643341, masked_loc_loss: 0.04364165663719177, masked_gen_loss: 0.36995071172714233 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:47 - INFO - total_loss: 0.4013231694698334, masked_loc_loss: 0.06418773531913757, masked_gen_loss: 0.3371354341506958 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:53 - INFO - total_loss: 0.40266337990760803, masked_loc_loss: 0.05530723184347153, masked_gen_loss: 0.3473561406135559 - (2851716:unified_unilip.py:926)
2026-01-07 19:10:59 - INFO - total_loss: 0.4103367030620575, masked_loc_loss: 0.07365646958351135, masked_gen_loss: 0.33668023347854614 - (2851716:unified_unilip.py:926)
2026-01-07 19:11:06 - INFO - total_loss: 0.3992089629173279, masked_loc_loss: 0.06066804379224777, masked_gen_loss: 0.3385409116744995 - (2851716:unified_unilip.py:926)
2026-01-07 19:11:12 - INFO - total_loss: 0.3829471468925476, masked_loc_loss: 0.05080176144838333, masked_gen_loss: 0.3321453928947449 - (2851716:unified_unilip.py:926)
2026-01-07 19:11:19 - INFO - total_loss: 0.3759308457374573, masked_loc_loss: 0.06869013607501984, masked_gen_loss: 0.30724069476127625 - (2851716:unified_unilip.py:926)
2026-01-07 19:11:25 - INFO - total_loss: 0.40838202834129333, masked_loc_loss: 0.03655126690864563, masked_gen_loss: 0.3718307614326477 - (2851716:unified_unilip.py:926)
2026-01-07 19:11:32 - INFO - total_loss: 0.40357378125190735, masked_loc_loss: 0.04511613771319389, masked_gen_loss: 0.35845765471458435 - (2851716:unified_unilip.py:926)
2026-01-07 19:11:45 - INFO - total_loss: 0.4272836148738861, masked_loc_loss: 0.11105915904045105, masked_gen_loss: 0.31622445583343506 - (2851716:unified_unilip.py:926)
2026-01-07 19:12:00 - INFO - total_loss: 0.4589957594871521, masked_loc_loss: 0.045545466244220734, masked_gen_loss: 0.41345030069351196 - (2851716:unified_unilip.py:926)
2026-01-07 19:12:14 - INFO - total_loss: 0.37819382548332214, masked_loc_loss: 0.05716891959309578, masked_gen_loss: 0.32102489471435547 - (2851716:unified_unilip.py:926)
2026-01-07 19:12:29 - INFO - total_loss: 0.43979084491729736, masked_loc_loss: 0.053722549229860306, masked_gen_loss: 0.38606828451156616 - (2851716:unified_unilip.py:926)
2026-01-07 19:12:35 - INFO - total_loss: 0.3666316270828247, masked_loc_loss: 0.046956777572631836, masked_gen_loss: 0.31967484951019287 - (2851716:unified_unilip.py:926)
2026-01-07 19:12:42 - INFO - total_loss: 0.3688175678253174, masked_loc_loss: 0.03469735011458397, masked_gen_loss: 0.3341202139854431 - (2851716:unified_unilip.py:926)
2026-01-07 19:12:56 - INFO - total_loss: 0.39741450548171997, masked_loc_loss: 0.08184653520584106, masked_gen_loss: 0.3155679702758789 - (2851716:unified_unilip.py:926)
2026-01-07 19:13:10 - INFO - total_loss: 0.4599005877971649, masked_loc_loss: 0.07915705442428589, masked_gen_loss: 0.38074353337287903 - (2851716:unified_unilip.py:926)
2026-01-07 19:13:25 - INFO - total_loss: 0.42360758781433105, masked_loc_loss: 0.06263171136379242, masked_gen_loss: 0.36097586154937744 - (2851716:unified_unilip.py:926)
2026-01-07 19:13:39 - INFO - total_loss: 0.4272918403148651, masked_loc_loss: 0.07052750140428543, masked_gen_loss: 0.3567643463611603 - (2851716:unified_unilip.py:926)
2026-01-07 19:13:45 - INFO - total_loss: 0.42502328753471375, masked_loc_loss: 0.05350515991449356, masked_gen_loss: 0.3715181350708008 - (2851716:unified_unilip.py:926)
2026-01-07 19:13:57 - INFO - total_loss: 0.3725574016571045, masked_loc_loss: 0.06571018695831299, masked_gen_loss: 0.3068472146987915 - (2851716:unified_unilip.py:926)
2026-01-07 19:14:11 - INFO - total_loss: 0.39054057002067566, masked_loc_loss: 0.05800405144691467, masked_gen_loss: 0.332536518573761 - (2851716:unified_unilip.py:926)
2026-01-07 19:14:26 - INFO - total_loss: 0.4722231328487396, masked_loc_loss: 0.07601352781057358, masked_gen_loss: 0.39620959758758545 - (2851716:unified_unilip.py:926)
2026-01-07 19:14:40 - INFO - total_loss: 0.42567744851112366, masked_loc_loss: 0.025839297100901604, masked_gen_loss: 0.3998381495475769 - (2851716:unified_unilip.py:926)
2026-01-07 19:14:49 - INFO - total_loss: 0.3843318223953247, masked_loc_loss: 0.05982358753681183, masked_gen_loss: 0.3245082497596741 - (2851716:unified_unilip.py:926)
2026-01-07 19:15:00 - INFO - total_loss: 0.4008580148220062, masked_loc_loss: 0.0350993312895298, masked_gen_loss: 0.3657586872577667 - (2851716:unified_unilip.py:926)
2026-01-07 19:15:15 - INFO - total_loss: 0.4580782949924469, masked_loc_loss: 0.043950460851192474, masked_gen_loss: 0.41412782669067383 - (2851716:unified_unilip.py:926)
2026-01-07 19:15:29 - INFO - total_loss: 0.3330874443054199, masked_loc_loss: 0.05547504127025604, masked_gen_loss: 0.2776124179363251 - (2851716:unified_unilip.py:926)
2026-01-07 19:15:44 - INFO - total_loss: 0.4520306885242462, masked_loc_loss: 0.08074602484703064, masked_gen_loss: 0.3712846636772156 - (2851716:unified_unilip.py:926)
2026-01-07 19:15:53 - INFO - total_loss: 0.4336273670196533, masked_loc_loss: 0.047286923974752426, masked_gen_loss: 0.3863404393196106 - (2851716:unified_unilip.py:926)
2026-01-07 19:16:04 - INFO - total_loss: 0.39561182260513306, masked_loc_loss: 0.05654829367995262, masked_gen_loss: 0.33906352519989014 - (2851716:unified_unilip.py:926)
2026-01-07 19:16:18 - INFO - total_loss: 0.43189337849617004, masked_loc_loss: 0.043591827154159546, masked_gen_loss: 0.3883015513420105 - (2851716:unified_unilip.py:926)
2026-01-07 19:16:33 - INFO - total_loss: 0.45255351066589355, masked_loc_loss: 0.036909542977809906, masked_gen_loss: 0.41564396023750305 - (2851716:unified_unilip.py:926)
2026-01-07 19:16:47 - INFO - total_loss: 0.4785882234573364, masked_loc_loss: 0.04717779904603958, masked_gen_loss: 0.43141043186187744 - (2851716:unified_unilip.py:926)
2026-01-07 19:16:58 - INFO - total_loss: 0.3299899697303772, masked_loc_loss: 0.07075570523738861, masked_gen_loss: 0.2592342495918274 - (2851716:unified_unilip.py:926)
2026-01-07 19:17:06 - INFO - total_loss: 0.38632315397262573, masked_loc_loss: 0.06612764298915863, masked_gen_loss: 0.3201954960823059 - (2851716:unified_unilip.py:926)
2026-01-07 19:17:19 - INFO - total_loss: 0.39569973945617676, masked_loc_loss: 0.04266589879989624, masked_gen_loss: 0.3530338406562805 - (2851716:unified_unilip.py:926)
2026-01-07 19:17:33 - INFO - total_loss: 0.40586531162261963, masked_loc_loss: 0.07080138474702835, masked_gen_loss: 0.3350639343261719 - (2851716:unified_unilip.py:926)
2026-01-07 19:17:48 - INFO - total_loss: 0.45504671335220337, masked_loc_loss: 0.055172547698020935, masked_gen_loss: 0.39987418055534363 - (2851716:unified_unilip.py:926)
2026-01-07 19:18:01 - INFO - total_loss: 0.39513060450553894, masked_loc_loss: 0.03013022057712078, masked_gen_loss: 0.3650003969669342 - (2851716:unified_unilip.py:926)
2026-01-07 19:18:08 - INFO - total_loss: 0.41044631600379944, masked_loc_loss: 0.05273212119936943, masked_gen_loss: 0.3577142059803009 - (2851716:unified_unilip.py:926)
2026-01-07 19:18:15 - INFO - total_loss: 0.40304481983184814, masked_loc_loss: 0.07324616611003876, masked_gen_loss: 0.3297986686229706 - (2851716:unified_unilip.py:926)
2026-01-07 19:18:29 - INFO - total_loss: 0.381998747587204, masked_loc_loss: 0.05115664750337601, masked_gen_loss: 0.33084210753440857 - (2851716:unified_unilip.py:926)
2026-01-07 19:18:43 - INFO - total_loss: 0.3911401033401489, masked_loc_loss: 0.08063170313835144, masked_gen_loss: 0.3105084002017975 - (2851716:unified_unilip.py:926)
2026-01-07 19:18:57 - INFO - total_loss: 0.39692220091819763, masked_loc_loss: 0.050611041486263275, masked_gen_loss: 0.34631115198135376 - (2851716:unified_unilip.py:926)
2026-01-07 19:19:11 - INFO - total_loss: 0.34620964527130127, masked_loc_loss: 0.03619300574064255, masked_gen_loss: 0.3100166320800781 - (2851716:unified_unilip.py:926)
2026-01-07 19:19:18 - INFO - total_loss: 0.4005841612815857, masked_loc_loss: 0.09016843140125275, masked_gen_loss: 0.31041571497917175 - (2851716:unified_unilip.py:926)
2026-01-07 19:19:29 - INFO - total_loss: 0.4249877333641052, masked_loc_loss: 0.07234491407871246, masked_gen_loss: 0.35264283418655396 - (2851716:unified_unilip.py:926)
2026-01-07 19:19:44 - INFO - total_loss: 0.4055747985839844, masked_loc_loss: 0.052355632185935974, masked_gen_loss: 0.3532191812992096 - (2851716:unified_unilip.py:926)
2026-01-07 19:19:58 - INFO - total_loss: 0.4140126705169678, masked_loc_loss: 0.029477525502443314, masked_gen_loss: 0.38453513383865356 - (2851716:unified_unilip.py:926)
2026-01-07 19:20:12 - INFO - total_loss: 0.43794333934783936, masked_loc_loss: 0.07894068956375122, masked_gen_loss: 0.35900264978408813 - (2851716:unified_unilip.py:926)
2026-01-07 19:20:21 - INFO - total_loss: 0.3754465579986572, masked_loc_loss: 0.08019585907459259, masked_gen_loss: 0.29525071382522583 - (2851716:unified_unilip.py:926)
2026-01-07 19:20:35 - INFO - total_loss: 0.4695921242237091, masked_loc_loss: 0.04132520407438278, masked_gen_loss: 0.4282669126987457 - (2851716:unified_unilip.py:926)
2026-01-07 19:20:50 - INFO - total_loss: 0.4253518283367157, masked_loc_loss: 0.045841775834560394, masked_gen_loss: 0.3795100450515747 - (2851716:unified_unilip.py:926)
2026-01-07 19:21:04 - INFO - total_loss: 0.369279682636261, masked_loc_loss: 0.0894707664847374, masked_gen_loss: 0.279808908700943 - (2851716:unified_unilip.py:926)
2026-01-07 19:21:19 - INFO - total_loss: 0.33013206720352173, masked_loc_loss: 0.04008357971906662, masked_gen_loss: 0.2900484800338745 - (2851716:unified_unilip.py:926)
2026-01-07 19:21:28 - INFO - total_loss: 0.41560423374176025, masked_loc_loss: 0.046385154128074646, masked_gen_loss: 0.3692190647125244 - (2851716:unified_unilip.py:926)
2026-01-07 19:21:42 - INFO - total_loss: 0.35237419605255127, masked_loc_loss: 0.06538087874650955, masked_gen_loss: 0.2869933247566223 - (2851716:unified_unilip.py:926)
2026-01-07 19:21:57 - INFO - total_loss: 0.40417760610580444, masked_loc_loss: 0.06367413699626923, masked_gen_loss: 0.340503454208374 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:09 - INFO - total_loss: 0.40686631202697754, masked_loc_loss: 0.07452819496393204, masked_gen_loss: 0.3323381245136261 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:15 - INFO - total_loss: 0.36963939666748047, masked_loc_loss: 0.0406513512134552, masked_gen_loss: 0.32898804545402527 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:22 - INFO - total_loss: 0.40381377935409546, masked_loc_loss: 0.061155036091804504, masked_gen_loss: 0.34265875816345215 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:29 - INFO - total_loss: 0.41432294249534607, masked_loc_loss: 0.062133874744176865, masked_gen_loss: 0.3521890640258789 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:35 - INFO - total_loss: 0.36744022369384766, masked_loc_loss: 0.05756838619709015, masked_gen_loss: 0.3098718225955963 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:42 - INFO - total_loss: 0.42257964611053467, masked_loc_loss: 0.055666618049144745, masked_gen_loss: 0.3669130206108093 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:48 - INFO - total_loss: 0.45398032665252686, masked_loc_loss: 0.05218005180358887, masked_gen_loss: 0.401800274848938 - (2851716:unified_unilip.py:926)
2026-01-07 19:22:55 - INFO - total_loss: 0.4155317544937134, masked_loc_loss: 0.05095855891704559, masked_gen_loss: 0.364573210477829 - (2851716:unified_unilip.py:926)
2026-01-07 19:23:01 - INFO - total_loss: 0.43586671352386475, masked_loc_loss: 0.05513833463191986, masked_gen_loss: 0.3807283937931061 - (2851716:unified_unilip.py:926)
2026-01-07 19:23:08 - INFO - total_loss: 0.4030064344406128, masked_loc_loss: 0.07434000074863434, masked_gen_loss: 0.32866644859313965 - (2851716:unified_unilip.py:926)
2026-01-07 19:23:14 - INFO - total_loss: 0.43936917185783386, masked_loc_loss: 0.05909060686826706, masked_gen_loss: 0.3802785575389862 - (2851716:unified_unilip.py:926)
2026-01-07 19:23:23 - INFO - total_loss: 0.3715255856513977, masked_loc_loss: 0.03254356607794762, masked_gen_loss: 0.3389820158481598 - (2851716:unified_unilip.py:926)
2026-01-07 19:23:37 - INFO - total_loss: 0.4056816101074219, masked_loc_loss: 0.0651981458067894, masked_gen_loss: 0.3404834568500519 - (2851716:unified_unilip.py:926)
2026-01-07 19:23:52 - INFO - total_loss: 0.43891531229019165, masked_loc_loss: 0.05708484351634979, masked_gen_loss: 0.38183045387268066 - (2851716:unified_unilip.py:926)
2026-01-07 19:24:06 - INFO - total_loss: 0.3625448942184448, masked_loc_loss: 0.04149831458926201, masked_gen_loss: 0.3210465908050537 - (2851716:unified_unilip.py:926)
2026-01-07 19:24:18 - INFO - total_loss: 0.4121294915676117, masked_loc_loss: 0.06437685340642929, masked_gen_loss: 0.3477526307106018 - (2851716:unified_unilip.py:926)
2026-01-07 19:24:25 - INFO - total_loss: 0.4333760738372803, masked_loc_loss: 0.0458676815032959, masked_gen_loss: 0.3875083923339844 - (2851716:unified_unilip.py:926)
2026-01-07 19:24:34 - INFO - total_loss: 0.34762781858444214, masked_loc_loss: 0.06838469207286835, masked_gen_loss: 0.279243141412735 - (2851716:unified_unilip.py:926)
2026-01-07 19:24:48 - INFO - total_loss: 0.35440656542778015, masked_loc_loss: 0.026943493634462357, masked_gen_loss: 0.3274630606174469 - (2851716:unified_unilip.py:926)
2026-01-07 19:25:02 - INFO - total_loss: 0.4261729121208191, masked_loc_loss: 0.03414557874202728, masked_gen_loss: 0.3920273184776306 - (2851716:unified_unilip.py:926)
2026-01-07 19:25:16 - INFO - total_loss: 0.3755459487438202, masked_loc_loss: 0.03843769058585167, masked_gen_loss: 0.3371082544326782 - (2851716:unified_unilip.py:926)
2026-01-07 19:25:28 - INFO - total_loss: 0.41852399706840515, masked_loc_loss: 0.04821474477648735, masked_gen_loss: 0.3703092634677887 - (2851716:unified_unilip.py:926)
2026-01-07 19:25:35 - INFO - total_loss: 0.3968328833580017, masked_loc_loss: 0.04631264507770538, masked_gen_loss: 0.3505202531814575 - (2851716:unified_unilip.py:926)
2026-01-07 19:25:46 - INFO - total_loss: 0.39998647570610046, masked_loc_loss: 0.05547024682164192, masked_gen_loss: 0.34451621770858765 - (2851716:unified_unilip.py:926)
2026-01-07 19:26:01 - INFO - total_loss: 0.36612680554389954, masked_loc_loss: 0.055587053298950195, masked_gen_loss: 0.31053975224494934 - (2851716:unified_unilip.py:926)
2026-01-07 19:26:15 - INFO - total_loss: 0.35628247261047363, masked_loc_loss: 0.0633622407913208, masked_gen_loss: 0.29292023181915283 - (2851716:unified_unilip.py:926)
2026-01-07 19:26:30 - INFO - total_loss: 0.41955941915512085, masked_loc_loss: 0.0408848337829113, masked_gen_loss: 0.37867459654808044 - (2851716:unified_unilip.py:926)
2026-01-07 19:26:38 - INFO - total_loss: 0.40602415800094604, masked_loc_loss: 0.045155517756938934, masked_gen_loss: 0.3608686327934265 - (2851716:unified_unilip.py:926)
2026-01-07 19:26:46 - INFO - total_loss: 0.387154757976532, masked_loc_loss: 0.06145583093166351, masked_gen_loss: 0.32569894194602966 - (2851716:unified_unilip.py:926)
2026-01-07 19:27:00 - INFO - total_loss: 0.4665030539035797, masked_loc_loss: 0.04700508713722229, masked_gen_loss: 0.4194979667663574 - (2851716:unified_unilip.py:926)
2026-01-07 19:27:14 - INFO - total_loss: 0.37457185983657837, masked_loc_loss: 0.029780108481645584, masked_gen_loss: 0.3447917401790619 - (2851716:unified_unilip.py:926)
2026-01-07 19:27:28 - INFO - total_loss: 0.3976947069168091, masked_loc_loss: 0.06723512709140778, masked_gen_loss: 0.3304595947265625 - (2851716:unified_unilip.py:926)
2026-01-07 19:27:42 - INFO - total_loss: 0.34378930926322937, masked_loc_loss: 0.05411102622747421, masked_gen_loss: 0.28967827558517456 - (2851716:unified_unilip.py:926)
2026-01-07 19:27:49 - INFO - total_loss: 0.38222333788871765, masked_loc_loss: 0.035218238830566406, masked_gen_loss: 0.34700509905815125 - (2851716:unified_unilip.py:926)
2026-01-07 19:28:04 - INFO - total_loss: 0.41851216554641724, masked_loc_loss: 0.03897905722260475, masked_gen_loss: 0.3795331120491028 - (2851716:unified_unilip.py:926)
2026-01-07 19:28:18 - INFO - total_loss: 0.4350300431251526, masked_loc_loss: 0.04800420626997948, masked_gen_loss: 0.3870258331298828 - (2851716:unified_unilip.py:926)
2026-01-07 19:28:33 - INFO - total_loss: 0.38845086097717285, masked_loc_loss: 0.026692815124988556, masked_gen_loss: 0.3617580533027649 - (2851716:unified_unilip.py:926)
2026-01-07 19:28:47 - INFO - total_loss: 0.4002004563808441, masked_loc_loss: 0.049399904906749725, masked_gen_loss: 0.3508005440235138 - (2851716:unified_unilip.py:926)
2026-01-07 19:28:53 - INFO - total_loss: 0.32913607358932495, masked_loc_loss: 0.057054586708545685, masked_gen_loss: 0.27208149433135986 - (2851716:unified_unilip.py:926)
2026-01-07 19:29:08 - INFO - total_loss: 0.4429093301296234, masked_loc_loss: 0.04246419295668602, masked_gen_loss: 0.4004451334476471 - (2851716:unified_unilip.py:926)
2026-01-07 19:29:22 - INFO - total_loss: 0.3575380742549896, masked_loc_loss: 0.03522741049528122, masked_gen_loss: 0.3223106563091278 - (2851716:unified_unilip.py:926)
2026-01-07 19:29:37 - INFO - total_loss: 0.37450915575027466, masked_loc_loss: 0.04886176437139511, masked_gen_loss: 0.32564738392829895 - (2851716:unified_unilip.py:926)
2026-01-07 19:29:51 - INFO - total_loss: 0.4340003728866577, masked_loc_loss: 0.06589385867118835, masked_gen_loss: 0.36810651421546936 - (2851716:unified_unilip.py:926)
2026-01-07 19:29:57 - INFO - total_loss: 0.37180325388908386, masked_loc_loss: 0.05036655813455582, masked_gen_loss: 0.32143670320510864 - (2851716:unified_unilip.py:926)
2026-01-07 19:30:11 - INFO - total_loss: 0.4115181267261505, masked_loc_loss: 0.04849463328719139, masked_gen_loss: 0.3630234897136688 - (2851716:unified_unilip.py:926)
2026-01-07 19:30:25 - INFO - total_loss: 0.38416019082069397, masked_loc_loss: 0.05677399784326553, masked_gen_loss: 0.32738620042800903 - (2851716:unified_unilip.py:926)
2026-01-07 19:30:40 - INFO - total_loss: 0.3766820430755615, masked_loc_loss: 0.03218960762023926, masked_gen_loss: 0.34449243545532227 - (2851716:unified_unilip.py:926)
2026-01-07 19:30:54 - INFO - total_loss: 0.3467233180999756, masked_loc_loss: 0.05361025407910347, masked_gen_loss: 0.2931130528450012 - (2851716:unified_unilip.py:926)
2026-01-07 19:31:01 - INFO - total_loss: 0.35736796259880066, masked_loc_loss: 0.03364040330052376, masked_gen_loss: 0.323727548122406 - (2851716:unified_unilip.py:926)
2026-01-07 19:31:07 - INFO - total_loss: 0.362618088722229, masked_loc_loss: 0.04768664762377739, masked_gen_loss: 0.3149314522743225 - (2851716:unified_unilip.py:926)
2026-01-07 19:31:21 - INFO - total_loss: 0.4434807300567627, masked_loc_loss: 0.046499110758304596, masked_gen_loss: 0.3969816267490387 - (2851716:unified_unilip.py:926)
2026-01-07 19:31:35 - INFO - total_loss: 0.38168060779571533, masked_loc_loss: 0.06194618344306946, masked_gen_loss: 0.3197344243526459 - (2851716:unified_unilip.py:926)
2026-01-07 19:31:49 - INFO - total_loss: 0.3939449191093445, masked_loc_loss: 0.06743915379047394, masked_gen_loss: 0.32650578022003174 - (2851716:unified_unilip.py:926)
2026-01-07 19:32:04 - INFO - total_loss: 0.3378993272781372, masked_loc_loss: 0.03777409344911575, masked_gen_loss: 0.30012524127960205 - (2851716:unified_unilip.py:926)
2026-01-07 19:32:11 - INFO - total_loss: 0.32003846764564514, masked_loc_loss: 0.04650130122900009, masked_gen_loss: 0.27353715896606445 - (2851716:unified_unilip.py:926)
2026-01-07 19:32:22 - INFO - total_loss: 0.4175783395767212, masked_loc_loss: 0.06372790038585663, masked_gen_loss: 0.35385045409202576 - (2851716:unified_unilip.py:926)
2026-01-07 19:32:37 - INFO - total_loss: 0.44173604249954224, masked_loc_loss: 0.040928758680820465, masked_gen_loss: 0.40080729126930237 - (2851716:unified_unilip.py:926)
2026-01-07 19:32:51 - INFO - total_loss: 0.3694128394126892, masked_loc_loss: 0.028501637279987335, masked_gen_loss: 0.34091120958328247 - (2851716:unified_unilip.py:926)
2026-01-07 19:33:05 - INFO - total_loss: 0.4204825460910797, masked_loc_loss: 0.06280887871980667, masked_gen_loss: 0.35767367482185364 - (2851716:unified_unilip.py:926)
2026-01-07 19:33:17 - INFO - total_loss: 0.4189833998680115, masked_loc_loss: 0.02136969193816185, masked_gen_loss: 0.3976137042045593 - (2851716:unified_unilip.py:926)
2026-01-07 19:33:31 - INFO - total_loss: 0.3363509774208069, masked_loc_loss: 0.05290956795215607, masked_gen_loss: 0.283441424369812 - (2851716:unified_unilip.py:926)
2026-01-07 19:33:46 - INFO - total_loss: 0.4842471480369568, masked_loc_loss: 0.08015453070402145, masked_gen_loss: 0.40409260988235474 - (2851716:unified_unilip.py:926)
2026-01-07 19:33:57 - INFO - total_loss: 0.3822145462036133, masked_loc_loss: 0.05910779908299446, masked_gen_loss: 0.3231067359447479 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:04 - INFO - total_loss: 0.3829747438430786, masked_loc_loss: 0.060157742351293564, masked_gen_loss: 0.32281699776649475 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:10 - INFO - total_loss: 0.3708842694759369, masked_loc_loss: 0.03819606453180313, masked_gen_loss: 0.33268821239471436 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:17 - INFO - total_loss: 0.40546679496765137, masked_loc_loss: 0.07767520844936371, masked_gen_loss: 0.32779157161712646 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:23 - INFO - total_loss: 0.3983685076236725, masked_loc_loss: 0.040916185826063156, masked_gen_loss: 0.3574523329734802 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:30 - INFO - total_loss: 0.4306643009185791, masked_loc_loss: 0.05518551170825958, masked_gen_loss: 0.3754788041114807 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:37 - INFO - total_loss: 0.3932083547115326, masked_loc_loss: 0.046625588089227676, masked_gen_loss: 0.3465827703475952 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:43 - INFO - total_loss: 0.4519869387149811, masked_loc_loss: 0.06150083616375923, masked_gen_loss: 0.39048609137535095 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:50 - INFO - total_loss: 0.40328502655029297, masked_loc_loss: 0.04568313807249069, masked_gen_loss: 0.3576018810272217 - (2851716:unified_unilip.py:926)
2026-01-07 19:34:57 - INFO - total_loss: 0.36800605058670044, masked_loc_loss: 0.06299617886543274, masked_gen_loss: 0.3050098717212677 - (2851716:unified_unilip.py:926)
2026-01-07 19:35:03 - INFO - total_loss: 0.3744848370552063, masked_loc_loss: 0.06345068663358688, masked_gen_loss: 0.3110341429710388 - (2851716:unified_unilip.py:926)
2026-01-07 19:35:16 - INFO - total_loss: 0.4096272587776184, masked_loc_loss: 0.05350453406572342, masked_gen_loss: 0.3561227321624756 - (2851716:unified_unilip.py:926)
2026-01-07 19:35:31 - INFO - total_loss: 0.3767685890197754, masked_loc_loss: 0.040789857506752014, masked_gen_loss: 0.3359787166118622 - (2851716:unified_unilip.py:926)
2026-01-07 19:35:46 - INFO - total_loss: 0.4134504795074463, masked_loc_loss: 0.07544606924057007, masked_gen_loss: 0.3380044102668762 - (2851716:unified_unilip.py:926)
2026-01-07 19:36:00 - INFO - total_loss: 0.43188732862472534, masked_loc_loss: 0.04549973085522652, masked_gen_loss: 0.38638758659362793 - (2851716:unified_unilip.py:926)
2026-01-07 19:36:09 - INFO - total_loss: 0.3650326728820801, masked_loc_loss: 0.03420070558786392, masked_gen_loss: 0.33083197474479675 - (2851716:unified_unilip.py:926)
2026-01-07 19:36:18 - INFO - total_loss: 0.4180890917778015, masked_loc_loss: 0.06371206790208817, masked_gen_loss: 0.35437703132629395 - (2851716:unified_unilip.py:926)
2026-01-07 19:36:33 - INFO - total_loss: 0.3585812747478485, masked_loc_loss: 0.05779870226979256, masked_gen_loss: 0.30078256130218506 - (2851716:unified_unilip.py:926)
2026-01-07 19:36:48 - INFO - total_loss: 0.43805569410324097, masked_loc_loss: 0.0501595176756382, masked_gen_loss: 0.38789618015289307 - (2851716:unified_unilip.py:926)
2026-01-07 19:37:02 - INFO - total_loss: 0.393290638923645, masked_loc_loss: 0.05444594845175743, masked_gen_loss: 0.3388446867465973 - (2851716:unified_unilip.py:926)
2026-01-07 19:37:14 - INFO - total_loss: 0.4775075912475586, masked_loc_loss: 0.0661102682352066, masked_gen_loss: 0.4113973379135132 - (2851716:unified_unilip.py:926)
2026-01-07 19:37:20 - INFO - total_loss: 0.3750302493572235, masked_loc_loss: 0.05625643953680992, masked_gen_loss: 0.3187738060951233 - (2851716:unified_unilip.py:926)
2026-01-07 19:37:30 - INFO - total_loss: 0.4448242783546448, masked_loc_loss: 0.07360386848449707, masked_gen_loss: 0.3712204098701477 - (2851716:unified_unilip.py:926)
2026-01-07 19:37:45 - INFO - total_loss: 0.40438514947891235, masked_loc_loss: 0.06580854952335358, masked_gen_loss: 0.33857661485671997 - (2851716:unified_unilip.py:926)
2026-01-07 19:37:59 - INFO - total_loss: 0.3656150698661804, masked_loc_loss: 0.06829779595136642, masked_gen_loss: 0.2973172664642334 - (2851716:unified_unilip.py:926)
2026-01-07 19:38:14 - INFO - total_loss: 0.43523257970809937, masked_loc_loss: 0.09933178126811981, masked_gen_loss: 0.33590081334114075 - (2851716:unified_unilip.py:926)
2026-01-07 19:38:24 - INFO - total_loss: 0.44251561164855957, masked_loc_loss: 0.05950319766998291, masked_gen_loss: 0.38301241397857666 - (2851716:unified_unilip.py:926)
2026-01-07 19:38:31 - INFO - total_loss: 0.4057091176509857, masked_loc_loss: 0.07704294472932816, masked_gen_loss: 0.32866618037223816 - (2851716:unified_unilip.py:926)
2026-01-07 19:38:41 - INFO - total_loss: 0.36722853779792786, masked_loc_loss: 0.0424383282661438, masked_gen_loss: 0.32479020953178406 - (2851716:unified_unilip.py:926)
2026-01-07 19:38:56 - INFO - total_loss: 0.40502166748046875, masked_loc_loss: 0.037871651351451874, masked_gen_loss: 0.3671500086784363 - (2851716:unified_unilip.py:926)
2026-01-07 19:39:10 - INFO - total_loss: 0.38190704584121704, masked_loc_loss: 0.03832442685961723, masked_gen_loss: 0.3435826301574707 - (2851716:unified_unilip.py:926)
2026-01-07 19:39:24 - INFO - total_loss: 0.4091799259185791, masked_loc_loss: 0.0419054813683033, masked_gen_loss: 0.3672744333744049 - (2851716:unified_unilip.py:926)
2026-01-07 19:39:35 - INFO - total_loss: 0.39239194989204407, masked_loc_loss: 0.03936249017715454, masked_gen_loss: 0.3530294597148895 - (2851716:unified_unilip.py:926)
2026-01-07 19:39:41 - INFO - total_loss: 0.3474917411804199, masked_loc_loss: 0.05241567641496658, masked_gen_loss: 0.29507607221603394 - (2851716:unified_unilip.py:926)
2026-01-07 19:39:55 - INFO - total_loss: 0.423345148563385, masked_loc_loss: 0.03807932883501053, masked_gen_loss: 0.3852658271789551 - (2851716:unified_unilip.py:926)
2026-01-07 19:40:09 - INFO - total_loss: 0.40369701385498047, masked_loc_loss: 0.05709725618362427, masked_gen_loss: 0.3465997576713562 - (2851716:unified_unilip.py:926)
2026-01-07 19:40:24 - INFO - total_loss: 0.39515432715415955, masked_loc_loss: 0.048819802701473236, masked_gen_loss: 0.3463345170021057 - (2851716:unified_unilip.py:926)
2026-01-07 19:40:38 - INFO - total_loss: 0.48464077711105347, masked_loc_loss: 0.044886305928230286, masked_gen_loss: 0.4397544860839844 - (2851716:unified_unilip.py:926)
2026-01-07 19:40:46 - INFO - total_loss: 0.38941287994384766, masked_loc_loss: 0.03248722106218338, masked_gen_loss: 0.3569256663322449 - (2851716:unified_unilip.py:926)
2026-01-07 19:40:52 - INFO - total_loss: 0.3859776556491852, masked_loc_loss: 0.0507412850856781, masked_gen_loss: 0.3352363705635071 - (2851716:unified_unilip.py:926)
2026-01-07 19:41:06 - INFO - total_loss: 0.40360602736473083, masked_loc_loss: 0.06718280911445618, masked_gen_loss: 0.33642321825027466 - (2851716:unified_unilip.py:926)
2026-01-07 19:41:21 - INFO - total_loss: 0.4226890802383423, masked_loc_loss: 0.05756594240665436, masked_gen_loss: 0.3651231527328491 - (2851716:unified_unilip.py:926)
2026-01-07 19:41:35 - INFO - total_loss: 0.3634735941886902, masked_loc_loss: 0.07848294079303741, masked_gen_loss: 0.28499066829681396 - (2851716:unified_unilip.py:926)
2026-01-07 19:41:50 - INFO - total_loss: 0.40875595808029175, masked_loc_loss: 0.05684804543852806, masked_gen_loss: 0.3519079089164734 - (2851716:unified_unilip.py:926)
2026-01-07 19:41:57 - INFO - total_loss: 0.41482046246528625, masked_loc_loss: 0.05382160469889641, masked_gen_loss: 0.36099886894226074 - (2851716:unified_unilip.py:926)
2026-01-07 19:42:06 - INFO - total_loss: 0.4238932132720947, masked_loc_loss: 0.061227742582559586, masked_gen_loss: 0.36266547441482544 - (2851716:unified_unilip.py:926)
2026-01-07 19:42:20 - INFO - total_loss: 0.44228988885879517, masked_loc_loss: 0.05695044994354248, masked_gen_loss: 0.3853394389152527 - (2851716:unified_unilip.py:926)
2026-01-07 19:42:35 - INFO - total_loss: 0.36267805099487305, masked_loc_loss: 0.03387313708662987, masked_gen_loss: 0.3288049101829529 - (2851716:unified_unilip.py:926)
2026-01-07 19:42:49 - INFO - total_loss: 0.37075239419937134, masked_loc_loss: 0.043166741728782654, masked_gen_loss: 0.3275856375694275 - (2851716:unified_unilip.py:926)
2026-01-07 19:43:01 - INFO - total_loss: 0.3786289095878601, masked_loc_loss: 0.06520622223615646, masked_gen_loss: 0.31342267990112305 - (2851716:unified_unilip.py:926)
2026-01-07 19:43:11 - INFO - total_loss: 0.3882308900356293, masked_loc_loss: 0.06271007657051086, masked_gen_loss: 0.3255208134651184 - (2851716:unified_unilip.py:926)
2026-01-07 19:43:25 - INFO - total_loss: 0.3690943121910095, masked_loc_loss: 0.03638416528701782, masked_gen_loss: 0.3327101469039917 - (2851716:unified_unilip.py:926)
2026-01-07 19:43:40 - INFO - total_loss: 0.3716687560081482, masked_loc_loss: 0.046556755900382996, masked_gen_loss: 0.325111985206604 - (2851716:unified_unilip.py:926)
2026-01-07 19:43:54 - INFO - total_loss: 0.4385654032230377, masked_loc_loss: 0.054710179567337036, masked_gen_loss: 0.3838552236557007 - (2851716:unified_unilip.py:926)
2026-01-07 19:44:05 - INFO - total_loss: 0.3157352805137634, masked_loc_loss: 0.038899488747119904, masked_gen_loss: 0.2768357992172241 - (2851716:unified_unilip.py:926)
2026-01-07 19:44:12 - INFO - total_loss: 0.37667298316955566, masked_loc_loss: 0.05967792123556137, masked_gen_loss: 0.3169950544834137 - (2851716:unified_unilip.py:926)
2026-01-07 19:44:25 - INFO - total_loss: 0.4372822940349579, masked_loc_loss: 0.05504491925239563, masked_gen_loss: 0.38223737478256226 - (2851716:unified_unilip.py:926)
2026-01-07 19:44:40 - INFO - total_loss: 0.3653699457645416, masked_loc_loss: 0.058764778077602386, masked_gen_loss: 0.30660516023635864 - (2851716:unified_unilip.py:926)
2026-01-07 19:44:54 - INFO - total_loss: 0.38767868280410767, masked_loc_loss: 0.042463675141334534, masked_gen_loss: 0.3452150225639343 - (2851716:unified_unilip.py:926)
2026-01-07 19:45:08 - INFO - total_loss: 0.35138219594955444, masked_loc_loss: 0.07073436677455902, masked_gen_loss: 0.28064781427383423 - (2851716:unified_unilip.py:926)
2026-01-07 19:45:15 - INFO - total_loss: 0.32059210538864136, masked_loc_loss: 0.03383053094148636, masked_gen_loss: 0.2867615818977356 - (2851716:unified_unilip.py:926)
2026-01-07 19:45:27 - INFO - total_loss: 0.44400376081466675, masked_loc_loss: 0.044375866651535034, masked_gen_loss: 0.3996278941631317 - (2851716:unified_unilip.py:926)
2026-01-07 19:45:41 - INFO - total_loss: 0.39854007959365845, masked_loc_loss: 0.04958152025938034, masked_gen_loss: 0.3489585518836975 - (2851716:unified_unilip.py:926)
2026-01-07 19:45:56 - INFO - total_loss: 0.42183759808540344, masked_loc_loss: 0.043410737067461014, masked_gen_loss: 0.37842684984207153 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:05 - INFO - total_loss: 0.4195622205734253, masked_loc_loss: 0.05129562318325043, masked_gen_loss: 0.36826658248901367 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:11 - INFO - total_loss: 0.3977358341217041, masked_loc_loss: 0.06634320318698883, masked_gen_loss: 0.33139264583587646 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:18 - INFO - total_loss: 0.3888643980026245, masked_loc_loss: 0.04526255279779434, masked_gen_loss: 0.34360185265541077 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:24 - INFO - total_loss: 0.44383344054222107, masked_loc_loss: 0.07591107487678528, masked_gen_loss: 0.3679223656654358 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:31 - INFO - total_loss: 0.4296844005584717, masked_loc_loss: 0.06290493905544281, masked_gen_loss: 0.3667794466018677 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:37 - INFO - total_loss: 0.37177008390426636, masked_loc_loss: 0.023236185312271118, masked_gen_loss: 0.34853389859199524 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:44 - INFO - total_loss: 0.35515740513801575, masked_loc_loss: 0.044616423547267914, masked_gen_loss: 0.31054097414016724 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:50 - INFO - total_loss: 0.42401790618896484, masked_loc_loss: 0.07824170589447021, masked_gen_loss: 0.34577620029449463 - (2851716:unified_unilip.py:926)
2026-01-07 19:46:57 - INFO - total_loss: 0.44390997290611267, masked_loc_loss: 0.04706881195306778, masked_gen_loss: 0.3968411684036255 - (2851716:unified_unilip.py:926)
2026-01-07 19:47:04 - INFO - total_loss: 0.4009767174720764, masked_loc_loss: 0.04641879349946976, masked_gen_loss: 0.35455793142318726 - (2851716:unified_unilip.py:926)
2026-01-07 19:47:10 - INFO - total_loss: 0.4308730363845825, masked_loc_loss: 0.04870755597949028, masked_gen_loss: 0.38216549158096313 - (2851716:unified_unilip.py:926)
2026-01-07 19:47:24 - INFO - total_loss: 0.4348541796207428, masked_loc_loss: 0.059877295047044754, masked_gen_loss: 0.37497687339782715 - (2851716:unified_unilip.py:926)
2026-01-07 19:47:39 - INFO - total_loss: 0.3316481113433838, masked_loc_loss: 0.077216237783432, masked_gen_loss: 0.2544318735599518 - (2851716:unified_unilip.py:926)
2026-01-07 19:47:54 - INFO - total_loss: 0.4242748022079468, masked_loc_loss: 0.04158471152186394, masked_gen_loss: 0.38269010186195374 - (2851716:unified_unilip.py:926)
2026-01-07 19:48:08 - INFO - total_loss: 0.3476475179195404, masked_loc_loss: 0.06873419135808945, masked_gen_loss: 0.27891331911087036 - (2851716:unified_unilip.py:926)
2026-01-07 19:48:15 - INFO - total_loss: 0.4846564531326294, masked_loc_loss: 0.06102144718170166, masked_gen_loss: 0.42363500595092773 - (2851716:unified_unilip.py:926)
2026-01-07 19:48:26 - INFO - total_loss: 0.3613922894001007, masked_loc_loss: 0.06166413426399231, masked_gen_loss: 0.2997281551361084 - (2851716:unified_unilip.py:926)
2026-01-07 19:48:41 - INFO - total_loss: 0.3445838987827301, masked_loc_loss: 0.04190453886985779, masked_gen_loss: 0.3026793599128723 - (2851716:unified_unilip.py:926)
2026-01-07 19:48:56 - INFO - total_loss: 0.35816454887390137, masked_loc_loss: 0.035388968884944916, masked_gen_loss: 0.32277557253837585 - (2851716:unified_unilip.py:926)
2026-01-07 19:49:10 - INFO - total_loss: 0.37387967109680176, masked_loc_loss: 0.05317426100373268, masked_gen_loss: 0.3207054138183594 - (2851716:unified_unilip.py:926)
2026-01-07 19:49:19 - INFO - total_loss: 0.40085741877555847, masked_loc_loss: 0.05694925785064697, masked_gen_loss: 0.3439081609249115 - (2851716:unified_unilip.py:926)
2026-01-07 19:49:31 - INFO - total_loss: 0.42392581701278687, masked_loc_loss: 0.0421861857175827, masked_gen_loss: 0.38173964619636536 - (2851716:unified_unilip.py:926)
2026-01-07 19:49:45 - INFO - total_loss: 0.3857719302177429, masked_loc_loss: 0.02838878706097603, masked_gen_loss: 0.357383131980896 - (2851716:unified_unilip.py:926)
2026-01-07 19:50:00 - INFO - total_loss: 0.39733535051345825, masked_loc_loss: 0.09062045812606812, masked_gen_loss: 0.30671489238739014 - (2851716:unified_unilip.py:926)
2026-01-07 19:50:14 - INFO - total_loss: 0.39486920833587646, masked_loc_loss: 0.06229691952466965, masked_gen_loss: 0.3325722813606262 - (2851716:unified_unilip.py:926)
2026-01-07 19:50:23 - INFO - total_loss: 0.3724741041660309, masked_loc_loss: 0.05844000726938248, masked_gen_loss: 0.314034104347229 - (2851716:unified_unilip.py:926)
2026-01-07 19:50:35 - INFO - total_loss: 0.4341146945953369, masked_loc_loss: 0.04459153115749359, masked_gen_loss: 0.3895231783390045 - (2851716:unified_unilip.py:926)
2026-01-07 19:50:50 - INFO - total_loss: 0.4327751100063324, masked_loc_loss: 0.05933788791298866, masked_gen_loss: 0.37343722581863403 - (2851716:unified_unilip.py:926)
2026-01-07 19:51:05 - INFO - total_loss: 0.3776812255382538, masked_loc_loss: 0.08134862780570984, masked_gen_loss: 0.29633259773254395 - (2851716:unified_unilip.py:926)
2026-01-07 19:51:19 - INFO - total_loss: 0.3650183379650116, masked_loc_loss: 0.033361174166202545, masked_gen_loss: 0.33165717124938965 - (2851716:unified_unilip.py:926)
2026-01-07 19:51:26 - INFO - total_loss: 0.4067096710205078, masked_loc_loss: 0.05476682260632515, masked_gen_loss: 0.35194283723831177 - (2851716:unified_unilip.py:926)
2026-01-07 19:51:33 - INFO - total_loss: 0.3424988389015198, masked_loc_loss: 0.042260583490133286, masked_gen_loss: 0.3002382516860962 - (2851716:unified_unilip.py:926)
2026-01-07 19:51:47 - INFO - total_loss: 0.385441392660141, masked_loc_loss: 0.04537155479192734, masked_gen_loss: 0.34006983041763306 - (2851716:unified_unilip.py:926)
2026-01-07 19:52:01 - INFO - total_loss: 0.3727096915245056, masked_loc_loss: 0.04165683686733246, masked_gen_loss: 0.33105286955833435 - (2851716:unified_unilip.py:926)
2026-01-07 19:52:16 - INFO - total_loss: 0.4061676859855652, masked_loc_loss: 0.03328331187367439, masked_gen_loss: 0.3728843629360199 - (2851716:unified_unilip.py:926)
2026-01-07 19:52:30 - INFO - total_loss: 0.4152398109436035, masked_loc_loss: 0.05162063613533974, masked_gen_loss: 0.3636191785335541 - (2851716:unified_unilip.py:926)
2026-01-07 19:52:37 - INFO - total_loss: 0.3852470815181732, masked_loc_loss: 0.042671434581279755, masked_gen_loss: 0.34257563948631287 - (2851716:unified_unilip.py:926)
2026-01-07 19:52:48 - INFO - total_loss: 0.4129831790924072, masked_loc_loss: 0.049235835671424866, masked_gen_loss: 0.36374732851982117 - (2851716:unified_unilip.py:926)
2026-01-07 19:53:02 - INFO - total_loss: 0.4069187045097351, masked_loc_loss: 0.03599243611097336, masked_gen_loss: 0.37092626094818115 - (2851716:unified_unilip.py:926)
2026-01-07 19:53:17 - INFO - total_loss: 0.3339594006538391, masked_loc_loss: 0.06915198266506195, masked_gen_loss: 0.26480743288993835 - (2851716:unified_unilip.py:926)
2026-01-07 19:53:31 - INFO - total_loss: 0.3978187143802643, masked_loc_loss: 0.02483336254954338, masked_gen_loss: 0.3729853630065918 - (2851716:unified_unilip.py:926)
2026-01-07 19:53:41 - INFO - total_loss: 0.3859158158302307, masked_loc_loss: 0.03584587574005127, masked_gen_loss: 0.35006994009017944 - (2851716:unified_unilip.py:926)
2026-01-07 19:53:53 - INFO - total_loss: 0.3887234926223755, masked_loc_loss: 0.07506148517131805, masked_gen_loss: 0.31366202235221863 - (2851716:unified_unilip.py:926)
2026-01-07 19:54:08 - INFO - total_loss: 0.3902093470096588, masked_loc_loss: 0.06201949715614319, masked_gen_loss: 0.3281898498535156 - (2851716:unified_unilip.py:926)
2026-01-07 19:54:22 - INFO - total_loss: 0.4030378460884094, masked_loc_loss: 0.048395588994026184, masked_gen_loss: 0.35464224219322205 - (2851716:unified_unilip.py:926)
2026-01-07 19:54:37 - INFO - total_loss: 0.3597244322299957, masked_loc_loss: 0.052386220544576645, masked_gen_loss: 0.3073382079601288 - (2851716:unified_unilip.py:926)
2026-01-07 19:54:46 - INFO - total_loss: 0.4109663963317871, masked_loc_loss: 0.046449579298496246, masked_gen_loss: 0.36451682448387146 - (2851716:unified_unilip.py:926)
2026-01-07 19:55:01 - INFO - total_loss: 0.40505194664001465, masked_loc_loss: 0.035335518419742584, masked_gen_loss: 0.36971643567085266 - (2851716:unified_unilip.py:926)
2026-01-07 19:55:15 - INFO - total_loss: 0.350413978099823, masked_loc_loss: 0.05572222173213959, masked_gen_loss: 0.2946917414665222 - (2851716:unified_unilip.py:926)
2026-01-07 19:55:29 - INFO - total_loss: 0.41600871086120605, masked_loc_loss: 0.04746047407388687, masked_gen_loss: 0.3685482442378998 - (2851716:unified_unilip.py:926)
2026-01-07 19:55:43 - INFO - total_loss: 0.42998242378234863, masked_loc_loss: 0.03958059847354889, masked_gen_loss: 0.39040184020996094 - (2851716:unified_unilip.py:926)
2026-01-07 19:55:52 - INFO - total_loss: 0.3745730221271515, masked_loc_loss: 0.09845739603042603, masked_gen_loss: 0.27611562609672546 - (2851716:unified_unilip.py:926)
2026-01-07 19:56:06 - INFO - total_loss: 0.3963058590888977, masked_loc_loss: 0.05082957446575165, masked_gen_loss: 0.34547629952430725 - (2851716:unified_unilip.py:926)
2026-01-07 19:56:20 - INFO - total_loss: 0.40509265661239624, masked_loc_loss: 0.06083923205733299, masked_gen_loss: 0.34425342082977295 - (2851716:unified_unilip.py:926)
2026-01-07 19:56:35 - INFO - total_loss: 0.36767080426216125, masked_loc_loss: 0.05283079296350479, masked_gen_loss: 0.31484001874923706 - (2851716:unified_unilip.py:926)
2026-01-07 19:56:47 - INFO - total_loss: 0.4089183807373047, masked_loc_loss: 0.0260723065584898, masked_gen_loss: 0.38284608721733093 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:00 - INFO - total_loss: 0.37769967317581177, masked_loc_loss: 0.07494257390499115, masked_gen_loss: 0.3027570843696594 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:15 - INFO - total_loss: 0.37920433282852173, masked_loc_loss: 0.037450410425662994, masked_gen_loss: 0.34175392985343933 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:29 - INFO - total_loss: 0.38390302658081055, masked_loc_loss: 0.04992334544658661, masked_gen_loss: 0.33397969603538513 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:36 - INFO - total_loss: 0.38651368021965027, masked_loc_loss: 0.03363071754574776, masked_gen_loss: 0.3528829514980316 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:42 - INFO - total_loss: 0.37768813967704773, masked_loc_loss: 0.053583599627017975, masked_gen_loss: 0.32410454750061035 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:48 - INFO - total_loss: 0.3748681843280792, masked_loc_loss: 0.021130293607711792, masked_gen_loss: 0.35373789072036743 - (2851716:unified_unilip.py:926)
2026-01-07 19:57:55 - INFO - total_loss: 0.33867737650871277, masked_loc_loss: 0.0466989204287529, masked_gen_loss: 0.2919784486293793 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:01 - INFO - total_loss: 0.4051927924156189, masked_loc_loss: 0.05246848240494728, masked_gen_loss: 0.3527243137359619 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:08 - INFO - total_loss: 0.33836930990219116, masked_loc_loss: 0.051547642797231674, masked_gen_loss: 0.2868216633796692 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:14 - INFO - total_loss: 0.446649968624115, masked_loc_loss: 0.05105367675423622, masked_gen_loss: 0.39559629559516907 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:21 - INFO - total_loss: 0.44836336374282837, masked_loc_loss: 0.08764083683490753, masked_gen_loss: 0.36072254180908203 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:27 - INFO - total_loss: 0.33010998368263245, masked_loc_loss: 0.05468658357858658, masked_gen_loss: 0.27542340755462646 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:34 - INFO - total_loss: 0.39055484533309937, masked_loc_loss: 0.044558241963386536, masked_gen_loss: 0.34599658846855164 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:40 - INFO - total_loss: 0.4349218010902405, masked_loc_loss: 0.049444153904914856, masked_gen_loss: 0.3854776620864868 - (2851716:unified_unilip.py:926)
2026-01-07 19:58:53 - INFO - total_loss: 0.4346640408039093, masked_loc_loss: 0.037733521312475204, masked_gen_loss: 0.3969305157661438 - (2851716:unified_unilip.py:926)
2026-01-07 19:59:07 - INFO - total_loss: 0.3316648602485657, masked_loc_loss: 0.03943251818418503, masked_gen_loss: 0.29223233461380005 - (2851716:unified_unilip.py:926)
2026-01-07 19:59:22 - INFO - total_loss: 0.3657577633857727, masked_loc_loss: 0.04707041010260582, masked_gen_loss: 0.3186873495578766 - (2851716:unified_unilip.py:926)
2026-01-07 19:59:37 - INFO - total_loss: 0.3706369996070862, masked_loc_loss: 0.024181202054023743, masked_gen_loss: 0.34645578265190125 - (2851716:unified_unilip.py:926)
2026-01-07 19:59:45 - INFO - total_loss: 0.4149717092514038, masked_loc_loss: 0.05101433023810387, masked_gen_loss: 0.36395737528800964 - (2851716:unified_unilip.py:926)
2026-01-07 19:59:51 - INFO - total_loss: 0.3843652307987213, masked_loc_loss: 0.07430539280176163, masked_gen_loss: 0.3100598454475403 - (2851716:unified_unilip.py:926)
2026-01-07 20:00:03 - INFO - total_loss: 0.4452890455722809, masked_loc_loss: 0.08653315156698227, masked_gen_loss: 0.358755886554718 - (2851716:unified_unilip.py:926)
2026-01-07 20:00:17 - INFO - total_loss: 0.4310726225376129, masked_loc_loss: 0.04303153231739998, masked_gen_loss: 0.38804107904434204 - (2851716:unified_unilip.py:926)
2026-01-07 20:00:32 - INFO - total_loss: 0.3798257112503052, masked_loc_loss: 0.03383852541446686, masked_gen_loss: 0.3459872007369995 - (2851716:unified_unilip.py:926)
2026-01-07 20:00:47 - INFO - total_loss: 0.3976671099662781, masked_loc_loss: 0.05136962980031967, masked_gen_loss: 0.3462974727153778 - (2851716:unified_unilip.py:926)
2026-01-07 20:00:56 - INFO - total_loss: 0.40417999029159546, masked_loc_loss: 0.035804420709609985, masked_gen_loss: 0.3683755695819855 - (2851716:unified_unilip.py:926)
2026-01-07 20:01:06 - INFO - total_loss: 0.43380242586135864, masked_loc_loss: 0.04810548201203346, masked_gen_loss: 0.3856969475746155 - (2851716:unified_unilip.py:926)
2026-01-07 20:01:20 - INFO - total_loss: 0.3703083395957947, masked_loc_loss: 0.04329604282975197, masked_gen_loss: 0.327012300491333 - (2851716:unified_unilip.py:926)
2026-01-07 20:01:35 - INFO - total_loss: 0.4001898765563965, masked_loc_loss: 0.042277656495571136, masked_gen_loss: 0.35791221261024475 - (2851716:unified_unilip.py:926)
2026-01-07 20:01:49 - INFO - total_loss: 0.36893507838249207, masked_loc_loss: 0.06900469213724136, masked_gen_loss: 0.2999303936958313 - (2851716:unified_unilip.py:926)
2026-01-07 20:02:01 - INFO - total_loss: 0.37670621275901794, masked_loc_loss: 0.05016901716589928, masked_gen_loss: 0.32653719186782837 - (2851716:unified_unilip.py:926)
2026-01-07 20:02:15 - INFO - total_loss: 0.35460156202316284, masked_loc_loss: 0.04111489653587341, masked_gen_loss: 0.31348666548728943 - (2851716:unified_unilip.py:926)
2026-01-07 20:02:29 - INFO - total_loss: 0.45298662781715393, masked_loc_loss: 0.05481068044900894, masked_gen_loss: 0.3981759548187256 - (2851716:unified_unilip.py:926)
2026-01-07 20:02:43 - INFO - total_loss: 0.3889622688293457, masked_loc_loss: 0.081819549202919, masked_gen_loss: 0.3071427345275879 - (2851716:unified_unilip.py:926)
2026-01-07 20:02:56 - INFO - total_loss: 0.40409332513809204, masked_loc_loss: 0.048551324754953384, masked_gen_loss: 0.35554200410842896 - (2851716:unified_unilip.py:926)
2026-01-07 20:03:10 - INFO - total_loss: 0.3868550956249237, masked_loc_loss: 0.055085740983486176, masked_gen_loss: 0.33176934719085693 - (2851716:unified_unilip.py:926)
2026-01-07 20:04:37 - INFO - total_loss: 0.41481950879096985, masked_loc_loss: 0.039554327726364136, masked_gen_loss: 0.3752651810646057 - (2851716:unified_unilip.py:926)
2026-01-07 20:04:43 - INFO - total_loss: 0.3199787735939026, masked_loc_loss: 0.056924693286418915, masked_gen_loss: 0.2630540728569031 - (2851716:unified_unilip.py:926)
2026-01-07 20:04:49 - INFO - total_loss: 0.431953102350235, masked_loc_loss: 0.0745401680469513, masked_gen_loss: 0.3574129343032837 - (2851716:unified_unilip.py:926)
2026-01-07 20:04:55 - INFO - total_loss: 0.36637601256370544, masked_loc_loss: 0.045101605355739594, masked_gen_loss: 0.32127439975738525 - (2851716:unified_unilip.py:926)
2026-01-07 20:05:03 - INFO - total_loss: 0.3922743499279022, masked_loc_loss: 0.08559451252222061, masked_gen_loss: 0.3066798448562622 - (2851716:unified_unilip.py:926)
2026-01-07 20:05:15 - INFO - total_loss: 0.3809664845466614, masked_loc_loss: 0.053444210439920425, masked_gen_loss: 0.32752227783203125 - (2851716:unified_unilip.py:926)
2026-01-07 20:05:21 - INFO - total_loss: 0.4428460896015167, masked_loc_loss: 0.0648355558514595, masked_gen_loss: 0.3780105412006378 - (2851716:unified_unilip.py:926)
2026-01-07 20:05:34 - INFO - total_loss: 0.3930889666080475, masked_loc_loss: 0.05773475021123886, masked_gen_loss: 0.335354208946228 - (2851716:unified_unilip.py:926)
2026-01-07 20:05:52 - INFO - total_loss: 0.3694705367088318, masked_loc_loss: 0.04085688292980194, masked_gen_loss: 0.32861363887786865 - (2851716:unified_unilip.py:926)
2026-01-07 20:06:03 - INFO - total_loss: 0.40205511450767517, masked_loc_loss: 0.07113686949014664, masked_gen_loss: 0.33091825246810913 - (2851716:unified_unilip.py:926)
2026-01-07 20:06:15 - INFO - total_loss: 0.3321695327758789, masked_loc_loss: 0.06736510992050171, masked_gen_loss: 0.2648044228553772 - (2851716:unified_unilip.py:926)
2026-01-07 20:06:24 - INFO - total_loss: 0.387850821018219, masked_loc_loss: 0.07847310602664948, masked_gen_loss: 0.3093777000904083 - (2851716:unified_unilip.py:926)
2026-01-07 20:06:31 - INFO - total_loss: 0.3610331416130066, masked_loc_loss: 0.07489676773548126, masked_gen_loss: 0.2861363887786865 - (2851716:unified_unilip.py:926)
2026-01-07 20:06:44 - INFO - total_loss: 0.4336061477661133, masked_loc_loss: 0.06226550042629242, masked_gen_loss: 0.37134063243865967 - (2851716:unified_unilip.py:926)
2026-01-07 20:06:59 - INFO - total_loss: 0.42190444469451904, masked_loc_loss: 0.045416127890348434, masked_gen_loss: 0.3764883279800415 - (2851716:unified_unilip.py:926)
2026-01-07 20:07:14 - INFO - total_loss: 0.39034372568130493, masked_loc_loss: 0.04608782380819321, masked_gen_loss: 0.34425589442253113 - (2851716:unified_unilip.py:926)
2026-01-07 20:07:28 - INFO - total_loss: 0.41304221749305725, masked_loc_loss: 0.03887667506933212, masked_gen_loss: 0.37416553497314453 - (2851716:unified_unilip.py:926)
2026-01-07 20:07:35 - INFO - total_loss: 0.4115809500217438, masked_loc_loss: 0.0587928369641304, masked_gen_loss: 0.35278812050819397 - (2851716:unified_unilip.py:926)
2026-01-07 20:07:47 - INFO - total_loss: 0.42766016721725464, masked_loc_loss: 0.043356508016586304, masked_gen_loss: 0.38430365920066833 - (2851716:unified_unilip.py:926)
2026-01-07 20:08:02 - INFO - total_loss: 0.4191359281539917, masked_loc_loss: 0.038528893142938614, masked_gen_loss: 0.3806070387363434 - (2851716:unified_unilip.py:926)
2026-01-07 20:08:17 - INFO - total_loss: 0.3560442328453064, masked_loc_loss: 0.05521971732378006, masked_gen_loss: 0.30082452297210693 - (2851716:unified_unilip.py:926)
2026-01-07 20:08:32 - INFO - total_loss: 0.32753419876098633, masked_loc_loss: 0.03378702700138092, masked_gen_loss: 0.2937471866607666 - (2851716:unified_unilip.py:926)
2026-01-07 20:08:40 - INFO - total_loss: 0.3785133361816406, masked_loc_loss: 0.052356839179992676, masked_gen_loss: 0.32615649700164795 - (2851716:unified_unilip.py:926)
2026-01-07 20:08:54 - INFO - total_loss: 0.40208864212036133, masked_loc_loss: 0.06392805278301239, masked_gen_loss: 0.33816060423851013 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:08 - INFO - total_loss: 0.3567018210887909, masked_loc_loss: 0.05765402317047119, masked_gen_loss: 0.2990477979183197 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:14 - INFO - total_loss: 0.45464271306991577, masked_loc_loss: 0.05364636331796646, masked_gen_loss: 0.4009963572025299 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:21 - INFO - total_loss: 0.4082382321357727, masked_loc_loss: 0.026107845827937126, masked_gen_loss: 0.38213038444519043 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:27 - INFO - total_loss: 0.38862186670303345, masked_loc_loss: 0.03055156208574772, masked_gen_loss: 0.3580703139305115 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:34 - INFO - total_loss: 0.4337461292743683, masked_loc_loss: 0.05669946223497391, masked_gen_loss: 0.377046674489975 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:40 - INFO - total_loss: 0.40781378746032715, masked_loc_loss: 0.06014592945575714, masked_gen_loss: 0.3476678729057312 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:47 - INFO - total_loss: 0.4030664563179016, masked_loc_loss: 0.021688610315322876, masked_gen_loss: 0.38137784600257874 - (2851716:unified_unilip.py:926)
2026-01-07 20:09:53 - INFO - total_loss: 0.39047423005104065, masked_loc_loss: 0.03034239262342453, masked_gen_loss: 0.3601318299770355 - (2851716:unified_unilip.py:926)
2026-01-07 20:10:00 - INFO - total_loss: 0.41880521178245544, masked_loc_loss: 0.05790736526250839, masked_gen_loss: 0.36089783906936646 - (2851716:unified_unilip.py:926)
2026-01-07 20:10:06 - INFO - total_loss: 0.4325296878814697, masked_loc_loss: 0.04319940507411957, masked_gen_loss: 0.38933026790618896 - (2851716:unified_unilip.py:926)
2026-01-07 20:10:12 - INFO - total_loss: 0.41191941499710083, masked_loc_loss: 0.031799934804439545, masked_gen_loss: 0.3801194727420807 - (2851716:unified_unilip.py:926)
2026-01-07 20:10:19 - INFO - total_loss: 0.4213259220123291, masked_loc_loss: 0.06706802546977997, masked_gen_loss: 0.3542579114437103 - (2851716:unified_unilip.py:926)
2026-01-07 20:10:33 - INFO - total_loss: 0.37690284848213196, masked_loc_loss: 0.07397035509347916, masked_gen_loss: 0.3029325008392334 - (2851716:unified_unilip.py:926)
2026-01-07 20:10:47 - INFO - total_loss: 0.38293370604515076, masked_loc_loss: 0.04584584757685661, masked_gen_loss: 0.33708786964416504 - (2851716:unified_unilip.py:926)
2026-01-07 20:11:01 - INFO - total_loss: 0.4169725775718689, masked_loc_loss: 0.06630932539701462, masked_gen_loss: 0.3506632447242737 - (2851716:unified_unilip.py:926)
2026-01-07 20:11:16 - INFO - total_loss: 0.4003053903579712, masked_loc_loss: 0.0804351419210434, masked_gen_loss: 0.319870263338089 - (2851716:unified_unilip.py:926)
2026-01-07 20:11:23 - INFO - total_loss: 0.3756706416606903, masked_loc_loss: 0.056989457458257675, masked_gen_loss: 0.31868118047714233 - (2851716:unified_unilip.py:926)
2026-01-07 20:11:29 - INFO - total_loss: 0.37585121393203735, masked_loc_loss: 0.04993259161710739, masked_gen_loss: 0.32591861486434937 - (2851716:unified_unilip.py:926)
2026-01-07 20:11:44 - INFO - total_loss: 0.34759488701820374, masked_loc_loss: 0.04529657959938049, masked_gen_loss: 0.30229830741882324 - (2851716:unified_unilip.py:926)
2026-01-07 20:11:58 - INFO - total_loss: 0.3795364201068878, masked_loc_loss: 0.04199858754873276, masked_gen_loss: 0.33753782510757446 - (2851716:unified_unilip.py:926)
2026-01-07 20:12:13 - INFO - total_loss: 0.36462587118148804, masked_loc_loss: 0.08430442959070206, masked_gen_loss: 0.2803214490413666 - (2851716:unified_unilip.py:926)
2026-01-07 20:12:27 - INFO - total_loss: 0.3804935812950134, masked_loc_loss: 0.05658029392361641, masked_gen_loss: 0.3239132761955261 - (2851716:unified_unilip.py:926)
2026-01-07 20:12:33 - INFO - total_loss: 0.3711228370666504, masked_loc_loss: 0.04289275407791138, masked_gen_loss: 0.328230082988739 - (2851716:unified_unilip.py:926)
2026-01-07 20:12:47 - INFO - total_loss: 0.41520389914512634, masked_loc_loss: 0.04605516791343689, masked_gen_loss: 0.36914873123168945 - (2851716:unified_unilip.py:926)
2026-01-07 20:13:02 - INFO - total_loss: 0.38266366720199585, masked_loc_loss: 0.051537275314331055, masked_gen_loss: 0.3311263918876648 - (2851716:unified_unilip.py:926)
2026-01-07 20:13:16 - INFO - total_loss: 0.3950106203556061, masked_loc_loss: 0.047877877950668335, masked_gen_loss: 0.34713274240493774 - (2851716:unified_unilip.py:926)
2026-01-07 20:13:31 - INFO - total_loss: 0.3999779224395752, masked_loc_loss: 0.03838254138827324, masked_gen_loss: 0.36159539222717285 - (2851716:unified_unilip.py:926)
2026-01-07 20:13:38 - INFO - total_loss: 0.43558114767074585, masked_loc_loss: 0.05304103344678879, masked_gen_loss: 0.38254010677337646 - (2851716:unified_unilip.py:926)
2026-01-07 20:13:48 - INFO - total_loss: 0.3885217607021332, masked_loc_loss: 0.04621296003460884, masked_gen_loss: 0.34230878949165344 - (2851716:unified_unilip.py:926)
2026-01-07 20:14:03 - INFO - total_loss: 0.4141526222229004, masked_loc_loss: 0.0727139264345169, masked_gen_loss: 0.3414387106895447 - (2851716:unified_unilip.py:926)
2026-01-07 20:14:17 - INFO - total_loss: 0.4346098005771637, masked_loc_loss: 0.05394526943564415, masked_gen_loss: 0.38066452741622925 - (2851716:unified_unilip.py:926)
2026-01-07 20:14:32 - INFO - total_loss: 0.3554425835609436, masked_loc_loss: 0.035146281123161316, masked_gen_loss: 0.3202962875366211 - (2851716:unified_unilip.py:926)
2026-01-07 20:14:42 - INFO - total_loss: 0.39895397424697876, masked_loc_loss: 0.040080007165670395, masked_gen_loss: 0.35887396335601807 - (2851716:unified_unilip.py:926)
2026-01-07 20:14:52 - INFO - total_loss: 0.42326802015304565, masked_loc_loss: 0.06651407480239868, masked_gen_loss: 0.356753945350647 - (2851716:unified_unilip.py:926)
2026-01-07 20:15:07 - INFO - total_loss: 0.3385363221168518, masked_loc_loss: 0.03064221888780594, masked_gen_loss: 0.30789411067962646 - (2851716:unified_unilip.py:926)
2026-01-07 20:15:21 - INFO - total_loss: 0.35748380422592163, masked_loc_loss: 0.05182643234729767, masked_gen_loss: 0.30565735697746277 - (2851716:unified_unilip.py:926)
2026-01-07 20:15:35 - INFO - total_loss: 0.3896735906600952, masked_loc_loss: 0.07656250149011612, masked_gen_loss: 0.3131110966205597 - (2851716:unified_unilip.py:926)
2026-01-07 20:15:45 - INFO - total_loss: 0.35661035776138306, masked_loc_loss: 0.05249212682247162, masked_gen_loss: 0.30411824584007263 - (2851716:unified_unilip.py:926)
2026-01-07 20:15:56 - INFO - total_loss: 0.35564088821411133, masked_loc_loss: 0.04547092691063881, masked_gen_loss: 0.3101699650287628 - (2851716:unified_unilip.py:926)
2026-01-07 20:16:10 - INFO - total_loss: 0.40736573934555054, masked_loc_loss: 0.028813723474740982, masked_gen_loss: 0.37855201959609985 - (2851716:unified_unilip.py:926)
2026-01-07 20:16:25 - INFO - total_loss: 0.3987225592136383, masked_loc_loss: 0.03687920421361923, masked_gen_loss: 0.3618433475494385 - (2851716:unified_unilip.py:926)
2026-01-07 20:16:39 - INFO - total_loss: 0.35987234115600586, masked_loc_loss: 0.02605496533215046, masked_gen_loss: 0.33381736278533936 - (2851716:unified_unilip.py:926)
2026-01-07 20:16:49 - INFO - total_loss: 0.35792970657348633, masked_loc_loss: 0.04222603142261505, masked_gen_loss: 0.31570369005203247 - (2851716:unified_unilip.py:926)
2026-01-07 20:16:58 - INFO - total_loss: 0.3878895044326782, masked_loc_loss: 0.024308351799845695, masked_gen_loss: 0.3635811507701874 - (2851716:unified_unilip.py:926)
2026-01-07 20:17:12 - INFO - total_loss: 0.4102032482624054, masked_loc_loss: 0.02955659106373787, masked_gen_loss: 0.38064664602279663 - (2851716:unified_unilip.py:926)
2026-01-07 20:17:26 - INFO - total_loss: 0.4300391674041748, masked_loc_loss: 0.056522589176893234, masked_gen_loss: 0.37351658940315247 - (2851716:unified_unilip.py:926)
2026-01-07 20:17:41 - INFO - total_loss: 0.3868853747844696, masked_loc_loss: 0.04960630461573601, masked_gen_loss: 0.3372790813446045 - (2851716:unified_unilip.py:926)
2026-01-07 20:17:53 - INFO - total_loss: 0.37618643045425415, masked_loc_loss: 0.04292929917573929, masked_gen_loss: 0.33325713872909546 - (2851716:unified_unilip.py:926)
2026-01-07 20:18:03 - INFO - total_loss: 0.44776439666748047, masked_loc_loss: 0.054321810603141785, masked_gen_loss: 0.3934425711631775 - (2851716:unified_unilip.py:926)
2026-01-07 20:18:18 - INFO - total_loss: 0.3586765229701996, masked_loc_loss: 0.02851625345647335, masked_gen_loss: 0.3301602602005005 - (2851716:unified_unilip.py:926)
2026-01-07 20:18:32 - INFO - total_loss: 0.4454655945301056, masked_loc_loss: 0.053002651780843735, masked_gen_loss: 0.39246293902397156 - (2851716:unified_unilip.py:926)
2026-01-07 20:18:47 - INFO - total_loss: 0.37634187936782837, masked_loc_loss: 0.03234553337097168, masked_gen_loss: 0.3439963459968567 - (2851716:unified_unilip.py:926)
2026-01-07 20:18:57 - INFO - total_loss: 0.381193071603775, masked_loc_loss: 0.03533479571342468, masked_gen_loss: 0.34585827589035034 - (2851716:unified_unilip.py:926)
2026-01-07 20:19:11 - INFO - total_loss: 0.40397146344184875, masked_loc_loss: 0.03901383653283119, masked_gen_loss: 0.36495763063430786 - (2851716:unified_unilip.py:926)
2026-01-07 20:19:26 - INFO - total_loss: 0.4059680104255676, masked_loc_loss: 0.048282042145729065, masked_gen_loss: 0.35768598318099976 - (2851716:unified_unilip.py:926)
2026-01-07 20:19:41 - INFO - total_loss: 0.4078250229358673, masked_loc_loss: 0.04459261894226074, masked_gen_loss: 0.36323240399360657 - (2851716:unified_unilip.py:926)
2026-01-07 20:19:55 - INFO - total_loss: 0.4006020426750183, masked_loc_loss: 0.06891069561243057, masked_gen_loss: 0.33169135451316833 - (2851716:unified_unilip.py:926)
2026-01-07 20:20:08 - INFO - total_loss: 0.42360490560531616, masked_loc_loss: 0.06654582917690277, masked_gen_loss: 0.3570590615272522 - (2851716:unified_unilip.py:926)
2026-01-07 20:20:23 - INFO - total_loss: 0.3855670094490051, masked_loc_loss: 0.02915615774691105, masked_gen_loss: 0.3564108610153198 - (2851716:unified_unilip.py:926)
2026-01-07 20:20:38 - INFO - total_loss: 0.35773965716362, masked_loc_loss: 0.03425869345664978, masked_gen_loss: 0.3234809637069702 - (2851716:unified_unilip.py:926)
2026-01-07 20:20:46 - INFO - total_loss: 0.41650915145874023, masked_loc_loss: 0.03201749920845032, masked_gen_loss: 0.3844916522502899 - (2851716:unified_unilip.py:926)
2026-01-07 20:20:53 - INFO - total_loss: 0.35735416412353516, masked_loc_loss: 0.021273557096719742, masked_gen_loss: 0.3360806107521057 - (2851716:unified_unilip.py:926)
2026-01-07 20:20:59 - INFO - total_loss: 0.3451988399028778, masked_loc_loss: 0.03969832882285118, masked_gen_loss: 0.30550050735473633 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:06 - INFO - total_loss: 0.4585298001766205, masked_loc_loss: 0.04395309090614319, masked_gen_loss: 0.4145767092704773 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:13 - INFO - total_loss: 0.41962355375289917, masked_loc_loss: 0.03368549421429634, masked_gen_loss: 0.38593804836273193 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:20 - INFO - total_loss: 0.3668360412120819, masked_loc_loss: 0.05728169530630112, masked_gen_loss: 0.3095543384552002 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:26 - INFO - total_loss: 0.33042460680007935, masked_loc_loss: 0.047744736075401306, masked_gen_loss: 0.28267985582351685 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:32 - INFO - total_loss: 0.335111528635025, masked_loc_loss: 0.04584639519453049, masked_gen_loss: 0.28926512598991394 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:39 - INFO - total_loss: 0.39791902899742126, masked_loc_loss: 0.05491826683282852, masked_gen_loss: 0.34300076961517334 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:46 - INFO - total_loss: 0.3988867998123169, masked_loc_loss: 0.047548890113830566, masked_gen_loss: 0.35133790969848633 - (2851716:unified_unilip.py:926)
2026-01-07 20:21:52 - INFO - total_loss: 0.47438931465148926, masked_loc_loss: 0.02195943519473076, masked_gen_loss: 0.4524298906326294 - (2851716:unified_unilip.py:926)
2026-01-07 20:22:06 - INFO - total_loss: 0.3997940719127655, masked_loc_loss: 0.03067842125892639, masked_gen_loss: 0.3691156506538391 - (2851716:unified_unilip.py:926)
2026-01-07 20:22:20 - INFO - total_loss: 0.39672642946243286, masked_loc_loss: 0.04045386239886284, masked_gen_loss: 0.3562725782394409 - (2851716:unified_unilip.py:926)
2026-01-07 20:22:35 - INFO - total_loss: 0.4003126323223114, masked_loc_loss: 0.03240904584527016, masked_gen_loss: 0.36790359020233154 - (2851716:unified_unilip.py:926)
2026-01-07 20:22:49 - INFO - total_loss: 0.3743531107902527, masked_loc_loss: 0.058745626360177994, masked_gen_loss: 0.315607488155365 - (2851716:unified_unilip.py:926)
2026-01-07 20:22:56 - INFO - total_loss: 0.37853237986564636, masked_loc_loss: 0.047393836081027985, masked_gen_loss: 0.331138551235199 - (2851716:unified_unilip.py:926)
2026-01-07 20:23:02 - INFO - total_loss: 0.3449285626411438, masked_loc_loss: 0.03825239837169647, masked_gen_loss: 0.30667614936828613 - (2851716:unified_unilip.py:926)
2026-01-07 20:23:14 - INFO - total_loss: 0.3400164842605591, masked_loc_loss: 0.03115789219737053, masked_gen_loss: 0.30885860323905945 - (2851716:unified_unilip.py:926)
2026-01-07 20:23:29 - INFO - total_loss: 0.42476946115493774, masked_loc_loss: 0.03657955676317215, masked_gen_loss: 0.3881899118423462 - (2851716:unified_unilip.py:926)
2026-01-07 20:23:43 - INFO - total_loss: 0.3535277247428894, masked_loc_loss: 0.029485581442713737, masked_gen_loss: 0.3240421414375305 - (2851716:unified_unilip.py:926)
2026-01-07 20:23:58 - INFO - total_loss: 0.4444893002510071, masked_loc_loss: 0.04257728159427643, masked_gen_loss: 0.40191203355789185 - (2851716:unified_unilip.py:926)
2026-01-07 20:24:06 - INFO - total_loss: 0.3645951449871063, masked_loc_loss: 0.041118644177913666, masked_gen_loss: 0.32347649335861206 - (2851716:unified_unilip.py:926)
2026-01-07 20:24:13 - INFO - total_loss: 0.4205648899078369, masked_loc_loss: 0.04066063091158867, masked_gen_loss: 0.37990427017211914 - (2851716:unified_unilip.py:926)
2026-01-07 20:24:28 - INFO - total_loss: 0.42601150274276733, masked_loc_loss: 0.05412788689136505, masked_gen_loss: 0.3718836307525635 - (2851716:unified_unilip.py:926)
2026-01-07 20:24:42 - INFO - total_loss: 0.41663333773612976, masked_loc_loss: 0.03570951148867607, masked_gen_loss: 0.3809238374233246 - (2851716:unified_unilip.py:926)
2026-01-07 20:24:57 - INFO - total_loss: 0.3445029854774475, masked_loc_loss: 0.047860220074653625, masked_gen_loss: 0.2966427505016327 - (2851716:unified_unilip.py:926)
2026-01-07 20:25:11 - INFO - total_loss: 0.4099244475364685, masked_loc_loss: 0.0642009824514389, masked_gen_loss: 0.3457234501838684 - (2851716:unified_unilip.py:926)
2026-01-07 20:25:19 - INFO - total_loss: 0.35859328508377075, masked_loc_loss: 0.07213550806045532, masked_gen_loss: 0.28645777702331543 - (2851716:unified_unilip.py:926)
2026-01-07 20:25:34 - INFO - total_loss: 0.3390708267688751, masked_loc_loss: 0.03735310211777687, masked_gen_loss: 0.30171772837638855 - (2851716:unified_unilip.py:926)
2026-01-07 20:25:48 - INFO - total_loss: 0.3907022476196289, masked_loc_loss: 0.031046876683831215, masked_gen_loss: 0.35965538024902344 - (2851716:unified_unilip.py:926)
2026-01-07 20:26:03 - INFO - total_loss: 0.41301649808883667, masked_loc_loss: 0.05054368078708649, masked_gen_loss: 0.3624728322029114 - (2851716:unified_unilip.py:926)
2026-01-07 20:26:15 - INFO - total_loss: 0.37534672021865845, masked_loc_loss: 0.08148889243602753, masked_gen_loss: 0.2938578128814697 - (2851716:unified_unilip.py:926)
2026-01-07 20:26:25 - INFO - total_loss: 0.3810209035873413, masked_loc_loss: 0.06517047435045242, masked_gen_loss: 0.3158504366874695 - (2851716:unified_unilip.py:926)
2026-01-07 20:26:40 - INFO - total_loss: 0.40933021903038025, masked_loc_loss: 0.049728188663721085, masked_gen_loss: 0.35960203409194946 - (2851716:unified_unilip.py:926)
2026-01-07 20:26:54 - INFO - total_loss: 0.33766302466392517, masked_loc_loss: 0.018594766035676003, masked_gen_loss: 0.3190682530403137 - (2851716:unified_unilip.py:926)
2026-01-07 20:27:08 - INFO - total_loss: 0.377178430557251, masked_loc_loss: 0.06293314695358276, masked_gen_loss: 0.3142452836036682 - (2851716:unified_unilip.py:926)
2026-01-07 20:27:20 - INFO - total_loss: 0.4017641842365265, masked_loc_loss: 0.07882565259933472, masked_gen_loss: 0.3229385316371918 - (2851716:unified_unilip.py:926)
2026-01-07 20:27:31 - INFO - total_loss: 0.45283812284469604, masked_loc_loss: 0.053530462086200714, masked_gen_loss: 0.3993076682090759 - (2851716:unified_unilip.py:926)
2026-01-07 20:27:46 - INFO - total_loss: 0.3251309394836426, masked_loc_loss: 0.055405452847480774, masked_gen_loss: 0.2697254717350006 - (2851716:unified_unilip.py:926)
2026-01-07 20:28:00 - INFO - total_loss: 0.39298078417778015, masked_loc_loss: 0.036796748638153076, masked_gen_loss: 0.3561840355396271 - (2851716:unified_unilip.py:926)
2026-01-07 20:28:15 - INFO - total_loss: 0.3927360475063324, masked_loc_loss: 0.04867495968937874, masked_gen_loss: 0.34406107664108276 - (2851716:unified_unilip.py:926)
2026-01-07 20:28:24 - INFO - total_loss: 0.3700236976146698, masked_loc_loss: 0.03642154484987259, masked_gen_loss: 0.3336021602153778 - (2851716:unified_unilip.py:926)
2026-01-07 20:28:37 - INFO - total_loss: 0.39485418796539307, masked_loc_loss: 0.04012174904346466, masked_gen_loss: 0.3547324538230896 - (2851716:unified_unilip.py:926)
2026-01-07 20:28:51 - INFO - total_loss: 0.4147346019744873, masked_loc_loss: 0.07110927999019623, masked_gen_loss: 0.3436253070831299 - (2851716:unified_unilip.py:926)
2026-01-07 20:29:06 - INFO - total_loss: 0.38185542821884155, masked_loc_loss: 0.03999350219964981, masked_gen_loss: 0.34186193346977234 - (2851716:unified_unilip.py:926)
2026-01-07 20:29:20 - INFO - total_loss: 0.40005290508270264, masked_loc_loss: 0.061209507286548615, masked_gen_loss: 0.3388434052467346 - (2851716:unified_unilip.py:926)
2026-01-07 20:29:27 - INFO - total_loss: 0.3533189594745636, masked_loc_loss: 0.04579951986670494, masked_gen_loss: 0.30751943588256836 - (2851716:unified_unilip.py:926)
2026-01-07 20:29:38 - INFO - total_loss: 0.3975696563720703, masked_loc_loss: 0.06815995275974274, masked_gen_loss: 0.3294096887111664 - (2851716:unified_unilip.py:926)
2026-01-07 20:29:52 - INFO - total_loss: 0.37977999448776245, masked_loc_loss: 0.055104970932006836, masked_gen_loss: 0.3246750235557556 - (2851716:unified_unilip.py:926)
2026-01-07 20:30:07 - INFO - total_loss: 0.37408679723739624, masked_loc_loss: 0.035032227635383606, masked_gen_loss: 0.33905458450317383 - (2851716:unified_unilip.py:926)
2026-01-07 20:30:21 - INFO - total_loss: 0.339671790599823, masked_loc_loss: 0.045688923448324203, masked_gen_loss: 0.2939828634262085 - (2851716:unified_unilip.py:926)
2026-01-07 20:30:31 - INFO - total_loss: 0.3695317506790161, masked_loc_loss: 0.05227382108569145, masked_gen_loss: 0.31725794076919556 - (2851716:unified_unilip.py:926)
2026-01-07 20:30:43 - INFO - total_loss: 0.4468367099761963, masked_loc_loss: 0.04815469682216644, masked_gen_loss: 0.39868199825286865 - (2851716:unified_unilip.py:926)
2026-01-07 20:30:58 - INFO - total_loss: 0.36598649621009827, masked_loc_loss: 0.04628271609544754, masked_gen_loss: 0.3197037875652313 - (2851716:unified_unilip.py:926)
2026-01-07 20:31:13 - INFO - total_loss: 0.3910139799118042, masked_loc_loss: 0.04766044020652771, masked_gen_loss: 0.3433535397052765 - (2851716:unified_unilip.py:926)
2026-01-07 20:31:27 - INFO - total_loss: 0.40983912348747253, masked_loc_loss: 0.04119480028748512, masked_gen_loss: 0.3686443269252777 - (2851716:unified_unilip.py:926)
2026-01-07 20:31:35 - INFO - total_loss: 0.39994028210639954, masked_loc_loss: 0.034689344465732574, masked_gen_loss: 0.36525094509124756 - (2851716:unified_unilip.py:926)
2026-01-07 20:31:50 - INFO - total_loss: 0.37692901492118835, masked_loc_loss: 0.05871381238102913, masked_gen_loss: 0.31821519136428833 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:04 - INFO - total_loss: 0.3643513321876526, masked_loc_loss: 0.06007593870162964, masked_gen_loss: 0.30427539348602295 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:18 - INFO - total_loss: 0.39458388090133667, masked_loc_loss: 0.03433407470583916, masked_gen_loss: 0.3602498173713684 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:25 - INFO - total_loss: 0.3374342918395996, masked_loc_loss: 0.04152487963438034, masked_gen_loss: 0.29590940475463867 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:32 - INFO - total_loss: 0.3568982779979706, masked_loc_loss: 0.04532960057258606, masked_gen_loss: 0.3115686774253845 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:38 - INFO - total_loss: 0.3992866277694702, masked_loc_loss: 0.0519571416079998, masked_gen_loss: 0.3473294973373413 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:45 - INFO - total_loss: 0.39713963866233826, masked_loc_loss: 0.06412708014249802, masked_gen_loss: 0.33301255106925964 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:51 - INFO - total_loss: 0.3633652627468109, masked_loc_loss: 0.04055962339043617, masked_gen_loss: 0.32280564308166504 - (2851716:unified_unilip.py:926)
2026-01-07 20:32:58 - INFO - total_loss: 0.38104549050331116, masked_loc_loss: 0.08661185950040817, masked_gen_loss: 0.2944336235523224 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:05 - INFO - total_loss: 0.4255465567111969, masked_loc_loss: 0.037528667598962784, masked_gen_loss: 0.3880178928375244 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:11 - INFO - total_loss: 0.3944661617279053, masked_loc_loss: 0.031026262789964676, masked_gen_loss: 0.3634398877620697 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:18 - INFO - total_loss: 0.40430718660354614, masked_loc_loss: 0.06247188150882721, masked_gen_loss: 0.34183529019355774 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:24 - INFO - total_loss: 0.43214213848114014, masked_loc_loss: 0.0658615380525589, masked_gen_loss: 0.36628058552742004 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:31 - INFO - total_loss: 0.37633007764816284, masked_loc_loss: 0.03885340318083763, masked_gen_loss: 0.3374766707420349 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:44 - INFO - total_loss: 0.3999845087528229, masked_loc_loss: 0.039797283709049225, masked_gen_loss: 0.36018723249435425 - (2851716:unified_unilip.py:926)
2026-01-07 20:33:59 - INFO - total_loss: 0.3725075125694275, masked_loc_loss: 0.0513470433652401, masked_gen_loss: 0.3211604654788971 - (2851716:unified_unilip.py:926)
2026-01-07 20:34:13 - INFO - total_loss: 0.37047848105430603, masked_loc_loss: 0.045240048319101334, masked_gen_loss: 0.325238436460495 - (2851716:unified_unilip.py:926)
2026-01-07 20:34:28 - INFO - total_loss: 0.3684624135494232, masked_loc_loss: 0.039015382528305054, masked_gen_loss: 0.32944703102111816 - (2851716:unified_unilip.py:926)
2026-01-07 20:34:35 - INFO - total_loss: 0.3681286573410034, masked_loc_loss: 0.061226267367601395, masked_gen_loss: 0.30690237879753113 - (2851716:unified_unilip.py:926)
2026-01-07 20:34:42 - INFO - total_loss: 0.37107542157173157, masked_loc_loss: 0.04626472666859627, masked_gen_loss: 0.3248106837272644 - (2851716:unified_unilip.py:926)
2026-01-07 20:34:56 - INFO - total_loss: 0.3846513330936432, masked_loc_loss: 0.04101722314953804, masked_gen_loss: 0.34363409876823425 - (2851716:unified_unilip.py:926)
2026-01-07 20:35:10 - INFO - total_loss: 0.3715903162956238, masked_loc_loss: 0.06672360748052597, masked_gen_loss: 0.3048667013645172 - (2851716:unified_unilip.py:926)
2026-01-07 20:35:24 - INFO - total_loss: 0.40910273790359497, masked_loc_loss: 0.03245040774345398, masked_gen_loss: 0.376652330160141 - (2851716:unified_unilip.py:926)
2026-01-07 20:35:39 - INFO - total_loss: 0.39361536502838135, masked_loc_loss: 0.062363915145397186, masked_gen_loss: 0.33125144243240356 - (2851716:unified_unilip.py:926)
2026-01-07 20:35:45 - INFO - total_loss: 0.42960917949676514, masked_loc_loss: 0.05101509392261505, masked_gen_loss: 0.3785941004753113 - (2851716:unified_unilip.py:926)
2026-01-07 20:35:53 - INFO - total_loss: 0.3762272298336029, masked_loc_loss: 0.039232876151800156, masked_gen_loss: 0.33699434995651245 - (2851716:unified_unilip.py:926)
2026-01-07 20:36:08 - INFO - total_loss: 0.3912602961063385, masked_loc_loss: 0.029582589864730835, masked_gen_loss: 0.36167770624160767 - (2851716:unified_unilip.py:926)
2026-01-07 20:36:22 - INFO - total_loss: 0.4197028577327728, masked_loc_loss: 0.04878604784607887, masked_gen_loss: 0.37091681361198425 - (2851716:unified_unilip.py:926)
2026-01-07 20:36:37 - INFO - total_loss: 0.3661196827888489, masked_loc_loss: 0.03568050637841225, masked_gen_loss: 0.33043918013572693 - (2851716:unified_unilip.py:926)
2026-01-07 20:36:49 - INFO - total_loss: 0.40879034996032715, masked_loc_loss: 0.07288289070129395, masked_gen_loss: 0.3359074592590332 - (2851716:unified_unilip.py:926)
2026-01-07 20:36:55 - INFO - total_loss: 0.36318790912628174, masked_loc_loss: 0.03433053568005562, masked_gen_loss: 0.3288573622703552 - (2851716:unified_unilip.py:926)
2026-01-07 20:37:10 - INFO - total_loss: 0.43018168210983276, masked_loc_loss: 0.03293054550886154, masked_gen_loss: 0.3972511291503906 - (2851716:unified_unilip.py:926)
2026-01-07 20:37:24 - INFO - total_loss: 0.4162401556968689, masked_loc_loss: 0.0671718567609787, masked_gen_loss: 0.349068284034729 - (2851716:unified_unilip.py:926)
2026-01-07 20:37:38 - INFO - total_loss: 0.35124510526657104, masked_loc_loss: 0.05384991317987442, masked_gen_loss: 0.2973951995372772 - (2851716:unified_unilip.py:926)
2026-01-07 20:37:53 - INFO - total_loss: 0.3317714035511017, masked_loc_loss: 0.03997516259551048, masked_gen_loss: 0.2917962372303009 - (2851716:unified_unilip.py:926)
2026-01-07 20:37:59 - INFO - total_loss: 0.4017758369445801, masked_loc_loss: 0.04673159867525101, masked_gen_loss: 0.35504424571990967 - (2851716:unified_unilip.py:926)
2026-01-07 20:38:14 - INFO - total_loss: 0.4217287003993988, masked_loc_loss: 0.040369533002376556, masked_gen_loss: 0.38135915994644165 - (2851716:unified_unilip.py:926)
2026-01-07 20:38:29 - INFO - total_loss: 0.3246087431907654, masked_loc_loss: 0.05436444282531738, masked_gen_loss: 0.270244300365448 - (2851716:unified_unilip.py:926)
2026-01-07 20:38:43 - INFO - total_loss: 0.3341183066368103, masked_loc_loss: 0.04329318180680275, masked_gen_loss: 0.29082512855529785 - (2851716:unified_unilip.py:926)
2026-01-07 20:38:57 - INFO - total_loss: 0.3759618401527405, masked_loc_loss: 0.05276596546173096, masked_gen_loss: 0.3231958746910095 - (2851716:unified_unilip.py:926)
2026-01-07 20:39:04 - INFO - total_loss: 0.3891351819038391, masked_loc_loss: 0.04538927972316742, masked_gen_loss: 0.3437458872795105 - (2851716:unified_unilip.py:926)
2026-01-07 20:39:17 - INFO - total_loss: 0.34348082542419434, masked_loc_loss: 0.03746853768825531, masked_gen_loss: 0.3060123026371002 - (2851716:unified_unilip.py:926)
2026-01-07 20:39:32 - INFO - total_loss: 0.46056413650512695, masked_loc_loss: 0.049828797578811646, masked_gen_loss: 0.4107353389263153 - (2851716:unified_unilip.py:926)
2026-01-07 20:39:47 - INFO - total_loss: 0.43056291341781616, masked_loc_loss: 0.0347820520401001, masked_gen_loss: 0.39578086137771606 - (2851716:unified_unilip.py:926)
2026-01-07 20:40:01 - INFO - total_loss: 0.36239585280418396, masked_loc_loss: 0.036644645035266876, masked_gen_loss: 0.3257512152194977 - (2851716:unified_unilip.py:926)
2026-01-07 20:40:08 - INFO - total_loss: 0.41679057478904724, masked_loc_loss: 0.04584130272269249, masked_gen_loss: 0.37094926834106445 - (2851716:unified_unilip.py:926)
2026-01-07 20:40:22 - INFO - total_loss: 0.3620751202106476, masked_loc_loss: 0.03792497515678406, masked_gen_loss: 0.3241501450538635 - (2851716:unified_unilip.py:926)
2026-01-07 20:40:37 - INFO - total_loss: 0.39757323265075684, masked_loc_loss: 0.03337578475475311, masked_gen_loss: 0.36419743299484253 - (2851716:unified_unilip.py:926)
2026-01-07 20:40:51 - INFO - total_loss: 0.4523690342903137, masked_loc_loss: 0.017559528350830078, masked_gen_loss: 0.43480950593948364 - (2851716:unified_unilip.py:926)
2026-01-07 20:41:05 - INFO - total_loss: 0.4284014105796814, masked_loc_loss: 0.02679997868835926, masked_gen_loss: 0.4016014337539673 - (2851716:unified_unilip.py:926)
2026-01-07 20:41:12 - INFO - total_loss: 0.37435460090637207, masked_loc_loss: 0.04298260062932968, masked_gen_loss: 0.3313719928264618 - (2851716:unified_unilip.py:926)
2026-01-07 20:41:26 - INFO - total_loss: 0.37456274032592773, masked_loc_loss: 0.040921323001384735, masked_gen_loss: 0.3336414098739624 - (2851716:unified_unilip.py:926)
2026-01-07 20:41:41 - INFO - total_loss: 0.43599528074264526, masked_loc_loss: 0.042559824883937836, masked_gen_loss: 0.39343544840812683 - (2851716:unified_unilip.py:926)
2026-01-07 20:41:55 - INFO - total_loss: 0.3808824419975281, masked_loc_loss: 0.052764892578125, masked_gen_loss: 0.3281175494194031 - (2851716:unified_unilip.py:926)
2026-01-07 20:42:09 - INFO - total_loss: 0.3974153995513916, masked_loc_loss: 0.04090278595685959, masked_gen_loss: 0.3565126061439514 - (2851716:unified_unilip.py:926)
2026-01-07 20:42:15 - INFO - total_loss: 0.3778025805950165, masked_loc_loss: 0.03101145289838314, masked_gen_loss: 0.3467911183834076 - (2851716:unified_unilip.py:926)
2026-01-07 20:42:29 - INFO - total_loss: 0.3891924023628235, masked_loc_loss: 0.03837175667285919, masked_gen_loss: 0.3508206605911255 - (2851716:unified_unilip.py:926)
2026-01-07 20:42:44 - INFO - total_loss: 0.3793248236179352, masked_loc_loss: 0.047748684883117676, masked_gen_loss: 0.3315761387348175 - (2851716:unified_unilip.py:926)
2026-01-07 20:42:58 - INFO - total_loss: 0.41282179951667786, masked_loc_loss: 0.03931843489408493, masked_gen_loss: 0.37350335717201233 - (2851716:unified_unilip.py:926)
2026-01-07 20:43:12 - INFO - total_loss: 0.466675728559494, masked_loc_loss: 0.027037179097533226, masked_gen_loss: 0.43963855504989624 - (2851716:unified_unilip.py:926)
2026-01-07 20:43:26 - INFO - total_loss: 0.3319685459136963, masked_loc_loss: 0.05127965658903122, masked_gen_loss: 0.2806888818740845 - (2851716:unified_unilip.py:926)
2026-01-07 20:43:40 - INFO - total_loss: 0.30696991086006165, masked_loc_loss: 0.05601508542895317, masked_gen_loss: 0.25095483660697937 - (2851716:unified_unilip.py:926)
2026-01-07 20:43:55 - INFO - total_loss: 0.3673284947872162, masked_loc_loss: 0.05590049549937248, masked_gen_loss: 0.3114280104637146 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:01 - INFO - total_loss: 0.3849092721939087, masked_loc_loss: 0.033112332224845886, masked_gen_loss: 0.3517969250679016 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:08 - INFO - total_loss: 0.37318718433380127, masked_loc_loss: 0.05827774852514267, masked_gen_loss: 0.314909428358078 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:14 - INFO - total_loss: 0.34467989206314087, masked_loc_loss: 0.05621832609176636, masked_gen_loss: 0.2884615659713745 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:21 - INFO - total_loss: 0.39399510622024536, masked_loc_loss: 0.05566481128334999, masked_gen_loss: 0.33833029866218567 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:27 - INFO - total_loss: 0.3741662800312042, masked_loc_loss: 0.055951185524463654, masked_gen_loss: 0.31821510195732117 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:34 - INFO - total_loss: 0.4058484137058258, masked_loc_loss: 0.058645524084568024, masked_gen_loss: 0.3472028970718384 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:41 - INFO - total_loss: 0.3690251111984253, masked_loc_loss: 0.043138377368450165, masked_gen_loss: 0.32588672637939453 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:47 - INFO - total_loss: 0.45643705129623413, masked_loc_loss: 0.06397078931331635, masked_gen_loss: 0.3924662470817566 - (2851716:unified_unilip.py:926)
2026-01-07 20:44:54 - INFO - total_loss: 0.3472716510295868, masked_loc_loss: 0.030481476336717606, masked_gen_loss: 0.3167901635169983 - (2851716:unified_unilip.py:926)
2026-01-07 20:45:00 - INFO - total_loss: 0.4131884276866913, masked_loc_loss: 0.0239097997546196, masked_gen_loss: 0.3892786204814911 - (2851716:unified_unilip.py:926)
2026-01-07 20:45:09 - INFO - total_loss: 0.3498481512069702, masked_loc_loss: 0.04304052144289017, masked_gen_loss: 0.30680763721466064 - (2851716:unified_unilip.py:926)
2026-01-07 20:45:24 - INFO - total_loss: 0.34439533948898315, masked_loc_loss: 0.08018920570611954, masked_gen_loss: 0.2642061412334442 - (2851716:unified_unilip.py:926)
2026-01-07 20:45:38 - INFO - total_loss: 0.38965100049972534, masked_loc_loss: 0.04321054369211197, masked_gen_loss: 0.34644046425819397 - (2851716:unified_unilip.py:926)
2026-01-07 20:45:53 - INFO - total_loss: 0.43698108196258545, masked_loc_loss: 0.06190069764852524, masked_gen_loss: 0.3750803768634796 - (2851716:unified_unilip.py:926)
2026-01-07 20:46:05 - INFO - total_loss: 0.3489251732826233, masked_loc_loss: 0.031959906220436096, masked_gen_loss: 0.3169652819633484 - (2851716:unified_unilip.py:926)
2026-01-07 20:46:12 - INFO - total_loss: 0.3380861282348633, masked_loc_loss: 0.023339450359344482, masked_gen_loss: 0.3147466778755188 - (2851716:unified_unilip.py:926)
2026-01-07 20:46:23 - INFO - total_loss: 0.37715691328048706, masked_loc_loss: 0.05239404737949371, masked_gen_loss: 0.32476288080215454 - (2851716:unified_unilip.py:926)
2026-01-07 20:46:37 - INFO - total_loss: 0.3798880875110626, masked_loc_loss: 0.05921907350420952, masked_gen_loss: 0.320669025182724 - (2851716:unified_unilip.py:926)
2026-01-07 20:46:52 - INFO - total_loss: 0.4242984652519226, masked_loc_loss: 0.026298709213733673, masked_gen_loss: 0.39799976348876953 - (2851716:unified_unilip.py:926)
2026-01-07 20:47:06 - INFO - total_loss: 0.34905320405960083, masked_loc_loss: 0.04505185782909393, masked_gen_loss: 0.3040013313293457 - (2851716:unified_unilip.py:926)
2026-01-07 20:47:16 - INFO - total_loss: 0.38378390669822693, masked_loc_loss: 0.04608163237571716, masked_gen_loss: 0.33770227432250977 - (2851716:unified_unilip.py:926)
2026-01-07 20:47:22 - INFO - total_loss: 0.4586549401283264, masked_loc_loss: 0.04358888044953346, masked_gen_loss: 0.41506606340408325 - (2851716:unified_unilip.py:926)
2026-01-07 20:47:36 - INFO - total_loss: 0.3940388858318329, masked_loc_loss: 0.05145597085356712, masked_gen_loss: 0.34258291125297546 - (2851716:unified_unilip.py:926)
2026-01-07 20:47:50 - INFO - total_loss: 0.3837936222553253, masked_loc_loss: 0.03487294912338257, masked_gen_loss: 0.34892067313194275 - (2851716:unified_unilip.py:926)
2026-01-07 20:48:05 - INFO - total_loss: 0.4135909974575043, masked_loc_loss: 0.030670780688524246, masked_gen_loss: 0.38292020559310913 - (2851716:unified_unilip.py:926)
2026-01-07 20:48:19 - INFO - total_loss: 0.4601188898086548, masked_loc_loss: 0.04139406606554985, masked_gen_loss: 0.41872483491897583 - (2851716:unified_unilip.py:926)
2026-01-07 20:48:26 - INFO - total_loss: 0.41023725271224976, masked_loc_loss: 0.07282854616641998, masked_gen_loss: 0.33740872144699097 - (2851716:unified_unilip.py:926)
2026-01-07 20:48:37 - INFO - total_loss: 0.4497181475162506, masked_loc_loss: 0.0546443872153759, masked_gen_loss: 0.3950737714767456 - (2851716:unified_unilip.py:926)
2026-01-07 20:48:51 - INFO - total_loss: 0.3990013003349304, masked_loc_loss: 0.033163800835609436, masked_gen_loss: 0.3658375144004822 - (2851716:unified_unilip.py:926)
2026-01-07 20:49:05 - INFO - total_loss: 0.415376752614975, masked_loc_loss: 0.03228343278169632, masked_gen_loss: 0.38309332728385925 - (2851716:unified_unilip.py:926)
2026-01-07 20:49:20 - INFO - total_loss: 0.38067540526390076, masked_loc_loss: 0.055104341357946396, masked_gen_loss: 0.32557106018066406 - (2851716:unified_unilip.py:926)
2026-01-07 20:49:30 - INFO - total_loss: 0.39102107286453247, masked_loc_loss: 0.048373397439718246, masked_gen_loss: 0.3426476716995239 - (2851716:unified_unilip.py:926)
2026-01-07 20:49:39 - INFO - total_loss: 0.4088311791419983, masked_loc_loss: 0.05252959579229355, masked_gen_loss: 0.35630157589912415 - (2851716:unified_unilip.py:926)
2026-01-07 20:49:53 - INFO - total_loss: 0.4091261029243469, masked_loc_loss: 0.04498942196369171, masked_gen_loss: 0.3641366958618164 - (2851716:unified_unilip.py:926)
2026-01-07 20:50:08 - INFO - total_loss: 0.44394955039024353, masked_loc_loss: 0.05075046792626381, masked_gen_loss: 0.39319908618927 - (2851716:unified_unilip.py:926)
2026-01-07 20:50:22 - INFO - total_loss: 0.4418652653694153, masked_loc_loss: 0.055404894053936005, masked_gen_loss: 0.3864603638648987 - (2851716:unified_unilip.py:926)
2026-01-07 20:50:34 - INFO - total_loss: 0.3843768835067749, masked_loc_loss: 0.0648682713508606, masked_gen_loss: 0.3195086121559143 - (2851716:unified_unilip.py:926)
2026-01-07 20:50:45 - INFO - total_loss: 0.4061106741428375, masked_loc_loss: 0.049675144255161285, masked_gen_loss: 0.35643553733825684 - (2851716:unified_unilip.py:926)
2026-01-07 20:50:59 - INFO - total_loss: 0.41775038838386536, masked_loc_loss: 0.027987265959382057, masked_gen_loss: 0.38976311683654785 - (2851716:unified_unilip.py:926)
2026-01-07 20:51:14 - INFO - total_loss: 0.3506130576133728, masked_loc_loss: 0.061236217617988586, masked_gen_loss: 0.2893768548965454 - (2851716:unified_unilip.py:926)
2026-01-07 20:51:28 - INFO - total_loss: 0.3699994385242462, masked_loc_loss: 0.052904821932315826, masked_gen_loss: 0.317094624042511 - (2851716:unified_unilip.py:926)
2026-01-07 20:51:39 - INFO - total_loss: 0.4093157649040222, masked_loc_loss: 0.02745339646935463, masked_gen_loss: 0.3818623721599579 - (2851716:unified_unilip.py:926)
2026-01-07 20:51:52 - INFO - total_loss: 0.3549647033214569, masked_loc_loss: 0.019908031448721886, masked_gen_loss: 0.3350566625595093 - (2851716:unified_unilip.py:926)
2026-01-07 20:52:07 - INFO - total_loss: 0.414745032787323, masked_loc_loss: 0.09513557702302933, masked_gen_loss: 0.31960946321487427 - (2851716:unified_unilip.py:926)
2026-01-07 20:52:21 - INFO - total_loss: 0.31185510754585266, masked_loc_loss: 0.0374884232878685, masked_gen_loss: 0.27436667680740356 - (2851716:unified_unilip.py:926)
2026-01-07 20:52:36 - INFO - total_loss: 0.4170454442501068, masked_loc_loss: 0.04418051615357399, masked_gen_loss: 0.3728649318218231 - (2851716:unified_unilip.py:926)
2026-01-07 20:52:44 - INFO - total_loss: 0.3788575232028961, masked_loc_loss: 0.03324994444847107, masked_gen_loss: 0.34560757875442505 - (2851716:unified_unilip.py:926)
2026-01-07 20:52:58 - INFO - total_loss: 0.34922248125076294, masked_loc_loss: 0.06080956384539604, masked_gen_loss: 0.2884129285812378 - (2851716:unified_unilip.py:926)
2026-01-07 20:53:12 - INFO - total_loss: 0.4081195294857025, masked_loc_loss: 0.04284069687128067, masked_gen_loss: 0.36527884006500244 - (2851716:unified_unilip.py:926)
2026-01-07 20:53:26 - INFO - total_loss: 0.37790828943252563, masked_loc_loss: 0.03920697420835495, masked_gen_loss: 0.3387013077735901 - (2851716:unified_unilip.py:926)
2026-01-07 20:53:40 - INFO - total_loss: 0.3875875473022461, masked_loc_loss: 0.032199107110500336, masked_gen_loss: 0.35538843274116516 - (2851716:unified_unilip.py:926)
2026-01-07 20:53:50 - INFO - total_loss: 0.3673059940338135, masked_loc_loss: 0.039553992450237274, masked_gen_loss: 0.3277519941329956 - (2851716:unified_unilip.py:926)
2026-01-07 20:54:04 - INFO - total_loss: 0.401802659034729, masked_loc_loss: 0.05061240494251251, masked_gen_loss: 0.3511902689933777 - (2851716:unified_unilip.py:926)
2026-01-07 20:54:19 - INFO - total_loss: 0.3992399573326111, masked_loc_loss: 0.05590419843792915, masked_gen_loss: 0.34333574771881104 - (2851716:unified_unilip.py:926)
2026-01-07 20:54:33 - INFO - total_loss: 0.35484549403190613, masked_loc_loss: 0.03992661088705063, masked_gen_loss: 0.3149188756942749 - (2851716:unified_unilip.py:926)
2026-01-07 20:54:44 - INFO - total_loss: 0.3629317283630371, masked_loc_loss: 0.0310845747590065, masked_gen_loss: 0.3318471610546112 - (2851716:unified_unilip.py:926)
2026-01-07 20:54:58 - INFO - total_loss: 0.39614221453666687, masked_loc_loss: 0.04100492596626282, masked_gen_loss: 0.35513728857040405 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:12 - INFO - total_loss: 0.3473784625530243, masked_loc_loss: 0.04747588187456131, masked_gen_loss: 0.2999025881290436 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:26 - INFO - total_loss: 0.40096616744995117, masked_loc_loss: 0.03154117986559868, masked_gen_loss: 0.3694249987602234 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:32 - INFO - total_loss: 0.3781721889972687, masked_loc_loss: 0.03292492777109146, masked_gen_loss: 0.3452472686767578 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:39 - INFO - total_loss: 0.3582662045955658, masked_loc_loss: 0.04767237976193428, masked_gen_loss: 0.3105938136577606 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:46 - INFO - total_loss: 0.4300914406776428, masked_loc_loss: 0.042271777987480164, masked_gen_loss: 0.38781964778900146 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:52 - INFO - total_loss: 0.340233713388443, masked_loc_loss: 0.04105592891573906, masked_gen_loss: 0.29917779564857483 - (2851716:unified_unilip.py:926)
2026-01-07 20:55:59 - INFO - total_loss: 0.38822507858276367, masked_loc_loss: 0.05453246831893921, masked_gen_loss: 0.33369261026382446 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:05 - INFO - total_loss: 0.33997851610183716, masked_loc_loss: 0.05289401859045029, masked_gen_loss: 0.2870844900608063 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:12 - INFO - total_loss: 0.39676111936569214, masked_loc_loss: 0.023202307522296906, masked_gen_loss: 0.37355881929397583 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:18 - INFO - total_loss: 0.42817845940589905, masked_loc_loss: 0.027288768440485, masked_gen_loss: 0.40088969469070435 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:25 - INFO - total_loss: 0.34579965472221375, masked_loc_loss: 0.03892996162176132, masked_gen_loss: 0.3068696856498718 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:31 - INFO - total_loss: 0.4110049903392792, masked_loc_loss: 0.03796496242284775, masked_gen_loss: 0.37304002046585083 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:42 - INFO - total_loss: 0.41609159111976624, masked_loc_loss: 0.022172586992383003, masked_gen_loss: 0.3939189910888672 - (2851716:unified_unilip.py:926)
2026-01-07 20:56:56 - INFO - total_loss: 0.35804054141044617, masked_loc_loss: 0.04691491276025772, masked_gen_loss: 0.31112563610076904 - (2851716:unified_unilip.py:926)
2026-01-07 20:57:12 - INFO - total_loss: 0.3479572534561157, masked_loc_loss: 0.07010741531848907, masked_gen_loss: 0.27784985303878784 - (2851716:unified_unilip.py:926)
2026-01-07 20:57:27 - INFO - total_loss: 0.34086546301841736, masked_loc_loss: 0.0497705340385437, masked_gen_loss: 0.29109492897987366 - (2851716:unified_unilip.py:926)
2026-01-07 20:57:36 - INFO - total_loss: 0.36845073103904724, masked_loc_loss: 0.061111610382795334, masked_gen_loss: 0.3073391318321228 - (2851716:unified_unilip.py:926)
2026-01-07 20:57:42 - INFO - total_loss: 0.38614118099212646, masked_loc_loss: 0.049030378460884094, masked_gen_loss: 0.3371107876300812 - (2851716:unified_unilip.py:926)
2026-01-07 20:57:56 - INFO - total_loss: 0.3704240024089813, masked_loc_loss: 0.04986467584967613, masked_gen_loss: 0.3205593228340149 - (2851716:unified_unilip.py:926)
2026-01-07 20:58:11 - INFO - total_loss: 0.41177523136138916, masked_loc_loss: 0.036917731165885925, masked_gen_loss: 0.37485748529434204 - (2851716:unified_unilip.py:926)
2026-01-07 20:58:26 - INFO - total_loss: 0.34576401114463806, masked_loc_loss: 0.035089604556560516, masked_gen_loss: 0.31067439913749695 - (2851716:unified_unilip.py:926)
2026-01-07 20:58:40 - INFO - total_loss: 0.38643598556518555, masked_loc_loss: 0.03261910006403923, masked_gen_loss: 0.3538168966770172 - (2851716:unified_unilip.py:926)
2026-01-07 20:58:46 - INFO - total_loss: 0.42875707149505615, masked_loc_loss: 0.06381110846996307, masked_gen_loss: 0.3649459481239319 - (2851716:unified_unilip.py:926)
2026-01-07 20:59:00 - INFO - total_loss: 0.41285911202430725, masked_loc_loss: 0.03326830640435219, masked_gen_loss: 0.37959080934524536 - (2851716:unified_unilip.py:926)
2026-01-07 20:59:14 - INFO - total_loss: 0.43583130836486816, masked_loc_loss: 0.028705889359116554, masked_gen_loss: 0.40712541341781616 - (2851716:unified_unilip.py:926)
2026-01-07 20:59:29 - INFO - total_loss: 0.38431766629219055, masked_loc_loss: 0.028725137934088707, masked_gen_loss: 0.3555925190448761 - (2851716:unified_unilip.py:926)
2026-01-07 20:59:43 - INFO - total_loss: 0.3773844838142395, masked_loc_loss: 0.03990130126476288, masked_gen_loss: 0.33748316764831543 - (2851716:unified_unilip.py:926)
2026-01-07 20:59:50 - INFO - total_loss: 0.34030115604400635, masked_loc_loss: 0.0228740107268095, masked_gen_loss: 0.3174271583557129 - (2851716:unified_unilip.py:926)
2026-01-07 21:00:03 - INFO - total_loss: 0.3619158864021301, masked_loc_loss: 0.05321752279996872, masked_gen_loss: 0.3086983561515808 - (2851716:unified_unilip.py:926)
2026-01-07 21:00:18 - INFO - total_loss: 0.3961328864097595, masked_loc_loss: 0.06440582126379013, masked_gen_loss: 0.3317270576953888 - (2851716:unified_unilip.py:926)
2026-01-07 21:00:32 - INFO - total_loss: 0.4205473065376282, masked_loc_loss: 0.04165761172771454, masked_gen_loss: 0.37888967990875244 - (2851716:unified_unilip.py:926)
2026-01-07 21:00:47 - INFO - total_loss: 0.31506210565567017, masked_loc_loss: 0.04555392265319824, masked_gen_loss: 0.2695081830024719 - (2851716:unified_unilip.py:926)
2026-01-07 21:00:54 - INFO - total_loss: 0.33610421419143677, masked_loc_loss: 0.04655536264181137, masked_gen_loss: 0.2895488440990448 - (2851716:unified_unilip.py:926)
2026-01-07 21:01:05 - INFO - total_loss: 0.38003575801849365, masked_loc_loss: 0.05130833759903908, masked_gen_loss: 0.3287274241447449 - (2851716:unified_unilip.py:926)
2026-01-07 21:01:20 - INFO - total_loss: 0.3843308985233307, masked_loc_loss: 0.053260307759046555, masked_gen_loss: 0.33107060194015503 - (2851716:unified_unilip.py:926)
2026-01-07 21:01:34 - INFO - total_loss: 0.4284147024154663, masked_loc_loss: 0.05211333930492401, masked_gen_loss: 0.3763013780117035 - (2851716:unified_unilip.py:926)
2026-01-07 21:01:49 - INFO - total_loss: 0.3797301650047302, masked_loc_loss: 0.06350522488355637, masked_gen_loss: 0.31622493267059326 - (2851716:unified_unilip.py:926)
2026-01-07 21:01:58 - INFO - total_loss: 0.41322094202041626, masked_loc_loss: 0.04223046451807022, masked_gen_loss: 0.37099048495292664 - (2851716:unified_unilip.py:926)
2026-01-07 21:02:11 - INFO - total_loss: 0.33934593200683594, masked_loc_loss: 0.03230157494544983, masked_gen_loss: 0.3070443570613861 - (2851716:unified_unilip.py:926)
2026-01-07 21:02:26 - INFO - total_loss: 0.37984558939933777, masked_loc_loss: 0.045394837856292725, masked_gen_loss: 0.33445075154304504 - (2851716:unified_unilip.py:926)
2026-01-07 21:02:40 - INFO - total_loss: 0.4011841416358948, masked_loc_loss: 0.0466153584420681, masked_gen_loss: 0.3545687794685364 - (2851716:unified_unilip.py:926)
2026-01-07 21:02:55 - INFO - total_loss: 0.3791443109512329, masked_loc_loss: 0.04260266572237015, masked_gen_loss: 0.33654165267944336 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:02 - INFO - total_loss: 0.4315803349018097, masked_loc_loss: 0.05361492186784744, masked_gen_loss: 0.37796542048454285 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:16 - INFO - total_loss: 0.4186633229255676, masked_loc_loss: 0.07883703708648682, masked_gen_loss: 0.3398262858390808 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:23 - INFO - total_loss: 0.36803120374679565, masked_loc_loss: 0.050490982830524445, masked_gen_loss: 0.3175402283668518 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:29 - INFO - total_loss: 0.39115676283836365, masked_loc_loss: 0.06237202510237694, masked_gen_loss: 0.3287847340106964 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:36 - INFO - total_loss: 0.3635285198688507, masked_loc_loss: 0.03384655341506004, masked_gen_loss: 0.32968196272850037 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:43 - INFO - total_loss: 0.4134270250797272, masked_loc_loss: 0.057476453483104706, masked_gen_loss: 0.35595056414604187 - (2851716:unified_unilip.py:926)
2026-01-07 21:03:56 - INFO - total_loss: 0.37102192640304565, masked_loc_loss: 0.08772046864032745, masked_gen_loss: 0.2833014726638794 - (2851716:unified_unilip.py:926)
2026-01-07 21:04:11 - INFO - total_loss: 0.3776267170906067, masked_loc_loss: 0.05067510902881622, masked_gen_loss: 0.32695162296295166 - (2851716:unified_unilip.py:926)
2026-01-07 21:04:25 - INFO - total_loss: 0.37181445956230164, masked_loc_loss: 0.08184534311294556, masked_gen_loss: 0.2899691164493561 - (2851716:unified_unilip.py:926)
2026-01-07 21:04:40 - INFO - total_loss: 0.40543267130851746, masked_loc_loss: 0.047928161919116974, masked_gen_loss: 0.3575045168399811 - (2851716:unified_unilip.py:926)
2026-01-07 21:04:54 - INFO - total_loss: 0.35078689455986023, masked_loc_loss: 0.03797456994652748, masked_gen_loss: 0.31281232833862305 - (2851716:unified_unilip.py:926)
2026-01-07 21:05:09 - INFO - total_loss: 0.35520729422569275, masked_loc_loss: 0.058319542557001114, masked_gen_loss: 0.29688775539398193 - (2851716:unified_unilip.py:926)
2026-01-07 21:05:22 - INFO - total_loss: 0.3888038992881775, masked_loc_loss: 0.05221115052700043, masked_gen_loss: 0.33659273386001587 - (2851716:unified_unilip.py:926)
2026-01-07 21:05:37 - INFO - total_loss: 0.40582242608070374, masked_loc_loss: 0.05917225405573845, masked_gen_loss: 0.3466501832008362 - (2851716:unified_unilip.py:926)
2026-01-07 21:05:51 - INFO - total_loss: 0.4036802053451538, masked_loc_loss: 0.04939727112650871, masked_gen_loss: 0.354282945394516 - (2851716:unified_unilip.py:926)
2026-01-07 21:06:05 - INFO - total_loss: 0.36164045333862305, masked_loc_loss: 0.06038945913314819, masked_gen_loss: 0.30125099420547485 - (2851716:unified_unilip.py:926)
2026-01-07 21:06:20 - INFO - total_loss: 0.36907538771629333, masked_loc_loss: 0.03972556069493294, masked_gen_loss: 0.3293498158454895 - (2851716:unified_unilip.py:926)
2026-01-07 21:06:33 - INFO - total_loss: 0.44143885374069214, masked_loc_loss: 0.054812345653772354, masked_gen_loss: 0.3866265118122101 - (2851716:unified_unilip.py:926)
2026-01-07 21:06:47 - INFO - total_loss: 0.47206100821495056, masked_loc_loss: 0.022138601168990135, masked_gen_loss: 0.4499224126338959 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:02 - INFO - total_loss: 0.35593217611312866, masked_loc_loss: 0.047619085758924484, masked_gen_loss: 0.3083131015300751 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:09 - INFO - total_loss: 0.3868444561958313, masked_loc_loss: 0.043562840670347214, masked_gen_loss: 0.343281626701355 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:15 - INFO - total_loss: 0.4556652903556824, masked_loc_loss: 0.05089593678712845, masked_gen_loss: 0.4047693610191345 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:22 - INFO - total_loss: 0.3403685986995697, masked_loc_loss: 0.03086617775261402, masked_gen_loss: 0.30950242280960083 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:28 - INFO - total_loss: 0.41192835569381714, masked_loc_loss: 0.05054553225636482, masked_gen_loss: 0.3613828122615814 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:35 - INFO - total_loss: 0.36534541845321655, masked_loc_loss: 0.03597801923751831, masked_gen_loss: 0.32936739921569824 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:41 - INFO - total_loss: 0.3901301622390747, masked_loc_loss: 0.034525755792856216, masked_gen_loss: 0.3556044101715088 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:48 - INFO - total_loss: 0.39114388823509216, masked_loc_loss: 0.03553187474608421, masked_gen_loss: 0.35561200976371765 - (2851716:unified_unilip.py:926)
2026-01-07 21:07:54 - INFO - total_loss: 0.40536344051361084, masked_loc_loss: 0.04403592646121979, masked_gen_loss: 0.36132752895355225 - (2851716:unified_unilip.py:926)
2026-01-07 21:08:01 - INFO - total_loss: 0.39874470233917236, masked_loc_loss: 0.06977944821119308, masked_gen_loss: 0.3289652466773987 - (2851716:unified_unilip.py:926)
2026-01-07 21:08:07 - INFO - total_loss: 0.36948880553245544, masked_loc_loss: 0.03839895501732826, masked_gen_loss: 0.3310898542404175 - (2851716:unified_unilip.py:926)
2026-01-07 21:08:16 - INFO - total_loss: 0.3548417091369629, masked_loc_loss: 0.04497857019305229, masked_gen_loss: 0.3098631501197815 - (2851716:unified_unilip.py:926)
2026-01-07 21:08:31 - INFO - total_loss: 0.35150694847106934, masked_loc_loss: 0.04421760141849518, masked_gen_loss: 0.30728933215141296 - (2851716:unified_unilip.py:926)
2026-01-07 21:08:46 - INFO - total_loss: 0.4044507145881653, masked_loc_loss: 0.04914556443691254, masked_gen_loss: 0.35530516505241394 - (2851716:unified_unilip.py:926)
2026-01-07 21:09:00 - INFO - total_loss: 0.37719079852104187, masked_loc_loss: 0.061099179089069366, masked_gen_loss: 0.3160916268825531 - (2851716:unified_unilip.py:926)
2026-01-07 21:09:12 - INFO - total_loss: 0.42773011326789856, masked_loc_loss: 0.026686109602451324, masked_gen_loss: 0.40104401111602783 - (2851716:unified_unilip.py:926)
2026-01-07 21:09:20 - INFO - total_loss: 0.36514753103256226, masked_loc_loss: 0.051293790340423584, masked_gen_loss: 0.31385374069213867 - (2851716:unified_unilip.py:926)
2026-01-07 21:09:35 - INFO - total_loss: 0.3920232057571411, masked_loc_loss: 0.026465484872460365, masked_gen_loss: 0.3655577301979065 - (2851716:unified_unilip.py:926)
2026-01-07 21:09:50 - INFO - total_loss: 0.36230629682540894, masked_loc_loss: 0.04977086931467056, masked_gen_loss: 0.31253543496131897 - (2851716:unified_unilip.py:926)
2026-01-07 21:10:04 - INFO - total_loss: 0.329281747341156, masked_loc_loss: 0.05839373916387558, masked_gen_loss: 0.27088800072669983 - (2851716:unified_unilip.py:926)
2026-01-07 21:10:16 - INFO - total_loss: 0.3869566023349762, masked_loc_loss: 0.0662507489323616, masked_gen_loss: 0.3207058608531952 - (2851716:unified_unilip.py:926)
2026-01-07 21:10:24 - INFO - total_loss: 0.3518403470516205, masked_loc_loss: 0.02650943584740162, masked_gen_loss: 0.325330913066864 - (2851716:unified_unilip.py:926)
2026-01-07 21:10:38 - INFO - total_loss: 0.407164990901947, masked_loc_loss: 0.02927868813276291, masked_gen_loss: 0.3778862953186035 - (2851716:unified_unilip.py:926)
2026-01-07 21:10:52 - INFO - total_loss: 0.3487132489681244, masked_loc_loss: 0.03986412286758423, masked_gen_loss: 0.30884912610054016 - (2851716:unified_unilip.py:926)
2026-01-07 21:11:07 - INFO - total_loss: 0.3649674355983734, masked_loc_loss: 0.03942989557981491, masked_gen_loss: 0.3255375325679779 - (2851716:unified_unilip.py:926)
2026-01-07 21:11:20 - INFO - total_loss: 0.3923115134239197, masked_loc_loss: 0.036209117621183395, masked_gen_loss: 0.3561024069786072 - (2851716:unified_unilip.py:926)
2026-01-07 21:11:27 - INFO - total_loss: 0.36995798349380493, masked_loc_loss: 0.04741260036826134, masked_gen_loss: 0.3225453794002533 - (2851716:unified_unilip.py:926)
2026-01-07 21:11:40 - INFO - total_loss: 0.35415828227996826, masked_loc_loss: 0.021639861166477203, masked_gen_loss: 0.33251842856407166 - (2851716:unified_unilip.py:926)
2026-01-07 21:11:55 - INFO - total_loss: 0.40964341163635254, masked_loc_loss: 0.027939463034272194, masked_gen_loss: 0.3817039430141449 - (2851716:unified_unilip.py:926)
2026-01-07 21:12:09 - INFO - total_loss: 0.41163283586502075, masked_loc_loss: 0.0217188261449337, masked_gen_loss: 0.38991400599479675 - (2851716:unified_unilip.py:926)
2026-01-07 21:12:23 - INFO - total_loss: 0.4016561508178711, masked_loc_loss: 0.06540273874998093, masked_gen_loss: 0.33625340461730957 - (2851716:unified_unilip.py:926)
2026-01-07 21:12:30 - INFO - total_loss: 0.367531418800354, masked_loc_loss: 0.03776668757200241, masked_gen_loss: 0.329764723777771 - (2851716:unified_unilip.py:926)
2026-01-07 21:12:44 - INFO - total_loss: 0.4042185842990875, masked_loc_loss: 0.054568056017160416, masked_gen_loss: 0.3496505320072174 - (2851716:unified_unilip.py:926)
2026-01-07 21:12:58 - INFO - total_loss: 0.3429203927516937, masked_loc_loss: 0.05556962639093399, masked_gen_loss: 0.28735077381134033 - (2851716:unified_unilip.py:926)
2026-01-07 21:13:12 - INFO - total_loss: 0.35710081458091736, masked_loc_loss: 0.0415007546544075, masked_gen_loss: 0.31560006737709045 - (2851716:unified_unilip.py:926)
2026-01-07 21:13:27 - INFO - total_loss: 0.38956964015960693, masked_loc_loss: 0.03986214101314545, masked_gen_loss: 0.3497075140476227 - (2851716:unified_unilip.py:926)
2026-01-07 21:13:34 - INFO - total_loss: 0.40718066692352295, masked_loc_loss: 0.03907568007707596, masked_gen_loss: 0.3681049942970276 - (2851716:unified_unilip.py:926)
2026-01-07 21:13:44 - INFO - total_loss: 0.40708160400390625, masked_loc_loss: 0.0561552494764328, masked_gen_loss: 0.35092633962631226 - (2851716:unified_unilip.py:926)
2026-01-07 21:13:59 - INFO - total_loss: 0.3802502155303955, masked_loc_loss: 0.038596026599407196, masked_gen_loss: 0.3416541814804077 - (2851716:unified_unilip.py:926)
2026-01-07 21:14:13 - INFO - total_loss: 0.34632349014282227, masked_loc_loss: 0.03903781622648239, masked_gen_loss: 0.3072856664657593 - (2851716:unified_unilip.py:926)
2026-01-07 21:14:28 - INFO - total_loss: 0.43282198905944824, masked_loc_loss: 0.04276728630065918, masked_gen_loss: 0.39005470275878906 - (2851716:unified_unilip.py:926)
2026-01-07 21:14:37 - INFO - total_loss: 0.38702499866485596, masked_loc_loss: 0.05356481298804283, masked_gen_loss: 0.3334601819515228 - (2851716:unified_unilip.py:926)
2026-01-07 21:14:46 - INFO - total_loss: 0.3999600410461426, masked_loc_loss: 0.04415453225374222, masked_gen_loss: 0.35580551624298096 - (2851716:unified_unilip.py:926)
2026-01-07 21:15:01 - INFO - total_loss: 0.37633848190307617, masked_loc_loss: 0.06583564728498459, masked_gen_loss: 0.310502827167511 - (2851716:unified_unilip.py:926)
2026-01-07 21:15:16 - INFO - total_loss: 0.3304513096809387, masked_loc_loss: 0.060196466743946075, masked_gen_loss: 0.27025485038757324 - (2851716:unified_unilip.py:926)
2026-01-07 21:15:30 - INFO - total_loss: 0.37041473388671875, masked_loc_loss: 0.04198222607374191, masked_gen_loss: 0.32843250036239624 - (2851716:unified_unilip.py:926)
2026-01-07 21:15:41 - INFO - total_loss: 0.47156521677970886, masked_loc_loss: 0.07234641164541245, masked_gen_loss: 0.3992187976837158 - (2851716:unified_unilip.py:926)
2026-01-07 21:15:50 - INFO - total_loss: 0.42538708448410034, masked_loc_loss: 0.02702021785080433, masked_gen_loss: 0.39836686849594116 - (2851716:unified_unilip.py:926)
2026-01-07 21:16:05 - INFO - total_loss: 0.39722147583961487, masked_loc_loss: 0.041285060346126556, masked_gen_loss: 0.3559364080429077 - (2851716:unified_unilip.py:926)
2026-01-07 21:16:20 - INFO - total_loss: 0.382874071598053, masked_loc_loss: 0.04488460719585419, masked_gen_loss: 0.3379894495010376 - (2851716:unified_unilip.py:926)
2026-01-07 21:16:34 - INFO - total_loss: 0.3697417378425598, masked_loc_loss: 0.056894488632678986, masked_gen_loss: 0.3128472566604614 - (2851716:unified_unilip.py:926)
2026-01-07 21:16:46 - INFO - total_loss: 0.35538381338119507, masked_loc_loss: 0.05098459869623184, masked_gen_loss: 0.3043992221355438 - (2851716:unified_unilip.py:926)
2026-01-07 21:16:53 - INFO - total_loss: 0.3605276644229889, masked_loc_loss: 0.032017260789871216, masked_gen_loss: 0.3285104036331177 - (2851716:unified_unilip.py:926)
2026-01-07 21:17:06 - INFO - total_loss: 0.3632563650608063, masked_loc_loss: 0.0444958433508873, masked_gen_loss: 0.3187605142593384 - (2851716:unified_unilip.py:926)
2026-01-07 21:17:21 - INFO - total_loss: 0.3520660102367401, masked_loc_loss: 0.041745398193597794, masked_gen_loss: 0.3103206157684326 - (2851716:unified_unilip.py:926)
2026-01-07 21:17:35 - INFO - total_loss: 0.3325841724872589, masked_loc_loss: 0.049226313829422, masked_gen_loss: 0.2833578586578369 - (2851716:unified_unilip.py:926)
2026-01-07 21:17:49 - INFO - total_loss: 0.39711472392082214, masked_loc_loss: 0.06189938634634018, masked_gen_loss: 0.33521533012390137 - (2851716:unified_unilip.py:926)
2026-01-07 21:17:59 - INFO - total_loss: 0.3410220742225647, masked_loc_loss: 0.03956209495663643, masked_gen_loss: 0.3014599680900574 - (2851716:unified_unilip.py:926)
2026-01-07 21:18:13 - INFO - total_loss: 0.3814016282558441, masked_loc_loss: 0.06104300543665886, masked_gen_loss: 0.32035863399505615 - (2851716:unified_unilip.py:926)
2026-01-07 21:18:28 - INFO - total_loss: 0.3641270399093628, masked_loc_loss: 0.04857952147722244, masked_gen_loss: 0.31554752588272095 - (2851716:unified_unilip.py:926)
2026-01-07 21:18:39 - INFO - total_loss: 0.40876802802085876, masked_loc_loss: 0.04881269484758377, masked_gen_loss: 0.3599553406238556 - (2851716:unified_unilip.py:926)
2026-01-07 21:18:46 - INFO - total_loss: 0.3288697898387909, masked_loc_loss: 0.04665336757898331, masked_gen_loss: 0.2822164297103882 - (2851716:unified_unilip.py:926)
2026-01-07 21:18:52 - INFO - total_loss: 0.391783744096756, masked_loc_loss: 0.03866444155573845, masked_gen_loss: 0.3531193137168884 - (2851716:unified_unilip.py:926)
2026-01-07 21:18:59 - INFO - total_loss: 0.3363696336746216, masked_loc_loss: 0.06682570278644562, masked_gen_loss: 0.26954394578933716 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:05 - INFO - total_loss: 0.39863651990890503, masked_loc_loss: 0.045238643884658813, masked_gen_loss: 0.3533978760242462 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:12 - INFO - total_loss: 0.3944585621356964, masked_loc_loss: 0.03286933898925781, masked_gen_loss: 0.3615892231464386 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:19 - INFO - total_loss: 0.3898315131664276, masked_loc_loss: 0.043730948120355606, masked_gen_loss: 0.3461005687713623 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:25 - INFO - total_loss: 0.33825165033340454, masked_loc_loss: 0.049461480230093, masked_gen_loss: 0.28879016637802124 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:31 - INFO - total_loss: 0.38321396708488464, masked_loc_loss: 0.03760460764169693, masked_gen_loss: 0.3456093668937683 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:38 - INFO - total_loss: 0.3657751679420471, masked_loc_loss: 0.04107728227972984, masked_gen_loss: 0.324697881937027 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:45 - INFO - total_loss: 0.4269244968891144, masked_loc_loss: 0.021228691563010216, masked_gen_loss: 0.4056957960128784 - (2851716:unified_unilip.py:926)
2026-01-07 21:19:54 - INFO - total_loss: 0.388864129781723, masked_loc_loss: 0.033088117837905884, masked_gen_loss: 0.35577601194381714 - (2851716:unified_unilip.py:926)
2026-01-07 21:20:09 - INFO - total_loss: 0.3808130621910095, masked_loc_loss: 0.04402107745409012, masked_gen_loss: 0.3367919921875 - (2851716:unified_unilip.py:926)
2026-01-07 21:20:24 - INFO - total_loss: 0.36468440294265747, masked_loc_loss: 0.0298138577491045, masked_gen_loss: 0.3348705470561981 - (2851716:unified_unilip.py:926)
2026-01-07 21:20:38 - INFO - total_loss: 0.3813305199146271, masked_loc_loss: 0.0538303479552269, masked_gen_loss: 0.3275001645088196 - (2851716:unified_unilip.py:926)
2026-01-07 21:20:49 - INFO - total_loss: 0.40404975414276123, masked_loc_loss: 0.05557128041982651, masked_gen_loss: 0.3484784662723541 - (2851716:unified_unilip.py:926)
2026-01-07 21:20:55 - INFO - total_loss: 0.3768996596336365, masked_loc_loss: 0.036114152520895004, masked_gen_loss: 0.34078550338745117 - (2851716:unified_unilip.py:926)
2026-01-07 21:21:04 - INFO - total_loss: 0.3451708257198334, masked_loc_loss: 0.03520312160253525, masked_gen_loss: 0.30996769666671753 - (2851716:unified_unilip.py:926)
2026-01-07 21:21:19 - INFO - total_loss: 0.38078010082244873, masked_loc_loss: 0.06835202872753143, masked_gen_loss: 0.3124280571937561 - (2851716:unified_unilip.py:926)
2026-01-07 21:21:33 - INFO - total_loss: 0.3835434913635254, masked_loc_loss: 0.05699186027050018, masked_gen_loss: 0.3265516459941864 - (2851716:unified_unilip.py:926)
2026-01-07 21:21:48 - INFO - total_loss: 0.40244942903518677, masked_loc_loss: 0.03747878223657608, masked_gen_loss: 0.3649706542491913 - (2851716:unified_unilip.py:926)
2026-01-07 21:22:00 - INFO - total_loss: 0.41018450260162354, masked_loc_loss: 0.03999653458595276, masked_gen_loss: 0.3701879680156708 - (2851716:unified_unilip.py:926)
2026-01-07 21:22:06 - INFO - total_loss: 0.36631160974502563, masked_loc_loss: 0.06616837531328201, masked_gen_loss: 0.3001432418823242 - (2851716:unified_unilip.py:926)
2026-01-07 21:22:13 - INFO - total_loss: 0.3234666883945465, masked_loc_loss: 0.028001993894577026, masked_gen_loss: 0.2954646944999695 - (2851716:unified_unilip.py:926)
2026-01-07 21:22:26 - INFO - total_loss: 0.4006946384906769, masked_loc_loss: 0.02746090665459633, masked_gen_loss: 0.37323373556137085 - (2851716:unified_unilip.py:926)
2026-01-07 21:22:41 - INFO - total_loss: 0.41267725825309753, masked_loc_loss: 0.030578462406992912, masked_gen_loss: 0.3820987939834595 - (2851716:unified_unilip.py:926)
2026-01-07 21:22:56 - INFO - total_loss: 0.3495676815509796, masked_loc_loss: 0.03235016018152237, masked_gen_loss: 0.31721752882003784 - (2851716:unified_unilip.py:926)
2026-01-07 21:23:11 - INFO - total_loss: 0.3938071131706238, masked_loc_loss: 0.04183071106672287, masked_gen_loss: 0.3519763946533203 - (2851716:unified_unilip.py:926)
2026-01-07 21:23:17 - INFO - total_loss: 0.3298730254173279, masked_loc_loss: 0.032272517681121826, masked_gen_loss: 0.29760050773620605 - (2851716:unified_unilip.py:926)
2026-01-07 21:23:26 - INFO - total_loss: 0.4275377690792084, masked_loc_loss: 0.043248631060123444, masked_gen_loss: 0.3842891454696655 - (2851716:unified_unilip.py:926)
2026-01-07 21:23:41 - INFO - total_loss: 0.40581172704696655, masked_loc_loss: 0.06061374768614769, masked_gen_loss: 0.34519797563552856 - (2851716:unified_unilip.py:926)
2026-01-07 21:23:55 - INFO - total_loss: 0.3856166899204254, masked_loc_loss: 0.03040790557861328, masked_gen_loss: 0.35520878434181213 - (2851716:unified_unilip.py:926)
2026-01-07 21:24:10 - INFO - total_loss: 0.3729666471481323, masked_loc_loss: 0.044109195470809937, masked_gen_loss: 0.3288574516773224 - (2851716:unified_unilip.py:926)
2026-01-07 21:24:21 - INFO - total_loss: 0.46065980195999146, masked_loc_loss: 0.04123520478606224, masked_gen_loss: 0.4194245934486389 - (2851716:unified_unilip.py:926)
2026-01-07 21:24:32 - INFO - total_loss: 0.39161360263824463, masked_loc_loss: 0.05064016580581665, masked_gen_loss: 0.340973436832428 - (2851716:unified_unilip.py:926)
2026-01-07 21:24:46 - INFO - total_loss: 0.3700467646121979, masked_loc_loss: 0.029447373002767563, masked_gen_loss: 0.34059938788414 - (2851716:unified_unilip.py:926)
2026-01-07 21:25:00 - INFO - total_loss: 0.38564974069595337, masked_loc_loss: 0.051777347922325134, masked_gen_loss: 0.33387240767478943 - (2851716:unified_unilip.py:926)
2026-01-07 21:25:15 - INFO - total_loss: 0.4000227153301239, masked_loc_loss: 0.049932632595300674, masked_gen_loss: 0.3500900864601135 - (2851716:unified_unilip.py:926)
2026-01-07 21:25:25 - INFO - total_loss: 0.39818626642227173, masked_loc_loss: 0.051989100873470306, masked_gen_loss: 0.3461971580982208 - (2851716:unified_unilip.py:926)
2026-01-07 21:25:34 - INFO - total_loss: 0.3653421998023987, masked_loc_loss: 0.041163139045238495, masked_gen_loss: 0.3241790533065796 - (2851716:unified_unilip.py:926)
2026-01-07 21:25:48 - INFO - total_loss: 0.3818025588989258, masked_loc_loss: 0.04323607310652733, masked_gen_loss: 0.33856648206710815 - (2851716:unified_unilip.py:926)
2026-01-07 21:26:02 - INFO - total_loss: 0.38079750537872314, masked_loc_loss: 0.04963357374072075, masked_gen_loss: 0.3311639428138733 - (2851716:unified_unilip.py:926)
2026-01-07 21:26:17 - INFO - total_loss: 0.37004750967025757, masked_loc_loss: 0.04234785586595535, masked_gen_loss: 0.3276996612548828 - (2851716:unified_unilip.py:926)
2026-01-07 21:26:28 - INFO - total_loss: 0.44181209802627563, masked_loc_loss: 0.019920896738767624, masked_gen_loss: 0.4218912124633789 - (2851716:unified_unilip.py:926)
2026-01-07 21:26:38 - INFO - total_loss: 0.418606698513031, masked_loc_loss: 0.04013644531369209, masked_gen_loss: 0.378470242023468 - (2851716:unified_unilip.py:926)
2026-01-07 21:26:52 - INFO - total_loss: 0.4194597899913788, masked_loc_loss: 0.02845670096576214, masked_gen_loss: 0.3910031020641327 - (2851716:unified_unilip.py:926)
2026-01-07 21:27:06 - INFO - total_loss: 0.3627904951572418, masked_loc_loss: 0.05909493565559387, masked_gen_loss: 0.30369555950164795 - (2851716:unified_unilip.py:926)
2026-01-07 21:27:21 - INFO - total_loss: 0.41299763321876526, masked_loc_loss: 0.04421388730406761, masked_gen_loss: 0.36878374218940735 - (2851716:unified_unilip.py:926)
2026-01-07 21:27:32 - INFO - total_loss: 0.42089006304740906, masked_loc_loss: 0.04280542582273483, masked_gen_loss: 0.37808462977409363 - (2851716:unified_unilip.py:926)
2026-01-07 21:27:39 - INFO - total_loss: 0.4126167297363281, masked_loc_loss: 0.04708492010831833, masked_gen_loss: 0.3655318021774292 - (2851716:unified_unilip.py:926)
2026-01-07 21:27:53 - INFO - total_loss: 0.40474969148635864, masked_loc_loss: 0.046136870980262756, masked_gen_loss: 0.3586128354072571 - (2851716:unified_unilip.py:926)
2026-01-07 21:28:08 - INFO - total_loss: 0.3181658387184143, masked_loc_loss: 0.03921812027692795, masked_gen_loss: 0.27894771099090576 - (2851716:unified_unilip.py:926)
2026-01-07 21:28:22 - INFO - total_loss: 0.37312841415405273, masked_loc_loss: 0.04874424636363983, masked_gen_loss: 0.3243841528892517 - (2851716:unified_unilip.py:926)
2026-01-07 21:28:36 - INFO - total_loss: 0.33223503828048706, masked_loc_loss: 0.04519600793719292, masked_gen_loss: 0.28703904151916504 - (2851716:unified_unilip.py:926)
2026-01-07 21:28:44 - INFO - total_loss: 0.33348768949508667, masked_loc_loss: 0.0323910266160965, masked_gen_loss: 0.301096647977829 - (2851716:unified_unilip.py:926)
2026-01-07 21:28:58 - INFO - total_loss: 0.4260854721069336, masked_loc_loss: 0.027326242998242378, masked_gen_loss: 0.39875921607017517 - (2851716:unified_unilip.py:926)
2026-01-07 21:29:13 - INFO - total_loss: 0.3960230052471161, masked_loc_loss: 0.06294843554496765, masked_gen_loss: 0.33307456970214844 - (2851716:unified_unilip.py:926)
2026-01-07 21:29:28 - INFO - total_loss: 0.4261370599269867, masked_loc_loss: 0.03772759065032005, masked_gen_loss: 0.38840946555137634 - (2851716:unified_unilip.py:926)
2026-01-07 21:29:40 - INFO - total_loss: 0.414293110370636, masked_loc_loss: 0.04888550192117691, masked_gen_loss: 0.3654076159000397 - (2851716:unified_unilip.py:926)
2026-01-07 21:29:55 - INFO - total_loss: 0.3533439040184021, masked_loc_loss: 0.036365676671266556, masked_gen_loss: 0.31697821617126465 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:09 - INFO - total_loss: 0.38023683428764343, masked_loc_loss: 0.028846409171819687, masked_gen_loss: 0.35139042139053345 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:23 - INFO - total_loss: 0.3502320647239685, masked_loc_loss: 0.0435052327811718, masked_gen_loss: 0.3067268431186676 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:30 - INFO - total_loss: 0.3864190876483917, masked_loc_loss: 0.03576844930648804, masked_gen_loss: 0.3506506383419037 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:37 - INFO - total_loss: 0.4079025685787201, masked_loc_loss: 0.03995492309331894, masked_gen_loss: 0.36794763803482056 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:43 - INFO - total_loss: 0.38308751583099365, masked_loc_loss: 0.04224115610122681, masked_gen_loss: 0.34084635972976685 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:52 - INFO - total_loss: 0.33793649077415466, masked_loc_loss: 0.050817396491765976, masked_gen_loss: 0.2871190905570984 - (2851716:unified_unilip.py:926)
2026-01-07 21:30:59 - INFO - total_loss: 0.3845983147621155, masked_loc_loss: 0.0473596528172493, masked_gen_loss: 0.3372386693954468 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:05 - INFO - total_loss: 0.3753633201122284, masked_loc_loss: 0.03509758785367012, masked_gen_loss: 0.3402657210826874 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:11 - INFO - total_loss: 0.3854103684425354, masked_loc_loss: 0.03792964294552803, masked_gen_loss: 0.3474807143211365 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:18 - INFO - total_loss: 0.4025785028934479, masked_loc_loss: 0.03774639591574669, masked_gen_loss: 0.3648321032524109 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:24 - INFO - total_loss: 0.3806632459163666, masked_loc_loss: 0.031166888773441315, masked_gen_loss: 0.34949636459350586 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:31 - INFO - total_loss: 0.3815368115901947, masked_loc_loss: 0.03240189328789711, masked_gen_loss: 0.3491349220275879 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:45 - INFO - total_loss: 0.37984973192214966, masked_loc_loss: 0.04046144336462021, masked_gen_loss: 0.33938828110694885 - (2851716:unified_unilip.py:926)
2026-01-07 21:31:59 - INFO - total_loss: 0.40228596329689026, masked_loc_loss: 0.02996906079351902, masked_gen_loss: 0.3723168969154358 - (2851716:unified_unilip.py:926)
2026-01-07 21:32:14 - INFO - total_loss: 0.39805421233177185, masked_loc_loss: 0.043445732444524765, masked_gen_loss: 0.3546084761619568 - (2851716:unified_unilip.py:926)
2026-01-07 21:32:28 - INFO - total_loss: 0.3785296380519867, masked_loc_loss: 0.024228783324360847, masked_gen_loss: 0.354300856590271 - (2851716:unified_unilip.py:926)
2026-01-07 21:32:34 - INFO - total_loss: 0.41216641664505005, masked_loc_loss: 0.054391391575336456, masked_gen_loss: 0.3577750325202942 - (2851716:unified_unilip.py:926)
2026-01-07 21:32:48 - INFO - total_loss: 0.37146371603012085, masked_loc_loss: 0.03532273322343826, masked_gen_loss: 0.3361409902572632 - (2851716:unified_unilip.py:926)
2026-01-07 21:33:03 - INFO - total_loss: 0.3380565643310547, masked_loc_loss: 0.030744753777980804, masked_gen_loss: 0.3073118031024933 - (2851716:unified_unilip.py:926)
2026-01-07 21:33:17 - INFO - total_loss: 0.3660881817340851, masked_loc_loss: 0.04959052801132202, masked_gen_loss: 0.31649765372276306 - (2851716:unified_unilip.py:926)
2026-01-07 21:33:31 - INFO - total_loss: 0.37967970967292786, masked_loc_loss: 0.040348611772060394, masked_gen_loss: 0.33933109045028687 - (2851716:unified_unilip.py:926)
2026-01-07 21:33:39 - INFO - total_loss: 0.402127206325531, masked_loc_loss: 0.04986423999071121, masked_gen_loss: 0.3522629737854004 - (2851716:unified_unilip.py:926)
2026-01-07 21:33:53 - INFO - total_loss: 0.3639305531978607, masked_loc_loss: 0.04297605901956558, masked_gen_loss: 0.32095450162887573 - (2851716:unified_unilip.py:926)
2026-01-07 21:34:07 - INFO - total_loss: 0.37399667501449585, masked_loc_loss: 0.05979852378368378, masked_gen_loss: 0.31419816613197327 - (2851716:unified_unilip.py:926)
2026-01-07 21:34:21 - INFO - total_loss: 0.42399972677230835, masked_loc_loss: 0.04466395825147629, masked_gen_loss: 0.37933576107025146 - (2851716:unified_unilip.py:926)
2026-01-07 21:34:34 - INFO - total_loss: 0.4053061306476593, masked_loc_loss: 0.057619061321020126, masked_gen_loss: 0.3476870656013489 - (2851716:unified_unilip.py:926)
2026-01-07 21:35:59 - INFO - total_loss: 0.379647433757782, masked_loc_loss: 0.038664571940898895, masked_gen_loss: 0.3409828543663025 - (2851716:unified_unilip.py:926)
2026-01-07 21:36:12 - INFO - total_loss: 0.3636179268360138, masked_loc_loss: 0.04151556268334389, masked_gen_loss: 0.3221023678779602 - (2851716:unified_unilip.py:926)
2026-01-07 21:36:26 - INFO - total_loss: 0.38814613223075867, masked_loc_loss: 0.020482225343585014, masked_gen_loss: 0.3676639199256897 - (2851716:unified_unilip.py:926)
2026-01-07 21:36:32 - INFO - total_loss: 0.35530897974967957, masked_loc_loss: 0.045077741146087646, masked_gen_loss: 0.3102312386035919 - (2851716:unified_unilip.py:926)
2026-01-07 21:36:38 - INFO - total_loss: 0.35588759183883667, masked_loc_loss: 0.03323713690042496, masked_gen_loss: 0.3226504623889923 - (2851716:unified_unilip.py:926)
2026-01-07 21:36:44 - INFO - total_loss: 0.3865486681461334, masked_loc_loss: 0.04580540210008621, masked_gen_loss: 0.3407432734966278 - (2851716:unified_unilip.py:926)
2026-01-07 21:36:50 - INFO - total_loss: 0.3570438623428345, masked_loc_loss: 0.034496456384658813, masked_gen_loss: 0.32254740595817566 - (2851716:unified_unilip.py:926)
2026-01-07 21:37:00 - INFO - total_loss: 0.3342773914337158, masked_loc_loss: 0.03582017123699188, masked_gen_loss: 0.29845720529556274 - (2851716:unified_unilip.py:926)
2026-01-07 21:37:15 - INFO - total_loss: 0.38725337386131287, masked_loc_loss: 0.04429933428764343, masked_gen_loss: 0.34295403957366943 - (2851716:unified_unilip.py:926)
2026-01-07 21:37:29 - INFO - total_loss: 0.37658941745758057, masked_loc_loss: 0.04699738323688507, masked_gen_loss: 0.3295920491218567 - (2851716:unified_unilip.py:926)
2026-01-07 21:37:44 - INFO - total_loss: 0.40039345622062683, masked_loc_loss: 0.04277249425649643, masked_gen_loss: 0.3576209545135498 - (2851716:unified_unilip.py:926)
2026-01-07 21:37:54 - INFO - total_loss: 0.3897026777267456, masked_loc_loss: 0.029395692050457, masked_gen_loss: 0.360306978225708 - (2851716:unified_unilip.py:926)
2026-01-07 21:38:01 - INFO - total_loss: 0.3645663857460022, masked_loc_loss: 0.03405366837978363, masked_gen_loss: 0.3305127024650574 - (2851716:unified_unilip.py:926)
2026-01-07 21:38:15 - INFO - total_loss: 0.4203835129737854, masked_loc_loss: 0.06098633259534836, masked_gen_loss: 0.35939717292785645 - (2851716:unified_unilip.py:926)
2026-01-07 21:38:30 - INFO - total_loss: 0.4442102909088135, masked_loc_loss: 0.07865424454212189, masked_gen_loss: 0.3655560612678528 - (2851716:unified_unilip.py:926)
2026-01-07 21:38:44 - INFO - total_loss: 0.38530534505844116, masked_loc_loss: 0.02652900479733944, masked_gen_loss: 0.358776330947876 - (2851716:unified_unilip.py:926)
2026-01-07 21:38:58 - INFO - total_loss: 0.3480396866798401, masked_loc_loss: 0.05790404602885246, masked_gen_loss: 0.2901356518268585 - (2851716:unified_unilip.py:926)
2026-01-07 21:39:04 - INFO - total_loss: 0.387918621301651, masked_loc_loss: 0.04599280282855034, masked_gen_loss: 0.34192582964897156 - (2851716:unified_unilip.py:926)
2026-01-07 21:39:18 - INFO - total_loss: 0.40691834688186646, masked_loc_loss: 0.03718407452106476, masked_gen_loss: 0.3697342574596405 - (2851716:unified_unilip.py:926)
2026-01-07 21:39:32 - INFO - total_loss: 0.4074081480503082, masked_loc_loss: 0.06280869245529175, masked_gen_loss: 0.3445994555950165 - (2851716:unified_unilip.py:926)
2026-01-07 21:39:46 - INFO - total_loss: 0.3887244760990143, masked_loc_loss: 0.049544282257556915, masked_gen_loss: 0.33918020129203796 - (2851716:unified_unilip.py:926)
2026-01-07 21:40:01 - INFO - total_loss: 0.3804331421852112, masked_loc_loss: 0.047162167727947235, masked_gen_loss: 0.33327096700668335 - (2851716:unified_unilip.py:926)
2026-01-07 21:40:07 - INFO - total_loss: 0.34769895672798157, masked_loc_loss: 0.04319491982460022, masked_gen_loss: 0.30450403690338135 - (2851716:unified_unilip.py:926)
2026-01-07 21:40:20 - INFO - total_loss: 0.3774118721485138, masked_loc_loss: 0.055570363998413086, masked_gen_loss: 0.3218415081501007 - (2851716:unified_unilip.py:926)
2026-01-07 21:40:35 - INFO - total_loss: 0.4109165370464325, masked_loc_loss: 0.03954460099339485, masked_gen_loss: 0.37137192487716675 - (2851716:unified_unilip.py:926)
2026-01-07 21:40:49 - INFO - total_loss: 0.3777679204940796, masked_loc_loss: 0.02430100366473198, masked_gen_loss: 0.3534669280052185 - (2851716:unified_unilip.py:926)
2026-01-07 21:41:03 - INFO - total_loss: 0.3078330457210541, masked_loc_loss: 0.04616881161928177, masked_gen_loss: 0.2616642415523529 - (2851716:unified_unilip.py:926)
2026-01-07 21:41:12 - INFO - total_loss: 0.37586358189582825, masked_loc_loss: 0.05790690705180168, masked_gen_loss: 0.31795668601989746 - (2851716:unified_unilip.py:926)
2026-01-07 21:41:27 - INFO - total_loss: 0.41790154576301575, masked_loc_loss: 0.051430843770504, masked_gen_loss: 0.36647069454193115 - (2851716:unified_unilip.py:926)
2026-01-07 21:41:41 - INFO - total_loss: 0.41456055641174316, masked_loc_loss: 0.05239766836166382, masked_gen_loss: 0.36216288805007935 - (2851716:unified_unilip.py:926)
2026-01-07 21:41:54 - INFO - total_loss: 0.40248069167137146, masked_loc_loss: 0.039062708616256714, masked_gen_loss: 0.36341798305511475 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:00 - INFO - total_loss: 0.36483192443847656, masked_loc_loss: 0.03951410949230194, masked_gen_loss: 0.3253178298473358 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:07 - INFO - total_loss: 0.37883415818214417, masked_loc_loss: 0.03912361338734627, masked_gen_loss: 0.339710533618927 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:13 - INFO - total_loss: 0.37947070598602295, masked_loc_loss: 0.051964059472084045, masked_gen_loss: 0.3275066316127777 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:20 - INFO - total_loss: 0.31892335414886475, masked_loc_loss: 0.026965677738189697, masked_gen_loss: 0.29195767641067505 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:26 - INFO - total_loss: 0.39062821865081787, masked_loc_loss: 0.030398281291127205, masked_gen_loss: 0.3602299392223358 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:33 - INFO - total_loss: 0.3128238320350647, masked_loc_loss: 0.041730739176273346, masked_gen_loss: 0.27109310030937195 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:39 - INFO - total_loss: 0.367757111787796, masked_loc_loss: 0.04816342517733574, masked_gen_loss: 0.3195936977863312 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:46 - INFO - total_loss: 0.3452662229537964, masked_loc_loss: 0.027358602732419968, masked_gen_loss: 0.3179076313972473 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:52 - INFO - total_loss: 0.41223183274269104, masked_loc_loss: 0.030791010707616806, masked_gen_loss: 0.38144081830978394 - (2851716:unified_unilip.py:926)
2026-01-07 21:42:59 - INFO - total_loss: 0.39906737208366394, masked_loc_loss: 0.06820321828126907, masked_gen_loss: 0.33086416125297546 - (2851716:unified_unilip.py:926)
2026-01-07 21:43:05 - INFO - total_loss: 0.36976879835128784, masked_loc_loss: 0.039914052933454514, masked_gen_loss: 0.3298547565937042 - (2851716:unified_unilip.py:926)
2026-01-07 21:43:12 - INFO - total_loss: 0.386007159948349, masked_loc_loss: 0.044432125985622406, masked_gen_loss: 0.341575026512146 - (2851716:unified_unilip.py:926)
2026-01-07 21:43:26 - INFO - total_loss: 0.3543630838394165, masked_loc_loss: 0.04113977402448654, masked_gen_loss: 0.31322330236434937 - (2851716:unified_unilip.py:926)
2026-01-07 21:43:41 - INFO - total_loss: 0.43384432792663574, masked_loc_loss: 0.03402281180024147, masked_gen_loss: 0.39982151985168457 - (2851716:unified_unilip.py:926)
2026-01-07 21:43:55 - INFO - total_loss: 0.4194187819957733, masked_loc_loss: 0.030777953565120697, masked_gen_loss: 0.388640820980072 - (2851716:unified_unilip.py:926)
2026-01-07 21:44:10 - INFO - total_loss: 0.3505233824253082, masked_loc_loss: 0.04043712839484215, masked_gen_loss: 0.3100862503051758 - (2851716:unified_unilip.py:926)
2026-01-07 21:44:17 - INFO - total_loss: 0.36950182914733887, masked_loc_loss: 0.03036295250058174, masked_gen_loss: 0.33913886547088623 - (2851716:unified_unilip.py:926)
2026-01-07 21:44:26 - INFO - total_loss: 0.3081132769584656, masked_loc_loss: 0.04322350025177002, masked_gen_loss: 0.26488977670669556 - (2851716:unified_unilip.py:926)
2026-01-07 21:44:40 - INFO - total_loss: 0.33122068643569946, masked_loc_loss: 0.04162275418639183, masked_gen_loss: 0.28959792852401733 - (2851716:unified_unilip.py:926)
2026-01-07 21:44:54 - INFO - total_loss: 0.4090850055217743, masked_loc_loss: 0.046361275017261505, masked_gen_loss: 0.3627237379550934 - (2851716:unified_unilip.py:926)
2026-01-07 21:45:09 - INFO - total_loss: 0.37357497215270996, masked_loc_loss: 0.04788931459188461, masked_gen_loss: 0.32568565011024475 - (2851716:unified_unilip.py:926)
2026-01-07 21:45:21 - INFO - total_loss: 0.3875904083251953, masked_loc_loss: 0.0645955353975296, masked_gen_loss: 0.3229948878288269 - (2851716:unified_unilip.py:926)
2026-01-07 21:45:27 - INFO - total_loss: 0.3505827784538269, masked_loc_loss: 0.04788762331008911, masked_gen_loss: 0.3026951551437378 - (2851716:unified_unilip.py:926)
2026-01-07 21:45:40 - INFO - total_loss: 0.405260294675827, masked_loc_loss: 0.04672429710626602, masked_gen_loss: 0.3585360050201416 - (2851716:unified_unilip.py:926)
2026-01-07 21:45:55 - INFO - total_loss: 0.4153607189655304, masked_loc_loss: 0.04457422345876694, masked_gen_loss: 0.37078648805618286 - (2851716:unified_unilip.py:926)
2026-01-07 21:46:09 - INFO - total_loss: 0.36314719915390015, masked_loc_loss: 0.05146263539791107, masked_gen_loss: 0.3116845488548279 - (2851716:unified_unilip.py:926)
2026-01-07 21:46:23 - INFO - total_loss: 0.38552260398864746, masked_loc_loss: 0.061032962054014206, masked_gen_loss: 0.32448965311050415 - (2851716:unified_unilip.py:926)
2026-01-07 21:46:30 - INFO - total_loss: 0.469475120306015, masked_loc_loss: 0.019223671406507492, masked_gen_loss: 0.4502514600753784 - (2851716:unified_unilip.py:926)
2026-01-07 21:46:40 - INFO - total_loss: 0.35273876786231995, masked_loc_loss: 0.03830740973353386, masked_gen_loss: 0.314431369304657 - (2851716:unified_unilip.py:926)
2026-01-07 21:46:54 - INFO - total_loss: 0.376817911863327, masked_loc_loss: 0.014508054591715336, masked_gen_loss: 0.36230984330177307 - (2851716:unified_unilip.py:926)
2026-01-07 21:47:09 - INFO - total_loss: 0.4217514395713806, masked_loc_loss: 0.06599251925945282, masked_gen_loss: 0.3557589054107666 - (2851716:unified_unilip.py:926)
2026-01-07 21:47:23 - INFO - total_loss: 0.3901306986808777, masked_loc_loss: 0.03457801043987274, masked_gen_loss: 0.35555270314216614 - (2851716:unified_unilip.py:926)
2026-01-07 21:47:33 - INFO - total_loss: 0.40405720472335815, masked_loc_loss: 0.05014878138899803, masked_gen_loss: 0.3539084196090698 - (2851716:unified_unilip.py:926)
2026-01-07 21:47:40 - INFO - total_loss: 0.3584933876991272, masked_loc_loss: 0.03196312487125397, masked_gen_loss: 0.3265302777290344 - (2851716:unified_unilip.py:926)
2026-01-07 21:47:55 - INFO - total_loss: 0.3872383236885071, masked_loc_loss: 0.03544003888964653, masked_gen_loss: 0.35179829597473145 - (2851716:unified_unilip.py:926)
2026-01-07 21:48:09 - INFO - total_loss: 0.39500269293785095, masked_loc_loss: 0.033843714743852615, masked_gen_loss: 0.36115896701812744 - (2851716:unified_unilip.py:926)
2026-01-07 21:48:23 - INFO - total_loss: 0.39016246795654297, masked_loc_loss: 0.05571354553103447, masked_gen_loss: 0.3344489336013794 - (2851716:unified_unilip.py:926)
2026-01-07 21:48:37 - INFO - total_loss: 0.3794821798801422, masked_loc_loss: 0.04846014827489853, masked_gen_loss: 0.3310220241546631 - (2851716:unified_unilip.py:926)
2026-01-07 21:48:44 - INFO - total_loss: 0.41074779629707336, masked_loc_loss: 0.04547930136322975, masked_gen_loss: 0.3652684986591339 - (2851716:unified_unilip.py:926)
2026-01-07 21:48:59 - INFO - total_loss: 0.4120889902114868, masked_loc_loss: 0.052731968462467194, masked_gen_loss: 0.3593570291996002 - (2851716:unified_unilip.py:926)
2026-01-07 21:49:13 - INFO - total_loss: 0.4095715582370758, masked_loc_loss: 0.035272497683763504, masked_gen_loss: 0.3742990493774414 - (2851716:unified_unilip.py:926)
2026-01-07 21:49:28 - INFO - total_loss: 0.3988255560398102, masked_loc_loss: 0.03765869140625, masked_gen_loss: 0.3611668646335602 - (2851716:unified_unilip.py:926)
2026-01-07 21:49:42 - INFO - total_loss: 0.38095539808273315, masked_loc_loss: 0.031028445810079575, masked_gen_loss: 0.3499269485473633 - (2851716:unified_unilip.py:926)
2026-01-07 21:49:52 - INFO - total_loss: 0.38503608107566833, masked_loc_loss: 0.04686906933784485, masked_gen_loss: 0.3381670117378235 - (2851716:unified_unilip.py:926)
2026-01-07 21:50:07 - INFO - total_loss: 0.33162832260131836, masked_loc_loss: 0.054132603108882904, masked_gen_loss: 0.27749571204185486 - (2851716:unified_unilip.py:926)
2026-01-07 21:50:21 - INFO - total_loss: 0.414216548204422, masked_loc_loss: 0.042416490614414215, masked_gen_loss: 0.3718000650405884 - (2851716:unified_unilip.py:926)
2026-01-07 21:50:36 - INFO - total_loss: 0.3363872170448303, masked_loc_loss: 0.04376541078090668, masked_gen_loss: 0.29262182116508484 - (2851716:unified_unilip.py:926)
2026-01-07 21:50:47 - INFO - total_loss: 0.3885346055030823, masked_loc_loss: 0.04450273513793945, masked_gen_loss: 0.3440318703651428 - (2851716:unified_unilip.py:926)
2026-01-07 21:51:00 - INFO - total_loss: 0.33557629585266113, masked_loc_loss: 0.050304532051086426, masked_gen_loss: 0.2852717638015747 - (2851716:unified_unilip.py:926)
2026-01-07 21:51:15 - INFO - total_loss: 0.39753273129463196, masked_loc_loss: 0.03981868177652359, masked_gen_loss: 0.35771405696868896 - (2851716:unified_unilip.py:926)
2026-01-07 21:51:29 - INFO - total_loss: 0.33226487040519714, masked_loc_loss: 0.038162559270858765, masked_gen_loss: 0.2941023111343384 - (2851716:unified_unilip.py:926)
2026-01-07 21:51:44 - INFO - total_loss: 0.3790709674358368, masked_loc_loss: 0.03658415749669075, masked_gen_loss: 0.34248679876327515 - (2851716:unified_unilip.py:926)
2026-01-07 21:51:54 - INFO - total_loss: 0.4747691750526428, masked_loc_loss: 0.07023780047893524, masked_gen_loss: 0.4045313596725464 - (2851716:unified_unilip.py:926)
2026-01-07 21:52:08 - INFO - total_loss: 0.3400060534477234, masked_loc_loss: 0.027676982805132866, masked_gen_loss: 0.31232908368110657 - (2851716:unified_unilip.py:926)
2026-01-07 21:52:22 - INFO - total_loss: 0.38991278409957886, masked_loc_loss: 0.0838187038898468, masked_gen_loss: 0.30609408020973206 - (2851716:unified_unilip.py:926)
2026-01-07 21:52:37 - INFO - total_loss: 0.35217371582984924, masked_loc_loss: 0.02675793692469597, masked_gen_loss: 0.32541579008102417 - (2851716:unified_unilip.py:926)
2026-01-07 21:52:48 - INFO - total_loss: 0.3686368763446808, masked_loc_loss: 0.023093977943062782, masked_gen_loss: 0.34554290771484375 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:02 - INFO - total_loss: 0.38974422216415405, masked_loc_loss: 0.026843644678592682, masked_gen_loss: 0.36290058493614197 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:16 - INFO - total_loss: 0.3882504999637604, masked_loc_loss: 0.06181984767317772, masked_gen_loss: 0.32643064856529236 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:30 - INFO - total_loss: 0.40836676955223083, masked_loc_loss: 0.03956436365842819, masked_gen_loss: 0.36880239844322205 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:37 - INFO - total_loss: 0.3721710443496704, masked_loc_loss: 0.01844513602554798, masked_gen_loss: 0.3537259101867676 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:43 - INFO - total_loss: 0.39557939767837524, masked_loc_loss: 0.04403302073478699, masked_gen_loss: 0.35154637694358826 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:49 - INFO - total_loss: 0.3829144239425659, masked_loc_loss: 0.04902810603380203, masked_gen_loss: 0.3338863253593445 - (2851716:unified_unilip.py:926)
2026-01-07 21:53:56 - INFO - total_loss: 0.35202428698539734, masked_loc_loss: 0.04796922579407692, masked_gen_loss: 0.3040550649166107 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:02 - INFO - total_loss: 0.38479897379875183, masked_loc_loss: 0.0607234463095665, masked_gen_loss: 0.32407552003860474 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:09 - INFO - total_loss: 0.37530186772346497, masked_loc_loss: 0.060523949563503265, masked_gen_loss: 0.3147779107093811 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:15 - INFO - total_loss: 0.34055331349372864, masked_loc_loss: 0.029284963384270668, masked_gen_loss: 0.3112683594226837 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:22 - INFO - total_loss: 0.37764737010002136, masked_loc_loss: 0.02711416594684124, masked_gen_loss: 0.35053321719169617 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:28 - INFO - total_loss: 0.3696478605270386, masked_loc_loss: 0.052581094205379486, masked_gen_loss: 0.3170667588710785 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:35 - INFO - total_loss: 0.3884260654449463, masked_loc_loss: 0.0298688355833292, masked_gen_loss: 0.35855722427368164 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:41 - INFO - total_loss: 0.3512907028198242, masked_loc_loss: 0.030240289866924286, masked_gen_loss: 0.32105040550231934 - (2851716:unified_unilip.py:926)
2026-01-07 21:54:55 - INFO - total_loss: 0.429501473903656, masked_loc_loss: 0.035078272223472595, masked_gen_loss: 0.3944232165813446 - (2851716:unified_unilip.py:926)
2026-01-07 21:55:10 - INFO - total_loss: 0.362787663936615, masked_loc_loss: 0.040624648332595825, masked_gen_loss: 0.32216301560401917 - (2851716:unified_unilip.py:926)
2026-01-07 21:55:25 - INFO - total_loss: 0.3797323405742645, masked_loc_loss: 0.04393217712640762, masked_gen_loss: 0.3358001708984375 - (2851716:unified_unilip.py:926)
2026-01-07 21:55:39 - INFO - total_loss: 0.3217845857143402, masked_loc_loss: 0.03838518261909485, masked_gen_loss: 0.28339940309524536 - (2851716:unified_unilip.py:926)
2026-01-07 21:55:46 - INFO - total_loss: 0.3788245916366577, masked_loc_loss: 0.02914329618215561, masked_gen_loss: 0.3496812880039215 - (2851716:unified_unilip.py:926)
2026-01-07 21:55:54 - INFO - total_loss: 0.38779038190841675, masked_loc_loss: 0.04362289607524872, masked_gen_loss: 0.3441675007343292 - (2851716:unified_unilip.py:926)
2026-01-07 21:56:09 - INFO - total_loss: 0.39938217401504517, masked_loc_loss: 0.08103130757808685, masked_gen_loss: 0.3183508813381195 - (2851716:unified_unilip.py:926)
2026-01-07 21:56:24 - INFO - total_loss: 0.38006699085235596, masked_loc_loss: 0.06659479439258575, masked_gen_loss: 0.3134722113609314 - (2851716:unified_unilip.py:926)
2026-01-07 21:56:38 - INFO - total_loss: 0.3690473437309265, masked_loc_loss: 0.03662170469760895, masked_gen_loss: 0.33242565393447876 - (2851716:unified_unilip.py:926)
2026-01-07 21:56:50 - INFO - total_loss: 0.3617843687534332, masked_loc_loss: 0.040404148399829865, masked_gen_loss: 0.32138022780418396 - (2851716:unified_unilip.py:926)
2026-01-07 21:56:59 - INFO - total_loss: 0.3815222978591919, masked_loc_loss: 0.03608877956867218, masked_gen_loss: 0.3454335033893585 - (2851716:unified_unilip.py:926)
2026-01-07 21:57:14 - INFO - total_loss: 0.41211262345314026, masked_loc_loss: 0.08025601506233215, masked_gen_loss: 0.3318566083908081 - (2851716:unified_unilip.py:926)
2026-01-07 21:57:28 - INFO - total_loss: 0.33660972118377686, masked_loc_loss: 0.034154221415519714, masked_gen_loss: 0.30245551466941833 - (2851716:unified_unilip.py:926)
2026-01-07 21:57:43 - INFO - total_loss: 0.3473651707172394, masked_loc_loss: 0.0456562340259552, masked_gen_loss: 0.3017089366912842 - (2851716:unified_unilip.py:926)
2026-01-07 21:57:55 - INFO - total_loss: 0.36716562509536743, masked_loc_loss: 0.07143402844667435, masked_gen_loss: 0.2957316040992737 - (2851716:unified_unilip.py:926)
2026-01-07 21:58:01 - INFO - total_loss: 0.37633126974105835, masked_loc_loss: 0.06516093015670776, masked_gen_loss: 0.3111703395843506 - (2851716:unified_unilip.py:926)
2026-01-07 21:58:16 - INFO - total_loss: 0.42654770612716675, masked_loc_loss: 0.06598186492919922, masked_gen_loss: 0.36056584119796753 - (2851716:unified_unilip.py:926)
2026-01-07 21:58:30 - INFO - total_loss: 0.41036033630371094, masked_loc_loss: 0.06608307361602783, masked_gen_loss: 0.3442772626876831 - (2851716:unified_unilip.py:926)
2026-01-07 21:58:44 - INFO - total_loss: 0.3702351450920105, masked_loc_loss: 0.02474595047533512, masked_gen_loss: 0.3454892039299011 - (2851716:unified_unilip.py:926)
2026-01-07 21:58:58 - INFO - total_loss: 0.4167670011520386, masked_loc_loss: 0.04235285520553589, masked_gen_loss: 0.3744141459465027 - (2851716:unified_unilip.py:926)
2026-01-07 21:59:05 - INFO - total_loss: 0.3831559121608734, masked_loc_loss: 0.04347265884280205, masked_gen_loss: 0.33968326449394226 - (2851716:unified_unilip.py:926)
2026-01-07 21:59:19 - INFO - total_loss: 0.41897010803222656, masked_loc_loss: 0.0379670225083828, masked_gen_loss: 0.38100308179855347 - (2851716:unified_unilip.py:926)
2026-01-07 21:59:33 - INFO - total_loss: 0.37732434272766113, masked_loc_loss: 0.04051714390516281, masked_gen_loss: 0.3368071913719177 - (2851716:unified_unilip.py:926)
2026-01-07 21:59:48 - INFO - total_loss: 0.38052892684936523, masked_loc_loss: 0.04053957387804985, masked_gen_loss: 0.3399893641471863 - (2851716:unified_unilip.py:926)
2026-01-07 22:00:02 - INFO - total_loss: 0.316926509141922, masked_loc_loss: 0.02794729359447956, masked_gen_loss: 0.2889792025089264 - (2851716:unified_unilip.py:926)
2026-01-07 22:00:08 - INFO - total_loss: 0.36728519201278687, masked_loc_loss: 0.02954591065645218, masked_gen_loss: 0.3377392888069153 - (2851716:unified_unilip.py:926)
2026-01-07 22:00:22 - INFO - total_loss: 0.3587395250797272, masked_loc_loss: 0.033709876239299774, masked_gen_loss: 0.3250296413898468 - (2851716:unified_unilip.py:926)
2026-01-07 22:00:37 - INFO - total_loss: 0.3651401102542877, masked_loc_loss: 0.033931516110897064, masked_gen_loss: 0.33120858669281006 - (2851716:unified_unilip.py:926)
2026-01-07 22:00:51 - INFO - total_loss: 0.3733654320240021, masked_loc_loss: 0.03962095454335213, masked_gen_loss: 0.33374446630477905 - (2851716:unified_unilip.py:926)
2026-01-07 22:01:06 - INFO - total_loss: 0.3662899136543274, masked_loc_loss: 0.033849723637104034, masked_gen_loss: 0.33244019746780396 - (2851716:unified_unilip.py:926)
2026-01-07 22:01:12 - INFO - total_loss: 0.37449055910110474, masked_loc_loss: 0.027455531060695648, masked_gen_loss: 0.3470350205898285 - (2851716:unified_unilip.py:926)
2026-01-07 22:01:24 - INFO - total_loss: 0.36573663353919983, masked_loc_loss: 0.038840536028146744, masked_gen_loss: 0.3268961012363434 - (2851716:unified_unilip.py:926)
2026-01-07 22:01:39 - INFO - total_loss: 0.32705041766166687, masked_loc_loss: 0.05175444483757019, masked_gen_loss: 0.2752959728240967 - (2851716:unified_unilip.py:926)
2026-01-07 22:01:53 - INFO - total_loss: 0.3373265862464905, masked_loc_loss: 0.04436355456709862, masked_gen_loss: 0.29296302795410156 - (2851716:unified_unilip.py:926)
2026-01-07 22:02:08 - INFO - total_loss: 0.4213065505027771, masked_loc_loss: 0.053895678371191025, masked_gen_loss: 0.3674108684062958 - (2851716:unified_unilip.py:926)
2026-01-07 22:02:17 - INFO - total_loss: 0.37144505977630615, masked_loc_loss: 0.029148884117603302, masked_gen_loss: 0.34229618310928345 - (2851716:unified_unilip.py:926)
2026-01-07 22:02:30 - INFO - total_loss: 0.42285725474357605, masked_loc_loss: 0.03705057501792908, masked_gen_loss: 0.385806679725647 - (2851716:unified_unilip.py:926)
2026-01-07 22:02:45 - INFO - total_loss: 0.32851752638816833, masked_loc_loss: 0.03874821215867996, masked_gen_loss: 0.28976932168006897 - (2851716:unified_unilip.py:926)
2026-01-07 22:02:59 - INFO - total_loss: 0.37176787853240967, masked_loc_loss: 0.06702759861946106, masked_gen_loss: 0.3047402799129486 - (2851716:unified_unilip.py:926)
2026-01-07 22:03:14 - INFO - total_loss: 0.3452543616294861, masked_loc_loss: 0.04522058367729187, masked_gen_loss: 0.3000337779521942 - (2851716:unified_unilip.py:926)
2026-01-07 22:03:21 - INFO - total_loss: 0.38152453303337097, masked_loc_loss: 0.02765451930463314, masked_gen_loss: 0.3538700044155121 - (2851716:unified_unilip.py:926)
2026-01-07 22:03:36 - INFO - total_loss: 0.32213664054870605, masked_loc_loss: 0.038207218050956726, masked_gen_loss: 0.2839294373989105 - (2851716:unified_unilip.py:926)
2026-01-07 22:03:50 - INFO - total_loss: 0.4134635329246521, masked_loc_loss: 0.04278005659580231, masked_gen_loss: 0.370683491230011 - (2851716:unified_unilip.py:926)
2026-01-07 22:04:04 - INFO - total_loss: 0.39643168449401855, masked_loc_loss: 0.0330769419670105, masked_gen_loss: 0.36335474252700806 - (2851716:unified_unilip.py:926)
2026-01-07 22:04:18 - INFO - total_loss: 0.3530087471008301, masked_loc_loss: 0.04470992833375931, masked_gen_loss: 0.30829882621765137 - (2851716:unified_unilip.py:926)
2026-01-07 22:04:29 - INFO - total_loss: 0.38362956047058105, masked_loc_loss: 0.03960653394460678, masked_gen_loss: 0.3440230190753937 - (2851716:unified_unilip.py:926)
2026-01-07 22:04:44 - INFO - total_loss: 0.34535637497901917, masked_loc_loss: 0.030207434669137, masked_gen_loss: 0.3151489496231079 - (2851716:unified_unilip.py:926)
2026-01-07 22:04:58 - INFO - total_loss: 0.3969859778881073, masked_loc_loss: 0.05150703340768814, masked_gen_loss: 0.34547895193099976 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:07 - INFO - total_loss: 0.4062260091304779, masked_loc_loss: 0.053087033331394196, masked_gen_loss: 0.3531389832496643 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:14 - INFO - total_loss: 0.40903669595718384, masked_loc_loss: 0.06856080889701843, masked_gen_loss: 0.3404758870601654 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:20 - INFO - total_loss: 0.3895125687122345, masked_loc_loss: 0.03480221703648567, masked_gen_loss: 0.35471034049987793 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:27 - INFO - total_loss: 0.33738288283348083, masked_loc_loss: 0.01925555430352688, masked_gen_loss: 0.3181273341178894 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:33 - INFO - total_loss: 0.3874015808105469, masked_loc_loss: 0.03694833815097809, masked_gen_loss: 0.3504532277584076 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:39 - INFO - total_loss: 0.3062545359134674, masked_loc_loss: 0.029912233352661133, masked_gen_loss: 0.2763423025608063 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:46 - INFO - total_loss: 0.40941569209098816, masked_loc_loss: 0.02151145599782467, masked_gen_loss: 0.38790422677993774 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:52 - INFO - total_loss: 0.39963746070861816, masked_loc_loss: 0.03303276747465134, masked_gen_loss: 0.36660468578338623 - (2851716:unified_unilip.py:926)
2026-01-07 22:05:59 - INFO - total_loss: 0.31977465748786926, masked_loc_loss: 0.04146193712949753, masked_gen_loss: 0.27831271290779114 - (2851716:unified_unilip.py:926)
2026-01-07 22:06:06 - INFO - total_loss: 0.3607819378376007, masked_loc_loss: 0.029527703300118446, masked_gen_loss: 0.331254243850708 - (2851716:unified_unilip.py:926)
2026-01-07 22:06:12 - INFO - total_loss: 0.38970139622688293, masked_loc_loss: 0.045299503952264786, masked_gen_loss: 0.34440189599990845 - (2851716:unified_unilip.py:926)
2026-01-07 22:06:18 - INFO - total_loss: 0.39380374550819397, masked_loc_loss: 0.06496445089578629, masked_gen_loss: 0.3288393020629883 - (2851716:unified_unilip.py:926)
2026-01-07 22:06:33 - INFO - total_loss: 0.3757576644420624, masked_loc_loss: 0.04142065718770027, masked_gen_loss: 0.3343369960784912 - (2851716:unified_unilip.py:926)
2026-01-07 22:06:47 - INFO - total_loss: 0.3702540695667267, masked_loc_loss: 0.03571222350001335, masked_gen_loss: 0.33454185724258423 - (2851716:unified_unilip.py:926)
2026-01-07 22:07:02 - INFO - total_loss: 0.40944722294807434, masked_loc_loss: 0.05776386335492134, masked_gen_loss: 0.3516833484172821 - (2851716:unified_unilip.py:926)
2026-01-07 22:07:16 - INFO - total_loss: 0.35769808292388916, masked_loc_loss: 0.047361984848976135, masked_gen_loss: 0.3103361129760742 - (2851716:unified_unilip.py:926)
2026-01-07 22:07:23 - INFO - total_loss: 0.38161298632621765, masked_loc_loss: 0.0368197038769722, masked_gen_loss: 0.34479328989982605 - (2851716:unified_unilip.py:926)
2026-01-07 22:07:31 - INFO - total_loss: 0.3731996715068817, masked_loc_loss: 0.024087587371468544, masked_gen_loss: 0.3491120934486389 - (2851716:unified_unilip.py:926)
2026-01-07 22:07:46 - INFO - total_loss: 0.37896397709846497, masked_loc_loss: 0.06265568733215332, masked_gen_loss: 0.31630828976631165 - (2851716:unified_unilip.py:926)
2026-01-07 22:08:01 - INFO - total_loss: 0.38382089138031006, masked_loc_loss: 0.032405924052000046, masked_gen_loss: 0.3514149785041809 - (2851716:unified_unilip.py:926)
2026-01-07 22:08:15 - INFO - total_loss: 0.38296812772750854, masked_loc_loss: 0.044448480010032654, masked_gen_loss: 0.3385196328163147 - (2851716:unified_unilip.py:926)
2026-01-07 22:08:27 - INFO - total_loss: 0.37198808789253235, masked_loc_loss: 0.0387556292116642, masked_gen_loss: 0.33323246240615845 - (2851716:unified_unilip.py:926)
2026-01-07 22:08:35 - INFO - total_loss: 0.35671526193618774, masked_loc_loss: 0.08237701654434204, masked_gen_loss: 0.2743382453918457 - (2851716:unified_unilip.py:926)
2026-01-07 22:08:49 - INFO - total_loss: 0.38197043538093567, masked_loc_loss: 0.03708723187446594, masked_gen_loss: 0.3448832035064697 - (2851716:unified_unilip.py:926)
2026-01-07 22:09:03 - INFO - total_loss: 0.40271812677383423, masked_loc_loss: 0.026565801352262497, masked_gen_loss: 0.3761523365974426 - (2851716:unified_unilip.py:926)
2026-01-07 22:09:18 - INFO - total_loss: 0.43626031279563904, masked_loc_loss: 0.049505673348903656, masked_gen_loss: 0.3867546319961548 - (2851716:unified_unilip.py:926)
2026-01-07 22:09:32 - INFO - total_loss: 0.4188591539859772, masked_loc_loss: 0.04913143068552017, masked_gen_loss: 0.3697277307510376 - (2851716:unified_unilip.py:926)
2026-01-07 22:09:42 - INFO - total_loss: 0.35810452699661255, masked_loc_loss: 0.03205832093954086, masked_gen_loss: 0.3260461986064911 - (2851716:unified_unilip.py:926)
2026-01-07 22:09:57 - INFO - total_loss: 0.38339731097221375, masked_loc_loss: 0.03536127135157585, masked_gen_loss: 0.3480360507965088 - (2851716:unified_unilip.py:926)
2026-01-07 22:10:11 - INFO - total_loss: 0.37071049213409424, masked_loc_loss: 0.04020427167415619, masked_gen_loss: 0.33050620555877686 - (2851716:unified_unilip.py:926)
2026-01-07 22:10:25 - INFO - total_loss: 0.4111816883087158, masked_loc_loss: 0.037600770592689514, masked_gen_loss: 0.3735809326171875 - (2851716:unified_unilip.py:926)
2026-01-07 22:10:36 - INFO - total_loss: 0.3809884786605835, masked_loc_loss: 0.036080773919820786, masked_gen_loss: 0.3449077010154724 - (2851716:unified_unilip.py:926)
2026-01-07 22:10:47 - INFO - total_loss: 0.336805522441864, masked_loc_loss: 0.035916924476623535, masked_gen_loss: 0.3008885979652405 - (2851716:unified_unilip.py:926)
2026-01-07 22:11:01 - INFO - total_loss: 0.39207348227500916, masked_loc_loss: 0.0470222607254982, masked_gen_loss: 0.34505122900009155 - (2851716:unified_unilip.py:926)
2026-01-07 22:11:16 - INFO - total_loss: 0.3526168465614319, masked_loc_loss: 0.049533769488334656, masked_gen_loss: 0.30308306217193604 - (2851716:unified_unilip.py:926)
2026-01-07 22:11:30 - INFO - total_loss: 0.36737746000289917, masked_loc_loss: 0.025963574647903442, masked_gen_loss: 0.3414138853549957 - (2851716:unified_unilip.py:926)
2026-01-07 22:11:39 - INFO - total_loss: 0.3366294801235199, masked_loc_loss: 0.02811947837471962, masked_gen_loss: 0.3085100054740906 - (2851716:unified_unilip.py:926)
2026-01-07 22:11:52 - INFO - total_loss: 0.3279224932193756, masked_loc_loss: 0.06266608834266663, masked_gen_loss: 0.265256404876709 - (2851716:unified_unilip.py:926)
2026-01-07 22:12:06 - INFO - total_loss: 0.45997628569602966, masked_loc_loss: 0.07474642992019653, masked_gen_loss: 0.38522985577583313 - (2851716:unified_unilip.py:926)
2026-01-07 22:12:21 - INFO - total_loss: 0.3587184250354767, masked_loc_loss: 0.03227876499295235, masked_gen_loss: 0.32643964886665344 - (2851716:unified_unilip.py:926)
2026-01-07 22:12:35 - INFO - total_loss: 0.3470958173274994, masked_loc_loss: 0.039352577179670334, masked_gen_loss: 0.30774325132369995 - (2851716:unified_unilip.py:926)
2026-01-07 22:12:42 - INFO - total_loss: 0.3832635283470154, masked_loc_loss: 0.04474964737892151, masked_gen_loss: 0.33851388096809387 - (2851716:unified_unilip.py:926)
2026-01-07 22:12:56 - INFO - total_loss: 0.3510484993457794, masked_loc_loss: 0.04242077097296715, masked_gen_loss: 0.308627724647522 - (2851716:unified_unilip.py:926)
2026-01-07 22:13:10 - INFO - total_loss: 0.37573152780532837, masked_loc_loss: 0.029004178941249847, masked_gen_loss: 0.3467273414134979 - (2851716:unified_unilip.py:926)
2026-01-07 22:13:25 - INFO - total_loss: 0.35707542300224304, masked_loc_loss: 0.02543865330517292, masked_gen_loss: 0.3316367566585541 - (2851716:unified_unilip.py:926)
2026-01-07 22:13:39 - INFO - total_loss: 0.3254949152469635, masked_loc_loss: 0.015817152336239815, masked_gen_loss: 0.30967774987220764 - (2851716:unified_unilip.py:926)
2026-01-07 22:13:47 - INFO - total_loss: 0.3746699392795563, masked_loc_loss: 0.02913150191307068, masked_gen_loss: 0.3455384373664856 - (2851716:unified_unilip.py:926)
2026-01-07 22:14:01 - INFO - total_loss: 0.38364318013191223, masked_loc_loss: 0.02742241695523262, masked_gen_loss: 0.3562207520008087 - (2851716:unified_unilip.py:926)
2026-01-07 22:14:16 - INFO - total_loss: 0.4094114899635315, masked_loc_loss: 0.043925896286964417, masked_gen_loss: 0.36548560857772827 - (2851716:unified_unilip.py:926)
2026-01-07 22:14:30 - INFO - total_loss: 0.3678678572177887, masked_loc_loss: 0.03529999405145645, masked_gen_loss: 0.33256787061691284 - (2851716:unified_unilip.py:926)
2026-01-07 22:14:44 - INFO - total_loss: 0.35832977294921875, masked_loc_loss: 0.05582381784915924, masked_gen_loss: 0.3025059700012207 - (2851716:unified_unilip.py:926)
2026-01-07 22:14:56 - INFO - total_loss: 0.31303849816322327, masked_loc_loss: 0.04363291710615158, masked_gen_loss: 0.2694055736064911 - (2851716:unified_unilip.py:926)
2026-01-07 22:15:11 - INFO - total_loss: 0.42789924144744873, masked_loc_loss: 0.03585420548915863, masked_gen_loss: 0.3920450210571289 - (2851716:unified_unilip.py:926)
2026-01-07 22:15:26 - INFO - total_loss: 0.3623076379299164, masked_loc_loss: 0.04532553628087044, masked_gen_loss: 0.31698209047317505 - (2851716:unified_unilip.py:926)
2026-01-07 22:15:41 - INFO - total_loss: 0.3510589897632599, masked_loc_loss: 0.029230883345007896, masked_gen_loss: 0.32182809710502625 - (2851716:unified_unilip.py:926)
2026-01-07 22:15:50 - INFO - total_loss: 0.41315874457359314, masked_loc_loss: 0.05192193388938904, masked_gen_loss: 0.3612368106842041 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:05 - INFO - total_loss: 0.36042070388793945, masked_loc_loss: 0.033349283039569855, masked_gen_loss: 0.3270714282989502 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:19 - INFO - total_loss: 0.4362027049064636, masked_loc_loss: 0.04452776908874512, masked_gen_loss: 0.3916749358177185 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:32 - INFO - total_loss: 0.412045955657959, masked_loc_loss: 0.03906556963920593, masked_gen_loss: 0.37298038601875305 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:38 - INFO - total_loss: 0.3312112092971802, masked_loc_loss: 0.050228431820869446, masked_gen_loss: 0.2809827923774719 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:45 - INFO - total_loss: 0.3297245502471924, masked_loc_loss: 0.02743149921298027, masked_gen_loss: 0.302293062210083 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:51 - INFO - total_loss: 0.3870300054550171, masked_loc_loss: 0.029643360525369644, masked_gen_loss: 0.35738664865493774 - (2851716:unified_unilip.py:926)
2026-01-07 22:16:58 - INFO - total_loss: 0.4153188467025757, masked_loc_loss: 0.04133337736129761, masked_gen_loss: 0.3739854693412781 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:04 - INFO - total_loss: 0.35611215233802795, masked_loc_loss: 0.052684396505355835, masked_gen_loss: 0.3034277558326721 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:10 - INFO - total_loss: 0.404796838760376, masked_loc_loss: 0.061823371797800064, masked_gen_loss: 0.3429734706878662 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:17 - INFO - total_loss: 0.3815747797489166, masked_loc_loss: 0.05225526541471481, masked_gen_loss: 0.3293195068836212 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:23 - INFO - total_loss: 0.3545600175857544, masked_loc_loss: 0.038317013531923294, masked_gen_loss: 0.3162429928779602 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:30 - INFO - total_loss: 0.41039860248565674, masked_loc_loss: 0.026320047676563263, masked_gen_loss: 0.3840785622596741 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:36 - INFO - total_loss: 0.3683639168739319, masked_loc_loss: 0.040899887681007385, masked_gen_loss: 0.3274640440940857 - (2851716:unified_unilip.py:926)
2026-01-07 22:17:47 - INFO - total_loss: 0.39668431878089905, masked_loc_loss: 0.0297255739569664, masked_gen_loss: 0.36695873737335205 - (2851716:unified_unilip.py:926)
2026-01-07 22:18:02 - INFO - total_loss: 0.3279654085636139, masked_loc_loss: 0.023680951446294785, masked_gen_loss: 0.3042844533920288 - (2851716:unified_unilip.py:926)
2026-01-07 22:18:17 - INFO - total_loss: 0.37710335850715637, masked_loc_loss: 0.05872692912817001, masked_gen_loss: 0.31837642192840576 - (2851716:unified_unilip.py:926)
2026-01-07 22:18:31 - INFO - total_loss: 0.310994029045105, masked_loc_loss: 0.0340748131275177, masked_gen_loss: 0.2769192159175873 - (2851716:unified_unilip.py:926)
2026-01-07 22:18:40 - INFO - total_loss: 0.3148095905780792, masked_loc_loss: 0.023276586085557938, masked_gen_loss: 0.2915329933166504 - (2851716:unified_unilip.py:926)
2026-01-07 22:18:47 - INFO - total_loss: 0.38279280066490173, masked_loc_loss: 0.03893212229013443, masked_gen_loss: 0.3438606858253479 - (2851716:unified_unilip.py:926)
2026-01-07 22:19:00 - INFO - total_loss: 0.385011225938797, masked_loc_loss: 0.03398987278342247, masked_gen_loss: 0.35102134943008423 - (2851716:unified_unilip.py:926)
2026-01-07 22:19:14 - INFO - total_loss: 0.448047399520874, masked_loc_loss: 0.04912787675857544, masked_gen_loss: 0.3989195227622986 - (2851716:unified_unilip.py:926)
2026-01-07 22:19:29 - INFO - total_loss: 0.3454012870788574, masked_loc_loss: 0.038877975195646286, masked_gen_loss: 0.30652332305908203 - (2851716:unified_unilip.py:926)
2026-01-07 22:19:43 - INFO - total_loss: 0.40080583095550537, masked_loc_loss: 0.05071495845913887, masked_gen_loss: 0.3500908613204956 - (2851716:unified_unilip.py:926)
2026-01-07 22:19:50 - INFO - total_loss: 0.4065684676170349, masked_loc_loss: 0.04234820604324341, masked_gen_loss: 0.3642202615737915 - (2851716:unified_unilip.py:926)
2026-01-07 22:19:59 - INFO - total_loss: 0.37382572889328003, masked_loc_loss: 0.03294474631547928, masked_gen_loss: 0.34088099002838135 - (2851716:unified_unilip.py:926)
2026-01-07 22:20:14 - INFO - total_loss: 0.3748583197593689, masked_loc_loss: 0.04436284676194191, masked_gen_loss: 0.3304954767227173 - (2851716:unified_unilip.py:926)
2026-01-07 22:20:28 - INFO - total_loss: 0.3237963318824768, masked_loc_loss: 0.02593044750392437, masked_gen_loss: 0.2978658974170685 - (2851716:unified_unilip.py:926)
2026-01-07 22:20:41 - INFO - total_loss: 0.37755241990089417, masked_loc_loss: 0.06661799550056458, masked_gen_loss: 0.3109344244003296 - (2851716:unified_unilip.py:926)
2026-01-07 22:20:54 - INFO - total_loss: 0.4301679730415344, masked_loc_loss: 0.04806898534297943, masked_gen_loss: 0.3820989727973938 - (2851716:unified_unilip.py:926)
2026-01-07 22:21:06 - INFO - total_loss: 0.3970041871070862, masked_loc_loss: 0.04548504203557968, masked_gen_loss: 0.3515191376209259 - (2851716:unified_unilip.py:926)
2026-01-07 22:21:20 - INFO - total_loss: 0.41978251934051514, masked_loc_loss: 0.03446822986006737, masked_gen_loss: 0.38531428575515747 - (2851716:unified_unilip.py:926)
2026-01-07 22:21:35 - INFO - total_loss: 0.321511834859848, masked_loc_loss: 0.048814933747053146, masked_gen_loss: 0.27269691228866577 - (2851716:unified_unilip.py:926)
2026-01-07 22:21:49 - INFO - total_loss: 0.42772501707077026, masked_loc_loss: 0.0504390150308609, masked_gen_loss: 0.37728598713874817 - (2851716:unified_unilip.py:926)
2026-01-07 22:21:58 - INFO - total_loss: 0.4263477325439453, masked_loc_loss: 0.05341117084026337, masked_gen_loss: 0.37293657660484314 - (2851716:unified_unilip.py:926)
2026-01-07 22:22:10 - INFO - total_loss: 0.3744693994522095, masked_loc_loss: 0.028421415016055107, masked_gen_loss: 0.3460479974746704 - (2851716:unified_unilip.py:926)
2026-01-07 22:22:25 - INFO - total_loss: 0.38103610277175903, masked_loc_loss: 0.0430540069937706, masked_gen_loss: 0.33798208832740784 - (2851716:unified_unilip.py:926)
2026-01-07 22:22:40 - INFO - total_loss: 0.38632461428642273, masked_loc_loss: 0.032750509679317474, masked_gen_loss: 0.35357409715652466 - (2851716:unified_unilip.py:926)
2026-01-07 22:22:55 - INFO - total_loss: 0.36856144666671753, masked_loc_loss: 0.05930827930569649, masked_gen_loss: 0.30925315618515015 - (2851716:unified_unilip.py:926)
2026-01-07 22:23:02 - INFO - total_loss: 0.3721591830253601, masked_loc_loss: 0.04480484127998352, masked_gen_loss: 0.3273543417453766 - (2851716:unified_unilip.py:926)
2026-01-07 22:23:16 - INFO - total_loss: 0.35806283354759216, masked_loc_loss: 0.02605060487985611, masked_gen_loss: 0.33201223611831665 - (2851716:unified_unilip.py:926)
2026-01-07 22:23:30 - INFO - total_loss: 0.34127140045166016, masked_loc_loss: 0.031026553362607956, masked_gen_loss: 0.3102448582649231 - (2851716:unified_unilip.py:926)
2026-01-07 22:23:45 - INFO - total_loss: 0.39345812797546387, masked_loc_loss: 0.020551465451717377, masked_gen_loss: 0.3729066550731659 - (2851716:unified_unilip.py:926)
2026-01-07 22:24:00 - INFO - total_loss: 0.403538316488266, masked_loc_loss: 0.0390719473361969, masked_gen_loss: 0.3644663691520691 - (2851716:unified_unilip.py:926)
2026-01-07 22:24:08 - INFO - total_loss: 0.3828902244567871, masked_loc_loss: 0.04130467772483826, masked_gen_loss: 0.34158554673194885 - (2851716:unified_unilip.py:926)
2026-01-07 22:24:22 - INFO - total_loss: 0.4007779061794281, masked_loc_loss: 0.053663693368434906, masked_gen_loss: 0.3471142053604126 - (2851716:unified_unilip.py:926)
2026-01-07 22:24:36 - INFO - total_loss: 0.4266042113304138, masked_loc_loss: 0.0439995676279068, masked_gen_loss: 0.3826046586036682 - (2851716:unified_unilip.py:926)
2026-01-07 22:24:51 - INFO - total_loss: 0.40671107172966003, masked_loc_loss: 0.0340021550655365, masked_gen_loss: 0.37270891666412354 - (2851716:unified_unilip.py:926)
2026-01-07 22:25:03 - INFO - total_loss: 0.32670530676841736, masked_loc_loss: 0.03949979692697525, masked_gen_loss: 0.2872055172920227 - (2851716:unified_unilip.py:926)
2026-01-07 22:25:10 - INFO - total_loss: 0.3772789239883423, masked_loc_loss: 0.03860406577587128, masked_gen_loss: 0.3386748433113098 - (2851716:unified_unilip.py:926)
2026-01-07 22:25:23 - INFO - total_loss: 0.4185546040534973, masked_loc_loss: 0.0398031584918499, masked_gen_loss: 0.3787514567375183 - (2851716:unified_unilip.py:926)
2026-01-07 22:25:38 - INFO - total_loss: 0.37686946988105774, masked_loc_loss: 0.017466891556978226, masked_gen_loss: 0.3594025671482086 - (2851716:unified_unilip.py:926)
2026-01-07 22:25:52 - INFO - total_loss: 0.3357815146446228, masked_loc_loss: 0.03307318687438965, masked_gen_loss: 0.30270832777023315 - (2851716:unified_unilip.py:926)
2026-01-07 22:26:06 - INFO - total_loss: 0.42946040630340576, masked_loc_loss: 0.01818394474685192, masked_gen_loss: 0.4112764596939087 - (2851716:unified_unilip.py:926)
2026-01-07 22:26:13 - INFO - total_loss: 0.3652718663215637, masked_loc_loss: 0.051893096417188644, masked_gen_loss: 0.31337878108024597 - (2851716:unified_unilip.py:926)
2026-01-07 22:26:28 - INFO - total_loss: 0.38781872391700745, masked_loc_loss: 0.026176078245043755, masked_gen_loss: 0.36164265871047974 - (2851716:unified_unilip.py:926)
2026-01-07 22:26:42 - INFO - total_loss: 0.3921278715133667, masked_loc_loss: 0.05809081345796585, masked_gen_loss: 0.33403706550598145 - (2851716:unified_unilip.py:926)
2026-01-07 22:26:56 - INFO - total_loss: 0.3484267592430115, masked_loc_loss: 0.020244983956217766, masked_gen_loss: 0.32818177342414856 - (2851716:unified_unilip.py:926)
2026-01-07 22:27:10 - INFO - total_loss: 0.38757795095443726, masked_loc_loss: 0.0404290109872818, masked_gen_loss: 0.34714892506599426 - (2851716:unified_unilip.py:926)
2026-01-07 22:27:23 - INFO - total_loss: 0.39781126379966736, masked_loc_loss: 0.028291024267673492, masked_gen_loss: 0.36952024698257446 - (2851716:unified_unilip.py:926)
2026-01-07 22:27:38 - INFO - total_loss: 0.397733211517334, masked_loc_loss: 0.048361003398895264, masked_gen_loss: 0.3493722081184387 - (2851716:unified_unilip.py:926)
2026-01-07 22:27:53 - INFO - total_loss: 0.3468494415283203, masked_loc_loss: 0.033966898918151855, masked_gen_loss: 0.31288254261016846 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:00 - INFO - total_loss: 0.3866211175918579, masked_loc_loss: 0.023100469261407852, masked_gen_loss: 0.36352065205574036 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:07 - INFO - total_loss: 0.32751670479774475, masked_loc_loss: 0.031906940042972565, masked_gen_loss: 0.2956097722053528 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:13 - INFO - total_loss: 0.36464330554008484, masked_loc_loss: 0.029204510152339935, masked_gen_loss: 0.3354387879371643 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:20 - INFO - total_loss: 0.36072206497192383, masked_loc_loss: 0.019076865166425705, masked_gen_loss: 0.341645210981369 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:26 - INFO - total_loss: 0.4294496774673462, masked_loc_loss: 0.04087723419070244, masked_gen_loss: 0.38857245445251465 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:33 - INFO - total_loss: 0.36350300908088684, masked_loc_loss: 0.0382407009601593, masked_gen_loss: 0.32526230812072754 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:39 - INFO - total_loss: 0.354953795671463, masked_loc_loss: 0.05466393008828163, masked_gen_loss: 0.3002898693084717 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:46 - INFO - total_loss: 0.36984363198280334, masked_loc_loss: 0.04151660576462746, masked_gen_loss: 0.3283270299434662 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:53 - INFO - total_loss: 0.36380353569984436, masked_loc_loss: 0.027274925261735916, masked_gen_loss: 0.33652859926223755 - (2851716:unified_unilip.py:926)
2026-01-07 22:28:59 - INFO - total_loss: 0.3814234435558319, masked_loc_loss: 0.0323127806186676, masked_gen_loss: 0.3491106629371643 - (2851716:unified_unilip.py:926)
2026-01-07 22:29:13 - INFO - total_loss: 0.3991832733154297, masked_loc_loss: 0.03288068622350693, masked_gen_loss: 0.36630257964134216 - (2851716:unified_unilip.py:926)
2026-01-07 22:29:28 - INFO - total_loss: 0.3922860026359558, masked_loc_loss: 0.06048488989472389, masked_gen_loss: 0.3318011164665222 - (2851716:unified_unilip.py:926)
2026-01-07 22:29:42 - INFO - total_loss: 0.3658806383609772, masked_loc_loss: 0.04910246282815933, masked_gen_loss: 0.31677818298339844 - (2851716:unified_unilip.py:926)
2026-01-07 22:29:57 - INFO - total_loss: 0.38788071274757385, masked_loc_loss: 0.04671809822320938, masked_gen_loss: 0.34116262197494507 - (2851716:unified_unilip.py:926)
2026-01-07 22:30:04 - INFO - total_loss: 0.35957542061805725, masked_loc_loss: 0.02709326706826687, masked_gen_loss: 0.33248215913772583 - (2851716:unified_unilip.py:926)
2026-01-07 22:30:17 - INFO - total_loss: 0.40299493074417114, masked_loc_loss: 0.05760732293128967, masked_gen_loss: 0.34538760781288147 - (2851716:unified_unilip.py:926)
2026-01-07 22:30:32 - INFO - total_loss: 0.3759801983833313, masked_loc_loss: 0.03786814957857132, masked_gen_loss: 0.3381120562553406 - (2851716:unified_unilip.py:926)
2026-01-07 22:30:46 - INFO - total_loss: 0.36928993463516235, masked_loc_loss: 0.04128558188676834, masked_gen_loss: 0.3280043601989746 - (2851716:unified_unilip.py:926)
2026-01-07 22:31:01 - INFO - total_loss: 0.3395026922225952, masked_loc_loss: 0.04833690822124481, masked_gen_loss: 0.2911657691001892 - (2851716:unified_unilip.py:926)
2026-01-07 22:31:08 - INFO - total_loss: 0.42892172932624817, masked_loc_loss: 0.058793824166059494, masked_gen_loss: 0.37012791633605957 - (2851716:unified_unilip.py:926)
2026-01-07 22:31:18 - INFO - total_loss: 0.3259953260421753, masked_loc_loss: 0.02903764322400093, masked_gen_loss: 0.29695767164230347 - (2851716:unified_unilip.py:926)
2026-01-07 22:31:32 - INFO - total_loss: 0.34465479850769043, masked_loc_loss: 0.03439347445964813, masked_gen_loss: 0.3102613091468811 - (2851716:unified_unilip.py:926)
2026-01-07 22:31:47 - INFO - total_loss: 0.35234495997428894, masked_loc_loss: 0.0482928492128849, masked_gen_loss: 0.30405211448669434 - (2851716:unified_unilip.py:926)
2026-01-07 22:32:01 - INFO - total_loss: 0.3965966999530792, masked_loc_loss: 0.03011736460030079, masked_gen_loss: 0.3664793372154236 - (2851716:unified_unilip.py:926)
2026-01-07 22:32:11 - INFO - total_loss: 0.37404587864875793, masked_loc_loss: 0.03118181973695755, masked_gen_loss: 0.342864066362381 - (2851716:unified_unilip.py:926)
2026-01-07 22:32:24 - INFO - total_loss: 0.3927493393421173, masked_loc_loss: 0.03908047452569008, masked_gen_loss: 0.35366886854171753 - (2851716:unified_unilip.py:926)
2026-01-07 22:32:39 - INFO - total_loss: 0.3366520404815674, masked_loc_loss: 0.06000979244709015, masked_gen_loss: 0.2766422629356384 - (2851716:unified_unilip.py:926)
2026-01-07 22:32:53 - INFO - total_loss: 0.3661627471446991, masked_loc_loss: 0.023902038112282753, masked_gen_loss: 0.3422607183456421 - (2851716:unified_unilip.py:926)
2026-01-07 22:33:08 - INFO - total_loss: 0.37900879979133606, masked_loc_loss: 0.04011968523263931, masked_gen_loss: 0.33888912200927734 - (2851716:unified_unilip.py:926)
2026-01-07 22:33:15 - INFO - total_loss: 0.40867260098457336, masked_loc_loss: 0.021830368787050247, masked_gen_loss: 0.3868422210216522 - (2851716:unified_unilip.py:926)
2026-01-07 22:33:29 - INFO - total_loss: 0.39300093054771423, masked_loc_loss: 0.0557221956551075, masked_gen_loss: 0.33727872371673584 - (2851716:unified_unilip.py:926)
2026-01-07 22:33:44 - INFO - total_loss: 0.3281879723072052, masked_loc_loss: 0.020774388685822487, masked_gen_loss: 0.30741357803344727 - (2851716:unified_unilip.py:926)
2026-01-07 22:33:59 - INFO - total_loss: 0.36413997411727905, masked_loc_loss: 0.015974214300513268, masked_gen_loss: 0.34816575050354004 - (2851716:unified_unilip.py:926)
2026-01-07 22:34:13 - INFO - total_loss: 0.3857569098472595, masked_loc_loss: 0.04741029441356659, masked_gen_loss: 0.33834660053253174 - (2851716:unified_unilip.py:926)
2026-01-07 22:34:20 - INFO - total_loss: 0.3950277864933014, masked_loc_loss: 0.03442588075995445, masked_gen_loss: 0.36060190200805664 - (2851716:unified_unilip.py:926)
2026-01-07 22:34:34 - INFO - total_loss: 0.41579997539520264, masked_loc_loss: 0.06336431205272675, masked_gen_loss: 0.3524356484413147 - (2851716:unified_unilip.py:926)
2026-01-07 22:34:49 - INFO - total_loss: 0.33047035336494446, masked_loc_loss: 0.031149668619036674, masked_gen_loss: 0.29932069778442383 - (2851716:unified_unilip.py:926)
2026-01-07 22:35:03 - INFO - total_loss: 0.3399161696434021, masked_loc_loss: 0.03447486460208893, masked_gen_loss: 0.305441290140152 - (2851716:unified_unilip.py:926)
2026-01-07 22:35:18 - INFO - total_loss: 0.3607006072998047, masked_loc_loss: 0.03994237631559372, masked_gen_loss: 0.32075822353363037 - (2851716:unified_unilip.py:926)
2026-01-07 22:35:28 - INFO - total_loss: 0.35113224387168884, masked_loc_loss: 0.029442735016345978, masked_gen_loss: 0.32168951630592346 - (2851716:unified_unilip.py:926)
2026-01-07 22:35:42 - INFO - total_loss: 0.3972688913345337, masked_loc_loss: 0.046937212347984314, masked_gen_loss: 0.3503316640853882 - (2851716:unified_unilip.py:926)
2026-01-07 22:35:57 - INFO - total_loss: 0.38962727785110474, masked_loc_loss: 0.0500807911157608, masked_gen_loss: 0.33954647183418274 - (2851716:unified_unilip.py:926)
2026-01-07 22:36:11 - INFO - total_loss: 0.3744514584541321, masked_loc_loss: 0.025578543543815613, masked_gen_loss: 0.3488729000091553 - (2851716:unified_unilip.py:926)
2026-01-07 22:36:22 - INFO - total_loss: 0.36094236373901367, masked_loc_loss: 0.04640299081802368, masked_gen_loss: 0.31453937292099 - (2851716:unified_unilip.py:926)
2026-01-07 22:36:33 - INFO - total_loss: 0.38127076625823975, masked_loc_loss: 0.0312761627137661, masked_gen_loss: 0.34999459981918335 - (2851716:unified_unilip.py:926)
2026-01-07 22:36:47 - INFO - total_loss: 0.36657294631004333, masked_loc_loss: 0.05336127057671547, masked_gen_loss: 0.31321167945861816 - (2851716:unified_unilip.py:926)
2026-01-07 22:37:02 - INFO - total_loss: 0.3925137519836426, masked_loc_loss: 0.05039495974779129, masked_gen_loss: 0.3421187996864319 - (2851716:unified_unilip.py:926)
2026-01-07 22:37:16 - INFO - total_loss: 0.3850401043891907, masked_loc_loss: 0.03279723972082138, masked_gen_loss: 0.3522428572177887 - (2851716:unified_unilip.py:926)
2026-01-07 22:37:25 - INFO - total_loss: 0.3964112401008606, masked_loc_loss: 0.04081074893474579, masked_gen_loss: 0.3556004762649536 - (2851716:unified_unilip.py:926)
2026-01-07 22:37:34 - INFO - total_loss: 0.3347182273864746, masked_loc_loss: 0.06616031378507614, masked_gen_loss: 0.26855790615081787 - (2851716:unified_unilip.py:926)
2026-01-07 22:37:49 - INFO - total_loss: 0.3824974000453949, masked_loc_loss: 0.022824693471193314, masked_gen_loss: 0.3596726953983307 - (2851716:unified_unilip.py:926)
2026-01-07 22:38:03 - INFO - total_loss: 0.40966299176216125, masked_loc_loss: 0.04927913472056389, masked_gen_loss: 0.36038386821746826 - (2851716:unified_unilip.py:926)
2026-01-07 22:38:17 - INFO - total_loss: 0.4010935425758362, masked_loc_loss: 0.05169243365526199, masked_gen_loss: 0.3494011163711548 - (2851716:unified_unilip.py:926)
2026-01-07 22:38:29 - INFO - total_loss: 0.38531413674354553, masked_loc_loss: 0.032769642770290375, masked_gen_loss: 0.35254448652267456 - (2851716:unified_unilip.py:926)
2026-01-07 22:38:42 - INFO - total_loss: 0.33673080801963806, masked_loc_loss: 0.05958012491464615, masked_gen_loss: 0.2771506905555725 - (2851716:unified_unilip.py:926)
2026-01-07 22:38:57 - INFO - total_loss: 0.3972950279712677, masked_loc_loss: 0.03402576968073845, masked_gen_loss: 0.36326926946640015 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:11 - INFO - total_loss: 0.38814637064933777, masked_loc_loss: 0.030595922842621803, masked_gen_loss: 0.3575504422187805 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:18 - INFO - total_loss: 0.3666074872016907, masked_loc_loss: 0.04331843554973602, masked_gen_loss: 0.32328906655311584 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:25 - INFO - total_loss: 0.38842904567718506, masked_loc_loss: 0.04269498586654663, masked_gen_loss: 0.3457340598106384 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:31 - INFO - total_loss: 0.3147554397583008, masked_loc_loss: 0.032701656222343445, masked_gen_loss: 0.28205379843711853 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:38 - INFO - total_loss: 0.40302973985671997, masked_loc_loss: 0.05191797390580177, masked_gen_loss: 0.3511117696762085 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:44 - INFO - total_loss: 0.38109132647514343, masked_loc_loss: 0.03737683966755867, masked_gen_loss: 0.34371447563171387 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:51 - INFO - total_loss: 0.3669683635234833, masked_loc_loss: 0.04499772936105728, masked_gen_loss: 0.3219706416130066 - (2851716:unified_unilip.py:926)
2026-01-07 22:39:58 - INFO - total_loss: 0.37261611223220825, masked_loc_loss: 0.02544235810637474, masked_gen_loss: 0.3471737504005432 - (2851716:unified_unilip.py:926)
2026-01-07 22:40:04 - INFO - total_loss: 0.38093435764312744, masked_loc_loss: 0.04302819073200226, masked_gen_loss: 0.337906152009964 - (2851716:unified_unilip.py:926)
2026-01-07 22:40:11 - INFO - total_loss: 0.4049922823905945, masked_loc_loss: 0.03819393739104271, masked_gen_loss: 0.3667983412742615 - (2851716:unified_unilip.py:926)
2026-01-07 22:40:17 - INFO - total_loss: 0.36087873578071594, masked_loc_loss: 0.048246629536151886, masked_gen_loss: 0.31263211369514465 - (2851716:unified_unilip.py:926)
2026-01-07 22:40:24 - INFO - total_loss: 0.4315817058086395, masked_loc_loss: 0.04208967089653015, masked_gen_loss: 0.3894920349121094 - (2851716:unified_unilip.py:926)
2026-01-07 22:40:39 - INFO - total_loss: 0.38099029660224915, masked_loc_loss: 0.046651579439640045, masked_gen_loss: 0.3343387246131897 - (2851716:unified_unilip.py:926)
2026-01-07 22:40:54 - INFO - total_loss: 0.4074350595474243, masked_loc_loss: 0.027911923825740814, masked_gen_loss: 0.3795231282711029 - (2851716:unified_unilip.py:926)
2026-01-07 22:41:08 - INFO - total_loss: 0.3932154178619385, masked_loc_loss: 0.04250934720039368, masked_gen_loss: 0.3507060706615448 - (2851716:unified_unilip.py:926)
2026-01-07 22:41:23 - INFO - total_loss: 0.34046950936317444, masked_loc_loss: 0.0555841401219368, masked_gen_loss: 0.28488537669181824 - (2851716:unified_unilip.py:926)
2026-01-07 22:41:29 - INFO - total_loss: 0.36143943667411804, masked_loc_loss: 0.04962405189871788, masked_gen_loss: 0.31181538105010986 - (2851716:unified_unilip.py:926)
2026-01-07 22:41:35 - INFO - total_loss: 0.3732892870903015, masked_loc_loss: 0.016621187329292297, masked_gen_loss: 0.3566681146621704 - (2851716:unified_unilip.py:926)
2026-01-07 22:41:47 - INFO - total_loss: 0.3507280647754669, masked_loc_loss: 0.036609746515750885, masked_gen_loss: 0.31411832571029663 - (2851716:unified_unilip.py:926)
2026-01-07 22:42:02 - INFO - total_loss: 0.40205615758895874, masked_loc_loss: 0.025676563382148743, masked_gen_loss: 0.3763795793056488 - (2851716:unified_unilip.py:926)
2026-01-07 22:42:17 - INFO - total_loss: 0.3450695872306824, masked_loc_loss: 0.03642109036445618, masked_gen_loss: 0.3086484968662262 - (2851716:unified_unilip.py:926)
2026-01-07 22:42:32 - INFO - total_loss: 0.34058529138565063, masked_loc_loss: 0.029905807226896286, masked_gen_loss: 0.31067949533462524 - (2851716:unified_unilip.py:926)
2026-01-07 22:42:39 - INFO - total_loss: 0.3772452473640442, masked_loc_loss: 0.02850545383989811, masked_gen_loss: 0.3487398028373718 - (2851716:unified_unilip.py:926)
2026-01-07 22:42:48 - INFO - total_loss: 0.34793877601623535, masked_loc_loss: 0.0729343444108963, masked_gen_loss: 0.27500444650650024 - (2851716:unified_unilip.py:926)
2026-01-07 22:43:02 - INFO - total_loss: 0.38452982902526855, masked_loc_loss: 0.04144531488418579, masked_gen_loss: 0.34308451414108276 - (2851716:unified_unilip.py:926)
2026-01-07 22:43:17 - INFO - total_loss: 0.39155662059783936, masked_loc_loss: 0.04466116428375244, masked_gen_loss: 0.3468954563140869 - (2851716:unified_unilip.py:926)
2026-01-07 22:43:31 - INFO - total_loss: 0.3860950767993927, masked_loc_loss: 0.06031521409749985, masked_gen_loss: 0.32577985525131226 - (2851716:unified_unilip.py:926)
2026-01-07 22:43:43 - INFO - total_loss: 0.3377350866794586, masked_loc_loss: 0.0368485152721405, masked_gen_loss: 0.3008865714073181 - (2851716:unified_unilip.py:926)
2026-01-07 22:43:52 - INFO - total_loss: 0.3490191102027893, masked_loc_loss: 0.02785995975136757, masked_gen_loss: 0.32115915417671204 - (2851716:unified_unilip.py:926)
2026-01-07 22:44:06 - INFO - total_loss: 0.3364441394805908, masked_loc_loss: 0.029949575662612915, masked_gen_loss: 0.3064945638179779 - (2851716:unified_unilip.py:926)
2026-01-07 22:44:21 - INFO - total_loss: 0.3443019986152649, masked_loc_loss: 0.029753610491752625, masked_gen_loss: 0.31454840302467346 - (2851716:unified_unilip.py:926)
2026-01-07 22:44:36 - INFO - total_loss: 0.3552528917789459, masked_loc_loss: 0.044729139655828476, masked_gen_loss: 0.31052374839782715 - (2851716:unified_unilip.py:926)
2026-01-07 22:44:46 - INFO - total_loss: 0.34863659739494324, masked_loc_loss: 0.05619891732931137, masked_gen_loss: 0.29243767261505127 - (2851716:unified_unilip.py:926)
2026-01-07 22:44:53 - INFO - total_loss: 0.3248513340950012, masked_loc_loss: 0.028414418920874596, masked_gen_loss: 0.2964369058609009 - (2851716:unified_unilip.py:926)
2026-01-07 22:45:07 - INFO - total_loss: 0.3853316307067871, masked_loc_loss: 0.019654367119073868, masked_gen_loss: 0.36567726731300354 - (2851716:unified_unilip.py:926)
2026-01-07 22:45:21 - INFO - total_loss: 0.36604413390159607, masked_loc_loss: 0.04311910271644592, masked_gen_loss: 0.32292503118515015 - (2851716:unified_unilip.py:926)
2026-01-07 22:45:36 - INFO - total_loss: 0.36630743741989136, masked_loc_loss: 0.041989073157310486, masked_gen_loss: 0.3243183493614197 - (2851716:unified_unilip.py:926)
2026-01-07 22:45:50 - INFO - total_loss: 0.35480421781539917, masked_loc_loss: 0.054954588413238525, masked_gen_loss: 0.29984962940216064 - (2851716:unified_unilip.py:926)
2026-01-07 22:45:57 - INFO - total_loss: 0.3866206407546997, masked_loc_loss: 0.017426781356334686, masked_gen_loss: 0.3691938519477844 - (2851716:unified_unilip.py:926)
2026-01-07 22:46:10 - INFO - total_loss: 0.35605117678642273, masked_loc_loss: 0.03083271160721779, masked_gen_loss: 0.32521846890449524 - (2851716:unified_unilip.py:926)
2026-01-07 22:46:25 - INFO - total_loss: 0.3950340449810028, masked_loc_loss: 0.02687322534620762, masked_gen_loss: 0.36816081404685974 - (2851716:unified_unilip.py:926)
2026-01-07 22:46:39 - INFO - total_loss: 0.3425312638282776, masked_loc_loss: 0.05727966129779816, masked_gen_loss: 0.2852516174316406 - (2851716:unified_unilip.py:926)
2026-01-07 22:46:54 - INFO - total_loss: 0.344113290309906, masked_loc_loss: 0.035470351576805115, masked_gen_loss: 0.3086429536342621 - (2851716:unified_unilip.py:926)
2026-01-07 22:47:01 - INFO - total_loss: 0.3685256242752075, masked_loc_loss: 0.036247216165065765, masked_gen_loss: 0.33227840065956116 - (2851716:unified_unilip.py:926)
2026-01-07 22:47:15 - INFO - total_loss: 0.4168913960456848, masked_loc_loss: 0.04363482445478439, masked_gen_loss: 0.3732565641403198 - (2851716:unified_unilip.py:926)
2026-01-07 22:47:30 - INFO - total_loss: 0.39357441663742065, masked_loc_loss: 0.03378940746188164, masked_gen_loss: 0.3597850203514099 - (2851716:unified_unilip.py:926)
2026-01-07 22:47:45 - INFO - total_loss: 0.35573798418045044, masked_loc_loss: 0.02917819283902645, masked_gen_loss: 0.32655978202819824 - (2851716:unified_unilip.py:926)
2026-01-07 22:47:59 - INFO - total_loss: 0.3962542712688446, masked_loc_loss: 0.03528718277812004, masked_gen_loss: 0.36096709966659546 - (2851716:unified_unilip.py:926)
2026-01-07 22:48:06 - INFO - total_loss: 0.40373510122299194, masked_loc_loss: 0.03530692309141159, masked_gen_loss: 0.36842817068099976 - (2851716:unified_unilip.py:926)
2026-01-07 22:48:19 - INFO - total_loss: 0.4256724417209625, masked_loc_loss: 0.03685507923364639, masked_gen_loss: 0.38881736993789673 - (2851716:unified_unilip.py:926)
2026-01-07 22:48:34 - INFO - total_loss: 0.34003815054893494, masked_loc_loss: 0.04161179065704346, masked_gen_loss: 0.2984263598918915 - (2851716:unified_unilip.py:926)
2026-01-07 22:48:48 - INFO - total_loss: 0.383255273103714, masked_loc_loss: 0.02637341246008873, masked_gen_loss: 0.35688185691833496 - (2851716:unified_unilip.py:926)
2026-01-07 22:49:02 - INFO - total_loss: 0.38824209570884705, masked_loc_loss: 0.06189107149839401, masked_gen_loss: 0.32635101675987244 - (2851716:unified_unilip.py:926)
2026-01-07 22:49:10 - INFO - total_loss: 0.3326050043106079, masked_loc_loss: 0.04329676926136017, masked_gen_loss: 0.28930824995040894 - (2851716:unified_unilip.py:926)
2026-01-07 22:49:23 - INFO - total_loss: 0.3618898391723633, masked_loc_loss: 0.041717223823070526, masked_gen_loss: 0.32017260789871216 - (2851716:unified_unilip.py:926)
2026-01-07 22:49:38 - INFO - total_loss: 0.3436225950717926, masked_loc_loss: 0.04374131187796593, masked_gen_loss: 0.2998812794685364 - (2851716:unified_unilip.py:926)
2026-01-07 22:49:52 - INFO - total_loss: 0.37479788064956665, masked_loc_loss: 0.026112163439393044, masked_gen_loss: 0.34868571162223816 - (2851716:unified_unilip.py:926)
2026-01-07 22:50:06 - INFO - total_loss: 0.4588441252708435, masked_loc_loss: 0.038882575929164886, masked_gen_loss: 0.419961541891098 - (2851716:unified_unilip.py:926)
2026-01-07 22:50:16 - INFO - total_loss: 0.3781150281429291, masked_loc_loss: 0.03484455496072769, masked_gen_loss: 0.343270480632782 - (2851716:unified_unilip.py:926)
2026-01-07 22:50:30 - INFO - total_loss: 0.37849897146224976, masked_loc_loss: 0.03360341861844063, masked_gen_loss: 0.34489554166793823 - (2851716:unified_unilip.py:926)
2026-01-07 22:50:44 - INFO - total_loss: 0.3719492256641388, masked_loc_loss: 0.041905101388692856, masked_gen_loss: 0.33004412055015564 - (2851716:unified_unilip.py:926)
2026-01-07 22:50:56 - INFO - total_loss: 0.3507120609283447, masked_loc_loss: 0.037862759083509445, masked_gen_loss: 0.3128493130207062 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:03 - INFO - total_loss: 0.36795368790626526, masked_loc_loss: 0.017982274293899536, masked_gen_loss: 0.3499714136123657 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:09 - INFO - total_loss: 0.3885882794857025, masked_loc_loss: 0.020779531449079514, masked_gen_loss: 0.3678087592124939 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:15 - INFO - total_loss: 0.33530494570732117, masked_loc_loss: 0.026230424642562866, masked_gen_loss: 0.3090745210647583 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:22 - INFO - total_loss: 0.39184680581092834, masked_loc_loss: 0.0207875557243824, masked_gen_loss: 0.37105923891067505 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:28 - INFO - total_loss: 0.3068688213825226, masked_loc_loss: 0.04981812834739685, masked_gen_loss: 0.25705069303512573 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:35 - INFO - total_loss: 0.390994131565094, masked_loc_loss: 0.05230399966239929, masked_gen_loss: 0.3386901319026947 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:41 - INFO - total_loss: 0.35631752014160156, masked_loc_loss: 0.03506023809313774, masked_gen_loss: 0.3212572932243347 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:48 - INFO - total_loss: 0.3991844952106476, masked_loc_loss: 0.029203373938798904, masked_gen_loss: 0.3699811100959778 - (2851716:unified_unilip.py:926)
2026-01-07 22:51:54 - INFO - total_loss: 0.35095617175102234, masked_loc_loss: 0.03194926306605339, masked_gen_loss: 0.31900691986083984 - (2851716:unified_unilip.py:926)
2026-01-07 22:52:01 - INFO - total_loss: 0.3772190809249878, masked_loc_loss: 0.028363270685076714, masked_gen_loss: 0.3488558232784271 - (2851716:unified_unilip.py:926)
2026-01-07 22:52:12 - INFO - total_loss: 0.4166083037853241, masked_loc_loss: 0.04455149173736572, masked_gen_loss: 0.3720568120479584 - (2851716:unified_unilip.py:926)
2026-01-07 22:52:27 - INFO - total_loss: 0.3970049023628235, masked_loc_loss: 0.056548941880464554, masked_gen_loss: 0.34045594930648804 - (2851716:unified_unilip.py:926)
2026-01-07 22:52:42 - INFO - total_loss: 0.3626675605773926, masked_loc_loss: 0.028445076197385788, masked_gen_loss: 0.3342224955558777 - (2851716:unified_unilip.py:926)
2026-01-07 22:52:57 - INFO - total_loss: 0.41592711210250854, masked_loc_loss: 0.03884423151612282, masked_gen_loss: 0.377082884311676 - (2851716:unified_unilip.py:926)
2026-01-07 22:53:05 - INFO - total_loss: 0.36084237694740295, masked_loc_loss: 0.04929814487695694, masked_gen_loss: 0.3115442395210266 - (2851716:unified_unilip.py:926)
2026-01-07 22:53:15 - INFO - total_loss: 0.363944947719574, masked_loc_loss: 0.035010211169719696, masked_gen_loss: 0.3289347290992737 - (2851716:unified_unilip.py:926)
2026-01-07 22:53:30 - INFO - total_loss: 0.42522817850112915, masked_loc_loss: 0.026687994599342346, masked_gen_loss: 0.3985401690006256 - (2851716:unified_unilip.py:926)
2026-01-07 22:53:45 - INFO - total_loss: 0.4121832251548767, masked_loc_loss: 0.05224847421050072, masked_gen_loss: 0.3599347472190857 - (2851716:unified_unilip.py:926)
2026-01-07 22:53:59 - INFO - total_loss: 0.36466461420059204, masked_loc_loss: 0.05423177033662796, masked_gen_loss: 0.3104328513145447 - (2851716:unified_unilip.py:926)
2026-01-07 22:54:10 - INFO - total_loss: 0.40605515241622925, masked_loc_loss: 0.033073246479034424, masked_gen_loss: 0.3729819059371948 - (2851716:unified_unilip.py:926)
2026-01-07 22:54:20 - INFO - total_loss: 0.3653617799282074, masked_loc_loss: 0.02249470353126526, masked_gen_loss: 0.34286707639694214 - (2851716:unified_unilip.py:926)
2026-01-07 22:54:35 - INFO - total_loss: 0.3929346799850464, masked_loc_loss: 0.044825393706560135, masked_gen_loss: 0.34810927510261536 - (2851716:unified_unilip.py:926)
2026-01-07 22:54:49 - INFO - total_loss: 0.4005790650844574, masked_loc_loss: 0.0467633381485939, masked_gen_loss: 0.3538157343864441 - (2851716:unified_unilip.py:926)
2026-01-07 22:55:04 - INFO - total_loss: 0.37019115686416626, masked_loc_loss: 0.05079744756221771, masked_gen_loss: 0.31939372420310974 - (2851716:unified_unilip.py:926)
2026-01-07 22:55:14 - INFO - total_loss: 0.39678946137428284, masked_loc_loss: 0.031505387276411057, masked_gen_loss: 0.3652840852737427 - (2851716:unified_unilip.py:926)
2026-01-07 22:55:24 - INFO - total_loss: 0.3992767930030823, masked_loc_loss: 0.05268608033657074, masked_gen_loss: 0.34659069776535034 - (2851716:unified_unilip.py:926)
2026-01-07 22:55:39 - INFO - total_loss: 0.38102447986602783, masked_loc_loss: 0.034150268882513046, masked_gen_loss: 0.3468742072582245 - (2851716:unified_unilip.py:926)
2026-01-07 22:55:53 - INFO - total_loss: 0.37650540471076965, masked_loc_loss: 0.051654186099767685, masked_gen_loss: 0.32485121488571167 - (2851716:unified_unilip.py:926)
2026-01-07 22:56:08 - INFO - total_loss: 0.31766584515571594, masked_loc_loss: 0.0385313406586647, masked_gen_loss: 0.27913451194763184 - (2851716:unified_unilip.py:926)
2026-01-07 22:56:18 - INFO - total_loss: 0.35014450550079346, masked_loc_loss: 0.058897268027067184, masked_gen_loss: 0.29124724864959717 - (2851716:unified_unilip.py:926)
2026-01-07 22:56:28 - INFO - total_loss: 0.4284672737121582, masked_loc_loss: 0.04989379644393921, masked_gen_loss: 0.378573477268219 - (2851716:unified_unilip.py:926)
2026-01-07 22:56:42 - INFO - total_loss: 0.41467422246932983, masked_loc_loss: 0.029578689485788345, masked_gen_loss: 0.3850955367088318 - (2851716:unified_unilip.py:926)
2026-01-07 22:56:57 - INFO - total_loss: 0.4054638743400574, masked_loc_loss: 0.02626161091029644, masked_gen_loss: 0.379202276468277 - (2851716:unified_unilip.py:926)
2026-01-07 22:57:11 - INFO - total_loss: 0.3526020348072052, masked_loc_loss: 0.03430413454771042, masked_gen_loss: 0.3182978928089142 - (2851716:unified_unilip.py:926)
2026-01-07 22:57:22 - INFO - total_loss: 0.3485068082809448, masked_loc_loss: 0.03529512882232666, masked_gen_loss: 0.31321167945861816 - (2851716:unified_unilip.py:926)
2026-01-07 22:57:32 - INFO - total_loss: 0.35348111391067505, masked_loc_loss: 0.041870467364788055, masked_gen_loss: 0.3116106390953064 - (2851716:unified_unilip.py:926)
2026-01-07 22:57:46 - INFO - total_loss: 0.38639792799949646, masked_loc_loss: 0.02881617657840252, masked_gen_loss: 0.35758176445961 - (2851716:unified_unilip.py:926)
2026-01-07 22:58:00 - INFO - total_loss: 0.3029782176017761, masked_loc_loss: 0.04568822681903839, masked_gen_loss: 0.2572900056838989 - (2851716:unified_unilip.py:926)
2026-01-07 22:58:15 - INFO - total_loss: 0.2963510751724243, masked_loc_loss: 0.03535209596157074, masked_gen_loss: 0.2609989643096924 - (2851716:unified_unilip.py:926)
2026-01-07 22:58:25 - INFO - total_loss: 0.4047958254814148, masked_loc_loss: 0.03098316490650177, masked_gen_loss: 0.3738126754760742 - (2851716:unified_unilip.py:926)
2026-01-07 22:58:35 - INFO - total_loss: 0.38002753257751465, masked_loc_loss: 0.022216781973838806, masked_gen_loss: 0.35781073570251465 - (2851716:unified_unilip.py:926)
2026-01-07 22:58:49 - INFO - total_loss: 0.4417082667350769, masked_loc_loss: 0.03467649221420288, masked_gen_loss: 0.407031774520874 - (2851716:unified_unilip.py:926)
2026-01-07 22:59:04 - INFO - total_loss: 0.397511750459671, masked_loc_loss: 0.035211462527513504, masked_gen_loss: 0.3623002767562866 - (2851716:unified_unilip.py:926)
2026-01-07 22:59:19 - INFO - total_loss: 0.35000836849212646, masked_loc_loss: 0.04580916464328766, masked_gen_loss: 0.30419921875 - (2851716:unified_unilip.py:926)
2026-01-07 22:59:29 - INFO - total_loss: 0.4488155245780945, masked_loc_loss: 0.050857894122600555, masked_gen_loss: 0.39795762300491333 - (2851716:unified_unilip.py:926)
2026-01-07 22:59:41 - INFO - total_loss: 0.38639214634895325, masked_loc_loss: 0.035223715007305145, masked_gen_loss: 0.3511684238910675 - (2851716:unified_unilip.py:926)
2026-01-07 22:59:56 - INFO - total_loss: 0.35768646001815796, masked_loc_loss: 0.056294187903404236, masked_gen_loss: 0.30139225721359253 - (2851716:unified_unilip.py:926)
2026-01-07 23:00:11 - INFO - total_loss: 0.38774850964546204, masked_loc_loss: 0.03876664489507675, masked_gen_loss: 0.3489818572998047 - (2851716:unified_unilip.py:926)
2026-01-07 23:00:25 - INFO - total_loss: 0.3923783302307129, masked_loc_loss: 0.02947259321808815, masked_gen_loss: 0.36290574073791504 - (2851716:unified_unilip.py:926)
2026-01-07 23:00:34 - INFO - total_loss: 0.3514162003993988, masked_loc_loss: 0.033697813749313354, masked_gen_loss: 0.31771838665008545 - (2851716:unified_unilip.py:926)
2026-01-07 23:00:48 - INFO - total_loss: 0.36246734857559204, masked_loc_loss: 0.03283229470252991, masked_gen_loss: 0.32963505387306213 - (2851716:unified_unilip.py:926)
2026-01-07 23:01:02 - INFO - total_loss: 0.3837900459766388, masked_loc_loss: 0.034156691282987595, masked_gen_loss: 0.3496333658695221 - (2851716:unified_unilip.py:926)
2026-01-07 23:01:17 - INFO - total_loss: 0.4012843370437622, masked_loc_loss: 0.04146271198987961, masked_gen_loss: 0.359821617603302 - (2851716:unified_unilip.py:926)
2026-01-07 23:01:31 - INFO - total_loss: 0.37303146719932556, masked_loc_loss: 0.03191802278161049, masked_gen_loss: 0.34111344814300537 - (2851716:unified_unilip.py:926)
2026-01-07 23:01:41 - INFO - total_loss: 0.31675097346305847, masked_loc_loss: 0.029269792139530182, masked_gen_loss: 0.2874811887741089 - (2851716:unified_unilip.py:926)
2026-01-07 23:01:55 - INFO - total_loss: 0.3442932367324829, masked_loc_loss: 0.03763570636510849, masked_gen_loss: 0.3066575229167938 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:10 - INFO - total_loss: 0.4329978823661804, masked_loc_loss: 0.01976914331316948, masked_gen_loss: 0.41322875022888184 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:21 - INFO - total_loss: 0.4393962025642395, masked_loc_loss: 0.021179551258683205, masked_gen_loss: 0.41821664571762085 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:28 - INFO - total_loss: 0.38933178782463074, masked_loc_loss: 0.03912784904241562, masked_gen_loss: 0.3502039313316345 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:34 - INFO - total_loss: 0.37487563490867615, masked_loc_loss: 0.03933579847216606, masked_gen_loss: 0.335539847612381 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:41 - INFO - total_loss: 0.32071152329444885, masked_loc_loss: 0.029670970514416695, masked_gen_loss: 0.2910405397415161 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:47 - INFO - total_loss: 0.36301273107528687, masked_loc_loss: 0.03508804365992546, masked_gen_loss: 0.3279246985912323 - (2851716:unified_unilip.py:926)
2026-01-07 23:02:54 - INFO - total_loss: 0.38257303833961487, masked_loc_loss: 0.059393998235464096, masked_gen_loss: 0.3231790363788605 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:00 - INFO - total_loss: 0.3266308605670929, masked_loc_loss: 0.022296439856290817, masked_gen_loss: 0.304334431886673 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:06 - INFO - total_loss: 0.37882786989212036, masked_loc_loss: 0.048686861991882324, masked_gen_loss: 0.33014100790023804 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:13 - INFO - total_loss: 0.3753970265388489, masked_loc_loss: 0.027204055339097977, masked_gen_loss: 0.34819296002388 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:19 - INFO - total_loss: 0.3856046795845032, masked_loc_loss: 0.024204308167099953, masked_gen_loss: 0.3614003658294678 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:26 - INFO - total_loss: 0.3416593670845032, masked_loc_loss: 0.03819400072097778, masked_gen_loss: 0.3034653663635254 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:34 - INFO - total_loss: 0.36972254514694214, masked_loc_loss: 0.02378605492413044, masked_gen_loss: 0.34593647718429565 - (2851716:unified_unilip.py:926)
2026-01-07 23:03:49 - INFO - total_loss: 0.42660146951675415, masked_loc_loss: 0.04348057880997658, masked_gen_loss: 0.38312089443206787 - (2851716:unified_unilip.py:926)
2026-01-07 23:04:03 - INFO - total_loss: 0.30924296379089355, masked_loc_loss: 0.03713326156139374, masked_gen_loss: 0.2721096873283386 - (2851716:unified_unilip.py:926)
2026-01-07 23:04:17 - INFO - total_loss: 0.38463646173477173, masked_loc_loss: 0.015254884958267212, masked_gen_loss: 0.3693815767765045 - (2851716:unified_unilip.py:926)
2026-01-07 23:04:29 - INFO - total_loss: 0.36668890714645386, masked_loc_loss: 0.030923444777727127, masked_gen_loss: 0.33576545119285583 - (2851716:unified_unilip.py:926)
2026-01-07 23:04:39 - INFO - total_loss: 0.42200765013694763, masked_loc_loss: 0.02855190448462963, masked_gen_loss: 0.39345574378967285 - (2851716:unified_unilip.py:926)
2026-01-07 23:04:53 - INFO - total_loss: 0.3876662850379944, masked_loc_loss: 0.058452822268009186, masked_gen_loss: 0.3292134702205658 - (2851716:unified_unilip.py:926)
2026-01-07 23:05:08 - INFO - total_loss: 0.3171577453613281, masked_loc_loss: 0.04183825105428696, masked_gen_loss: 0.27531948685646057 - (2851716:unified_unilip.py:926)
2026-01-07 23:05:22 - INFO - total_loss: 0.34519535303115845, masked_loc_loss: 0.05253661423921585, masked_gen_loss: 0.2926587462425232 - (2851716:unified_unilip.py:926)
2026-01-07 23:05:37 - INFO - total_loss: 0.3746394217014313, masked_loc_loss: 0.057412855327129364, masked_gen_loss: 0.3172265589237213 - (2851716:unified_unilip.py:926)
2026-01-07 23:05:51 - INFO - total_loss: 0.36072584986686707, masked_loc_loss: 0.030822670087218285, masked_gen_loss: 0.32990318536758423 - (2851716:unified_unilip.py:926)
2026-01-07 23:06:05 - INFO - total_loss: 0.38907507061958313, masked_loc_loss: 0.05126079544425011, masked_gen_loss: 0.3378142714500427 - (2851716:unified_unilip.py:926)
2026-01-07 23:06:20 - INFO - total_loss: 0.3908047080039978, masked_loc_loss: 0.044242437928915024, masked_gen_loss: 0.3465622663497925 - (2851716:unified_unilip.py:926)
2026-01-07 23:06:34 - INFO - total_loss: 0.3603859543800354, masked_loc_loss: 0.022741008549928665, masked_gen_loss: 0.33764493465423584 - (2851716:unified_unilip.py:926)
2026-01-07 23:06:49 - INFO - total_loss: 0.32075250148773193, masked_loc_loss: 0.038782015442848206, masked_gen_loss: 0.28197047114372253 - (2851716:unified_unilip.py:926)
2026-01-07 23:08:15 - INFO - total_loss: 0.35634511709213257, masked_loc_loss: 0.030563652515411377, masked_gen_loss: 0.3257814645767212 - (2851716:unified_unilip.py:926)
2026-01-07 23:08:21 - INFO - total_loss: 0.32503175735473633, masked_loc_loss: 0.02749216929078102, masked_gen_loss: 0.2975395917892456 - (2851716:unified_unilip.py:926)
2026-01-07 23:08:27 - INFO - total_loss: 0.4138548970222473, masked_loc_loss: 0.03356284648180008, masked_gen_loss: 0.38029205799102783 - (2851716:unified_unilip.py:926)
2026-01-07 23:08:38 - INFO - total_loss: 0.3567647933959961, masked_loc_loss: 0.045237720012664795, masked_gen_loss: 0.3115270733833313 - (2851716:unified_unilip.py:926)
2026-01-07 23:08:52 - INFO - total_loss: 0.3710575997829437, masked_loc_loss: 0.035764239728450775, masked_gen_loss: 0.33529335260391235 - (2851716:unified_unilip.py:926)
2026-01-07 23:09:05 - INFO - total_loss: 0.37962573766708374, masked_loc_loss: 0.027454599738121033, masked_gen_loss: 0.3521711528301239 - (2851716:unified_unilip.py:926)
2026-01-07 23:09:20 - INFO - total_loss: 0.2540660500526428, masked_loc_loss: 0.022999271750450134, masked_gen_loss: 0.2310667634010315 - (2851716:unified_unilip.py:926)
2026-01-07 23:09:28 - INFO - total_loss: 0.3125779628753662, masked_loc_loss: 0.022610565647482872, masked_gen_loss: 0.2899673879146576 - (2851716:unified_unilip.py:926)
2026-01-07 23:09:34 - INFO - total_loss: 0.38044604659080505, masked_loc_loss: 0.025315720587968826, masked_gen_loss: 0.35513031482696533 - (2851716:unified_unilip.py:926)
2026-01-07 23:09:45 - INFO - total_loss: 0.4276699423789978, masked_loc_loss: 0.04030032455921173, masked_gen_loss: 0.38736963272094727 - (2851716:unified_unilip.py:926)
2026-01-07 23:10:00 - INFO - total_loss: 0.2989535629749298, masked_loc_loss: 0.028480399399995804, masked_gen_loss: 0.2704731523990631 - (2851716:unified_unilip.py:926)
2026-01-07 23:10:14 - INFO - total_loss: 0.35913872718811035, masked_loc_loss: 0.0414765328168869, masked_gen_loss: 0.31766220927238464 - (2851716:unified_unilip.py:926)
2026-01-07 23:10:29 - INFO - total_loss: 0.36223304271698, masked_loc_loss: 0.023132074624300003, masked_gen_loss: 0.3391009569168091 - (2851716:unified_unilip.py:926)
2026-01-07 23:10:37 - INFO - total_loss: 0.3690595030784607, masked_loc_loss: 0.04685421288013458, masked_gen_loss: 0.3222053050994873 - (2851716:unified_unilip.py:926)
2026-01-07 23:10:44 - INFO - total_loss: 0.3943476378917694, masked_loc_loss: 0.02703688107430935, masked_gen_loss: 0.3673107624053955 - (2851716:unified_unilip.py:926)
2026-01-07 23:10:58 - INFO - total_loss: 0.4233957529067993, masked_loc_loss: 0.059835974127054214, masked_gen_loss: 0.3635597825050354 - (2851716:unified_unilip.py:926)
2026-01-07 23:11:13 - INFO - total_loss: 0.3690955340862274, masked_loc_loss: 0.042531512677669525, masked_gen_loss: 0.3265640139579773 - (2851716:unified_unilip.py:926)
2026-01-07 23:11:27 - INFO - total_loss: 0.416628897190094, masked_loc_loss: 0.07166248559951782, masked_gen_loss: 0.34496641159057617 - (2851716:unified_unilip.py:926)
2026-01-07 23:11:41 - INFO - total_loss: 0.3981834948062897, masked_loc_loss: 0.020055491477251053, masked_gen_loss: 0.3781279921531677 - (2851716:unified_unilip.py:926)
2026-01-07 23:11:47 - INFO - total_loss: 0.3914223909378052, masked_loc_loss: 0.030048497021198273, masked_gen_loss: 0.3613739013671875 - (2851716:unified_unilip.py:926)
2026-01-07 23:11:59 - INFO - total_loss: 0.3992081582546234, masked_loc_loss: 0.042612023651599884, masked_gen_loss: 0.3565961420536041 - (2851716:unified_unilip.py:926)
2026-01-07 23:12:14 - INFO - total_loss: 0.38983309268951416, masked_loc_loss: 0.027844108641147614, masked_gen_loss: 0.36198899149894714 - (2851716:unified_unilip.py:926)
2026-01-07 23:12:28 - INFO - total_loss: 0.3428550064563751, masked_loc_loss: 0.040487490594387054, masked_gen_loss: 0.30236750841140747 - (2851716:unified_unilip.py:926)
2026-01-07 23:12:43 - INFO - total_loss: 0.3871437609195709, masked_loc_loss: 0.028009915724396706, masked_gen_loss: 0.35913383960723877 - (2851716:unified_unilip.py:926)
2026-01-07 23:12:51 - INFO - total_loss: 0.37331196665763855, masked_loc_loss: 0.03897186368703842, masked_gen_loss: 0.33434009552001953 - (2851716:unified_unilip.py:926)
2026-01-07 23:13:04 - INFO - total_loss: 0.3728606700897217, masked_loc_loss: 0.021236494183540344, masked_gen_loss: 0.35162419080734253 - (2851716:unified_unilip.py:926)
2026-01-07 23:13:19 - INFO - total_loss: 0.3945017457008362, masked_loc_loss: 0.043475501239299774, masked_gen_loss: 0.3510262370109558 - (2851716:unified_unilip.py:926)
2026-01-07 23:13:34 - INFO - total_loss: 0.35213330388069153, masked_loc_loss: 0.01768302544951439, masked_gen_loss: 0.33445027470588684 - (2851716:unified_unilip.py:926)
2026-01-07 23:13:41 - INFO - total_loss: 0.42806267738342285, masked_loc_loss: 0.029421504586935043, masked_gen_loss: 0.3986411690711975 - (2851716:unified_unilip.py:926)
2026-01-07 23:13:47 - INFO - total_loss: 0.3028547167778015, masked_loc_loss: 0.023779336363077164, masked_gen_loss: 0.27907538414001465 - (2851716:unified_unilip.py:926)
2026-01-07 23:13:54 - INFO - total_loss: 0.4186655580997467, masked_loc_loss: 0.031798847019672394, masked_gen_loss: 0.3868667185306549 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:00 - INFO - total_loss: 0.3466555178165436, masked_loc_loss: 0.022554250434041023, masked_gen_loss: 0.3241012692451477 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:07 - INFO - total_loss: 0.3416612148284912, masked_loc_loss: 0.015887321904301643, masked_gen_loss: 0.3257738947868347 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:13 - INFO - total_loss: 0.4024218022823334, masked_loc_loss: 0.034305721521377563, masked_gen_loss: 0.3681160807609558 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:20 - INFO - total_loss: 0.3687954246997833, masked_loc_loss: 0.03815269470214844, masked_gen_loss: 0.3306427299976349 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:26 - INFO - total_loss: 0.3523309528827667, masked_loc_loss: 0.039970070123672485, masked_gen_loss: 0.31236088275909424 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:33 - INFO - total_loss: 0.3196974992752075, masked_loc_loss: 0.022422434762120247, masked_gen_loss: 0.2972750663757324 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:40 - INFO - total_loss: 0.34929224848747253, masked_loc_loss: 0.026350557804107666, masked_gen_loss: 0.32294169068336487 - (2851716:unified_unilip.py:926)
2026-01-07 23:14:47 - INFO - total_loss: 0.33495205640792847, masked_loc_loss: 0.02326643094420433, masked_gen_loss: 0.31168562173843384 - (2851716:unified_unilip.py:926)
2026-01-07 23:15:01 - INFO - total_loss: 0.4427347779273987, masked_loc_loss: 0.040068432688713074, masked_gen_loss: 0.4026663303375244 - (2851716:unified_unilip.py:926)
2026-01-07 23:15:16 - INFO - total_loss: 0.39880380034446716, masked_loc_loss: 0.022775286808609962, masked_gen_loss: 0.37602850794792175 - (2851716:unified_unilip.py:926)
2026-01-07 23:15:30 - INFO - total_loss: 0.4210793375968933, masked_loc_loss: 0.04218190908432007, masked_gen_loss: 0.37889742851257324 - (2851716:unified_unilip.py:926)
2026-01-07 23:15:44 - INFO - total_loss: 0.36949095129966736, masked_loc_loss: 0.0287594236433506, masked_gen_loss: 0.34073153138160706 - (2851716:unified_unilip.py:926)
2026-01-07 23:15:50 - INFO - total_loss: 0.3677218556404114, masked_loc_loss: 0.03219421207904816, masked_gen_loss: 0.335527628660202 - (2851716:unified_unilip.py:926)
2026-01-07 23:15:57 - INFO - total_loss: 0.41124027967453003, masked_loc_loss: 0.036455683410167694, masked_gen_loss: 0.37478458881378174 - (2851716:unified_unilip.py:926)
2026-01-07 23:16:11 - INFO - total_loss: 0.38879284262657166, masked_loc_loss: 0.020230863243341446, masked_gen_loss: 0.3685619831085205 - (2851716:unified_unilip.py:926)
2026-01-07 23:16:26 - INFO - total_loss: 0.3473735451698303, masked_loc_loss: 0.02601243183016777, masked_gen_loss: 0.32136112451553345 - (2851716:unified_unilip.py:926)
2026-01-07 23:16:40 - INFO - total_loss: 0.34497883915901184, masked_loc_loss: 0.05582810565829277, masked_gen_loss: 0.28915074467658997 - (2851716:unified_unilip.py:926)
2026-01-07 23:16:54 - INFO - total_loss: 0.39410310983657837, masked_loc_loss: 0.03254463151097298, masked_gen_loss: 0.3615584671497345 - (2851716:unified_unilip.py:926)
2026-01-07 23:17:01 - INFO - total_loss: 0.36668676137924194, masked_loc_loss: 0.02888333797454834, masked_gen_loss: 0.3378034234046936 - (2851716:unified_unilip.py:926)
2026-01-07 23:17:09 - INFO - total_loss: 0.43333759903907776, masked_loc_loss: 0.023364625871181488, masked_gen_loss: 0.4099729657173157 - (2851716:unified_unilip.py:926)
2026-01-07 23:17:23 - INFO - total_loss: 0.3243510127067566, masked_loc_loss: 0.027095243334770203, masked_gen_loss: 0.2972557544708252 - (2851716:unified_unilip.py:926)
2026-01-07 23:17:37 - INFO - total_loss: 0.37485626339912415, masked_loc_loss: 0.029880430549383163, masked_gen_loss: 0.3449758291244507 - (2851716:unified_unilip.py:926)
2026-01-07 23:17:52 - INFO - total_loss: 0.3710556924343109, masked_loc_loss: 0.02396792732179165, masked_gen_loss: 0.3470877707004547 - (2851716:unified_unilip.py:926)
2026-01-07 23:18:04 - INFO - total_loss: 0.3670589327812195, masked_loc_loss: 0.03134565055370331, masked_gen_loss: 0.335713267326355 - (2851716:unified_unilip.py:926)
2026-01-07 23:18:11 - INFO - total_loss: 0.4059367775917053, masked_loc_loss: 0.03992791473865509, masked_gen_loss: 0.3660088777542114 - (2851716:unified_unilip.py:926)
2026-01-07 23:18:25 - INFO - total_loss: 0.37582749128341675, masked_loc_loss: 0.05227480083703995, masked_gen_loss: 0.3235526978969574 - (2851716:unified_unilip.py:926)
2026-01-07 23:18:39 - INFO - total_loss: 0.35697299242019653, masked_loc_loss: 0.06959088146686554, masked_gen_loss: 0.2873821258544922 - (2851716:unified_unilip.py:926)
2026-01-07 23:18:54 - INFO - total_loss: 0.3844548761844635, masked_loc_loss: 0.02229098603129387, masked_gen_loss: 0.3621639013290405 - (2851716:unified_unilip.py:926)
2026-01-07 23:19:08 - INFO - total_loss: 0.36340054869651794, masked_loc_loss: 0.04936414211988449, masked_gen_loss: 0.31403639912605286 - (2851716:unified_unilip.py:926)
2026-01-07 23:19:14 - INFO - total_loss: 0.3648942708969116, masked_loc_loss: 0.03565001115202904, masked_gen_loss: 0.3292442560195923 - (2851716:unified_unilip.py:926)
2026-01-07 23:19:29 - INFO - total_loss: 0.4186870753765106, masked_loc_loss: 0.041847825050354004, masked_gen_loss: 0.3768392503261566 - (2851716:unified_unilip.py:926)
2026-01-07 23:19:43 - INFO - total_loss: 0.36820387840270996, masked_loc_loss: 0.026060007512569427, masked_gen_loss: 0.34214386343955994 - (2851716:unified_unilip.py:926)
2026-01-07 23:19:58 - INFO - total_loss: 0.39179718494415283, masked_loc_loss: 0.028402917087078094, masked_gen_loss: 0.36339426040649414 - (2851716:unified_unilip.py:926)
2026-01-07 23:20:12 - INFO - total_loss: 0.3791796565055847, masked_loc_loss: 0.03593555837869644, masked_gen_loss: 0.34324410557746887 - (2851716:unified_unilip.py:926)
2026-01-07 23:20:20 - INFO - total_loss: 0.40997374057769775, masked_loc_loss: 0.08442770689725876, masked_gen_loss: 0.3255460262298584 - (2851716:unified_unilip.py:926)
2026-01-07 23:20:35 - INFO - total_loss: 0.4032868444919586, masked_loc_loss: 0.02943231910467148, masked_gen_loss: 0.37385451793670654 - (2851716:unified_unilip.py:926)
2026-01-07 23:20:50 - INFO - total_loss: 0.34973350167274475, masked_loc_loss: 0.04187466949224472, masked_gen_loss: 0.30785882472991943 - (2851716:unified_unilip.py:926)
2026-01-07 23:21:04 - INFO - total_loss: 0.3527415990829468, masked_loc_loss: 0.034264933317899704, masked_gen_loss: 0.31847667694091797 - (2851716:unified_unilip.py:926)
2026-01-07 23:21:17 - INFO - total_loss: 0.3731708824634552, masked_loc_loss: 0.026350464671850204, masked_gen_loss: 0.3468204140663147 - (2851716:unified_unilip.py:926)
2026-01-07 23:21:27 - INFO - total_loss: 0.41851821541786194, masked_loc_loss: 0.06605155020952225, masked_gen_loss: 0.3524666726589203 - (2851716:unified_unilip.py:926)
2026-01-07 23:21:42 - INFO - total_loss: 0.38703978061676025, masked_loc_loss: 0.07762019336223602, masked_gen_loss: 0.3094196021556854 - (2851716:unified_unilip.py:926)
2026-01-07 23:21:56 - INFO - total_loss: 0.4057904779911041, masked_loc_loss: 0.04242747277021408, masked_gen_loss: 0.36336299777030945 - (2851716:unified_unilip.py:926)
2026-01-07 23:22:11 - INFO - total_loss: 0.39235132932662964, masked_loc_loss: 0.029122933745384216, masked_gen_loss: 0.36322838068008423 - (2851716:unified_unilip.py:926)
2026-01-07 23:22:21 - INFO - total_loss: 0.2944663465023041, masked_loc_loss: 0.03321322798728943, masked_gen_loss: 0.26125311851501465 - (2851716:unified_unilip.py:926)
2026-01-07 23:22:27 - INFO - total_loss: 0.4451298117637634, masked_loc_loss: 0.061698220670223236, masked_gen_loss: 0.3834315836429596 - (2851716:unified_unilip.py:926)
2026-01-07 23:22:42 - INFO - total_loss: 0.3490426242351532, masked_loc_loss: 0.027955826371908188, masked_gen_loss: 0.3210867941379547 - (2851716:unified_unilip.py:926)
2026-01-07 23:22:59 - INFO - total_loss: 0.32029956579208374, masked_loc_loss: 0.042753979563713074, masked_gen_loss: 0.2775455713272095 - (2851716:unified_unilip.py:926)
2026-01-07 23:23:14 - INFO - total_loss: 0.3638479709625244, masked_loc_loss: 0.029720958322286606, masked_gen_loss: 0.3341270089149475 - (2851716:unified_unilip.py:926)
2026-01-07 23:23:24 - INFO - total_loss: 0.3896501660346985, masked_loc_loss: 0.031035348773002625, masked_gen_loss: 0.35861483216285706 - (2851716:unified_unilip.py:926)
2026-01-07 23:23:31 - INFO - total_loss: 0.3492690324783325, masked_loc_loss: 0.028665509074926376, masked_gen_loss: 0.32060351967811584 - (2851716:unified_unilip.py:926)
2026-01-07 23:23:44 - INFO - total_loss: 0.3547741770744324, masked_loc_loss: 0.0373392254114151, masked_gen_loss: 0.31743496656417847 - (2851716:unified_unilip.py:926)
2026-01-07 23:23:59 - INFO - total_loss: 0.3736998438835144, masked_loc_loss: 0.030295303091406822, masked_gen_loss: 0.34340453147888184 - (2851716:unified_unilip.py:926)
2026-01-07 23:24:13 - INFO - total_loss: 0.43836939334869385, masked_loc_loss: 0.03873014450073242, masked_gen_loss: 0.3996392488479614 - (2851716:unified_unilip.py:926)
2026-01-07 23:24:27 - INFO - total_loss: 0.34394949674606323, masked_loc_loss: 0.0263513196259737, masked_gen_loss: 0.3175981640815735 - (2851716:unified_unilip.py:926)
2026-01-07 23:24:34 - INFO - total_loss: 0.3611350655555725, masked_loc_loss: 0.04514385759830475, masked_gen_loss: 0.31599122285842896 - (2851716:unified_unilip.py:926)
2026-01-07 23:24:49 - INFO - total_loss: 0.38001561164855957, masked_loc_loss: 0.032792702317237854, masked_gen_loss: 0.3472228944301605 - (2851716:unified_unilip.py:926)
2026-01-07 23:25:03 - INFO - total_loss: 0.32133370637893677, masked_loc_loss: 0.03780491650104523, masked_gen_loss: 0.28352880477905273 - (2851716:unified_unilip.py:926)
2026-01-07 23:25:17 - INFO - total_loss: 0.37507838010787964, masked_loc_loss: 0.030035492032766342, masked_gen_loss: 0.345042884349823 - (2851716:unified_unilip.py:926)
2026-01-07 23:25:23 - INFO - total_loss: 0.38350558280944824, masked_loc_loss: 0.01220017857849598, masked_gen_loss: 0.3713054060935974 - (2851716:unified_unilip.py:926)
2026-01-07 23:25:30 - INFO - total_loss: 0.32707035541534424, masked_loc_loss: 0.041678085923194885, masked_gen_loss: 0.28539228439331055 - (2851716:unified_unilip.py:926)
