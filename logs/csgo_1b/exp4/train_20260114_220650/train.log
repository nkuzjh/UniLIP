2026-01-14 22:06:50 - INFO - Loaded WandB API key from .wandb_api_key.txt - (2126245:train_csgo.py:1281)
2026-01-14 22:06:52 - INFO - model_args: ModelArguments(model_name_or_path='UniLIP-1B', version='internvl', freeze_backbone=True, tune_mm_mlp_adapter=False, vision_tower=None, gen_vision_tower=None, mm_vision_select_layer=-1, pretrain_mm_mlp_adapter=None, pretrain_gen_mlp_adapter=None, vision_tower_pretrained=None, mm_projector_type='linear', gen_projector_type='linear', mm_use_im_start_end=False, mm_use_im_patch_token=False, mm_patch_merge_type='flat', mm_vision_select_feature='patch', n_query=256, n_und_query=0, gen_pooling='all', unilip_path='', unilip_factor=10.6, weighting_scheme='logit_normal', fix_dit=False, fix_connect=False, fix_vit=True, fix_llm=True, connect_layer=6, mllm_path='', mllm_hf_path='OpenGVLab/InternVL3-1B-hf', vae_path='', dit_path='', action_dit_layer=3, is_action_dit_dense_timestep=False) - (2126245:train_csgo.py:1293)
2026-01-14 22:06:52 - INFO - data_args: DataArguments(csgo_config='csgo_configs/exp4.yaml', data_path=None, lazy_preprocess=True, is_multimodal=False, csgo_image_folder='data/preprocessed_data', shortcaption_image_folder=None, data_type='mix', image_aspect_ratio='square') - (2126245:train_csgo.py:1294)
2026-01-14 22:06:52 - INFO - training_args: TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=True,
bf16_full_eval=False,
bits=16,
cache_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=deepspeed_scripts/zero0.json,
disable_tqdm=False,
do_eval=False,
do_predict=False,
do_train=False,
double_quant=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
freeze_mm_mlp_adapter=False,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
group_by_modality_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0001,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=outputs/csgo_1b/exp4/runs/Jan14_22-06-49_gpu-05,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=IntervalStrategy.STEPS,
lora_alpha=16,
lora_bias=none,
lora_dropout=0.05,
lora_enable=False,
lora_r=64,
lora_weight_path=,
lr_scheduler_kwargs={'min_lr': 1e-05},
lr_scheduler_type=SchedulerType.COSINE_WITH_MIN_LR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mm_projector_lr=None,
model_max_length=1024,
mp_parameters=,
mpt_attn_impl=triton,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=100.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=outputs/csgo_1b/exp4,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=128,
per_device_train_batch_size=128,
prediction_loss_only=False,
pretrain_path=none,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
quant_type=nf4,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=10,
save_strategy=SaveStrategy.STEPS,
save_total_limit=1,
seed=42,
skip_memory_metrics=True,
tf32=True,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.003,
warmup_steps=0,
weight_decay=0.0,
) - (2126245:train_csgo.py:1295)
2026-01-14 22:06:52 - INFO - csgo_config: {'debug': False, 'is_multi_task': True, 'is_action_dit_dense_timestep': True, 'data_dir': 'data/preprocessed_data', 'train_maps': ['de_dust2', 'de_nuke', 'de_ancient'], 'val_maps': ['de_dust2', 'de_nuke', 'de_ancient'], 'test_maps': ['de_dust2', 'de_nuke', 'de_ancient']} - (2126245:train_csgo.py:1296)
2026-01-14 22:06:53 - INFO - vision_select_layer: -1 - (2126245:configuration_internvl_chat.py:69)
2026-01-14 22:06:53 - INFO - ps_version: v2 - (2126245:configuration_internvl_chat.py:70)
2026-01-14 22:06:53 - INFO - min_dynamic_patch: 1 - (2126245:configuration_internvl_chat.py:71)
2026-01-14 22:06:53 - INFO - max_dynamic_patch: 12 - (2126245:configuration_internvl_chat.py:72)
2026-01-14 22:06:53 - INFO - vision_config is None. Initializing the InternVisionConfig with default values. - (2126245:configuration_internvl_chat.py:42)
2026-01-14 22:06:53 - INFO - llm_config is None. Initializing the LlamaConfig config with default values (`LlamaConfig`). - (2126245:configuration_internvl_chat.py:46)
2026-01-14 22:06:53 - INFO - vision_select_layer: -1 - (2126245:configuration_internvl_chat.py:69)
2026-01-14 22:06:53 - INFO - ps_version: v1 - (2126245:configuration_internvl_chat.py:70)
2026-01-14 22:06:53 - INFO - min_dynamic_patch: 1 - (2126245:configuration_internvl_chat.py:71)
2026-01-14 22:06:53 - INFO - max_dynamic_patch: 6 - (2126245:configuration_internvl_chat.py:72)
2026-01-14 22:06:53 - INFO - num_image_token: 256 - (2126245:modeling_internvl_chat.py:59)
2026-01-14 22:06:53 - INFO - ps_version: v2 - (2126245:modeling_internvl_chat.py:60)
2026-01-14 22:07:06 - INFO - Using conversation format: internvl - (2126245:train_csgo.py:1378)
2026-01-14 22:07:06 - INFO - fix connect False - (2126245:unified_unilip.py:185)
2026-01-14 22:07:06 - INFO - fix dit False - (2126245:unified_unilip.py:186)
2026-01-14 22:07:06 - INFO - unilip load from checkpoint!!! - (2126245:unified_unilip.py:253)
2026-01-14 22:07:06 - INFO - DiT load from checkpoint!!! - (2126245:unified_unilip.py:266)
2026-01-14 22:07:06 - INFO - Connector load from checkpoint!!! - (2126245:unified_unilip.py:287)
2026-01-14 22:07:06 - INFO - latent_queries load from checkpoint!!! - (2126245:unified_unilip.py:309)
2026-01-14 22:07:06 - INFO - Initializing Action Connector from OpenGVLab/InternVL3-1B-hf slice... - (2126245:unified_unilip.py:332)
2026-01-14 22:07:07 - INFO - Action DiT weights initialized successfully! - (2126245:unified_unilip.py:343)
2026-01-14 22:07:07 - INFO - Replacing action_dit norms with AdaRMS... - (2126245:unified_unilip.py:347)
2026-01-14 22:07:07 - INFO - Action VAE weights initialized successfully! - (2126245:unified_unilip.py:387)
2026-01-14 22:07:14 - INFO -      trainable params: model.latent_queries - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.patch_embed.proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.patch_embed.proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_1.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_1.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_2.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.time_embed.emb.timestep_embedder.linear_2.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.time_embed.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.time_embed.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.caption_projection.linear_1.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.caption_projection.linear_1.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.caption_projection.linear_2.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.caption_projection.linear_2.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.caption_norm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.0.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.1.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.2.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.3.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.4.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.5.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.6.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.7.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.8.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.9.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.10.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.11.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.12.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.13.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.14.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.15.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.16.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.17.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.18.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.19.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.20.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.21.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.22.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.23.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.24.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.25.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.26.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.scale_shift_table - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn1.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_q.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_q.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_k.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_k.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_v.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_v.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_out.0.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.attn2.to_out.0.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_inverted.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_inverted.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_depth.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_depth.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.transformer_blocks.27.ff.conv_point.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.proj_out.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.dit.proj_out.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.0.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.1.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.2.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.3.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.4.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.layers.5.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.llm_connector.norm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.projector.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.projector.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.input_layernorm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.input_layernorm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.post_attention_layernorm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.0.post_attention_layernorm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.input_layernorm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.input_layernorm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.post_attention_layernorm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.1.post_attention_layernorm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.q_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.q_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.k_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.k_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.v_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.v_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.self_attn.o_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.gate_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.up_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.mlp.down_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.input_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.input_layernorm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.input_layernorm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.post_attention_layernorm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.post_attention_layernorm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.layers.2.post_attention_layernorm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.norm.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.norm.linear.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_dit.norm.linear.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_in_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_in_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.time_mlp_in.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.time_mlp_in.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.time_mlp_out.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.time_mlp_out.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_out_proj.weight - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO -      trainable params: model.action_out_proj.bias - (2126245:train_csgo.py:1425)
2026-01-14 22:07:14 - INFO - Total parameters: 1713131496 - (2126245:train_csgo.py:1427)
2026-01-14 22:07:14 - INFO - Trainable parameters: 746752421 - (2126245:train_csgo.py:1428)
2026-01-14 22:07:14 - INFO - trainable percent: 43.589907 % - (2126245:train_csgo.py:1429)
2026-01-14 22:07:14 - INFO -  Loading Multi-Task CS2 Dataset... - (2126245:unified_task_dataset.py:489)
2026-01-14 22:07:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_dust2/splits_20000_5000/train_split.json... - (2126245:unified_task_dataset.py:497)
2026-01-14 22:07:14 - INFO - Loading CS2 Data Split data/preprocessed_data/de_nuke/splits_20000_5000/train_split.json... - (2126245:unified_task_dataset.py:497)
2026-01-14 22:07:15 - INFO - Loading CS2 Data Split data/preprocessed_data/de_ancient/splits_20000_5000/train_split.json... - (2126245:unified_task_dataset.py:497)
2026-01-14 22:07:15 - INFO -  Total entries: 60000 - (2126245:unified_task_dataset.py:528)
2026-01-14 22:07:28 - INFO -   idx  name                                                                              shape                           trainable
-----  --------------------------------------------------------------------------------  ------------------------------  -----------
    0  model.latent_queries                                                              torch.Size([1, 256, 896])       True
    1  model.vision_tower.embeddings.class_embedding                                     torch.Size([1, 1, 1024])        False
    2  model.vision_tower.embeddings.position_embedding                                  torch.Size([1, 1025, 1024])     False
    3  model.vision_tower.embeddings.patch_embedding.weight                              torch.Size([1024, 3, 14, 14])   False
    4  model.vision_tower.embeddings.patch_embedding.bias                                torch.Size([1024])              False
    5  model.vision_tower.encoder.layers.0.ls1                                           torch.Size([1024])              False
    6  model.vision_tower.encoder.layers.0.ls2                                           torch.Size([1024])              False
    7  model.vision_tower.encoder.layers.0.attn.qkv.weight                               torch.Size([3072, 1024])        False
    8  model.vision_tower.encoder.layers.0.attn.qkv.bias                                 torch.Size([3072])              False
    9  model.vision_tower.encoder.layers.0.attn.proj.weight                              torch.Size([1024, 1024])        False
   10  model.vision_tower.encoder.layers.0.attn.proj.bias                                torch.Size([1024])              False
   11  model.vision_tower.encoder.layers.0.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   12  model.vision_tower.encoder.layers.0.mlp.fc1.bias                                  torch.Size([4096])              False
   13  model.vision_tower.encoder.layers.0.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   14  model.vision_tower.encoder.layers.0.mlp.fc2.bias                                  torch.Size([1024])              False
   15  model.vision_tower.encoder.layers.0.norm1.weight                                  torch.Size([1024])              False
   16  model.vision_tower.encoder.layers.0.norm1.bias                                    torch.Size([1024])              False
   17  model.vision_tower.encoder.layers.0.norm2.weight                                  torch.Size([1024])              False
   18  model.vision_tower.encoder.layers.0.norm2.bias                                    torch.Size([1024])              False
   19  model.vision_tower.encoder.layers.1.ls1                                           torch.Size([1024])              False
   20  model.vision_tower.encoder.layers.1.ls2                                           torch.Size([1024])              False
   21  model.vision_tower.encoder.layers.1.attn.qkv.weight                               torch.Size([3072, 1024])        False
   22  model.vision_tower.encoder.layers.1.attn.qkv.bias                                 torch.Size([3072])              False
   23  model.vision_tower.encoder.layers.1.attn.proj.weight                              torch.Size([1024, 1024])        False
   24  model.vision_tower.encoder.layers.1.attn.proj.bias                                torch.Size([1024])              False
   25  model.vision_tower.encoder.layers.1.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   26  model.vision_tower.encoder.layers.1.mlp.fc1.bias                                  torch.Size([4096])              False
   27  model.vision_tower.encoder.layers.1.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   28  model.vision_tower.encoder.layers.1.mlp.fc2.bias                                  torch.Size([1024])              False
   29  model.vision_tower.encoder.layers.1.norm1.weight                                  torch.Size([1024])              False
   30  model.vision_tower.encoder.layers.1.norm1.bias                                    torch.Size([1024])              False
   31  model.vision_tower.encoder.layers.1.norm2.weight                                  torch.Size([1024])              False
   32  model.vision_tower.encoder.layers.1.norm2.bias                                    torch.Size([1024])              False
   33  model.vision_tower.encoder.layers.2.ls1                                           torch.Size([1024])              False
   34  model.vision_tower.encoder.layers.2.ls2                                           torch.Size([1024])              False
   35  model.vision_tower.encoder.layers.2.attn.qkv.weight                               torch.Size([3072, 1024])        False
   36  model.vision_tower.encoder.layers.2.attn.qkv.bias                                 torch.Size([3072])              False
   37  model.vision_tower.encoder.layers.2.attn.proj.weight                              torch.Size([1024, 1024])        False
   38  model.vision_tower.encoder.layers.2.attn.proj.bias                                torch.Size([1024])              False
   39  model.vision_tower.encoder.layers.2.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   40  model.vision_tower.encoder.layers.2.mlp.fc1.bias                                  torch.Size([4096])              False
   41  model.vision_tower.encoder.layers.2.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   42  model.vision_tower.encoder.layers.2.mlp.fc2.bias                                  torch.Size([1024])              False
   43  model.vision_tower.encoder.layers.2.norm1.weight                                  torch.Size([1024])              False
   44  model.vision_tower.encoder.layers.2.norm1.bias                                    torch.Size([1024])              False
   45  model.vision_tower.encoder.layers.2.norm2.weight                                  torch.Size([1024])              False
   46  model.vision_tower.encoder.layers.2.norm2.bias                                    torch.Size([1024])              False
   47  model.vision_tower.encoder.layers.3.ls1                                           torch.Size([1024])              False
   48  model.vision_tower.encoder.layers.3.ls2                                           torch.Size([1024])              False
   49  model.vision_tower.encoder.layers.3.attn.qkv.weight                               torch.Size([3072, 1024])        False
   50  model.vision_tower.encoder.layers.3.attn.qkv.bias                                 torch.Size([3072])              False
   51  model.vision_tower.encoder.layers.3.attn.proj.weight                              torch.Size([1024, 1024])        False
   52  model.vision_tower.encoder.layers.3.attn.proj.bias                                torch.Size([1024])              False
   53  model.vision_tower.encoder.layers.3.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   54  model.vision_tower.encoder.layers.3.mlp.fc1.bias                                  torch.Size([4096])              False
   55  model.vision_tower.encoder.layers.3.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   56  model.vision_tower.encoder.layers.3.mlp.fc2.bias                                  torch.Size([1024])              False
   57  model.vision_tower.encoder.layers.3.norm1.weight                                  torch.Size([1024])              False
   58  model.vision_tower.encoder.layers.3.norm1.bias                                    torch.Size([1024])              False
   59  model.vision_tower.encoder.layers.3.norm2.weight                                  torch.Size([1024])              False
   60  model.vision_tower.encoder.layers.3.norm2.bias                                    torch.Size([1024])              False
   61  model.vision_tower.encoder.layers.4.ls1                                           torch.Size([1024])              False
   62  model.vision_tower.encoder.layers.4.ls2                                           torch.Size([1024])              False
   63  model.vision_tower.encoder.layers.4.attn.qkv.weight                               torch.Size([3072, 1024])        False
   64  model.vision_tower.encoder.layers.4.attn.qkv.bias                                 torch.Size([3072])              False
   65  model.vision_tower.encoder.layers.4.attn.proj.weight                              torch.Size([1024, 1024])        False
   66  model.vision_tower.encoder.layers.4.attn.proj.bias                                torch.Size([1024])              False
   67  model.vision_tower.encoder.layers.4.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   68  model.vision_tower.encoder.layers.4.mlp.fc1.bias                                  torch.Size([4096])              False
   69  model.vision_tower.encoder.layers.4.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   70  model.vision_tower.encoder.layers.4.mlp.fc2.bias                                  torch.Size([1024])              False
   71  model.vision_tower.encoder.layers.4.norm1.weight                                  torch.Size([1024])              False
   72  model.vision_tower.encoder.layers.4.norm1.bias                                    torch.Size([1024])              False
   73  model.vision_tower.encoder.layers.4.norm2.weight                                  torch.Size([1024])              False
   74  model.vision_tower.encoder.layers.4.norm2.bias                                    torch.Size([1024])              False
   75  model.vision_tower.encoder.layers.5.ls1                                           torch.Size([1024])              False
   76  model.vision_tower.encoder.layers.5.ls2                                           torch.Size([1024])              False
   77  model.vision_tower.encoder.layers.5.attn.qkv.weight                               torch.Size([3072, 1024])        False
   78  model.vision_tower.encoder.layers.5.attn.qkv.bias                                 torch.Size([3072])              False
   79  model.vision_tower.encoder.layers.5.attn.proj.weight                              torch.Size([1024, 1024])        False
   80  model.vision_tower.encoder.layers.5.attn.proj.bias                                torch.Size([1024])              False
   81  model.vision_tower.encoder.layers.5.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   82  model.vision_tower.encoder.layers.5.mlp.fc1.bias                                  torch.Size([4096])              False
   83  model.vision_tower.encoder.layers.5.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   84  model.vision_tower.encoder.layers.5.mlp.fc2.bias                                  torch.Size([1024])              False
   85  model.vision_tower.encoder.layers.5.norm1.weight                                  torch.Size([1024])              False
   86  model.vision_tower.encoder.layers.5.norm1.bias                                    torch.Size([1024])              False
   87  model.vision_tower.encoder.layers.5.norm2.weight                                  torch.Size([1024])              False
   88  model.vision_tower.encoder.layers.5.norm2.bias                                    torch.Size([1024])              False
   89  model.vision_tower.encoder.layers.6.ls1                                           torch.Size([1024])              False
   90  model.vision_tower.encoder.layers.6.ls2                                           torch.Size([1024])              False
   91  model.vision_tower.encoder.layers.6.attn.qkv.weight                               torch.Size([3072, 1024])        False
   92  model.vision_tower.encoder.layers.6.attn.qkv.bias                                 torch.Size([3072])              False
   93  model.vision_tower.encoder.layers.6.attn.proj.weight                              torch.Size([1024, 1024])        False
   94  model.vision_tower.encoder.layers.6.attn.proj.bias                                torch.Size([1024])              False
   95  model.vision_tower.encoder.layers.6.mlp.fc1.weight                                torch.Size([4096, 1024])        False
   96  model.vision_tower.encoder.layers.6.mlp.fc1.bias                                  torch.Size([4096])              False
   97  model.vision_tower.encoder.layers.6.mlp.fc2.weight                                torch.Size([1024, 4096])        False
   98  model.vision_tower.encoder.layers.6.mlp.fc2.bias                                  torch.Size([1024])              False
   99  model.vision_tower.encoder.layers.6.norm1.weight                                  torch.Size([1024])              False
  100  model.vision_tower.encoder.layers.6.norm1.bias                                    torch.Size([1024])              False
  101  model.vision_tower.encoder.layers.6.norm2.weight                                  torch.Size([1024])              False
  102  model.vision_tower.encoder.layers.6.norm2.bias                                    torch.Size([1024])              False
  103  model.vision_tower.encoder.layers.7.ls1                                           torch.Size([1024])              False
  104  model.vision_tower.encoder.layers.7.ls2                                           torch.Size([1024])              False
  105  model.vision_tower.encoder.layers.7.attn.qkv.weight                               torch.Size([3072, 1024])        False
  106  model.vision_tower.encoder.layers.7.attn.qkv.bias                                 torch.Size([3072])              False
  107  model.vision_tower.encoder.layers.7.attn.proj.weight                              torch.Size([1024, 1024])        False
  108  model.vision_tower.encoder.layers.7.attn.proj.bias                                torch.Size([1024])              False
  109  model.vision_tower.encoder.layers.7.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  110  model.vision_tower.encoder.layers.7.mlp.fc1.bias                                  torch.Size([4096])              False
  111  model.vision_tower.encoder.layers.7.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  112  model.vision_tower.encoder.layers.7.mlp.fc2.bias                                  torch.Size([1024])              False
  113  model.vision_tower.encoder.layers.7.norm1.weight                                  torch.Size([1024])              False
  114  model.vision_tower.encoder.layers.7.norm1.bias                                    torch.Size([1024])              False
  115  model.vision_tower.encoder.layers.7.norm2.weight                                  torch.Size([1024])              False
  116  model.vision_tower.encoder.layers.7.norm2.bias                                    torch.Size([1024])              False
  117  model.vision_tower.encoder.layers.8.ls1                                           torch.Size([1024])              False
  118  model.vision_tower.encoder.layers.8.ls2                                           torch.Size([1024])              False
  119  model.vision_tower.encoder.layers.8.attn.qkv.weight                               torch.Size([3072, 1024])        False
  120  model.vision_tower.encoder.layers.8.attn.qkv.bias                                 torch.Size([3072])              False
  121  model.vision_tower.encoder.layers.8.attn.proj.weight                              torch.Size([1024, 1024])        False
  122  model.vision_tower.encoder.layers.8.attn.proj.bias                                torch.Size([1024])              False
  123  model.vision_tower.encoder.layers.8.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  124  model.vision_tower.encoder.layers.8.mlp.fc1.bias                                  torch.Size([4096])              False
  125  model.vision_tower.encoder.layers.8.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  126  model.vision_tower.encoder.layers.8.mlp.fc2.bias                                  torch.Size([1024])              False
  127  model.vision_tower.encoder.layers.8.norm1.weight                                  torch.Size([1024])              False
  128  model.vision_tower.encoder.layers.8.norm1.bias                                    torch.Size([1024])              False
  129  model.vision_tower.encoder.layers.8.norm2.weight                                  torch.Size([1024])              False
  130  model.vision_tower.encoder.layers.8.norm2.bias                                    torch.Size([1024])              False
  131  model.vision_tower.encoder.layers.9.ls1                                           torch.Size([1024])              False
  132  model.vision_tower.encoder.layers.9.ls2                                           torch.Size([1024])              False
  133  model.vision_tower.encoder.layers.9.attn.qkv.weight                               torch.Size([3072, 1024])        False
  134  model.vision_tower.encoder.layers.9.attn.qkv.bias                                 torch.Size([3072])              False
  135  model.vision_tower.encoder.layers.9.attn.proj.weight                              torch.Size([1024, 1024])        False
  136  model.vision_tower.encoder.layers.9.attn.proj.bias                                torch.Size([1024])              False
  137  model.vision_tower.encoder.layers.9.mlp.fc1.weight                                torch.Size([4096, 1024])        False
  138  model.vision_tower.encoder.layers.9.mlp.fc1.bias                                  torch.Size([4096])              False
  139  model.vision_tower.encoder.layers.9.mlp.fc2.weight                                torch.Size([1024, 4096])        False
  140  model.vision_tower.encoder.layers.9.mlp.fc2.bias                                  torch.Size([1024])              False
  141  model.vision_tower.encoder.layers.9.norm1.weight                                  torch.Size([1024])              False
  142  model.vision_tower.encoder.layers.9.norm1.bias                                    torch.Size([1024])              False
  143  model.vision_tower.encoder.layers.9.norm2.weight                                  torch.Size([1024])              False
  144  model.vision_tower.encoder.layers.9.norm2.bias                                    torch.Size([1024])              False
  145  model.vision_tower.encoder.layers.10.ls1                                          torch.Size([1024])              False
  146  model.vision_tower.encoder.layers.10.ls2                                          torch.Size([1024])              False
  147  model.vision_tower.encoder.layers.10.attn.qkv.weight                              torch.Size([3072, 1024])        False
  148  model.vision_tower.encoder.layers.10.attn.qkv.bias                                torch.Size([3072])              False
  149  model.vision_tower.encoder.layers.10.attn.proj.weight                             torch.Size([1024, 1024])        False
  150  model.vision_tower.encoder.layers.10.attn.proj.bias                               torch.Size([1024])              False
  151  model.vision_tower.encoder.layers.10.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  152  model.vision_tower.encoder.layers.10.mlp.fc1.bias                                 torch.Size([4096])              False
  153  model.vision_tower.encoder.layers.10.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  154  model.vision_tower.encoder.layers.10.mlp.fc2.bias                                 torch.Size([1024])              False
  155  model.vision_tower.encoder.layers.10.norm1.weight                                 torch.Size([1024])              False
  156  model.vision_tower.encoder.layers.10.norm1.bias                                   torch.Size([1024])              False
  157  model.vision_tower.encoder.layers.10.norm2.weight                                 torch.Size([1024])              False
  158  model.vision_tower.encoder.layers.10.norm2.bias                                   torch.Size([1024])              False
  159  model.vision_tower.encoder.layers.11.ls1                                          torch.Size([1024])              False
  160  model.vision_tower.encoder.layers.11.ls2                                          torch.Size([1024])              False
  161  model.vision_tower.encoder.layers.11.attn.qkv.weight                              torch.Size([3072, 1024])        False
  162  model.vision_tower.encoder.layers.11.attn.qkv.bias                                torch.Size([3072])              False
  163  model.vision_tower.encoder.layers.11.attn.proj.weight                             torch.Size([1024, 1024])        False
  164  model.vision_tower.encoder.layers.11.attn.proj.bias                               torch.Size([1024])              False
  165  model.vision_tower.encoder.layers.11.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  166  model.vision_tower.encoder.layers.11.mlp.fc1.bias                                 torch.Size([4096])              False
  167  model.vision_tower.encoder.layers.11.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  168  model.vision_tower.encoder.layers.11.mlp.fc2.bias                                 torch.Size([1024])              False
  169  model.vision_tower.encoder.layers.11.norm1.weight                                 torch.Size([1024])              False
  170  model.vision_tower.encoder.layers.11.norm1.bias                                   torch.Size([1024])              False
  171  model.vision_tower.encoder.layers.11.norm2.weight                                 torch.Size([1024])              False
  172  model.vision_tower.encoder.layers.11.norm2.bias                                   torch.Size([1024])              False
  173  model.vision_tower.encoder.layers.12.ls1                                          torch.Size([1024])              False
  174  model.vision_tower.encoder.layers.12.ls2                                          torch.Size([1024])              False
  175  model.vision_tower.encoder.layers.12.attn.qkv.weight                              torch.Size([3072, 1024])        False
  176  model.vision_tower.encoder.layers.12.attn.qkv.bias                                torch.Size([3072])              False
  177  model.vision_tower.encoder.layers.12.attn.proj.weight                             torch.Size([1024, 1024])        False
  178  model.vision_tower.encoder.layers.12.attn.proj.bias                               torch.Size([1024])              False
  179  model.vision_tower.encoder.layers.12.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  180  model.vision_tower.encoder.layers.12.mlp.fc1.bias                                 torch.Size([4096])              False
  181  model.vision_tower.encoder.layers.12.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  182  model.vision_tower.encoder.layers.12.mlp.fc2.bias                                 torch.Size([1024])              False
  183  model.vision_tower.encoder.layers.12.norm1.weight                                 torch.Size([1024])              False
  184  model.vision_tower.encoder.layers.12.norm1.bias                                   torch.Size([1024])              False
  185  model.vision_tower.encoder.layers.12.norm2.weight                                 torch.Size([1024])              False
  186  model.vision_tower.encoder.layers.12.norm2.bias                                   torch.Size([1024])              False
  187  model.vision_tower.encoder.layers.13.ls1                                          torch.Size([1024])              False
  188  model.vision_tower.encoder.layers.13.ls2                                          torch.Size([1024])              False
  189  model.vision_tower.encoder.layers.13.attn.qkv.weight                              torch.Size([3072, 1024])        False
  190  model.vision_tower.encoder.layers.13.attn.qkv.bias                                torch.Size([3072])              False
  191  model.vision_tower.encoder.layers.13.attn.proj.weight                             torch.Size([1024, 1024])        False
  192  model.vision_tower.encoder.layers.13.attn.proj.bias                               torch.Size([1024])              False
  193  model.vision_tower.encoder.layers.13.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  194  model.vision_tower.encoder.layers.13.mlp.fc1.bias                                 torch.Size([4096])              False
  195  model.vision_tower.encoder.layers.13.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  196  model.vision_tower.encoder.layers.13.mlp.fc2.bias                                 torch.Size([1024])              False
  197  model.vision_tower.encoder.layers.13.norm1.weight                                 torch.Size([1024])              False
  198  model.vision_tower.encoder.layers.13.norm1.bias                                   torch.Size([1024])              False
  199  model.vision_tower.encoder.layers.13.norm2.weight                                 torch.Size([1024])              False
  200  model.vision_tower.encoder.layers.13.norm2.bias                                   torch.Size([1024])              False
  201  model.vision_tower.encoder.layers.14.ls1                                          torch.Size([1024])              False
  202  model.vision_tower.encoder.layers.14.ls2                                          torch.Size([1024])              False
  203  model.vision_tower.encoder.layers.14.attn.qkv.weight                              torch.Size([3072, 1024])        False
  204  model.vision_tower.encoder.layers.14.attn.qkv.bias                                torch.Size([3072])              False
  205  model.vision_tower.encoder.layers.14.attn.proj.weight                             torch.Size([1024, 1024])        False
  206  model.vision_tower.encoder.layers.14.attn.proj.bias                               torch.Size([1024])              False
  207  model.vision_tower.encoder.layers.14.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  208  model.vision_tower.encoder.layers.14.mlp.fc1.bias                                 torch.Size([4096])              False
  209  model.vision_tower.encoder.layers.14.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  210  model.vision_tower.encoder.layers.14.mlp.fc2.bias                                 torch.Size([1024])              False
  211  model.vision_tower.encoder.layers.14.norm1.weight                                 torch.Size([1024])              False
  212  model.vision_tower.encoder.layers.14.norm1.bias                                   torch.Size([1024])              False
  213  model.vision_tower.encoder.layers.14.norm2.weight                                 torch.Size([1024])              False
  214  model.vision_tower.encoder.layers.14.norm2.bias                                   torch.Size([1024])              False
  215  model.vision_tower.encoder.layers.15.ls1                                          torch.Size([1024])              False
  216  model.vision_tower.encoder.layers.15.ls2                                          torch.Size([1024])              False
  217  model.vision_tower.encoder.layers.15.attn.qkv.weight                              torch.Size([3072, 1024])        False
  218  model.vision_tower.encoder.layers.15.attn.qkv.bias                                torch.Size([3072])              False
  219  model.vision_tower.encoder.layers.15.attn.proj.weight                             torch.Size([1024, 1024])        False
  220  model.vision_tower.encoder.layers.15.attn.proj.bias                               torch.Size([1024])              False
  221  model.vision_tower.encoder.layers.15.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  222  model.vision_tower.encoder.layers.15.mlp.fc1.bias                                 torch.Size([4096])              False
  223  model.vision_tower.encoder.layers.15.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  224  model.vision_tower.encoder.layers.15.mlp.fc2.bias                                 torch.Size([1024])              False
  225  model.vision_tower.encoder.layers.15.norm1.weight                                 torch.Size([1024])              False
  226  model.vision_tower.encoder.layers.15.norm1.bias                                   torch.Size([1024])              False
  227  model.vision_tower.encoder.layers.15.norm2.weight                                 torch.Size([1024])              False
  228  model.vision_tower.encoder.layers.15.norm2.bias                                   torch.Size([1024])              False
  229  model.vision_tower.encoder.layers.16.ls1                                          torch.Size([1024])              False
  230  model.vision_tower.encoder.layers.16.ls2                                          torch.Size([1024])              False
  231  model.vision_tower.encoder.layers.16.attn.qkv.weight                              torch.Size([3072, 1024])        False
  232  model.vision_tower.encoder.layers.16.attn.qkv.bias                                torch.Size([3072])              False
  233  model.vision_tower.encoder.layers.16.attn.proj.weight                             torch.Size([1024, 1024])        False
  234  model.vision_tower.encoder.layers.16.attn.proj.bias                               torch.Size([1024])              False
  235  model.vision_tower.encoder.layers.16.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  236  model.vision_tower.encoder.layers.16.mlp.fc1.bias                                 torch.Size([4096])              False
  237  model.vision_tower.encoder.layers.16.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  238  model.vision_tower.encoder.layers.16.mlp.fc2.bias                                 torch.Size([1024])              False
  239  model.vision_tower.encoder.layers.16.norm1.weight                                 torch.Size([1024])              False
  240  model.vision_tower.encoder.layers.16.norm1.bias                                   torch.Size([1024])              False
  241  model.vision_tower.encoder.layers.16.norm2.weight                                 torch.Size([1024])              False
  242  model.vision_tower.encoder.layers.16.norm2.bias                                   torch.Size([1024])              False
  243  model.vision_tower.encoder.layers.17.ls1                                          torch.Size([1024])              False
  244  model.vision_tower.encoder.layers.17.ls2                                          torch.Size([1024])              False
  245  model.vision_tower.encoder.layers.17.attn.qkv.weight                              torch.Size([3072, 1024])        False
  246  model.vision_tower.encoder.layers.17.attn.qkv.bias                                torch.Size([3072])              False
  247  model.vision_tower.encoder.layers.17.attn.proj.weight                             torch.Size([1024, 1024])        False
  248  model.vision_tower.encoder.layers.17.attn.proj.bias                               torch.Size([1024])              False
  249  model.vision_tower.encoder.layers.17.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  250  model.vision_tower.encoder.layers.17.mlp.fc1.bias                                 torch.Size([4096])              False
  251  model.vision_tower.encoder.layers.17.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  252  model.vision_tower.encoder.layers.17.mlp.fc2.bias                                 torch.Size([1024])              False
  253  model.vision_tower.encoder.layers.17.norm1.weight                                 torch.Size([1024])              False
  254  model.vision_tower.encoder.layers.17.norm1.bias                                   torch.Size([1024])              False
  255  model.vision_tower.encoder.layers.17.norm2.weight                                 torch.Size([1024])              False
  256  model.vision_tower.encoder.layers.17.norm2.bias                                   torch.Size([1024])              False
  257  model.vision_tower.encoder.layers.18.ls1                                          torch.Size([1024])              False
  258  model.vision_tower.encoder.layers.18.ls2                                          torch.Size([1024])              False
  259  model.vision_tower.encoder.layers.18.attn.qkv.weight                              torch.Size([3072, 1024])        False
  260  model.vision_tower.encoder.layers.18.attn.qkv.bias                                torch.Size([3072])              False
  261  model.vision_tower.encoder.layers.18.attn.proj.weight                             torch.Size([1024, 1024])        False
  262  model.vision_tower.encoder.layers.18.attn.proj.bias                               torch.Size([1024])              False
  263  model.vision_tower.encoder.layers.18.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  264  model.vision_tower.encoder.layers.18.mlp.fc1.bias                                 torch.Size([4096])              False
  265  model.vision_tower.encoder.layers.18.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  266  model.vision_tower.encoder.layers.18.mlp.fc2.bias                                 torch.Size([1024])              False
  267  model.vision_tower.encoder.layers.18.norm1.weight                                 torch.Size([1024])              False
  268  model.vision_tower.encoder.layers.18.norm1.bias                                   torch.Size([1024])              False
  269  model.vision_tower.encoder.layers.18.norm2.weight                                 torch.Size([1024])              False
  270  model.vision_tower.encoder.layers.18.norm2.bias                                   torch.Size([1024])              False
  271  model.vision_tower.encoder.layers.19.ls1                                          torch.Size([1024])              False
  272  model.vision_tower.encoder.layers.19.ls2                                          torch.Size([1024])              False
  273  model.vision_tower.encoder.layers.19.attn.qkv.weight                              torch.Size([3072, 1024])        False
  274  model.vision_tower.encoder.layers.19.attn.qkv.bias                                torch.Size([3072])              False
  275  model.vision_tower.encoder.layers.19.attn.proj.weight                             torch.Size([1024, 1024])        False
  276  model.vision_tower.encoder.layers.19.attn.proj.bias                               torch.Size([1024])              False
  277  model.vision_tower.encoder.layers.19.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  278  model.vision_tower.encoder.layers.19.mlp.fc1.bias                                 torch.Size([4096])              False
  279  model.vision_tower.encoder.layers.19.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  280  model.vision_tower.encoder.layers.19.mlp.fc2.bias                                 torch.Size([1024])              False
  281  model.vision_tower.encoder.layers.19.norm1.weight                                 torch.Size([1024])              False
  282  model.vision_tower.encoder.layers.19.norm1.bias                                   torch.Size([1024])              False
  283  model.vision_tower.encoder.layers.19.norm2.weight                                 torch.Size([1024])              False
  284  model.vision_tower.encoder.layers.19.norm2.bias                                   torch.Size([1024])              False
  285  model.vision_tower.encoder.layers.20.ls1                                          torch.Size([1024])              False
  286  model.vision_tower.encoder.layers.20.ls2                                          torch.Size([1024])              False
  287  model.vision_tower.encoder.layers.20.attn.qkv.weight                              torch.Size([3072, 1024])        False
  288  model.vision_tower.encoder.layers.20.attn.qkv.bias                                torch.Size([3072])              False
  289  model.vision_tower.encoder.layers.20.attn.proj.weight                             torch.Size([1024, 1024])        False
  290  model.vision_tower.encoder.layers.20.attn.proj.bias                               torch.Size([1024])              False
  291  model.vision_tower.encoder.layers.20.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  292  model.vision_tower.encoder.layers.20.mlp.fc1.bias                                 torch.Size([4096])              False
  293  model.vision_tower.encoder.layers.20.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  294  model.vision_tower.encoder.layers.20.mlp.fc2.bias                                 torch.Size([1024])              False
  295  model.vision_tower.encoder.layers.20.norm1.weight                                 torch.Size([1024])              False
  296  model.vision_tower.encoder.layers.20.norm1.bias                                   torch.Size([1024])              False
  297  model.vision_tower.encoder.layers.20.norm2.weight                                 torch.Size([1024])              False
  298  model.vision_tower.encoder.layers.20.norm2.bias                                   torch.Size([1024])              False
  299  model.vision_tower.encoder.layers.21.ls1                                          torch.Size([1024])              False
  300  model.vision_tower.encoder.layers.21.ls2                                          torch.Size([1024])              False
  301  model.vision_tower.encoder.layers.21.attn.qkv.weight                              torch.Size([3072, 1024])        False
  302  model.vision_tower.encoder.layers.21.attn.qkv.bias                                torch.Size([3072])              False
  303  model.vision_tower.encoder.layers.21.attn.proj.weight                             torch.Size([1024, 1024])        False
  304  model.vision_tower.encoder.layers.21.attn.proj.bias                               torch.Size([1024])              False
  305  model.vision_tower.encoder.layers.21.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  306  model.vision_tower.encoder.layers.21.mlp.fc1.bias                                 torch.Size([4096])              False
  307  model.vision_tower.encoder.layers.21.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  308  model.vision_tower.encoder.layers.21.mlp.fc2.bias                                 torch.Size([1024])              False
  309  model.vision_tower.encoder.layers.21.norm1.weight                                 torch.Size([1024])              False
  310  model.vision_tower.encoder.layers.21.norm1.bias                                   torch.Size([1024])              False
  311  model.vision_tower.encoder.layers.21.norm2.weight                                 torch.Size([1024])              False
  312  model.vision_tower.encoder.layers.21.norm2.bias                                   torch.Size([1024])              False
  313  model.vision_tower.encoder.layers.22.ls1                                          torch.Size([1024])              False
  314  model.vision_tower.encoder.layers.22.ls2                                          torch.Size([1024])              False
  315  model.vision_tower.encoder.layers.22.attn.qkv.weight                              torch.Size([3072, 1024])        False
  316  model.vision_tower.encoder.layers.22.attn.qkv.bias                                torch.Size([3072])              False
  317  model.vision_tower.encoder.layers.22.attn.proj.weight                             torch.Size([1024, 1024])        False
  318  model.vision_tower.encoder.layers.22.attn.proj.bias                               torch.Size([1024])              False
  319  model.vision_tower.encoder.layers.22.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  320  model.vision_tower.encoder.layers.22.mlp.fc1.bias                                 torch.Size([4096])              False
  321  model.vision_tower.encoder.layers.22.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  322  model.vision_tower.encoder.layers.22.mlp.fc2.bias                                 torch.Size([1024])              False
  323  model.vision_tower.encoder.layers.22.norm1.weight                                 torch.Size([1024])              False
  324  model.vision_tower.encoder.layers.22.norm1.bias                                   torch.Size([1024])              False
  325  model.vision_tower.encoder.layers.22.norm2.weight                                 torch.Size([1024])              False
  326  model.vision_tower.encoder.layers.22.norm2.bias                                   torch.Size([1024])              False
  327  model.vision_tower.encoder.layers.23.ls1                                          torch.Size([1024])              False
  328  model.vision_tower.encoder.layers.23.ls2                                          torch.Size([1024])              False
  329  model.vision_tower.encoder.layers.23.attn.qkv.weight                              torch.Size([3072, 1024])        False
  330  model.vision_tower.encoder.layers.23.attn.qkv.bias                                torch.Size([3072])              False
  331  model.vision_tower.encoder.layers.23.attn.proj.weight                             torch.Size([1024, 1024])        False
  332  model.vision_tower.encoder.layers.23.attn.proj.bias                               torch.Size([1024])              False
  333  model.vision_tower.encoder.layers.23.mlp.fc1.weight                               torch.Size([4096, 1024])        False
  334  model.vision_tower.encoder.layers.23.mlp.fc1.bias                                 torch.Size([4096])              False
  335  model.vision_tower.encoder.layers.23.mlp.fc2.weight                               torch.Size([1024, 4096])        False
  336  model.vision_tower.encoder.layers.23.mlp.fc2.bias                                 torch.Size([1024])              False
  337  model.vision_tower.encoder.layers.23.norm1.weight                                 torch.Size([1024])              False
  338  model.vision_tower.encoder.layers.23.norm1.bias                                   torch.Size([1024])              False
  339  model.vision_tower.encoder.layers.23.norm2.weight                                 torch.Size([1024])              False
  340  model.vision_tower.encoder.layers.23.norm2.bias                                   torch.Size([1024])              False
  341  model.multi_modal_projector.0.weight                                              torch.Size([4096])              False
  342  model.multi_modal_projector.0.bias                                                torch.Size([4096])              False
  343  model.multi_modal_projector.1.weight                                              torch.Size([896, 4096])         False
  344  model.multi_modal_projector.1.bias                                                torch.Size([896])               False
  345  model.multi_modal_projector.3.weight                                              torch.Size([896, 896])          False
  346  model.multi_modal_projector.3.bias                                                torch.Size([896])               False
  347  model.language_model.embed_tokens.weight                                          torch.Size([151678, 896])       False
  348  model.language_model.layers.0.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  349  model.language_model.layers.0.self_attn.q_proj.bias                               torch.Size([896])               False
  350  model.language_model.layers.0.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  351  model.language_model.layers.0.self_attn.k_proj.bias                               torch.Size([128])               False
  352  model.language_model.layers.0.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  353  model.language_model.layers.0.self_attn.v_proj.bias                               torch.Size([128])               False
  354  model.language_model.layers.0.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  355  model.language_model.layers.0.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  356  model.language_model.layers.0.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  357  model.language_model.layers.0.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  358  model.language_model.layers.0.input_layernorm.weight                              torch.Size([896])               False
  359  model.language_model.layers.0.post_attention_layernorm.weight                     torch.Size([896])               False
  360  model.language_model.layers.1.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  361  model.language_model.layers.1.self_attn.q_proj.bias                               torch.Size([896])               False
  362  model.language_model.layers.1.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  363  model.language_model.layers.1.self_attn.k_proj.bias                               torch.Size([128])               False
  364  model.language_model.layers.1.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  365  model.language_model.layers.1.self_attn.v_proj.bias                               torch.Size([128])               False
  366  model.language_model.layers.1.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  367  model.language_model.layers.1.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  368  model.language_model.layers.1.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  369  model.language_model.layers.1.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  370  model.language_model.layers.1.input_layernorm.weight                              torch.Size([896])               False
  371  model.language_model.layers.1.post_attention_layernorm.weight                     torch.Size([896])               False
  372  model.language_model.layers.2.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  373  model.language_model.layers.2.self_attn.q_proj.bias                               torch.Size([896])               False
  374  model.language_model.layers.2.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  375  model.language_model.layers.2.self_attn.k_proj.bias                               torch.Size([128])               False
  376  model.language_model.layers.2.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  377  model.language_model.layers.2.self_attn.v_proj.bias                               torch.Size([128])               False
  378  model.language_model.layers.2.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  379  model.language_model.layers.2.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  380  model.language_model.layers.2.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  381  model.language_model.layers.2.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  382  model.language_model.layers.2.input_layernorm.weight                              torch.Size([896])               False
  383  model.language_model.layers.2.post_attention_layernorm.weight                     torch.Size([896])               False
  384  model.language_model.layers.3.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  385  model.language_model.layers.3.self_attn.q_proj.bias                               torch.Size([896])               False
  386  model.language_model.layers.3.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  387  model.language_model.layers.3.self_attn.k_proj.bias                               torch.Size([128])               False
  388  model.language_model.layers.3.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  389  model.language_model.layers.3.self_attn.v_proj.bias                               torch.Size([128])               False
  390  model.language_model.layers.3.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  391  model.language_model.layers.3.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  392  model.language_model.layers.3.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  393  model.language_model.layers.3.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  394  model.language_model.layers.3.input_layernorm.weight                              torch.Size([896])               False
  395  model.language_model.layers.3.post_attention_layernorm.weight                     torch.Size([896])               False
  396  model.language_model.layers.4.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  397  model.language_model.layers.4.self_attn.q_proj.bias                               torch.Size([896])               False
  398  model.language_model.layers.4.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  399  model.language_model.layers.4.self_attn.k_proj.bias                               torch.Size([128])               False
  400  model.language_model.layers.4.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  401  model.language_model.layers.4.self_attn.v_proj.bias                               torch.Size([128])               False
  402  model.language_model.layers.4.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  403  model.language_model.layers.4.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  404  model.language_model.layers.4.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  405  model.language_model.layers.4.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  406  model.language_model.layers.4.input_layernorm.weight                              torch.Size([896])               False
  407  model.language_model.layers.4.post_attention_layernorm.weight                     torch.Size([896])               False
  408  model.language_model.layers.5.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  409  model.language_model.layers.5.self_attn.q_proj.bias                               torch.Size([896])               False
  410  model.language_model.layers.5.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  411  model.language_model.layers.5.self_attn.k_proj.bias                               torch.Size([128])               False
  412  model.language_model.layers.5.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  413  model.language_model.layers.5.self_attn.v_proj.bias                               torch.Size([128])               False
  414  model.language_model.layers.5.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  415  model.language_model.layers.5.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  416  model.language_model.layers.5.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  417  model.language_model.layers.5.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  418  model.language_model.layers.5.input_layernorm.weight                              torch.Size([896])               False
  419  model.language_model.layers.5.post_attention_layernorm.weight                     torch.Size([896])               False
  420  model.language_model.layers.6.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  421  model.language_model.layers.6.self_attn.q_proj.bias                               torch.Size([896])               False
  422  model.language_model.layers.6.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  423  model.language_model.layers.6.self_attn.k_proj.bias                               torch.Size([128])               False
  424  model.language_model.layers.6.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  425  model.language_model.layers.6.self_attn.v_proj.bias                               torch.Size([128])               False
  426  model.language_model.layers.6.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  427  model.language_model.layers.6.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  428  model.language_model.layers.6.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  429  model.language_model.layers.6.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  430  model.language_model.layers.6.input_layernorm.weight                              torch.Size([896])               False
  431  model.language_model.layers.6.post_attention_layernorm.weight                     torch.Size([896])               False
  432  model.language_model.layers.7.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  433  model.language_model.layers.7.self_attn.q_proj.bias                               torch.Size([896])               False
  434  model.language_model.layers.7.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  435  model.language_model.layers.7.self_attn.k_proj.bias                               torch.Size([128])               False
  436  model.language_model.layers.7.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  437  model.language_model.layers.7.self_attn.v_proj.bias                               torch.Size([128])               False
  438  model.language_model.layers.7.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  439  model.language_model.layers.7.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  440  model.language_model.layers.7.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  441  model.language_model.layers.7.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  442  model.language_model.layers.7.input_layernorm.weight                              torch.Size([896])               False
  443  model.language_model.layers.7.post_attention_layernorm.weight                     torch.Size([896])               False
  444  model.language_model.layers.8.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  445  model.language_model.layers.8.self_attn.q_proj.bias                               torch.Size([896])               False
  446  model.language_model.layers.8.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  447  model.language_model.layers.8.self_attn.k_proj.bias                               torch.Size([128])               False
  448  model.language_model.layers.8.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  449  model.language_model.layers.8.self_attn.v_proj.bias                               torch.Size([128])               False
  450  model.language_model.layers.8.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  451  model.language_model.layers.8.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  452  model.language_model.layers.8.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  453  model.language_model.layers.8.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  454  model.language_model.layers.8.input_layernorm.weight                              torch.Size([896])               False
  455  model.language_model.layers.8.post_attention_layernorm.weight                     torch.Size([896])               False
  456  model.language_model.layers.9.self_attn.q_proj.weight                             torch.Size([896, 896])          False
  457  model.language_model.layers.9.self_attn.q_proj.bias                               torch.Size([896])               False
  458  model.language_model.layers.9.self_attn.k_proj.weight                             torch.Size([128, 896])          False
  459  model.language_model.layers.9.self_attn.k_proj.bias                               torch.Size([128])               False
  460  model.language_model.layers.9.self_attn.v_proj.weight                             torch.Size([128, 896])          False
  461  model.language_model.layers.9.self_attn.v_proj.bias                               torch.Size([128])               False
  462  model.language_model.layers.9.self_attn.o_proj.weight                             torch.Size([896, 896])          False
  463  model.language_model.layers.9.mlp.gate_proj.weight                                torch.Size([4864, 896])         False
  464  model.language_model.layers.9.mlp.up_proj.weight                                  torch.Size([4864, 896])         False
  465  model.language_model.layers.9.mlp.down_proj.weight                                torch.Size([896, 4864])         False
  466  model.language_model.layers.9.input_layernorm.weight                              torch.Size([896])               False
  467  model.language_model.layers.9.post_attention_layernorm.weight                     torch.Size([896])               False
  468  model.language_model.layers.10.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  469  model.language_model.layers.10.self_attn.q_proj.bias                              torch.Size([896])               False
  470  model.language_model.layers.10.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  471  model.language_model.layers.10.self_attn.k_proj.bias                              torch.Size([128])               False
  472  model.language_model.layers.10.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  473  model.language_model.layers.10.self_attn.v_proj.bias                              torch.Size([128])               False
  474  model.language_model.layers.10.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  475  model.language_model.layers.10.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  476  model.language_model.layers.10.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  477  model.language_model.layers.10.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  478  model.language_model.layers.10.input_layernorm.weight                             torch.Size([896])               False
  479  model.language_model.layers.10.post_attention_layernorm.weight                    torch.Size([896])               False
  480  model.language_model.layers.11.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  481  model.language_model.layers.11.self_attn.q_proj.bias                              torch.Size([896])               False
  482  model.language_model.layers.11.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  483  model.language_model.layers.11.self_attn.k_proj.bias                              torch.Size([128])               False
  484  model.language_model.layers.11.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  485  model.language_model.layers.11.self_attn.v_proj.bias                              torch.Size([128])               False
  486  model.language_model.layers.11.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  487  model.language_model.layers.11.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  488  model.language_model.layers.11.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  489  model.language_model.layers.11.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  490  model.language_model.layers.11.input_layernorm.weight                             torch.Size([896])               False
  491  model.language_model.layers.11.post_attention_layernorm.weight                    torch.Size([896])               False
  492  model.language_model.layers.12.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  493  model.language_model.layers.12.self_attn.q_proj.bias                              torch.Size([896])               False
  494  model.language_model.layers.12.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  495  model.language_model.layers.12.self_attn.k_proj.bias                              torch.Size([128])               False
  496  model.language_model.layers.12.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  497  model.language_model.layers.12.self_attn.v_proj.bias                              torch.Size([128])               False
  498  model.language_model.layers.12.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  499  model.language_model.layers.12.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  500  model.language_model.layers.12.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  501  model.language_model.layers.12.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  502  model.language_model.layers.12.input_layernorm.weight                             torch.Size([896])               False
  503  model.language_model.layers.12.post_attention_layernorm.weight                    torch.Size([896])               False
  504  model.language_model.layers.13.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  505  model.language_model.layers.13.self_attn.q_proj.bias                              torch.Size([896])               False
  506  model.language_model.layers.13.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  507  model.language_model.layers.13.self_attn.k_proj.bias                              torch.Size([128])               False
  508  model.language_model.layers.13.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  509  model.language_model.layers.13.self_attn.v_proj.bias                              torch.Size([128])               False
  510  model.language_model.layers.13.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  511  model.language_model.layers.13.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  512  model.language_model.layers.13.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  513  model.language_model.layers.13.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  514  model.language_model.layers.13.input_layernorm.weight                             torch.Size([896])               False
  515  model.language_model.layers.13.post_attention_layernorm.weight                    torch.Size([896])               False
  516  model.language_model.layers.14.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  517  model.language_model.layers.14.self_attn.q_proj.bias                              torch.Size([896])               False
  518  model.language_model.layers.14.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  519  model.language_model.layers.14.self_attn.k_proj.bias                              torch.Size([128])               False
  520  model.language_model.layers.14.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  521  model.language_model.layers.14.self_attn.v_proj.bias                              torch.Size([128])               False
  522  model.language_model.layers.14.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  523  model.language_model.layers.14.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  524  model.language_model.layers.14.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  525  model.language_model.layers.14.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  526  model.language_model.layers.14.input_layernorm.weight                             torch.Size([896])               False
  527  model.language_model.layers.14.post_attention_layernorm.weight                    torch.Size([896])               False
  528  model.language_model.layers.15.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  529  model.language_model.layers.15.self_attn.q_proj.bias                              torch.Size([896])               False
  530  model.language_model.layers.15.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  531  model.language_model.layers.15.self_attn.k_proj.bias                              torch.Size([128])               False
  532  model.language_model.layers.15.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  533  model.language_model.layers.15.self_attn.v_proj.bias                              torch.Size([128])               False
  534  model.language_model.layers.15.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  535  model.language_model.layers.15.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  536  model.language_model.layers.15.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  537  model.language_model.layers.15.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  538  model.language_model.layers.15.input_layernorm.weight                             torch.Size([896])               False
  539  model.language_model.layers.15.post_attention_layernorm.weight                    torch.Size([896])               False
  540  model.language_model.layers.16.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  541  model.language_model.layers.16.self_attn.q_proj.bias                              torch.Size([896])               False
  542  model.language_model.layers.16.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  543  model.language_model.layers.16.self_attn.k_proj.bias                              torch.Size([128])               False
  544  model.language_model.layers.16.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  545  model.language_model.layers.16.self_attn.v_proj.bias                              torch.Size([128])               False
  546  model.language_model.layers.16.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  547  model.language_model.layers.16.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  548  model.language_model.layers.16.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  549  model.language_model.layers.16.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  550  model.language_model.layers.16.input_layernorm.weight                             torch.Size([896])               False
  551  model.language_model.layers.16.post_attention_layernorm.weight                    torch.Size([896])               False
  552  model.language_model.layers.17.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  553  model.language_model.layers.17.self_attn.q_proj.bias                              torch.Size([896])               False
  554  model.language_model.layers.17.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  555  model.language_model.layers.17.self_attn.k_proj.bias                              torch.Size([128])               False
  556  model.language_model.layers.17.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  557  model.language_model.layers.17.self_attn.v_proj.bias                              torch.Size([128])               False
  558  model.language_model.layers.17.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  559  model.language_model.layers.17.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  560  model.language_model.layers.17.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  561  model.language_model.layers.17.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  562  model.language_model.layers.17.input_layernorm.weight                             torch.Size([896])               False
  563  model.language_model.layers.17.post_attention_layernorm.weight                    torch.Size([896])               False
  564  model.language_model.layers.18.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  565  model.language_model.layers.18.self_attn.q_proj.bias                              torch.Size([896])               False
  566  model.language_model.layers.18.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  567  model.language_model.layers.18.self_attn.k_proj.bias                              torch.Size([128])               False
  568  model.language_model.layers.18.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  569  model.language_model.layers.18.self_attn.v_proj.bias                              torch.Size([128])               False
  570  model.language_model.layers.18.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  571  model.language_model.layers.18.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  572  model.language_model.layers.18.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  573  model.language_model.layers.18.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  574  model.language_model.layers.18.input_layernorm.weight                             torch.Size([896])               False
  575  model.language_model.layers.18.post_attention_layernorm.weight                    torch.Size([896])               False
  576  model.language_model.layers.19.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  577  model.language_model.layers.19.self_attn.q_proj.bias                              torch.Size([896])               False
  578  model.language_model.layers.19.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  579  model.language_model.layers.19.self_attn.k_proj.bias                              torch.Size([128])               False
  580  model.language_model.layers.19.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  581  model.language_model.layers.19.self_attn.v_proj.bias                              torch.Size([128])               False
  582  model.language_model.layers.19.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  583  model.language_model.layers.19.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  584  model.language_model.layers.19.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  585  model.language_model.layers.19.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  586  model.language_model.layers.19.input_layernorm.weight                             torch.Size([896])               False
  587  model.language_model.layers.19.post_attention_layernorm.weight                    torch.Size([896])               False
  588  model.language_model.layers.20.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  589  model.language_model.layers.20.self_attn.q_proj.bias                              torch.Size([896])               False
  590  model.language_model.layers.20.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  591  model.language_model.layers.20.self_attn.k_proj.bias                              torch.Size([128])               False
  592  model.language_model.layers.20.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  593  model.language_model.layers.20.self_attn.v_proj.bias                              torch.Size([128])               False
  594  model.language_model.layers.20.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  595  model.language_model.layers.20.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  596  model.language_model.layers.20.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  597  model.language_model.layers.20.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  598  model.language_model.layers.20.input_layernorm.weight                             torch.Size([896])               False
  599  model.language_model.layers.20.post_attention_layernorm.weight                    torch.Size([896])               False
  600  model.language_model.layers.21.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  601  model.language_model.layers.21.self_attn.q_proj.bias                              torch.Size([896])               False
  602  model.language_model.layers.21.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  603  model.language_model.layers.21.self_attn.k_proj.bias                              torch.Size([128])               False
  604  model.language_model.layers.21.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  605  model.language_model.layers.21.self_attn.v_proj.bias                              torch.Size([128])               False
  606  model.language_model.layers.21.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  607  model.language_model.layers.21.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  608  model.language_model.layers.21.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  609  model.language_model.layers.21.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  610  model.language_model.layers.21.input_layernorm.weight                             torch.Size([896])               False
  611  model.language_model.layers.21.post_attention_layernorm.weight                    torch.Size([896])               False
  612  model.language_model.layers.22.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  613  model.language_model.layers.22.self_attn.q_proj.bias                              torch.Size([896])               False
  614  model.language_model.layers.22.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  615  model.language_model.layers.22.self_attn.k_proj.bias                              torch.Size([128])               False
  616  model.language_model.layers.22.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  617  model.language_model.layers.22.self_attn.v_proj.bias                              torch.Size([128])               False
  618  model.language_model.layers.22.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  619  model.language_model.layers.22.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  620  model.language_model.layers.22.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  621  model.language_model.layers.22.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  622  model.language_model.layers.22.input_layernorm.weight                             torch.Size([896])               False
  623  model.language_model.layers.22.post_attention_layernorm.weight                    torch.Size([896])               False
  624  model.language_model.layers.23.self_attn.q_proj.weight                            torch.Size([896, 896])          False
  625  model.language_model.layers.23.self_attn.q_proj.bias                              torch.Size([896])               False
  626  model.language_model.layers.23.self_attn.k_proj.weight                            torch.Size([128, 896])          False
  627  model.language_model.layers.23.self_attn.k_proj.bias                              torch.Size([128])               False
  628  model.language_model.layers.23.self_attn.v_proj.weight                            torch.Size([128, 896])          False
  629  model.language_model.layers.23.self_attn.v_proj.bias                              torch.Size([128])               False
  630  model.language_model.layers.23.self_attn.o_proj.weight                            torch.Size([896, 896])          False
  631  model.language_model.layers.23.mlp.gate_proj.weight                               torch.Size([4864, 896])         False
  632  model.language_model.layers.23.mlp.up_proj.weight                                 torch.Size([4864, 896])         False
  633  model.language_model.layers.23.mlp.down_proj.weight                               torch.Size([896, 4864])         False
  634  model.language_model.layers.23.input_layernorm.weight                             torch.Size([896])               False
  635  model.language_model.layers.23.post_attention_layernorm.weight                    torch.Size([896])               False
  636  model.language_model.norm.weight                                                  torch.Size([896])               False
  637  model.dit.scale_shift_table                                                       torch.Size([2, 1152])           True
  638  model.dit.patch_embed.proj.weight                                                 torch.Size([1152, 32, 1, 1])    True
  639  model.dit.patch_embed.proj.bias                                                   torch.Size([1152])              True
  640  model.dit.time_embed.emb.timestep_embedder.linear_1.weight                        torch.Size([1152, 256])         True
  641  model.dit.time_embed.emb.timestep_embedder.linear_1.bias                          torch.Size([1152])              True
  642  model.dit.time_embed.emb.timestep_embedder.linear_2.weight                        torch.Size([1152, 1152])        True
  643  model.dit.time_embed.emb.timestep_embedder.linear_2.bias                          torch.Size([1152])              True
  644  model.dit.time_embed.linear.weight                                                torch.Size([6912, 1152])        True
  645  model.dit.time_embed.linear.bias                                                  torch.Size([6912])              True
  646  model.dit.caption_projection.linear_1.weight                                      torch.Size([1152, 2304])        True
  647  model.dit.caption_projection.linear_1.bias                                        torch.Size([1152])              True
  648  model.dit.caption_projection.linear_2.weight                                      torch.Size([1152, 1152])        True
  649  model.dit.caption_projection.linear_2.bias                                        torch.Size([1152])              True
  650  model.dit.caption_norm.weight                                                     torch.Size([1152])              True
  651  model.dit.transformer_blocks.0.scale_shift_table                                  torch.Size([6, 1152])           True
  652  model.dit.transformer_blocks.0.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  653  model.dit.transformer_blocks.0.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  654  model.dit.transformer_blocks.0.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  655  model.dit.transformer_blocks.0.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  656  model.dit.transformer_blocks.0.attn1.to_out.0.bias                                torch.Size([1152])              True
  657  model.dit.transformer_blocks.0.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  658  model.dit.transformer_blocks.0.attn2.to_q.bias                                    torch.Size([1152])              True
  659  model.dit.transformer_blocks.0.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  660  model.dit.transformer_blocks.0.attn2.to_k.bias                                    torch.Size([1152])              True
  661  model.dit.transformer_blocks.0.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  662  model.dit.transformer_blocks.0.attn2.to_v.bias                                    torch.Size([1152])              True
  663  model.dit.transformer_blocks.0.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  664  model.dit.transformer_blocks.0.attn2.to_out.0.bias                                torch.Size([1152])              True
  665  model.dit.transformer_blocks.0.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  666  model.dit.transformer_blocks.0.ff.conv_inverted.bias                              torch.Size([5760])              True
  667  model.dit.transformer_blocks.0.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  668  model.dit.transformer_blocks.0.ff.conv_depth.bias                                 torch.Size([5760])              True
  669  model.dit.transformer_blocks.0.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  670  model.dit.transformer_blocks.1.scale_shift_table                                  torch.Size([6, 1152])           True
  671  model.dit.transformer_blocks.1.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  672  model.dit.transformer_blocks.1.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  673  model.dit.transformer_blocks.1.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  674  model.dit.transformer_blocks.1.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  675  model.dit.transformer_blocks.1.attn1.to_out.0.bias                                torch.Size([1152])              True
  676  model.dit.transformer_blocks.1.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  677  model.dit.transformer_blocks.1.attn2.to_q.bias                                    torch.Size([1152])              True
  678  model.dit.transformer_blocks.1.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  679  model.dit.transformer_blocks.1.attn2.to_k.bias                                    torch.Size([1152])              True
  680  model.dit.transformer_blocks.1.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  681  model.dit.transformer_blocks.1.attn2.to_v.bias                                    torch.Size([1152])              True
  682  model.dit.transformer_blocks.1.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  683  model.dit.transformer_blocks.1.attn2.to_out.0.bias                                torch.Size([1152])              True
  684  model.dit.transformer_blocks.1.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  685  model.dit.transformer_blocks.1.ff.conv_inverted.bias                              torch.Size([5760])              True
  686  model.dit.transformer_blocks.1.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  687  model.dit.transformer_blocks.1.ff.conv_depth.bias                                 torch.Size([5760])              True
  688  model.dit.transformer_blocks.1.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  689  model.dit.transformer_blocks.2.scale_shift_table                                  torch.Size([6, 1152])           True
  690  model.dit.transformer_blocks.2.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  691  model.dit.transformer_blocks.2.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  692  model.dit.transformer_blocks.2.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  693  model.dit.transformer_blocks.2.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  694  model.dit.transformer_blocks.2.attn1.to_out.0.bias                                torch.Size([1152])              True
  695  model.dit.transformer_blocks.2.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  696  model.dit.transformer_blocks.2.attn2.to_q.bias                                    torch.Size([1152])              True
  697  model.dit.transformer_blocks.2.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  698  model.dit.transformer_blocks.2.attn2.to_k.bias                                    torch.Size([1152])              True
  699  model.dit.transformer_blocks.2.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  700  model.dit.transformer_blocks.2.attn2.to_v.bias                                    torch.Size([1152])              True
  701  model.dit.transformer_blocks.2.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  702  model.dit.transformer_blocks.2.attn2.to_out.0.bias                                torch.Size([1152])              True
  703  model.dit.transformer_blocks.2.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  704  model.dit.transformer_blocks.2.ff.conv_inverted.bias                              torch.Size([5760])              True
  705  model.dit.transformer_blocks.2.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  706  model.dit.transformer_blocks.2.ff.conv_depth.bias                                 torch.Size([5760])              True
  707  model.dit.transformer_blocks.2.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  708  model.dit.transformer_blocks.3.scale_shift_table                                  torch.Size([6, 1152])           True
  709  model.dit.transformer_blocks.3.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  710  model.dit.transformer_blocks.3.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  711  model.dit.transformer_blocks.3.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  712  model.dit.transformer_blocks.3.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  713  model.dit.transformer_blocks.3.attn1.to_out.0.bias                                torch.Size([1152])              True
  714  model.dit.transformer_blocks.3.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  715  model.dit.transformer_blocks.3.attn2.to_q.bias                                    torch.Size([1152])              True
  716  model.dit.transformer_blocks.3.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  717  model.dit.transformer_blocks.3.attn2.to_k.bias                                    torch.Size([1152])              True
  718  model.dit.transformer_blocks.3.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  719  model.dit.transformer_blocks.3.attn2.to_v.bias                                    torch.Size([1152])              True
  720  model.dit.transformer_blocks.3.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  721  model.dit.transformer_blocks.3.attn2.to_out.0.bias                                torch.Size([1152])              True
  722  model.dit.transformer_blocks.3.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  723  model.dit.transformer_blocks.3.ff.conv_inverted.bias                              torch.Size([5760])              True
  724  model.dit.transformer_blocks.3.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  725  model.dit.transformer_blocks.3.ff.conv_depth.bias                                 torch.Size([5760])              True
  726  model.dit.transformer_blocks.3.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  727  model.dit.transformer_blocks.4.scale_shift_table                                  torch.Size([6, 1152])           True
  728  model.dit.transformer_blocks.4.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  729  model.dit.transformer_blocks.4.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  730  model.dit.transformer_blocks.4.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  731  model.dit.transformer_blocks.4.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  732  model.dit.transformer_blocks.4.attn1.to_out.0.bias                                torch.Size([1152])              True
  733  model.dit.transformer_blocks.4.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  734  model.dit.transformer_blocks.4.attn2.to_q.bias                                    torch.Size([1152])              True
  735  model.dit.transformer_blocks.4.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  736  model.dit.transformer_blocks.4.attn2.to_k.bias                                    torch.Size([1152])              True
  737  model.dit.transformer_blocks.4.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  738  model.dit.transformer_blocks.4.attn2.to_v.bias                                    torch.Size([1152])              True
  739  model.dit.transformer_blocks.4.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  740  model.dit.transformer_blocks.4.attn2.to_out.0.bias                                torch.Size([1152])              True
  741  model.dit.transformer_blocks.4.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  742  model.dit.transformer_blocks.4.ff.conv_inverted.bias                              torch.Size([5760])              True
  743  model.dit.transformer_blocks.4.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  744  model.dit.transformer_blocks.4.ff.conv_depth.bias                                 torch.Size([5760])              True
  745  model.dit.transformer_blocks.4.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  746  model.dit.transformer_blocks.5.scale_shift_table                                  torch.Size([6, 1152])           True
  747  model.dit.transformer_blocks.5.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  748  model.dit.transformer_blocks.5.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  749  model.dit.transformer_blocks.5.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  750  model.dit.transformer_blocks.5.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  751  model.dit.transformer_blocks.5.attn1.to_out.0.bias                                torch.Size([1152])              True
  752  model.dit.transformer_blocks.5.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  753  model.dit.transformer_blocks.5.attn2.to_q.bias                                    torch.Size([1152])              True
  754  model.dit.transformer_blocks.5.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  755  model.dit.transformer_blocks.5.attn2.to_k.bias                                    torch.Size([1152])              True
  756  model.dit.transformer_blocks.5.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  757  model.dit.transformer_blocks.5.attn2.to_v.bias                                    torch.Size([1152])              True
  758  model.dit.transformer_blocks.5.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  759  model.dit.transformer_blocks.5.attn2.to_out.0.bias                                torch.Size([1152])              True
  760  model.dit.transformer_blocks.5.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  761  model.dit.transformer_blocks.5.ff.conv_inverted.bias                              torch.Size([5760])              True
  762  model.dit.transformer_blocks.5.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  763  model.dit.transformer_blocks.5.ff.conv_depth.bias                                 torch.Size([5760])              True
  764  model.dit.transformer_blocks.5.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  765  model.dit.transformer_blocks.6.scale_shift_table                                  torch.Size([6, 1152])           True
  766  model.dit.transformer_blocks.6.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  767  model.dit.transformer_blocks.6.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  768  model.dit.transformer_blocks.6.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  769  model.dit.transformer_blocks.6.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  770  model.dit.transformer_blocks.6.attn1.to_out.0.bias                                torch.Size([1152])              True
  771  model.dit.transformer_blocks.6.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  772  model.dit.transformer_blocks.6.attn2.to_q.bias                                    torch.Size([1152])              True
  773  model.dit.transformer_blocks.6.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  774  model.dit.transformer_blocks.6.attn2.to_k.bias                                    torch.Size([1152])              True
  775  model.dit.transformer_blocks.6.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  776  model.dit.transformer_blocks.6.attn2.to_v.bias                                    torch.Size([1152])              True
  777  model.dit.transformer_blocks.6.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  778  model.dit.transformer_blocks.6.attn2.to_out.0.bias                                torch.Size([1152])              True
  779  model.dit.transformer_blocks.6.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  780  model.dit.transformer_blocks.6.ff.conv_inverted.bias                              torch.Size([5760])              True
  781  model.dit.transformer_blocks.6.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  782  model.dit.transformer_blocks.6.ff.conv_depth.bias                                 torch.Size([5760])              True
  783  model.dit.transformer_blocks.6.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  784  model.dit.transformer_blocks.7.scale_shift_table                                  torch.Size([6, 1152])           True
  785  model.dit.transformer_blocks.7.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  786  model.dit.transformer_blocks.7.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  787  model.dit.transformer_blocks.7.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  788  model.dit.transformer_blocks.7.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  789  model.dit.transformer_blocks.7.attn1.to_out.0.bias                                torch.Size([1152])              True
  790  model.dit.transformer_blocks.7.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  791  model.dit.transformer_blocks.7.attn2.to_q.bias                                    torch.Size([1152])              True
  792  model.dit.transformer_blocks.7.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  793  model.dit.transformer_blocks.7.attn2.to_k.bias                                    torch.Size([1152])              True
  794  model.dit.transformer_blocks.7.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  795  model.dit.transformer_blocks.7.attn2.to_v.bias                                    torch.Size([1152])              True
  796  model.dit.transformer_blocks.7.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  797  model.dit.transformer_blocks.7.attn2.to_out.0.bias                                torch.Size([1152])              True
  798  model.dit.transformer_blocks.7.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  799  model.dit.transformer_blocks.7.ff.conv_inverted.bias                              torch.Size([5760])              True
  800  model.dit.transformer_blocks.7.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  801  model.dit.transformer_blocks.7.ff.conv_depth.bias                                 torch.Size([5760])              True
  802  model.dit.transformer_blocks.7.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  803  model.dit.transformer_blocks.8.scale_shift_table                                  torch.Size([6, 1152])           True
  804  model.dit.transformer_blocks.8.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  805  model.dit.transformer_blocks.8.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  806  model.dit.transformer_blocks.8.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  807  model.dit.transformer_blocks.8.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  808  model.dit.transformer_blocks.8.attn1.to_out.0.bias                                torch.Size([1152])              True
  809  model.dit.transformer_blocks.8.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  810  model.dit.transformer_blocks.8.attn2.to_q.bias                                    torch.Size([1152])              True
  811  model.dit.transformer_blocks.8.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  812  model.dit.transformer_blocks.8.attn2.to_k.bias                                    torch.Size([1152])              True
  813  model.dit.transformer_blocks.8.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  814  model.dit.transformer_blocks.8.attn2.to_v.bias                                    torch.Size([1152])              True
  815  model.dit.transformer_blocks.8.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  816  model.dit.transformer_blocks.8.attn2.to_out.0.bias                                torch.Size([1152])              True
  817  model.dit.transformer_blocks.8.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  818  model.dit.transformer_blocks.8.ff.conv_inverted.bias                              torch.Size([5760])              True
  819  model.dit.transformer_blocks.8.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  820  model.dit.transformer_blocks.8.ff.conv_depth.bias                                 torch.Size([5760])              True
  821  model.dit.transformer_blocks.8.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  822  model.dit.transformer_blocks.9.scale_shift_table                                  torch.Size([6, 1152])           True
  823  model.dit.transformer_blocks.9.attn1.to_q.weight                                  torch.Size([1152, 1152])        True
  824  model.dit.transformer_blocks.9.attn1.to_k.weight                                  torch.Size([1152, 1152])        True
  825  model.dit.transformer_blocks.9.attn1.to_v.weight                                  torch.Size([1152, 1152])        True
  826  model.dit.transformer_blocks.9.attn1.to_out.0.weight                              torch.Size([1152, 1152])        True
  827  model.dit.transformer_blocks.9.attn1.to_out.0.bias                                torch.Size([1152])              True
  828  model.dit.transformer_blocks.9.attn2.to_q.weight                                  torch.Size([1152, 1152])        True
  829  model.dit.transformer_blocks.9.attn2.to_q.bias                                    torch.Size([1152])              True
  830  model.dit.transformer_blocks.9.attn2.to_k.weight                                  torch.Size([1152, 1152])        True
  831  model.dit.transformer_blocks.9.attn2.to_k.bias                                    torch.Size([1152])              True
  832  model.dit.transformer_blocks.9.attn2.to_v.weight                                  torch.Size([1152, 1152])        True
  833  model.dit.transformer_blocks.9.attn2.to_v.bias                                    torch.Size([1152])              True
  834  model.dit.transformer_blocks.9.attn2.to_out.0.weight                              torch.Size([1152, 1152])        True
  835  model.dit.transformer_blocks.9.attn2.to_out.0.bias                                torch.Size([1152])              True
  836  model.dit.transformer_blocks.9.ff.conv_inverted.weight                            torch.Size([5760, 1152, 1, 1])  True
  837  model.dit.transformer_blocks.9.ff.conv_inverted.bias                              torch.Size([5760])              True
  838  model.dit.transformer_blocks.9.ff.conv_depth.weight                               torch.Size([5760, 1, 3, 3])     True
  839  model.dit.transformer_blocks.9.ff.conv_depth.bias                                 torch.Size([5760])              True
  840  model.dit.transformer_blocks.9.ff.conv_point.weight                               torch.Size([1152, 2880, 1, 1])  True
  841  model.dit.transformer_blocks.10.scale_shift_table                                 torch.Size([6, 1152])           True
  842  model.dit.transformer_blocks.10.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  843  model.dit.transformer_blocks.10.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  844  model.dit.transformer_blocks.10.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  845  model.dit.transformer_blocks.10.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  846  model.dit.transformer_blocks.10.attn1.to_out.0.bias                               torch.Size([1152])              True
  847  model.dit.transformer_blocks.10.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  848  model.dit.transformer_blocks.10.attn2.to_q.bias                                   torch.Size([1152])              True
  849  model.dit.transformer_blocks.10.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  850  model.dit.transformer_blocks.10.attn2.to_k.bias                                   torch.Size([1152])              True
  851  model.dit.transformer_blocks.10.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  852  model.dit.transformer_blocks.10.attn2.to_v.bias                                   torch.Size([1152])              True
  853  model.dit.transformer_blocks.10.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  854  model.dit.transformer_blocks.10.attn2.to_out.0.bias                               torch.Size([1152])              True
  855  model.dit.transformer_blocks.10.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  856  model.dit.transformer_blocks.10.ff.conv_inverted.bias                             torch.Size([5760])              True
  857  model.dit.transformer_blocks.10.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  858  model.dit.transformer_blocks.10.ff.conv_depth.bias                                torch.Size([5760])              True
  859  model.dit.transformer_blocks.10.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  860  model.dit.transformer_blocks.11.scale_shift_table                                 torch.Size([6, 1152])           True
  861  model.dit.transformer_blocks.11.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  862  model.dit.transformer_blocks.11.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  863  model.dit.transformer_blocks.11.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  864  model.dit.transformer_blocks.11.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  865  model.dit.transformer_blocks.11.attn1.to_out.0.bias                               torch.Size([1152])              True
  866  model.dit.transformer_blocks.11.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  867  model.dit.transformer_blocks.11.attn2.to_q.bias                                   torch.Size([1152])              True
  868  model.dit.transformer_blocks.11.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  869  model.dit.transformer_blocks.11.attn2.to_k.bias                                   torch.Size([1152])              True
  870  model.dit.transformer_blocks.11.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  871  model.dit.transformer_blocks.11.attn2.to_v.bias                                   torch.Size([1152])              True
  872  model.dit.transformer_blocks.11.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  873  model.dit.transformer_blocks.11.attn2.to_out.0.bias                               torch.Size([1152])              True
  874  model.dit.transformer_blocks.11.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  875  model.dit.transformer_blocks.11.ff.conv_inverted.bias                             torch.Size([5760])              True
  876  model.dit.transformer_blocks.11.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  877  model.dit.transformer_blocks.11.ff.conv_depth.bias                                torch.Size([5760])              True
  878  model.dit.transformer_blocks.11.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  879  model.dit.transformer_blocks.12.scale_shift_table                                 torch.Size([6, 1152])           True
  880  model.dit.transformer_blocks.12.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  881  model.dit.transformer_blocks.12.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  882  model.dit.transformer_blocks.12.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  883  model.dit.transformer_blocks.12.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  884  model.dit.transformer_blocks.12.attn1.to_out.0.bias                               torch.Size([1152])              True
  885  model.dit.transformer_blocks.12.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  886  model.dit.transformer_blocks.12.attn2.to_q.bias                                   torch.Size([1152])              True
  887  model.dit.transformer_blocks.12.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  888  model.dit.transformer_blocks.12.attn2.to_k.bias                                   torch.Size([1152])              True
  889  model.dit.transformer_blocks.12.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  890  model.dit.transformer_blocks.12.attn2.to_v.bias                                   torch.Size([1152])              True
  891  model.dit.transformer_blocks.12.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  892  model.dit.transformer_blocks.12.attn2.to_out.0.bias                               torch.Size([1152])              True
  893  model.dit.transformer_blocks.12.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  894  model.dit.transformer_blocks.12.ff.conv_inverted.bias                             torch.Size([5760])              True
  895  model.dit.transformer_blocks.12.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  896  model.dit.transformer_blocks.12.ff.conv_depth.bias                                torch.Size([5760])              True
  897  model.dit.transformer_blocks.12.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  898  model.dit.transformer_blocks.13.scale_shift_table                                 torch.Size([6, 1152])           True
  899  model.dit.transformer_blocks.13.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  900  model.dit.transformer_blocks.13.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  901  model.dit.transformer_blocks.13.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  902  model.dit.transformer_blocks.13.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  903  model.dit.transformer_blocks.13.attn1.to_out.0.bias                               torch.Size([1152])              True
  904  model.dit.transformer_blocks.13.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  905  model.dit.transformer_blocks.13.attn2.to_q.bias                                   torch.Size([1152])              True
  906  model.dit.transformer_blocks.13.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  907  model.dit.transformer_blocks.13.attn2.to_k.bias                                   torch.Size([1152])              True
  908  model.dit.transformer_blocks.13.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  909  model.dit.transformer_blocks.13.attn2.to_v.bias                                   torch.Size([1152])              True
  910  model.dit.transformer_blocks.13.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  911  model.dit.transformer_blocks.13.attn2.to_out.0.bias                               torch.Size([1152])              True
  912  model.dit.transformer_blocks.13.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  913  model.dit.transformer_blocks.13.ff.conv_inverted.bias                             torch.Size([5760])              True
  914  model.dit.transformer_blocks.13.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  915  model.dit.transformer_blocks.13.ff.conv_depth.bias                                torch.Size([5760])              True
  916  model.dit.transformer_blocks.13.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  917  model.dit.transformer_blocks.14.scale_shift_table                                 torch.Size([6, 1152])           True
  918  model.dit.transformer_blocks.14.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  919  model.dit.transformer_blocks.14.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  920  model.dit.transformer_blocks.14.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  921  model.dit.transformer_blocks.14.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  922  model.dit.transformer_blocks.14.attn1.to_out.0.bias                               torch.Size([1152])              True
  923  model.dit.transformer_blocks.14.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  924  model.dit.transformer_blocks.14.attn2.to_q.bias                                   torch.Size([1152])              True
  925  model.dit.transformer_blocks.14.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  926  model.dit.transformer_blocks.14.attn2.to_k.bias                                   torch.Size([1152])              True
  927  model.dit.transformer_blocks.14.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  928  model.dit.transformer_blocks.14.attn2.to_v.bias                                   torch.Size([1152])              True
  929  model.dit.transformer_blocks.14.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  930  model.dit.transformer_blocks.14.attn2.to_out.0.bias                               torch.Size([1152])              True
  931  model.dit.transformer_blocks.14.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  932  model.dit.transformer_blocks.14.ff.conv_inverted.bias                             torch.Size([5760])              True
  933  model.dit.transformer_blocks.14.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  934  model.dit.transformer_blocks.14.ff.conv_depth.bias                                torch.Size([5760])              True
  935  model.dit.transformer_blocks.14.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  936  model.dit.transformer_blocks.15.scale_shift_table                                 torch.Size([6, 1152])           True
  937  model.dit.transformer_blocks.15.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  938  model.dit.transformer_blocks.15.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  939  model.dit.transformer_blocks.15.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  940  model.dit.transformer_blocks.15.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  941  model.dit.transformer_blocks.15.attn1.to_out.0.bias                               torch.Size([1152])              True
  942  model.dit.transformer_blocks.15.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  943  model.dit.transformer_blocks.15.attn2.to_q.bias                                   torch.Size([1152])              True
  944  model.dit.transformer_blocks.15.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  945  model.dit.transformer_blocks.15.attn2.to_k.bias                                   torch.Size([1152])              True
  946  model.dit.transformer_blocks.15.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  947  model.dit.transformer_blocks.15.attn2.to_v.bias                                   torch.Size([1152])              True
  948  model.dit.transformer_blocks.15.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  949  model.dit.transformer_blocks.15.attn2.to_out.0.bias                               torch.Size([1152])              True
  950  model.dit.transformer_blocks.15.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  951  model.dit.transformer_blocks.15.ff.conv_inverted.bias                             torch.Size([5760])              True
  952  model.dit.transformer_blocks.15.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  953  model.dit.transformer_blocks.15.ff.conv_depth.bias                                torch.Size([5760])              True
  954  model.dit.transformer_blocks.15.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  955  model.dit.transformer_blocks.16.scale_shift_table                                 torch.Size([6, 1152])           True
  956  model.dit.transformer_blocks.16.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  957  model.dit.transformer_blocks.16.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  958  model.dit.transformer_blocks.16.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  959  model.dit.transformer_blocks.16.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  960  model.dit.transformer_blocks.16.attn1.to_out.0.bias                               torch.Size([1152])              True
  961  model.dit.transformer_blocks.16.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  962  model.dit.transformer_blocks.16.attn2.to_q.bias                                   torch.Size([1152])              True
  963  model.dit.transformer_blocks.16.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  964  model.dit.transformer_blocks.16.attn2.to_k.bias                                   torch.Size([1152])              True
  965  model.dit.transformer_blocks.16.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  966  model.dit.transformer_blocks.16.attn2.to_v.bias                                   torch.Size([1152])              True
  967  model.dit.transformer_blocks.16.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  968  model.dit.transformer_blocks.16.attn2.to_out.0.bias                               torch.Size([1152])              True
  969  model.dit.transformer_blocks.16.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  970  model.dit.transformer_blocks.16.ff.conv_inverted.bias                             torch.Size([5760])              True
  971  model.dit.transformer_blocks.16.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  972  model.dit.transformer_blocks.16.ff.conv_depth.bias                                torch.Size([5760])              True
  973  model.dit.transformer_blocks.16.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  974  model.dit.transformer_blocks.17.scale_shift_table                                 torch.Size([6, 1152])           True
  975  model.dit.transformer_blocks.17.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  976  model.dit.transformer_blocks.17.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  977  model.dit.transformer_blocks.17.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  978  model.dit.transformer_blocks.17.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  979  model.dit.transformer_blocks.17.attn1.to_out.0.bias                               torch.Size([1152])              True
  980  model.dit.transformer_blocks.17.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
  981  model.dit.transformer_blocks.17.attn2.to_q.bias                                   torch.Size([1152])              True
  982  model.dit.transformer_blocks.17.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
  983  model.dit.transformer_blocks.17.attn2.to_k.bias                                   torch.Size([1152])              True
  984  model.dit.transformer_blocks.17.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
  985  model.dit.transformer_blocks.17.attn2.to_v.bias                                   torch.Size([1152])              True
  986  model.dit.transformer_blocks.17.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
  987  model.dit.transformer_blocks.17.attn2.to_out.0.bias                               torch.Size([1152])              True
  988  model.dit.transformer_blocks.17.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
  989  model.dit.transformer_blocks.17.ff.conv_inverted.bias                             torch.Size([5760])              True
  990  model.dit.transformer_blocks.17.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
  991  model.dit.transformer_blocks.17.ff.conv_depth.bias                                torch.Size([5760])              True
  992  model.dit.transformer_blocks.17.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
  993  model.dit.transformer_blocks.18.scale_shift_table                                 torch.Size([6, 1152])           True
  994  model.dit.transformer_blocks.18.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
  995  model.dit.transformer_blocks.18.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
  996  model.dit.transformer_blocks.18.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
  997  model.dit.transformer_blocks.18.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
  998  model.dit.transformer_blocks.18.attn1.to_out.0.bias                               torch.Size([1152])              True
  999  model.dit.transformer_blocks.18.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1000  model.dit.transformer_blocks.18.attn2.to_q.bias                                   torch.Size([1152])              True
 1001  model.dit.transformer_blocks.18.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1002  model.dit.transformer_blocks.18.attn2.to_k.bias                                   torch.Size([1152])              True
 1003  model.dit.transformer_blocks.18.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1004  model.dit.transformer_blocks.18.attn2.to_v.bias                                   torch.Size([1152])              True
 1005  model.dit.transformer_blocks.18.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1006  model.dit.transformer_blocks.18.attn2.to_out.0.bias                               torch.Size([1152])              True
 1007  model.dit.transformer_blocks.18.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1008  model.dit.transformer_blocks.18.ff.conv_inverted.bias                             torch.Size([5760])              True
 1009  model.dit.transformer_blocks.18.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1010  model.dit.transformer_blocks.18.ff.conv_depth.bias                                torch.Size([5760])              True
 1011  model.dit.transformer_blocks.18.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1012  model.dit.transformer_blocks.19.scale_shift_table                                 torch.Size([6, 1152])           True
 1013  model.dit.transformer_blocks.19.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1014  model.dit.transformer_blocks.19.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1015  model.dit.transformer_blocks.19.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1016  model.dit.transformer_blocks.19.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1017  model.dit.transformer_blocks.19.attn1.to_out.0.bias                               torch.Size([1152])              True
 1018  model.dit.transformer_blocks.19.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1019  model.dit.transformer_blocks.19.attn2.to_q.bias                                   torch.Size([1152])              True
 1020  model.dit.transformer_blocks.19.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1021  model.dit.transformer_blocks.19.attn2.to_k.bias                                   torch.Size([1152])              True
 1022  model.dit.transformer_blocks.19.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1023  model.dit.transformer_blocks.19.attn2.to_v.bias                                   torch.Size([1152])              True
 1024  model.dit.transformer_blocks.19.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1025  model.dit.transformer_blocks.19.attn2.to_out.0.bias                               torch.Size([1152])              True
 1026  model.dit.transformer_blocks.19.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1027  model.dit.transformer_blocks.19.ff.conv_inverted.bias                             torch.Size([5760])              True
 1028  model.dit.transformer_blocks.19.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1029  model.dit.transformer_blocks.19.ff.conv_depth.bias                                torch.Size([5760])              True
 1030  model.dit.transformer_blocks.19.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1031  model.dit.transformer_blocks.20.scale_shift_table                                 torch.Size([6, 1152])           True
 1032  model.dit.transformer_blocks.20.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1033  model.dit.transformer_blocks.20.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1034  model.dit.transformer_blocks.20.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1035  model.dit.transformer_blocks.20.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1036  model.dit.transformer_blocks.20.attn1.to_out.0.bias                               torch.Size([1152])              True
 1037  model.dit.transformer_blocks.20.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1038  model.dit.transformer_blocks.20.attn2.to_q.bias                                   torch.Size([1152])              True
 1039  model.dit.transformer_blocks.20.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1040  model.dit.transformer_blocks.20.attn2.to_k.bias                                   torch.Size([1152])              True
 1041  model.dit.transformer_blocks.20.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1042  model.dit.transformer_blocks.20.attn2.to_v.bias                                   torch.Size([1152])              True
 1043  model.dit.transformer_blocks.20.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1044  model.dit.transformer_blocks.20.attn2.to_out.0.bias                               torch.Size([1152])              True
 1045  model.dit.transformer_blocks.20.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1046  model.dit.transformer_blocks.20.ff.conv_inverted.bias                             torch.Size([5760])              True
 1047  model.dit.transformer_blocks.20.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1048  model.dit.transformer_blocks.20.ff.conv_depth.bias                                torch.Size([5760])              True
 1049  model.dit.transformer_blocks.20.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1050  model.dit.transformer_blocks.21.scale_shift_table                                 torch.Size([6, 1152])           True
 1051  model.dit.transformer_blocks.21.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1052  model.dit.transformer_blocks.21.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1053  model.dit.transformer_blocks.21.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1054  model.dit.transformer_blocks.21.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1055  model.dit.transformer_blocks.21.attn1.to_out.0.bias                               torch.Size([1152])              True
 1056  model.dit.transformer_blocks.21.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1057  model.dit.transformer_blocks.21.attn2.to_q.bias                                   torch.Size([1152])              True
 1058  model.dit.transformer_blocks.21.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1059  model.dit.transformer_blocks.21.attn2.to_k.bias                                   torch.Size([1152])              True
 1060  model.dit.transformer_blocks.21.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1061  model.dit.transformer_blocks.21.attn2.to_v.bias                                   torch.Size([1152])              True
 1062  model.dit.transformer_blocks.21.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1063  model.dit.transformer_blocks.21.attn2.to_out.0.bias                               torch.Size([1152])              True
 1064  model.dit.transformer_blocks.21.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1065  model.dit.transformer_blocks.21.ff.conv_inverted.bias                             torch.Size([5760])              True
 1066  model.dit.transformer_blocks.21.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1067  model.dit.transformer_blocks.21.ff.conv_depth.bias                                torch.Size([5760])              True
 1068  model.dit.transformer_blocks.21.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1069  model.dit.transformer_blocks.22.scale_shift_table                                 torch.Size([6, 1152])           True
 1070  model.dit.transformer_blocks.22.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1071  model.dit.transformer_blocks.22.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1072  model.dit.transformer_blocks.22.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1073  model.dit.transformer_blocks.22.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1074  model.dit.transformer_blocks.22.attn1.to_out.0.bias                               torch.Size([1152])              True
 1075  model.dit.transformer_blocks.22.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1076  model.dit.transformer_blocks.22.attn2.to_q.bias                                   torch.Size([1152])              True
 1077  model.dit.transformer_blocks.22.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1078  model.dit.transformer_blocks.22.attn2.to_k.bias                                   torch.Size([1152])              True
 1079  model.dit.transformer_blocks.22.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1080  model.dit.transformer_blocks.22.attn2.to_v.bias                                   torch.Size([1152])              True
 1081  model.dit.transformer_blocks.22.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1082  model.dit.transformer_blocks.22.attn2.to_out.0.bias                               torch.Size([1152])              True
 1083  model.dit.transformer_blocks.22.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1084  model.dit.transformer_blocks.22.ff.conv_inverted.bias                             torch.Size([5760])              True
 1085  model.dit.transformer_blocks.22.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1086  model.dit.transformer_blocks.22.ff.conv_depth.bias                                torch.Size([5760])              True
 1087  model.dit.transformer_blocks.22.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1088  model.dit.transformer_blocks.23.scale_shift_table                                 torch.Size([6, 1152])           True
 1089  model.dit.transformer_blocks.23.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1090  model.dit.transformer_blocks.23.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1091  model.dit.transformer_blocks.23.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1092  model.dit.transformer_blocks.23.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1093  model.dit.transformer_blocks.23.attn1.to_out.0.bias                               torch.Size([1152])              True
 1094  model.dit.transformer_blocks.23.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1095  model.dit.transformer_blocks.23.attn2.to_q.bias                                   torch.Size([1152])              True
 1096  model.dit.transformer_blocks.23.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1097  model.dit.transformer_blocks.23.attn2.to_k.bias                                   torch.Size([1152])              True
 1098  model.dit.transformer_blocks.23.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1099  model.dit.transformer_blocks.23.attn2.to_v.bias                                   torch.Size([1152])              True
 1100  model.dit.transformer_blocks.23.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1101  model.dit.transformer_blocks.23.attn2.to_out.0.bias                               torch.Size([1152])              True
 1102  model.dit.transformer_blocks.23.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1103  model.dit.transformer_blocks.23.ff.conv_inverted.bias                             torch.Size([5760])              True
 1104  model.dit.transformer_blocks.23.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1105  model.dit.transformer_blocks.23.ff.conv_depth.bias                                torch.Size([5760])              True
 1106  model.dit.transformer_blocks.23.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1107  model.dit.transformer_blocks.24.scale_shift_table                                 torch.Size([6, 1152])           True
 1108  model.dit.transformer_blocks.24.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1109  model.dit.transformer_blocks.24.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1110  model.dit.transformer_blocks.24.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1111  model.dit.transformer_blocks.24.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1112  model.dit.transformer_blocks.24.attn1.to_out.0.bias                               torch.Size([1152])              True
 1113  model.dit.transformer_blocks.24.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1114  model.dit.transformer_blocks.24.attn2.to_q.bias                                   torch.Size([1152])              True
 1115  model.dit.transformer_blocks.24.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1116  model.dit.transformer_blocks.24.attn2.to_k.bias                                   torch.Size([1152])              True
 1117  model.dit.transformer_blocks.24.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1118  model.dit.transformer_blocks.24.attn2.to_v.bias                                   torch.Size([1152])              True
 1119  model.dit.transformer_blocks.24.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1120  model.dit.transformer_blocks.24.attn2.to_out.0.bias                               torch.Size([1152])              True
 1121  model.dit.transformer_blocks.24.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1122  model.dit.transformer_blocks.24.ff.conv_inverted.bias                             torch.Size([5760])              True
 1123  model.dit.transformer_blocks.24.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1124  model.dit.transformer_blocks.24.ff.conv_depth.bias                                torch.Size([5760])              True
 1125  model.dit.transformer_blocks.24.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1126  model.dit.transformer_blocks.25.scale_shift_table                                 torch.Size([6, 1152])           True
 1127  model.dit.transformer_blocks.25.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1128  model.dit.transformer_blocks.25.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1129  model.dit.transformer_blocks.25.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1130  model.dit.transformer_blocks.25.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1131  model.dit.transformer_blocks.25.attn1.to_out.0.bias                               torch.Size([1152])              True
 1132  model.dit.transformer_blocks.25.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1133  model.dit.transformer_blocks.25.attn2.to_q.bias                                   torch.Size([1152])              True
 1134  model.dit.transformer_blocks.25.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1135  model.dit.transformer_blocks.25.attn2.to_k.bias                                   torch.Size([1152])              True
 1136  model.dit.transformer_blocks.25.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1137  model.dit.transformer_blocks.25.attn2.to_v.bias                                   torch.Size([1152])              True
 1138  model.dit.transformer_blocks.25.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1139  model.dit.transformer_blocks.25.attn2.to_out.0.bias                               torch.Size([1152])              True
 1140  model.dit.transformer_blocks.25.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1141  model.dit.transformer_blocks.25.ff.conv_inverted.bias                             torch.Size([5760])              True
 1142  model.dit.transformer_blocks.25.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1143  model.dit.transformer_blocks.25.ff.conv_depth.bias                                torch.Size([5760])              True
 1144  model.dit.transformer_blocks.25.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1145  model.dit.transformer_blocks.26.scale_shift_table                                 torch.Size([6, 1152])           True
 1146  model.dit.transformer_blocks.26.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1147  model.dit.transformer_blocks.26.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1148  model.dit.transformer_blocks.26.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1149  model.dit.transformer_blocks.26.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1150  model.dit.transformer_blocks.26.attn1.to_out.0.bias                               torch.Size([1152])              True
 1151  model.dit.transformer_blocks.26.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1152  model.dit.transformer_blocks.26.attn2.to_q.bias                                   torch.Size([1152])              True
 1153  model.dit.transformer_blocks.26.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1154  model.dit.transformer_blocks.26.attn2.to_k.bias                                   torch.Size([1152])              True
 1155  model.dit.transformer_blocks.26.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1156  model.dit.transformer_blocks.26.attn2.to_v.bias                                   torch.Size([1152])              True
 1157  model.dit.transformer_blocks.26.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1158  model.dit.transformer_blocks.26.attn2.to_out.0.bias                               torch.Size([1152])              True
 1159  model.dit.transformer_blocks.26.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1160  model.dit.transformer_blocks.26.ff.conv_inverted.bias                             torch.Size([5760])              True
 1161  model.dit.transformer_blocks.26.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1162  model.dit.transformer_blocks.26.ff.conv_depth.bias                                torch.Size([5760])              True
 1163  model.dit.transformer_blocks.26.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1164  model.dit.transformer_blocks.27.scale_shift_table                                 torch.Size([6, 1152])           True
 1165  model.dit.transformer_blocks.27.attn1.to_q.weight                                 torch.Size([1152, 1152])        True
 1166  model.dit.transformer_blocks.27.attn1.to_k.weight                                 torch.Size([1152, 1152])        True
 1167  model.dit.transformer_blocks.27.attn1.to_v.weight                                 torch.Size([1152, 1152])        True
 1168  model.dit.transformer_blocks.27.attn1.to_out.0.weight                             torch.Size([1152, 1152])        True
 1169  model.dit.transformer_blocks.27.attn1.to_out.0.bias                               torch.Size([1152])              True
 1170  model.dit.transformer_blocks.27.attn2.to_q.weight                                 torch.Size([1152, 1152])        True
 1171  model.dit.transformer_blocks.27.attn2.to_q.bias                                   torch.Size([1152])              True
 1172  model.dit.transformer_blocks.27.attn2.to_k.weight                                 torch.Size([1152, 1152])        True
 1173  model.dit.transformer_blocks.27.attn2.to_k.bias                                   torch.Size([1152])              True
 1174  model.dit.transformer_blocks.27.attn2.to_v.weight                                 torch.Size([1152, 1152])        True
 1175  model.dit.transformer_blocks.27.attn2.to_v.bias                                   torch.Size([1152])              True
 1176  model.dit.transformer_blocks.27.attn2.to_out.0.weight                             torch.Size([1152, 1152])        True
 1177  model.dit.transformer_blocks.27.attn2.to_out.0.bias                               torch.Size([1152])              True
 1178  model.dit.transformer_blocks.27.ff.conv_inverted.weight                           torch.Size([5760, 1152, 1, 1])  True
 1179  model.dit.transformer_blocks.27.ff.conv_inverted.bias                             torch.Size([5760])              True
 1180  model.dit.transformer_blocks.27.ff.conv_depth.weight                              torch.Size([5760, 1, 3, 3])     True
 1181  model.dit.transformer_blocks.27.ff.conv_depth.bias                                torch.Size([5760])              True
 1182  model.dit.transformer_blocks.27.ff.conv_point.weight                              torch.Size([1152, 2880, 1, 1])  True
 1183  model.dit.proj_out.weight                                                         torch.Size([32, 1152])          True
 1184  model.dit.proj_out.bias                                                           torch.Size([32])                True
 1185  model.vae_decoder.decoder.conv_in.weight                                          torch.Size([1024, 32, 3, 3])    False
 1186  model.vae_decoder.decoder.conv_in.bias                                            torch.Size([1024])              False
 1187  model.vae_decoder.decoder.up_blocks.0.0.conv.weight                               torch.Size([128, 256, 3, 3])    False
 1188  model.vae_decoder.decoder.up_blocks.0.0.conv.bias                                 torch.Size([128])               False
 1189  model.vae_decoder.decoder.up_blocks.0.1.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1190  model.vae_decoder.decoder.up_blocks.0.1.conv1.bias                                torch.Size([128])               False
 1191  model.vae_decoder.decoder.up_blocks.0.1.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1192  model.vae_decoder.decoder.up_blocks.0.1.norm.weight                               torch.Size([128])               False
 1193  model.vae_decoder.decoder.up_blocks.0.1.norm.bias                                 torch.Size([128])               False
 1194  model.vae_decoder.decoder.up_blocks.0.2.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1195  model.vae_decoder.decoder.up_blocks.0.2.conv1.bias                                torch.Size([128])               False
 1196  model.vae_decoder.decoder.up_blocks.0.2.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1197  model.vae_decoder.decoder.up_blocks.0.2.norm.weight                               torch.Size([128])               False
 1198  model.vae_decoder.decoder.up_blocks.0.2.norm.bias                                 torch.Size([128])               False
 1199  model.vae_decoder.decoder.up_blocks.0.3.conv1.weight                              torch.Size([128, 128, 3, 3])    False
 1200  model.vae_decoder.decoder.up_blocks.0.3.conv1.bias                                torch.Size([128])               False
 1201  model.vae_decoder.decoder.up_blocks.0.3.conv2.weight                              torch.Size([128, 128, 3, 3])    False
 1202  model.vae_decoder.decoder.up_blocks.0.3.norm.weight                               torch.Size([128])               False
 1203  model.vae_decoder.decoder.up_blocks.0.3.norm.bias                                 torch.Size([128])               False
 1204  model.vae_decoder.decoder.up_blocks.1.0.conv.weight                               torch.Size([256, 512, 3, 3])    False
 1205  model.vae_decoder.decoder.up_blocks.1.0.conv.bias                                 torch.Size([256])               False
 1206  model.vae_decoder.decoder.up_blocks.1.1.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1207  model.vae_decoder.decoder.up_blocks.1.1.conv1.bias                                torch.Size([256])               False
 1208  model.vae_decoder.decoder.up_blocks.1.1.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1209  model.vae_decoder.decoder.up_blocks.1.1.norm.weight                               torch.Size([256])               False
 1210  model.vae_decoder.decoder.up_blocks.1.1.norm.bias                                 torch.Size([256])               False
 1211  model.vae_decoder.decoder.up_blocks.1.2.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1212  model.vae_decoder.decoder.up_blocks.1.2.conv1.bias                                torch.Size([256])               False
 1213  model.vae_decoder.decoder.up_blocks.1.2.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1214  model.vae_decoder.decoder.up_blocks.1.2.norm.weight                               torch.Size([256])               False
 1215  model.vae_decoder.decoder.up_blocks.1.2.norm.bias                                 torch.Size([256])               False
 1216  model.vae_decoder.decoder.up_blocks.1.3.conv1.weight                              torch.Size([256, 256, 3, 3])    False
 1217  model.vae_decoder.decoder.up_blocks.1.3.conv1.bias                                torch.Size([256])               False
 1218  model.vae_decoder.decoder.up_blocks.1.3.conv2.weight                              torch.Size([256, 256, 3, 3])    False
 1219  model.vae_decoder.decoder.up_blocks.1.3.norm.weight                               torch.Size([256])               False
 1220  model.vae_decoder.decoder.up_blocks.1.3.norm.bias                                 torch.Size([256])               False
 1221  model.vae_decoder.decoder.up_blocks.2.0.conv.weight                               torch.Size([512, 512, 3, 3])    False
 1222  model.vae_decoder.decoder.up_blocks.2.0.conv.bias                                 torch.Size([512])               False
 1223  model.vae_decoder.decoder.up_blocks.2.1.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1224  model.vae_decoder.decoder.up_blocks.2.1.conv1.bias                                torch.Size([512])               False
 1225  model.vae_decoder.decoder.up_blocks.2.1.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1226  model.vae_decoder.decoder.up_blocks.2.1.norm.weight                               torch.Size([512])               False
 1227  model.vae_decoder.decoder.up_blocks.2.1.norm.bias                                 torch.Size([512])               False
 1228  model.vae_decoder.decoder.up_blocks.2.2.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1229  model.vae_decoder.decoder.up_blocks.2.2.conv1.bias                                torch.Size([512])               False
 1230  model.vae_decoder.decoder.up_blocks.2.2.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1231  model.vae_decoder.decoder.up_blocks.2.2.norm.weight                               torch.Size([512])               False
 1232  model.vae_decoder.decoder.up_blocks.2.2.norm.bias                                 torch.Size([512])               False
 1233  model.vae_decoder.decoder.up_blocks.2.3.conv1.weight                              torch.Size([512, 512, 3, 3])    False
 1234  model.vae_decoder.decoder.up_blocks.2.3.conv1.bias                                torch.Size([512])               False
 1235  model.vae_decoder.decoder.up_blocks.2.3.conv2.weight                              torch.Size([512, 512, 3, 3])    False
 1236  model.vae_decoder.decoder.up_blocks.2.3.norm.weight                               torch.Size([512])               False
 1237  model.vae_decoder.decoder.up_blocks.2.3.norm.bias                                 torch.Size([512])               False
 1238  model.vae_decoder.decoder.up_blocks.3.0.conv.weight                               torch.Size([512, 1024, 3, 3])   False
 1239  model.vae_decoder.decoder.up_blocks.3.0.conv.bias                                 torch.Size([512])               False
 1240  model.vae_decoder.decoder.up_blocks.3.1.attn.to_q.weight                          torch.Size([512, 512])          False
 1241  model.vae_decoder.decoder.up_blocks.3.1.attn.to_k.weight                          torch.Size([512, 512])          False
 1242  model.vae_decoder.decoder.up_blocks.3.1.attn.to_v.weight                          torch.Size([512, 512])          False
 1243  model.vae_decoder.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1244  model.vae_decoder.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1245  model.vae_decoder.decoder.up_blocks.3.1.attn.to_out.weight                        torch.Size([512, 1024])         False
 1246  model.vae_decoder.decoder.up_blocks.3.1.attn.norm_out.weight                      torch.Size([512])               False
 1247  model.vae_decoder.decoder.up_blocks.3.1.attn.norm_out.bias                        torch.Size([512])               False
 1248  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1249  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1250  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1251  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1252  model.vae_decoder.decoder.up_blocks.3.1.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1253  model.vae_decoder.decoder.up_blocks.3.1.conv_out.norm.weight                      torch.Size([512])               False
 1254  model.vae_decoder.decoder.up_blocks.3.1.conv_out.norm.bias                        torch.Size([512])               False
 1255  model.vae_decoder.decoder.up_blocks.3.2.attn.to_q.weight                          torch.Size([512, 512])          False
 1256  model.vae_decoder.decoder.up_blocks.3.2.attn.to_k.weight                          torch.Size([512, 512])          False
 1257  model.vae_decoder.decoder.up_blocks.3.2.attn.to_v.weight                          torch.Size([512, 512])          False
 1258  model.vae_decoder.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1259  model.vae_decoder.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1260  model.vae_decoder.decoder.up_blocks.3.2.attn.to_out.weight                        torch.Size([512, 1024])         False
 1261  model.vae_decoder.decoder.up_blocks.3.2.attn.norm_out.weight                      torch.Size([512])               False
 1262  model.vae_decoder.decoder.up_blocks.3.2.attn.norm_out.bias                        torch.Size([512])               False
 1263  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1264  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1265  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1266  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1267  model.vae_decoder.decoder.up_blocks.3.2.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1268  model.vae_decoder.decoder.up_blocks.3.2.conv_out.norm.weight                      torch.Size([512])               False
 1269  model.vae_decoder.decoder.up_blocks.3.2.conv_out.norm.bias                        torch.Size([512])               False
 1270  model.vae_decoder.decoder.up_blocks.3.3.attn.to_q.weight                          torch.Size([512, 512])          False
 1271  model.vae_decoder.decoder.up_blocks.3.3.attn.to_k.weight                          torch.Size([512, 512])          False
 1272  model.vae_decoder.decoder.up_blocks.3.3.attn.to_v.weight                          torch.Size([512, 512])          False
 1273  model.vae_decoder.decoder.up_blocks.3.3.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([1536, 1, 5, 5])     False
 1274  model.vae_decoder.decoder.up_blocks.3.3.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([1536, 32, 1, 1])    False
 1275  model.vae_decoder.decoder.up_blocks.3.3.attn.to_out.weight                        torch.Size([512, 1024])         False
 1276  model.vae_decoder.decoder.up_blocks.3.3.attn.norm_out.weight                      torch.Size([512])               False
 1277  model.vae_decoder.decoder.up_blocks.3.3.attn.norm_out.bias                        torch.Size([512])               False
 1278  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_inverted.weight             torch.Size([4096, 512, 1, 1])   False
 1279  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_inverted.bias               torch.Size([4096])              False
 1280  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_depth.weight                torch.Size([4096, 1, 3, 3])     False
 1281  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_depth.bias                  torch.Size([4096])              False
 1282  model.vae_decoder.decoder.up_blocks.3.3.conv_out.conv_point.weight                torch.Size([512, 2048, 1, 1])   False
 1283  model.vae_decoder.decoder.up_blocks.3.3.conv_out.norm.weight                      torch.Size([512])               False
 1284  model.vae_decoder.decoder.up_blocks.3.3.conv_out.norm.bias                        torch.Size([512])               False
 1285  model.vae_decoder.decoder.up_blocks.4.0.conv.weight                               torch.Size([1024, 1024, 3, 3])  False
 1286  model.vae_decoder.decoder.up_blocks.4.0.conv.bias                                 torch.Size([1024])              False
 1287  model.vae_decoder.decoder.up_blocks.4.1.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1288  model.vae_decoder.decoder.up_blocks.4.1.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1289  model.vae_decoder.decoder.up_blocks.4.1.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1290  model.vae_decoder.decoder.up_blocks.4.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1291  model.vae_decoder.decoder.up_blocks.4.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1292  model.vae_decoder.decoder.up_blocks.4.1.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1293  model.vae_decoder.decoder.up_blocks.4.1.attn.norm_out.weight                      torch.Size([1024])              False
 1294  model.vae_decoder.decoder.up_blocks.4.1.attn.norm_out.bias                        torch.Size([1024])              False
 1295  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1296  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1297  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1298  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1299  model.vae_decoder.decoder.up_blocks.4.1.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1300  model.vae_decoder.decoder.up_blocks.4.1.conv_out.norm.weight                      torch.Size([1024])              False
 1301  model.vae_decoder.decoder.up_blocks.4.1.conv_out.norm.bias                        torch.Size([1024])              False
 1302  model.vae_decoder.decoder.up_blocks.4.2.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1303  model.vae_decoder.decoder.up_blocks.4.2.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1304  model.vae_decoder.decoder.up_blocks.4.2.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1305  model.vae_decoder.decoder.up_blocks.4.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1306  model.vae_decoder.decoder.up_blocks.4.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1307  model.vae_decoder.decoder.up_blocks.4.2.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1308  model.vae_decoder.decoder.up_blocks.4.2.attn.norm_out.weight                      torch.Size([1024])              False
 1309  model.vae_decoder.decoder.up_blocks.4.2.attn.norm_out.bias                        torch.Size([1024])              False
 1310  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1311  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1312  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1313  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1314  model.vae_decoder.decoder.up_blocks.4.2.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1315  model.vae_decoder.decoder.up_blocks.4.2.conv_out.norm.weight                      torch.Size([1024])              False
 1316  model.vae_decoder.decoder.up_blocks.4.2.conv_out.norm.bias                        torch.Size([1024])              False
 1317  model.vae_decoder.decoder.up_blocks.4.3.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1318  model.vae_decoder.decoder.up_blocks.4.3.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1319  model.vae_decoder.decoder.up_blocks.4.3.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1320  model.vae_decoder.decoder.up_blocks.4.3.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1321  model.vae_decoder.decoder.up_blocks.4.3.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1322  model.vae_decoder.decoder.up_blocks.4.3.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1323  model.vae_decoder.decoder.up_blocks.4.3.attn.norm_out.weight                      torch.Size([1024])              False
 1324  model.vae_decoder.decoder.up_blocks.4.3.attn.norm_out.bias                        torch.Size([1024])              False
 1325  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1326  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1327  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1328  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1329  model.vae_decoder.decoder.up_blocks.4.3.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1330  model.vae_decoder.decoder.up_blocks.4.3.conv_out.norm.weight                      torch.Size([1024])              False
 1331  model.vae_decoder.decoder.up_blocks.4.3.conv_out.norm.bias                        torch.Size([1024])              False
 1332  model.vae_decoder.decoder.up_blocks.5.0.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1333  model.vae_decoder.decoder.up_blocks.5.0.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1334  model.vae_decoder.decoder.up_blocks.5.0.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1335  model.vae_decoder.decoder.up_blocks.5.0.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1336  model.vae_decoder.decoder.up_blocks.5.0.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1337  model.vae_decoder.decoder.up_blocks.5.0.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1338  model.vae_decoder.decoder.up_blocks.5.0.attn.norm_out.weight                      torch.Size([1024])              False
 1339  model.vae_decoder.decoder.up_blocks.5.0.attn.norm_out.bias                        torch.Size([1024])              False
 1340  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1341  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1342  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1343  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1344  model.vae_decoder.decoder.up_blocks.5.0.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1345  model.vae_decoder.decoder.up_blocks.5.0.conv_out.norm.weight                      torch.Size([1024])              False
 1346  model.vae_decoder.decoder.up_blocks.5.0.conv_out.norm.bias                        torch.Size([1024])              False
 1347  model.vae_decoder.decoder.up_blocks.5.1.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1348  model.vae_decoder.decoder.up_blocks.5.1.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1349  model.vae_decoder.decoder.up_blocks.5.1.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1350  model.vae_decoder.decoder.up_blocks.5.1.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1351  model.vae_decoder.decoder.up_blocks.5.1.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1352  model.vae_decoder.decoder.up_blocks.5.1.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1353  model.vae_decoder.decoder.up_blocks.5.1.attn.norm_out.weight                      torch.Size([1024])              False
 1354  model.vae_decoder.decoder.up_blocks.5.1.attn.norm_out.bias                        torch.Size([1024])              False
 1355  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1356  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1357  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1358  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1359  model.vae_decoder.decoder.up_blocks.5.1.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1360  model.vae_decoder.decoder.up_blocks.5.1.conv_out.norm.weight                      torch.Size([1024])              False
 1361  model.vae_decoder.decoder.up_blocks.5.1.conv_out.norm.bias                        torch.Size([1024])              False
 1362  model.vae_decoder.decoder.up_blocks.5.2.attn.to_q.weight                          torch.Size([1024, 1024])        False
 1363  model.vae_decoder.decoder.up_blocks.5.2.attn.to_k.weight                          torch.Size([1024, 1024])        False
 1364  model.vae_decoder.decoder.up_blocks.5.2.attn.to_v.weight                          torch.Size([1024, 1024])        False
 1365  model.vae_decoder.decoder.up_blocks.5.2.attn.to_qkv_multiscale.0.proj_in.weight   torch.Size([3072, 1, 5, 5])     False
 1366  model.vae_decoder.decoder.up_blocks.5.2.attn.to_qkv_multiscale.0.proj_out.weight  torch.Size([3072, 32, 1, 1])    False
 1367  model.vae_decoder.decoder.up_blocks.5.2.attn.to_out.weight                        torch.Size([1024, 2048])        False
 1368  model.vae_decoder.decoder.up_blocks.5.2.attn.norm_out.weight                      torch.Size([1024])              False
 1369  model.vae_decoder.decoder.up_blocks.5.2.attn.norm_out.bias                        torch.Size([1024])              False
 1370  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_inverted.weight             torch.Size([8192, 1024, 1, 1])  False
 1371  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_inverted.bias               torch.Size([8192])              False
 1372  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_depth.weight                torch.Size([8192, 1, 3, 3])     False
 1373  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_depth.bias                  torch.Size([8192])              False
 1374  model.vae_decoder.decoder.up_blocks.5.2.conv_out.conv_point.weight                torch.Size([1024, 4096, 1, 1])  False
 1375  model.vae_decoder.decoder.up_blocks.5.2.conv_out.norm.weight                      torch.Size([1024])              False
 1376  model.vae_decoder.decoder.up_blocks.5.2.conv_out.norm.bias                        torch.Size([1024])              False
 1377  model.vae_decoder.decoder.norm_out.weight                                         torch.Size([128])               False
 1378  model.vae_decoder.decoder.norm_out.bias                                           torch.Size([128])               False
 1379  model.vae_decoder.decoder.conv_out.weight                                         torch.Size([3, 128, 3, 3])      False
 1380  model.vae_decoder.decoder.conv_out.bias                                           torch.Size([3])                 False
 1381  model.vae_decoder.down_blocks.0.mlp.0.weight                                      torch.Size([896])               False
 1382  model.vae_decoder.down_blocks.0.mlp.0.bias                                        torch.Size([896])               False
 1383  model.vae_decoder.down_blocks.0.mlp.1.weight                                      torch.Size([896, 896])          False
 1384  model.vae_decoder.down_blocks.0.mlp.1.bias                                        torch.Size([896])               False
 1385  model.vae_decoder.down_blocks.0.mlp.3.weight                                      torch.Size([896, 896])          False
 1386  model.vae_decoder.down_blocks.0.mlp.3.bias                                        torch.Size([896])               False
 1387  model.vae_decoder.down_blocks.1.mlp.0.weight                                      torch.Size([896])               False
 1388  model.vae_decoder.down_blocks.1.mlp.0.bias                                        torch.Size([896])               False
 1389  model.vae_decoder.down_blocks.1.mlp.1.weight                                      torch.Size([896, 896])          False
 1390  model.vae_decoder.down_blocks.1.mlp.1.bias                                        torch.Size([896])               False
 1391  model.vae_decoder.down_blocks.1.mlp.3.weight                                      torch.Size([896, 896])          False
 1392  model.vae_decoder.down_blocks.1.mlp.3.bias                                        torch.Size([896])               False
 1393  model.vae_decoder.down_blocks.2.mlp.0.weight                                      torch.Size([896])               False
 1394  model.vae_decoder.down_blocks.2.mlp.0.bias                                        torch.Size([896])               False
 1395  model.vae_decoder.down_blocks.2.mlp.1.weight                                      torch.Size([896, 896])          False
 1396  model.vae_decoder.down_blocks.2.mlp.1.bias                                        torch.Size([896])               False
 1397  model.vae_decoder.down_blocks.2.mlp.3.weight                                      torch.Size([896, 896])          False
 1398  model.vae_decoder.down_blocks.2.mlp.3.bias                                        torch.Size([896])               False
 1399  model.vae_decoder.down_mlp.0.weight                                               torch.Size([896])               False
 1400  model.vae_decoder.down_mlp.0.bias                                                 torch.Size([896])               False
 1401  model.vae_decoder.down_mlp.1.weight                                               torch.Size([32, 896])           False
 1402  model.vae_decoder.down_mlp.1.bias                                                 torch.Size([32])                False
 1403  model.vae_decoder.down_mlp.3.weight                                               torch.Size([32, 32])            False
 1404  model.vae_decoder.down_mlp.3.bias                                                 torch.Size([32])                False
 1405  model.llm_connector.layers.0.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1406  model.llm_connector.layers.0.self_attn.q_proj.bias                                torch.Size([896])               True
 1407  model.llm_connector.layers.0.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1408  model.llm_connector.layers.0.self_attn.k_proj.bias                                torch.Size([128])               True
 1409  model.llm_connector.layers.0.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1410  model.llm_connector.layers.0.self_attn.v_proj.bias                                torch.Size([128])               True
 1411  model.llm_connector.layers.0.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1412  model.llm_connector.layers.0.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1413  model.llm_connector.layers.0.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1414  model.llm_connector.layers.0.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1415  model.llm_connector.layers.0.input_layernorm.weight                               torch.Size([896])               True
 1416  model.llm_connector.layers.0.post_attention_layernorm.weight                      torch.Size([896])               True
 1417  model.llm_connector.layers.1.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1418  model.llm_connector.layers.1.self_attn.q_proj.bias                                torch.Size([896])               True
 1419  model.llm_connector.layers.1.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1420  model.llm_connector.layers.1.self_attn.k_proj.bias                                torch.Size([128])               True
 1421  model.llm_connector.layers.1.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1422  model.llm_connector.layers.1.self_attn.v_proj.bias                                torch.Size([128])               True
 1423  model.llm_connector.layers.1.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1424  model.llm_connector.layers.1.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1425  model.llm_connector.layers.1.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1426  model.llm_connector.layers.1.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1427  model.llm_connector.layers.1.input_layernorm.weight                               torch.Size([896])               True
 1428  model.llm_connector.layers.1.post_attention_layernorm.weight                      torch.Size([896])               True
 1429  model.llm_connector.layers.2.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1430  model.llm_connector.layers.2.self_attn.q_proj.bias                                torch.Size([896])               True
 1431  model.llm_connector.layers.2.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1432  model.llm_connector.layers.2.self_attn.k_proj.bias                                torch.Size([128])               True
 1433  model.llm_connector.layers.2.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1434  model.llm_connector.layers.2.self_attn.v_proj.bias                                torch.Size([128])               True
 1435  model.llm_connector.layers.2.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1436  model.llm_connector.layers.2.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1437  model.llm_connector.layers.2.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1438  model.llm_connector.layers.2.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1439  model.llm_connector.layers.2.input_layernorm.weight                               torch.Size([896])               True
 1440  model.llm_connector.layers.2.post_attention_layernorm.weight                      torch.Size([896])               True
 1441  model.llm_connector.layers.3.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1442  model.llm_connector.layers.3.self_attn.q_proj.bias                                torch.Size([896])               True
 1443  model.llm_connector.layers.3.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1444  model.llm_connector.layers.3.self_attn.k_proj.bias                                torch.Size([128])               True
 1445  model.llm_connector.layers.3.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1446  model.llm_connector.layers.3.self_attn.v_proj.bias                                torch.Size([128])               True
 1447  model.llm_connector.layers.3.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1448  model.llm_connector.layers.3.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1449  model.llm_connector.layers.3.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1450  model.llm_connector.layers.3.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1451  model.llm_connector.layers.3.input_layernorm.weight                               torch.Size([896])               True
 1452  model.llm_connector.layers.3.post_attention_layernorm.weight                      torch.Size([896])               True
 1453  model.llm_connector.layers.4.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1454  model.llm_connector.layers.4.self_attn.q_proj.bias                                torch.Size([896])               True
 1455  model.llm_connector.layers.4.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1456  model.llm_connector.layers.4.self_attn.k_proj.bias                                torch.Size([128])               True
 1457  model.llm_connector.layers.4.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1458  model.llm_connector.layers.4.self_attn.v_proj.bias                                torch.Size([128])               True
 1459  model.llm_connector.layers.4.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1460  model.llm_connector.layers.4.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1461  model.llm_connector.layers.4.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1462  model.llm_connector.layers.4.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1463  model.llm_connector.layers.4.input_layernorm.weight                               torch.Size([896])               True
 1464  model.llm_connector.layers.4.post_attention_layernorm.weight                      torch.Size([896])               True
 1465  model.llm_connector.layers.5.self_attn.q_proj.weight                              torch.Size([896, 896])          True
 1466  model.llm_connector.layers.5.self_attn.q_proj.bias                                torch.Size([896])               True
 1467  model.llm_connector.layers.5.self_attn.k_proj.weight                              torch.Size([128, 896])          True
 1468  model.llm_connector.layers.5.self_attn.k_proj.bias                                torch.Size([128])               True
 1469  model.llm_connector.layers.5.self_attn.v_proj.weight                              torch.Size([128, 896])          True
 1470  model.llm_connector.layers.5.self_attn.v_proj.bias                                torch.Size([128])               True
 1471  model.llm_connector.layers.5.self_attn.o_proj.weight                              torch.Size([896, 896])          True
 1472  model.llm_connector.layers.5.mlp.gate_proj.weight                                 torch.Size([4864, 896])         True
 1473  model.llm_connector.layers.5.mlp.up_proj.weight                                   torch.Size([4864, 896])         True
 1474  model.llm_connector.layers.5.mlp.down_proj.weight                                 torch.Size([896, 4864])         True
 1475  model.llm_connector.layers.5.input_layernorm.weight                               torch.Size([896])               True
 1476  model.llm_connector.layers.5.post_attention_layernorm.weight                      torch.Size([896])               True
 1477  model.llm_connector.norm.weight                                                   torch.Size([896])               True
 1478  model.projector.weight                                                            torch.Size([2304, 896])         True
 1479  model.projector.bias                                                              torch.Size([2304])              True
 1480  model.action_dit.layers.0.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1481  model.action_dit.layers.0.self_attn.q_proj.bias                                   torch.Size([896])               True
 1482  model.action_dit.layers.0.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1483  model.action_dit.layers.0.self_attn.k_proj.bias                                   torch.Size([128])               True
 1484  model.action_dit.layers.0.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1485  model.action_dit.layers.0.self_attn.v_proj.bias                                   torch.Size([128])               True
 1486  model.action_dit.layers.0.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1487  model.action_dit.layers.0.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1488  model.action_dit.layers.0.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1489  model.action_dit.layers.0.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1490  model.action_dit.layers.0.input_layernorm.weight                                  torch.Size([896])               True
 1491  model.action_dit.layers.0.input_layernorm.linear.weight                           torch.Size([2688, 896])         True
 1492  model.action_dit.layers.0.input_layernorm.linear.bias                             torch.Size([2688])              True
 1493  model.action_dit.layers.0.post_attention_layernorm.weight                         torch.Size([896])               True
 1494  model.action_dit.layers.0.post_attention_layernorm.linear.weight                  torch.Size([2688, 896])         True
 1495  model.action_dit.layers.0.post_attention_layernorm.linear.bias                    torch.Size([2688])              True
 1496  model.action_dit.layers.1.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1497  model.action_dit.layers.1.self_attn.q_proj.bias                                   torch.Size([896])               True
 1498  model.action_dit.layers.1.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1499  model.action_dit.layers.1.self_attn.k_proj.bias                                   torch.Size([128])               True
 1500  model.action_dit.layers.1.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1501  model.action_dit.layers.1.self_attn.v_proj.bias                                   torch.Size([128])               True
 1502  model.action_dit.layers.1.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1503  model.action_dit.layers.1.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1504  model.action_dit.layers.1.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1505  model.action_dit.layers.1.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1506  model.action_dit.layers.1.input_layernorm.weight                                  torch.Size([896])               True
 1507  model.action_dit.layers.1.input_layernorm.linear.weight                           torch.Size([2688, 896])         True
 1508  model.action_dit.layers.1.input_layernorm.linear.bias                             torch.Size([2688])              True
 1509  model.action_dit.layers.1.post_attention_layernorm.weight                         torch.Size([896])               True
 1510  model.action_dit.layers.1.post_attention_layernorm.linear.weight                  torch.Size([2688, 896])         True
 1511  model.action_dit.layers.1.post_attention_layernorm.linear.bias                    torch.Size([2688])              True
 1512  model.action_dit.layers.2.self_attn.q_proj.weight                                 torch.Size([896, 896])          True
 1513  model.action_dit.layers.2.self_attn.q_proj.bias                                   torch.Size([896])               True
 1514  model.action_dit.layers.2.self_attn.k_proj.weight                                 torch.Size([128, 896])          True
 1515  model.action_dit.layers.2.self_attn.k_proj.bias                                   torch.Size([128])               True
 1516  model.action_dit.layers.2.self_attn.v_proj.weight                                 torch.Size([128, 896])          True
 1517  model.action_dit.layers.2.self_attn.v_proj.bias                                   torch.Size([128])               True
 1518  model.action_dit.layers.2.self_attn.o_proj.weight                                 torch.Size([896, 896])          True
 1519  model.action_dit.layers.2.mlp.gate_proj.weight                                    torch.Size([4864, 896])         True
 1520  model.action_dit.layers.2.mlp.up_proj.weight                                      torch.Size([4864, 896])         True
 1521  model.action_dit.layers.2.mlp.down_proj.weight                                    torch.Size([896, 4864])         True
 1522  model.action_dit.layers.2.input_layernorm.weight                                  torch.Size([896])               True
 1523  model.action_dit.layers.2.input_layernorm.linear.weight                           torch.Size([2688, 896])         True
 1524  model.action_dit.layers.2.input_layernorm.linear.bias                             torch.Size([2688])              True
 1525  model.action_dit.layers.2.post_attention_layernorm.weight                         torch.Size([896])               True
 1526  model.action_dit.layers.2.post_attention_layernorm.linear.weight                  torch.Size([2688, 896])         True
 1527  model.action_dit.layers.2.post_attention_layernorm.linear.bias                    torch.Size([2688])              True
 1528  model.action_dit.norm.weight                                                      torch.Size([896])               True
 1529  model.action_dit.norm.linear.weight                                               torch.Size([2688, 896])         True
 1530  model.action_dit.norm.linear.bias                                                 torch.Size([2688])              True
 1531  model.action_in_proj.weight                                                       torch.Size([896, 5])            True
 1532  model.action_in_proj.bias                                                         torch.Size([896])               True
 1533  model.time_mlp_in.weight                                                          torch.Size([896, 896])          True
 1534  model.time_mlp_in.bias                                                            torch.Size([896])               True
 1535  model.time_mlp_out.weight                                                         torch.Size([896, 896])          True
 1536  model.time_mlp_out.bias                                                           torch.Size([896])               True
 1537  model.action_out_proj.weight                                                      torch.Size([5, 896])            True
 1538  model.action_out_proj.bias                                                        torch.Size([5])                 True
 1539  lm_head.weight                                                                    torch.Size([151678, 896])       False - (2126245:train_csgo.py:1489)
2026-01-14 22:08:46 - INFO - total_loss: 12.347886085510254, masked_loc_loss: 11.69312858581543, masked_gen_loss: 0.6547572612762451 - (2126245:unified_unilip.py:1102)
2026-01-14 22:08:57 - INFO - total_loss: 14.532821655273438, masked_loc_loss: 14.023265838623047, masked_gen_loss: 0.5095553994178772 - (2126245:unified_unilip.py:1102)
2026-01-14 22:09:06 - INFO - total_loss: 11.580476760864258, masked_loc_loss: 10.936025619506836, masked_gen_loss: 0.644451379776001 - (2126245:unified_unilip.py:1102)
2026-01-14 22:09:15 - INFO - total_loss: 11.647212982177734, masked_loc_loss: 10.999166488647461, masked_gen_loss: 0.6480469107627869 - (2126245:unified_unilip.py:1102)
2026-01-14 22:09:46 - INFO - total_loss: 15.200657844543457, masked_loc_loss: 14.691082000732422, masked_gen_loss: 0.509575605392456 - (2126245:unified_unilip.py:1102)
2026-01-14 22:09:54 - INFO - total_loss: 11.957087516784668, masked_loc_loss: 11.322120666503906, masked_gen_loss: 0.6349669098854065 - (2126245:unified_unilip.py:1102)
2026-01-14 22:10:03 - INFO - total_loss: 13.612549781799316, masked_loc_loss: 13.058126449584961, masked_gen_loss: 0.554422914981842 - (2126245:unified_unilip.py:1102)
2026-01-14 22:10:12 - INFO - total_loss: 15.124985694885254, masked_loc_loss: 14.652498245239258, masked_gen_loss: 0.47248774766921997 - (2126245:unified_unilip.py:1102)
2026-01-14 22:10:48 - INFO - total_loss: 14.110655784606934, masked_loc_loss: 13.582063674926758, masked_gen_loss: 0.5285918712615967 - (2126245:unified_unilip.py:1102)
2026-01-14 22:10:57 - INFO - total_loss: 13.339770317077637, masked_loc_loss: 12.805627822875977, masked_gen_loss: 0.5341426134109497 - (2126245:unified_unilip.py:1102)
2026-01-14 22:11:31 - INFO - total_loss: 12.78242301940918, masked_loc_loss: 12.229400634765625, masked_gen_loss: 0.5530219078063965 - (2126245:unified_unilip.py:1102)
2026-01-14 22:11:40 - INFO - total_loss: 13.452728271484375, masked_loc_loss: 12.934216499328613, masked_gen_loss: 0.5185118913650513 - (2126245:unified_unilip.py:1102)
2026-01-14 22:11:51 - INFO - total_loss: 12.05072021484375, masked_loc_loss: 11.473658561706543, masked_gen_loss: 0.5770619511604309 - (2126245:unified_unilip.py:1102)
2026-01-14 22:11:59 - INFO - total_loss: 12.12740707397461, masked_loc_loss: 11.61375904083252, masked_gen_loss: 0.513648271560669 - (2126245:unified_unilip.py:1102)
2026-01-14 22:12:08 - INFO - total_loss: 11.63357925415039, masked_loc_loss: 11.109936714172363, masked_gen_loss: 0.523642361164093 - (2126245:unified_unilip.py:1102)
2026-01-14 22:12:17 - INFO - total_loss: 11.967947959899902, masked_loc_loss: 11.511231422424316, masked_gen_loss: 0.4567161202430725 - (2126245:unified_unilip.py:1102)
2026-01-14 22:12:54 - INFO - total_loss: 11.07841968536377, masked_loc_loss: 10.631240844726562, masked_gen_loss: 0.44717878103256226 - (2126245:unified_unilip.py:1102)
2026-01-14 22:13:03 - INFO - total_loss: 9.697443962097168, masked_loc_loss: 9.193424224853516, masked_gen_loss: 0.5040193796157837 - (2126245:unified_unilip.py:1102)
2026-01-14 22:13:12 - INFO - total_loss: 11.415116310119629, masked_loc_loss: 11.012174606323242, masked_gen_loss: 0.40294164419174194 - (2126245:unified_unilip.py:1102)
2026-01-14 22:13:21 - INFO - total_loss: 9.438945770263672, masked_loc_loss: 8.979681015014648, masked_gen_loss: 0.4592650532722473 - (2126245:unified_unilip.py:1102)
2026-01-14 22:13:57 - INFO - total_loss: 8.943733215332031, masked_loc_loss: 8.524656295776367, masked_gen_loss: 0.4190770089626312 - (2126245:unified_unilip.py:1102)
2026-01-14 22:14:06 - INFO - total_loss: 8.66215991973877, masked_loc_loss: 8.284814834594727, masked_gen_loss: 0.3773454427719116 - (2126245:unified_unilip.py:1102)
2026-01-14 22:14:15 - INFO - total_loss: 8.118865966796875, masked_loc_loss: 7.766222953796387, masked_gen_loss: 0.35264283418655396 - (2126245:unified_unilip.py:1102)
2026-01-14 22:14:23 - INFO - total_loss: 6.443277359008789, masked_loc_loss: 5.994364261627197, masked_gen_loss: 0.44891291856765747 - (2126245:unified_unilip.py:1102)
2026-01-14 22:14:58 - INFO - total_loss: 5.663385391235352, masked_loc_loss: 5.187386512756348, masked_gen_loss: 0.47599905729293823 - (2126245:unified_unilip.py:1102)
2026-01-14 22:15:07 - INFO - total_loss: 5.596488952636719, masked_loc_loss: 5.128489971160889, masked_gen_loss: 0.4679989516735077 - (2126245:unified_unilip.py:1102)
2026-01-14 22:15:16 - INFO - total_loss: 5.992827415466309, masked_loc_loss: 5.562808036804199, masked_gen_loss: 0.4300192892551422 - (2126245:unified_unilip.py:1102)
2026-01-14 22:15:25 - INFO - total_loss: 6.607994079589844, masked_loc_loss: 6.224063873291016, masked_gen_loss: 0.3839302361011505 - (2126245:unified_unilip.py:1102)
2026-01-14 22:15:59 - INFO - total_loss: 6.148247718811035, masked_loc_loss: 5.727773666381836, masked_gen_loss: 0.42047393321990967 - (2126245:unified_unilip.py:1102)
2026-01-14 22:16:07 - INFO - total_loss: 6.1896772384643555, masked_loc_loss: 5.810366630554199, masked_gen_loss: 0.37931081652641296 - (2126245:unified_unilip.py:1102)
2026-01-14 22:16:35 - INFO - total_loss: 5.543911457061768, masked_loc_loss: 5.138405799865723, masked_gen_loss: 0.4055056571960449 - (2126245:unified_unilip.py:1102)
2026-01-14 22:16:44 - INFO - total_loss: 5.173772811889648, masked_loc_loss: 4.772911071777344, masked_gen_loss: 0.400861918926239 - (2126245:unified_unilip.py:1102)
2026-01-14 22:17:07 - INFO - total_loss: 4.537112236022949, masked_loc_loss: 4.061324119567871, masked_gen_loss: 0.47578805685043335 - (2126245:unified_unilip.py:1102)
2026-01-14 22:17:15 - INFO - total_loss: 4.484607219696045, masked_loc_loss: 4.054681777954102, masked_gen_loss: 0.4299253523349762 - (2126245:unified_unilip.py:1102)
2026-01-14 22:17:24 - INFO - total_loss: 4.671115875244141, masked_loc_loss: 4.2389140129089355, masked_gen_loss: 0.43220165371894836 - (2126245:unified_unilip.py:1102)
2026-01-14 22:17:33 - INFO - total_loss: 5.088038444519043, masked_loc_loss: 4.704148292541504, masked_gen_loss: 0.383890300989151 - (2126245:unified_unilip.py:1102)
2026-01-14 22:18:07 - INFO - total_loss: 4.273837566375732, masked_loc_loss: 3.8230395317077637, masked_gen_loss: 0.45079803466796875 - (2126245:unified_unilip.py:1102)
2026-01-14 22:18:16 - INFO - total_loss: 4.980343341827393, masked_loc_loss: 4.634331226348877, masked_gen_loss: 0.34601202607154846 - (2126245:unified_unilip.py:1102)
2026-01-14 22:18:24 - INFO - total_loss: 4.876490592956543, masked_loc_loss: 4.528190612792969, masked_gen_loss: 0.3482997417449951 - (2126245:unified_unilip.py:1102)
2026-01-14 22:18:33 - INFO - total_loss: 4.311678886413574, masked_loc_loss: 3.8918681144714355, masked_gen_loss: 0.4198107123374939 - (2126245:unified_unilip.py:1102)
2026-01-14 22:19:08 - INFO - total_loss: 4.206916809082031, masked_loc_loss: 3.8068666458129883, masked_gen_loss: 0.4000501036643982 - (2126245:unified_unilip.py:1102)
2026-01-14 22:19:17 - INFO - total_loss: 3.8374552726745605, masked_loc_loss: 3.414621591567993, masked_gen_loss: 0.422833651304245 - (2126245:unified_unilip.py:1102)
2026-01-14 22:19:26 - INFO - total_loss: 3.859334707260132, masked_loc_loss: 3.4640421867370605, masked_gen_loss: 0.3952925503253937 - (2126245:unified_unilip.py:1102)
2026-01-14 22:19:35 - INFO - total_loss: 4.104082107543945, masked_loc_loss: 3.7256250381469727, masked_gen_loss: 0.3784571588039398 - (2126245:unified_unilip.py:1102)
2026-01-14 22:20:09 - INFO - total_loss: 3.5757999420166016, masked_loc_loss: 3.153683662414551, masked_gen_loss: 0.42211630940437317 - (2126245:unified_unilip.py:1102)
2026-01-14 22:20:18 - INFO - total_loss: 3.929896116256714, masked_loc_loss: 3.5714728832244873, masked_gen_loss: 0.3584231734275818 - (2126245:unified_unilip.py:1102)
2026-01-14 22:20:26 - INFO - total_loss: 3.9389119148254395, masked_loc_loss: 3.5942935943603516, masked_gen_loss: 0.34461843967437744 - (2126245:unified_unilip.py:1102)
2026-01-14 22:20:35 - INFO - total_loss: 3.4831912517547607, masked_loc_loss: 3.111360549926758, masked_gen_loss: 0.37183070182800293 - (2126245:unified_unilip.py:1102)
2026-01-14 22:21:09 - INFO - total_loss: 3.7184243202209473, masked_loc_loss: 3.390299081802368, masked_gen_loss: 0.3281252086162567 - (2126245:unified_unilip.py:1102)
2026-01-14 22:21:18 - INFO - total_loss: 3.6317567825317383, masked_loc_loss: 3.2962939739227295, masked_gen_loss: 0.33546292781829834 - (2126245:unified_unilip.py:1102)
2026-01-14 22:21:45 - INFO - total_loss: 3.2126927375793457, masked_loc_loss: 2.7969424724578857, masked_gen_loss: 0.4157502055168152 - (2126245:unified_unilip.py:1102)
2026-01-14 22:21:53 - INFO - total_loss: 2.849087953567505, masked_loc_loss: 2.415900230407715, masked_gen_loss: 0.43318769335746765 - (2126245:unified_unilip.py:1102)
2026-01-14 22:22:10 - INFO - total_loss: 2.5166525840759277, masked_loc_loss: 2.078197956085205, masked_gen_loss: 0.4384547472000122 - (2126245:unified_unilip.py:1102)
2026-01-14 22:22:18 - INFO - total_loss: 2.4195961952209473, masked_loc_loss: 1.976745843887329, masked_gen_loss: 0.4428502321243286 - (2126245:unified_unilip.py:1102)
2026-01-14 22:22:27 - INFO - total_loss: 2.6054656505584717, masked_loc_loss: 2.18373966217041, masked_gen_loss: 0.42172592878341675 - (2126245:unified_unilip.py:1102)
2026-01-14 22:22:36 - INFO - total_loss: 2.628593921661377, masked_loc_loss: 2.2532193660736084, masked_gen_loss: 0.37537455558776855 - (2126245:unified_unilip.py:1102)
2026-01-14 22:23:10 - INFO - total_loss: 3.006664991378784, masked_loc_loss: 2.6959986686706543, masked_gen_loss: 0.3106662929058075 - (2126245:unified_unilip.py:1102)
2026-01-14 22:23:19 - INFO - total_loss: 2.513669967651367, masked_loc_loss: 2.132236957550049, masked_gen_loss: 0.38143301010131836 - (2126245:unified_unilip.py:1102)
2026-01-14 22:23:28 - INFO - total_loss: 2.3586883544921875, masked_loc_loss: 1.9797444343566895, masked_gen_loss: 0.3789440393447876 - (2126245:unified_unilip.py:1102)
2026-01-14 22:23:37 - INFO - total_loss: 2.2900595664978027, masked_loc_loss: 1.8965191841125488, masked_gen_loss: 0.39354026317596436 - (2126245:unified_unilip.py:1102)
2026-01-14 22:24:10 - INFO - total_loss: 2.5849716663360596, masked_loc_loss: 2.275472640991211, masked_gen_loss: 0.30949896574020386 - (2126245:unified_unilip.py:1102)
2026-01-14 22:24:22 - INFO - total_loss: 2.347113609313965, masked_loc_loss: 1.9963994026184082, masked_gen_loss: 0.3507142663002014 - (2126245:unified_unilip.py:1102)
2026-01-14 22:24:30 - INFO - total_loss: 2.198514938354492, masked_loc_loss: 1.8182473182678223, masked_gen_loss: 0.3802676200866699 - (2126245:unified_unilip.py:1102)
2026-01-14 22:24:39 - INFO - total_loss: 1.8897008895874023, masked_loc_loss: 1.485119104385376, masked_gen_loss: 0.40458181500434875 - (2126245:unified_unilip.py:1102)
2026-01-14 22:25:09 - INFO - total_loss: 1.927952766418457, masked_loc_loss: 1.5413577556610107, masked_gen_loss: 0.3865950405597687 - (2126245:unified_unilip.py:1102)
2026-01-14 22:25:23 - INFO - total_loss: 2.249342679977417, masked_loc_loss: 1.9476557970046997, masked_gen_loss: 0.30168694257736206 - (2126245:unified_unilip.py:1102)
2026-01-14 22:25:32 - INFO - total_loss: 1.9586641788482666, masked_loc_loss: 1.58856201171875, masked_gen_loss: 0.3701021671295166 - (2126245:unified_unilip.py:1102)
2026-01-14 22:25:40 - INFO - total_loss: 1.7844793796539307, masked_loc_loss: 1.3884533643722534, masked_gen_loss: 0.39602601528167725 - (2126245:unified_unilip.py:1102)
2026-01-14 22:26:06 - INFO - total_loss: 1.9844272136688232, masked_loc_loss: 1.6117329597473145, masked_gen_loss: 0.37269431352615356 - (2126245:unified_unilip.py:1102)
2026-01-14 22:26:20 - INFO - total_loss: 1.729907512664795, masked_loc_loss: 1.325094223022461, masked_gen_loss: 0.40481334924697876 - (2126245:unified_unilip.py:1102)
2026-01-14 22:26:49 - INFO - total_loss: 1.9287210702896118, masked_loc_loss: 1.6080243587493896, masked_gen_loss: 0.3206966817378998 - (2126245:unified_unilip.py:1102)
2026-01-14 22:26:57 - INFO - total_loss: 1.7595710754394531, masked_loc_loss: 1.4039019346237183, masked_gen_loss: 0.3556690812110901 - (2126245:unified_unilip.py:1102)
2026-01-14 22:27:06 - INFO - total_loss: 1.5922887325286865, masked_loc_loss: 1.2149813175201416, masked_gen_loss: 0.3773074150085449 - (2126245:unified_unilip.py:1102)
2026-01-14 22:27:19 - INFO - total_loss: 1.5748579502105713, masked_loc_loss: 1.2203246355056763, masked_gen_loss: 0.35453328490257263 - (2126245:unified_unilip.py:1102)
2026-01-14 22:27:28 - INFO - total_loss: 1.5875542163848877, masked_loc_loss: 1.220808744430542, masked_gen_loss: 0.3667454123497009 - (2126245:unified_unilip.py:1102)
2026-01-14 22:27:37 - INFO - total_loss: 1.4945920705795288, masked_loc_loss: 1.0925562381744385, masked_gen_loss: 0.40203580260276794 - (2126245:unified_unilip.py:1102)
2026-01-14 22:28:02 - INFO - total_loss: 1.3657293319702148, masked_loc_loss: 0.9427161812782288, masked_gen_loss: 0.42301318049430847 - (2126245:unified_unilip.py:1102)
2026-01-14 22:28:20 - INFO - total_loss: 1.5314444303512573, masked_loc_loss: 1.222405195236206, masked_gen_loss: 0.30903923511505127 - (2126245:unified_unilip.py:1102)
2026-01-14 22:28:29 - INFO - total_loss: 1.3752820491790771, masked_loc_loss: 0.9982579350471497, masked_gen_loss: 0.37702417373657227 - (2126245:unified_unilip.py:1102)
2026-01-14 22:28:37 - INFO - total_loss: 1.2101023197174072, masked_loc_loss: 0.7718222141265869, masked_gen_loss: 0.4382800757884979 - (2126245:unified_unilip.py:1102)
2026-01-14 22:29:09 - INFO - total_loss: 1.3260713815689087, masked_loc_loss: 0.9624919891357422, masked_gen_loss: 0.3635793626308441 - (2126245:unified_unilip.py:1102)
2026-01-14 22:29:19 - INFO - total_loss: 1.1954996585845947, masked_loc_loss: 0.7760275602340698, masked_gen_loss: 0.4194720387458801 - (2126245:unified_unilip.py:1102)
2026-01-14 22:29:28 - INFO - total_loss: 1.240767240524292, masked_loc_loss: 0.8305536508560181, masked_gen_loss: 0.41021353006362915 - (2126245:unified_unilip.py:1102)
2026-01-14 22:29:37 - INFO - total_loss: 1.2576767206192017, masked_loc_loss: 0.9105089902877808, masked_gen_loss: 0.3471677303314209 - (2126245:unified_unilip.py:1102)
2026-01-14 22:29:59 - INFO - total_loss: 1.2802491188049316, masked_loc_loss: 0.9185450077056885, masked_gen_loss: 0.3617040514945984 - (2126245:unified_unilip.py:1102)
2026-01-14 22:30:20 - INFO - total_loss: 1.0411746501922607, masked_loc_loss: 0.6371704339981079, masked_gen_loss: 0.40400415658950806 - (2126245:unified_unilip.py:1102)
2026-01-14 22:30:29 - INFO - total_loss: 1.2077443599700928, masked_loc_loss: 0.9207757711410522, masked_gen_loss: 0.2869686484336853 - (2126245:unified_unilip.py:1102)
2026-01-14 22:30:38 - INFO - total_loss: 1.2403912544250488, masked_loc_loss: 0.8810827732086182, masked_gen_loss: 0.35930851101875305 - (2126245:unified_unilip.py:1102)
2026-01-14 22:30:56 - INFO - total_loss: 1.1204413175582886, masked_loc_loss: 0.76347416639328, masked_gen_loss: 0.35696712136268616 - (2126245:unified_unilip.py:1102)
2026-01-14 22:31:18 - INFO - total_loss: 1.0501196384429932, masked_loc_loss: 0.6216038465499878, masked_gen_loss: 0.42851585149765015 - (2126245:unified_unilip.py:1102)
2026-01-14 22:31:44 - INFO - total_loss: 1.1616051197052002, masked_loc_loss: 0.8526825904846191, masked_gen_loss: 0.30892258882522583 - (2126245:unified_unilip.py:1102)
2026-01-14 22:31:53 - INFO - total_loss: 1.095084309577942, masked_loc_loss: 0.7317628264427185, masked_gen_loss: 0.3633214831352234 - (2126245:unified_unilip.py:1102)
2026-01-14 22:32:02 - INFO - total_loss: 0.9856060743331909, masked_loc_loss: 0.5708111524581909, masked_gen_loss: 0.4147949516773224 - (2126245:unified_unilip.py:1102)
2026-01-14 22:32:17 - INFO - total_loss: 1.0602357387542725, masked_loc_loss: 0.6644798517227173, masked_gen_loss: 0.39575594663619995 - (2126245:unified_unilip.py:1102)
2026-01-14 22:32:26 - INFO - total_loss: 1.1274895668029785, masked_loc_loss: 0.7320432066917419, masked_gen_loss: 0.3954463601112366 - (2126245:unified_unilip.py:1102)
2026-01-14 22:32:34 - INFO - total_loss: 1.0926095247268677, masked_loc_loss: 0.7432916164398193, masked_gen_loss: 0.34931790828704834 - (2126245:unified_unilip.py:1102)
2026-01-14 22:32:52 - INFO - total_loss: 1.0513883829116821, masked_loc_loss: 0.7291395664215088, masked_gen_loss: 0.32224881649017334 - (2126245:unified_unilip.py:1102)
2026-01-14 22:33:17 - INFO - total_loss: 1.0236687660217285, masked_loc_loss: 0.6133098006248474, masked_gen_loss: 0.41035890579223633 - (2126245:unified_unilip.py:1102)
2026-01-14 22:33:26 - INFO - total_loss: 0.9251202940940857, masked_loc_loss: 0.48854610323905945, masked_gen_loss: 0.43657419085502625 - (2126245:unified_unilip.py:1102)
2026-01-14 22:33:35 - INFO - total_loss: 0.9143548011779785, masked_loc_loss: 0.5386089086532593, masked_gen_loss: 0.37574589252471924 - (2126245:unified_unilip.py:1102)
2026-01-14 22:34:01 - INFO - total_loss: 0.909347414970398, masked_loc_loss: 0.5125989317893982, masked_gen_loss: 0.39674851298332214 - (2126245:unified_unilip.py:1102)
2026-01-14 22:34:16 - INFO - total_loss: 0.939968466758728, masked_loc_loss: 0.6002429723739624, masked_gen_loss: 0.33972546458244324 - (2126245:unified_unilip.py:1102)
2026-01-14 22:34:25 - INFO - total_loss: 0.9628098011016846, masked_loc_loss: 0.5610560774803162, masked_gen_loss: 0.4017537236213684 - (2126245:unified_unilip.py:1102)
2026-01-14 22:34:34 - INFO - total_loss: 1.0138870477676392, masked_loc_loss: 0.692814826965332, masked_gen_loss: 0.32107219099998474 - (2126245:unified_unilip.py:1102)
2026-01-14 22:34:49 - INFO - total_loss: 0.9463075399398804, masked_loc_loss: 0.5492456555366516, masked_gen_loss: 0.39706188440322876 - (2126245:unified_unilip.py:1102)
2026-01-14 22:35:16 - INFO - total_loss: 1.0331592559814453, masked_loc_loss: 0.6363240480422974, masked_gen_loss: 0.39683520793914795 - (2126245:unified_unilip.py:1102)
2026-01-14 22:35:25 - INFO - total_loss: 0.9804019927978516, masked_loc_loss: 0.5649473667144775, masked_gen_loss: 0.415454626083374 - (2126245:unified_unilip.py:1102)
2026-01-14 22:35:34 - INFO - total_loss: 0.9395349025726318, masked_loc_loss: 0.4479421079158783, masked_gen_loss: 0.4915928244590759 - (2126245:unified_unilip.py:1102)
2026-01-14 22:35:47 - INFO - total_loss: 0.9137206077575684, masked_loc_loss: 0.48597657680511475, masked_gen_loss: 0.4277440011501312 - (2126245:unified_unilip.py:1102)
2026-01-14 22:36:14 - INFO - total_loss: 1.0082098245620728, masked_loc_loss: 0.6209250688552856, masked_gen_loss: 0.3872847557067871 - (2126245:unified_unilip.py:1102)
2026-01-14 22:36:43 - INFO - total_loss: 0.8956097364425659, masked_loc_loss: 0.46458184719085693, masked_gen_loss: 0.431027889251709 - (2126245:unified_unilip.py:1102)
2026-01-14 22:36:52 - INFO - total_loss: 1.004652976989746, masked_loc_loss: 0.6523128747940063, masked_gen_loss: 0.35234004259109497 - (2126245:unified_unilip.py:1102)
2026-01-14 22:37:01 - INFO - total_loss: 1.009577989578247, masked_loc_loss: 0.6769405603408813, masked_gen_loss: 0.33263736963272095 - (2126245:unified_unilip.py:1102)
2026-01-14 22:37:14 - INFO - total_loss: 0.9904452562332153, masked_loc_loss: 0.6800824999809265, masked_gen_loss: 0.3103627562522888 - (2126245:unified_unilip.py:1102)
2026-01-14 22:37:23 - INFO - total_loss: 1.0030882358551025, masked_loc_loss: 0.6117822527885437, masked_gen_loss: 0.39130592346191406 - (2126245:unified_unilip.py:1102)
2026-01-14 22:37:32 - INFO - total_loss: 0.9150649309158325, masked_loc_loss: 0.5916767120361328, masked_gen_loss: 0.3233882486820221 - (2126245:unified_unilip.py:1102)
2026-01-14 22:37:46 - INFO - total_loss: 0.9392365217208862, masked_loc_loss: 0.6072918772697449, masked_gen_loss: 0.33194467425346375 - (2126245:unified_unilip.py:1102)
2026-01-14 22:38:14 - INFO - total_loss: 0.9137536287307739, masked_loc_loss: 0.5687757730484009, masked_gen_loss: 0.34497782588005066 - (2126245:unified_unilip.py:1102)
2026-01-14 22:38:22 - INFO - total_loss: 0.899072527885437, masked_loc_loss: 0.4805350601673126, masked_gen_loss: 0.4185374677181244 - (2126245:unified_unilip.py:1102)
2026-01-14 22:38:31 - INFO - total_loss: 0.9044690132141113, masked_loc_loss: 0.5371507406234741, masked_gen_loss: 0.3673182725906372 - (2126245:unified_unilip.py:1102)
2026-01-14 22:39:00 - INFO - total_loss: 0.861794114112854, masked_loc_loss: 0.4734342694282532, masked_gen_loss: 0.38835984468460083 - (2126245:unified_unilip.py:1102)
2026-01-14 22:39:11 - INFO - total_loss: 0.9659745693206787, masked_loc_loss: 0.5907909870147705, masked_gen_loss: 0.3751835823059082 - (2126245:unified_unilip.py:1102)
2026-01-14 22:39:20 - INFO - total_loss: 0.9381593465805054, masked_loc_loss: 0.5263158082962036, masked_gen_loss: 0.41184350848197937 - (2126245:unified_unilip.py:1102)
2026-01-14 22:39:29 - INFO - total_loss: 0.9479053020477295, masked_loc_loss: 0.5943349599838257, masked_gen_loss: 0.3535703420639038 - (2126245:unified_unilip.py:1102)
2026-01-14 22:39:44 - INFO - total_loss: 0.8631058931350708, masked_loc_loss: 0.4233834445476532, masked_gen_loss: 0.43972247838974 - (2126245:unified_unilip.py:1102)
2026-01-14 22:40:12 - INFO - total_loss: 0.9891419410705566, masked_loc_loss: 0.6592282056808472, masked_gen_loss: 0.3299137055873871 - (2126245:unified_unilip.py:1102)
2026-01-14 22:40:21 - INFO - total_loss: 0.9554529190063477, masked_loc_loss: 0.5692607164382935, masked_gen_loss: 0.3861922025680542 - (2126245:unified_unilip.py:1102)
2026-01-14 22:40:29 - INFO - total_loss: 0.9591997265815735, masked_loc_loss: 0.6302458643913269, masked_gen_loss: 0.3289538621902466 - (2126245:unified_unilip.py:1102)
2026-01-14 22:40:43 - INFO - total_loss: 0.9246864914894104, masked_loc_loss: 0.48854196071624756, masked_gen_loss: 0.43614453077316284 - (2126245:unified_unilip.py:1102)
2026-01-14 22:41:12 - INFO - total_loss: 0.9782707095146179, masked_loc_loss: 0.6467483043670654, masked_gen_loss: 0.3315224051475525 - (2126245:unified_unilip.py:1102)
2026-01-14 22:41:39 - INFO - total_loss: 0.8855588436126709, masked_loc_loss: 0.5290336608886719, masked_gen_loss: 0.3565252125263214 - (2126245:unified_unilip.py:1102)
2026-01-14 22:41:48 - INFO - total_loss: 0.8673797249794006, masked_loc_loss: 0.49014681577682495, masked_gen_loss: 0.3772329092025757 - (2126245:unified_unilip.py:1102)
2026-01-14 22:41:57 - INFO - total_loss: 0.9972987174987793, masked_loc_loss: 0.6462317705154419, masked_gen_loss: 0.3510669469833374 - (2126245:unified_unilip.py:1102)
2026-01-14 22:42:11 - INFO - total_loss: 0.8423714637756348, masked_loc_loss: 0.5097012519836426, masked_gen_loss: 0.3326701819896698 - (2126245:unified_unilip.py:1102)
2026-01-14 22:42:19 - INFO - total_loss: 0.9054359793663025, masked_loc_loss: 0.5529793500900269, masked_gen_loss: 0.35245662927627563 - (2126245:unified_unilip.py:1102)
2026-01-14 22:42:28 - INFO - total_loss: 0.881587028503418, masked_loc_loss: 0.5156654715538025, masked_gen_loss: 0.36592158675193787 - (2126245:unified_unilip.py:1102)
2026-01-14 22:42:40 - INFO - total_loss: 0.8918712139129639, masked_loc_loss: 0.5604057908058167, masked_gen_loss: 0.3314654231071472 - (2126245:unified_unilip.py:1102)
2026-01-14 22:43:10 - INFO - total_loss: 0.8575872182846069, masked_loc_loss: 0.49267005920410156, masked_gen_loss: 0.36491715908050537 - (2126245:unified_unilip.py:1102)
2026-01-14 22:43:19 - INFO - total_loss: 0.9847607612609863, masked_loc_loss: 0.7179058790206909, masked_gen_loss: 0.266854852437973 - (2126245:unified_unilip.py:1102)
2026-01-14 22:43:27 - INFO - total_loss: 0.8753163814544678, masked_loc_loss: 0.5109829902648926, masked_gen_loss: 0.3643333911895752 - (2126245:unified_unilip.py:1102)
2026-01-14 22:43:54 - INFO - total_loss: 0.850783109664917, masked_loc_loss: 0.46306565403938293, masked_gen_loss: 0.38771748542785645 - (2126245:unified_unilip.py:1102)
2026-01-14 22:44:08 - INFO - total_loss: 0.8592211008071899, masked_loc_loss: 0.4901428818702698, masked_gen_loss: 0.3690781891345978 - (2126245:unified_unilip.py:1102)
2026-01-14 22:44:17 - INFO - total_loss: 0.8559455871582031, masked_loc_loss: 0.4700763523578644, masked_gen_loss: 0.38586926460266113 - (2126245:unified_unilip.py:1102)
2026-01-14 22:44:26 - INFO - total_loss: 0.8637722134590149, masked_loc_loss: 0.4780665636062622, masked_gen_loss: 0.3857056498527527 - (2126245:unified_unilip.py:1102)
2026-01-14 22:44:36 - INFO - total_loss: 0.8637897968292236, masked_loc_loss: 0.49895164370536804, masked_gen_loss: 0.364838182926178 - (2126245:unified_unilip.py:1102)
2026-01-14 22:45:09 - INFO - total_loss: 0.8266685605049133, masked_loc_loss: 0.38751453161239624, masked_gen_loss: 0.4391540288925171 - (2126245:unified_unilip.py:1102)
2026-01-14 22:45:18 - INFO - total_loss: 0.8531994819641113, masked_loc_loss: 0.4538835883140564, masked_gen_loss: 0.39931589365005493 - (2126245:unified_unilip.py:1102)
2026-01-14 22:45:27 - INFO - total_loss: 0.8788166642189026, masked_loc_loss: 0.5321001410484314, masked_gen_loss: 0.3467165231704712 - (2126245:unified_unilip.py:1102)
2026-01-14 22:45:36 - INFO - total_loss: 0.8345688581466675, masked_loc_loss: 0.4460349977016449, masked_gen_loss: 0.3885338604450226 - (2126245:unified_unilip.py:1102)
2026-01-14 22:46:09 - INFO - total_loss: 0.8779729604721069, masked_loc_loss: 0.5391944646835327, masked_gen_loss: 0.3387784957885742 - (2126245:unified_unilip.py:1102)
2026-01-14 22:46:35 - INFO - total_loss: 0.9615751504898071, masked_loc_loss: 0.7135838866233826, masked_gen_loss: 0.24799126386642456 - (2126245:unified_unilip.py:1102)
2026-01-14 22:46:44 - INFO - total_loss: 0.9273703694343567, masked_loc_loss: 0.5550611019134521, masked_gen_loss: 0.37230926752090454 - (2126245:unified_unilip.py:1102)
2026-01-14 22:46:53 - INFO - total_loss: 0.8375241756439209, masked_loc_loss: 0.47990882396698, masked_gen_loss: 0.3576153516769409 - (2126245:unified_unilip.py:1102)
2026-01-14 22:47:08 - INFO - total_loss: 0.8624237775802612, masked_loc_loss: 0.47943776845932007, masked_gen_loss: 0.38298603892326355 - (2126245:unified_unilip.py:1102)
2026-01-14 22:47:17 - INFO - total_loss: 0.9440850019454956, masked_loc_loss: 0.6092096567153931, masked_gen_loss: 0.33487531542778015 - (2126245:unified_unilip.py:1102)
2026-01-14 22:47:26 - INFO - total_loss: 0.8379812240600586, masked_loc_loss: 0.498612642288208, masked_gen_loss: 0.3393685519695282 - (2126245:unified_unilip.py:1102)
2026-01-14 22:47:35 - INFO - total_loss: 0.8340504169464111, masked_loc_loss: 0.47138041257858276, masked_gen_loss: 0.362669974565506 - (2126245:unified_unilip.py:1102)
2026-01-14 22:48:09 - INFO - total_loss: 0.8538261651992798, masked_loc_loss: 0.4727809429168701, masked_gen_loss: 0.3810451924800873 - (2126245:unified_unilip.py:1102)
2026-01-14 22:48:17 - INFO - total_loss: 0.8871179819107056, masked_loc_loss: 0.46914732456207275, masked_gen_loss: 0.4179706573486328 - (2126245:unified_unilip.py:1102)
2026-01-14 22:48:26 - INFO - total_loss: 0.8463600873947144, masked_loc_loss: 0.48037776350975037, masked_gen_loss: 0.3659823536872864 - (2126245:unified_unilip.py:1102)
2026-01-14 22:48:52 - INFO - total_loss: 0.8716337084770203, masked_loc_loss: 0.5191586017608643, masked_gen_loss: 0.352475106716156 - (2126245:unified_unilip.py:1102)
2026-01-14 22:49:07 - INFO - total_loss: 0.8654493093490601, masked_loc_loss: 0.48863711953163147, masked_gen_loss: 0.376812219619751 - (2126245:unified_unilip.py:1102)
2026-01-14 22:49:16 - INFO - total_loss: 0.8139348030090332, masked_loc_loss: 0.5586809515953064, masked_gen_loss: 0.2552538812160492 - (2126245:unified_unilip.py:1102)
2026-01-14 22:49:24 - INFO - total_loss: 0.8592491149902344, masked_loc_loss: 0.4749750792980194, masked_gen_loss: 0.38427406549453735 - (2126245:unified_unilip.py:1102)
2026-01-14 22:49:33 - INFO - total_loss: 0.8647944927215576, masked_loc_loss: 0.5356779098510742, masked_gen_loss: 0.3291165828704834 - (2126245:unified_unilip.py:1102)
2026-01-14 22:50:07 - INFO - total_loss: 0.8479709625244141, masked_loc_loss: 0.40822306275367737, masked_gen_loss: 0.4397479295730591 - (2126245:unified_unilip.py:1102)
2026-01-14 22:50:16 - INFO - total_loss: 0.8353286981582642, masked_loc_loss: 0.5142898559570312, masked_gen_loss: 0.3210388720035553 - (2126245:unified_unilip.py:1102)
2026-01-14 22:50:25 - INFO - total_loss: 0.8736352920532227, masked_loc_loss: 0.4890720546245575, masked_gen_loss: 0.3845632076263428 - (2126245:unified_unilip.py:1102)
2026-01-14 22:50:33 - INFO - total_loss: 0.8688279390335083, masked_loc_loss: 0.4920542240142822, masked_gen_loss: 0.3767737150192261 - (2126245:unified_unilip.py:1102)
2026-01-14 22:51:04 - INFO - total_loss: 0.8150071501731873, masked_loc_loss: 0.43909209966659546, masked_gen_loss: 0.3759150505065918 - (2126245:unified_unilip.py:1102)
2026-01-14 22:51:29 - INFO - total_loss: 0.8660197257995605, masked_loc_loss: 0.5698213577270508, masked_gen_loss: 0.2961983382701874 - (2126245:unified_unilip.py:1102)
2026-01-14 22:51:38 - INFO - total_loss: 0.8710278272628784, masked_loc_loss: 0.4962478578090668, masked_gen_loss: 0.37477993965148926 - (2126245:unified_unilip.py:1102)
2026-01-14 22:51:46 - INFO - total_loss: 0.785468578338623, masked_loc_loss: 0.4623967707157135, masked_gen_loss: 0.32307183742523193 - (2126245:unified_unilip.py:1102)
2026-01-14 22:52:02 - INFO - total_loss: 0.838021993637085, masked_loc_loss: 0.487138569355011, masked_gen_loss: 0.3508833944797516 - (2126245:unified_unilip.py:1102)
2026-01-14 22:52:11 - INFO - total_loss: 0.7757226824760437, masked_loc_loss: 0.3799484968185425, masked_gen_loss: 0.3957741856575012 - (2126245:unified_unilip.py:1102)
2026-01-14 22:52:20 - INFO - total_loss: 0.920167863368988, masked_loc_loss: 0.5875111818313599, masked_gen_loss: 0.3326566815376282 - (2126245:unified_unilip.py:1102)
2026-01-14 22:52:29 - INFO - total_loss: 0.9019849300384521, masked_loc_loss: 0.5035561323165894, masked_gen_loss: 0.3984287977218628 - (2126245:unified_unilip.py:1102)
2026-01-14 22:53:05 - INFO - total_loss: 0.8174195289611816, masked_loc_loss: 0.434282511472702, masked_gen_loss: 0.3831369876861572 - (2126245:unified_unilip.py:1102)
2026-01-14 22:53:13 - INFO - total_loss: 0.8910898566246033, masked_loc_loss: 0.5502457618713379, masked_gen_loss: 0.3408440947532654 - (2126245:unified_unilip.py:1102)
2026-01-14 22:53:22 - INFO - total_loss: 0.8887083530426025, masked_loc_loss: 0.5052565932273865, masked_gen_loss: 0.38345178961753845 - (2126245:unified_unilip.py:1102)
2026-01-14 22:53:48 - INFO - total_loss: 0.9084734320640564, masked_loc_loss: 0.5996226072311401, masked_gen_loss: 0.30885082483291626 - (2126245:unified_unilip.py:1102)
2026-01-14 22:54:03 - INFO - total_loss: 0.8410283327102661, masked_loc_loss: 0.5306358337402344, masked_gen_loss: 0.31039249897003174 - (2126245:unified_unilip.py:1102)
2026-01-14 22:54:12 - INFO - total_loss: 0.7400023341178894, masked_loc_loss: 0.35414278507232666, masked_gen_loss: 0.38585954904556274 - (2126245:unified_unilip.py:1102)
2026-01-14 22:54:21 - INFO - total_loss: 0.8628343939781189, masked_loc_loss: 0.5079577565193176, masked_gen_loss: 0.35487663745880127 - (2126245:unified_unilip.py:1102)
2026-01-14 22:54:29 - INFO - total_loss: 0.8929797410964966, masked_loc_loss: 0.5453141927719116, masked_gen_loss: 0.3476655185222626 - (2126245:unified_unilip.py:1102)
2026-01-14 22:55:03 - INFO - total_loss: 0.84501713514328, masked_loc_loss: 0.5016455054283142, masked_gen_loss: 0.3433716297149658 - (2126245:unified_unilip.py:1102)
2026-01-14 22:55:12 - INFO - total_loss: 0.909778356552124, masked_loc_loss: 0.5665172338485718, masked_gen_loss: 0.34326112270355225 - (2126245:unified_unilip.py:1102)
2026-01-14 22:55:21 - INFO - total_loss: 0.8043301105499268, masked_loc_loss: 0.40124624967575073, masked_gen_loss: 0.403083860874176 - (2126245:unified_unilip.py:1102)
2026-01-14 22:55:30 - INFO - total_loss: 0.84806227684021, masked_loc_loss: 0.5229923725128174, masked_gen_loss: 0.32506993412971497 - (2126245:unified_unilip.py:1102)
2026-01-14 22:56:00 - INFO - total_loss: 0.7593238949775696, masked_loc_loss: 0.3924253582954407, masked_gen_loss: 0.3668985366821289 - (2126245:unified_unilip.py:1102)
2026-01-14 22:56:28 - INFO - total_loss: 0.8573673963546753, masked_loc_loss: 0.4661352336406708, masked_gen_loss: 0.39123213291168213 - (2126245:unified_unilip.py:1102)
2026-01-14 22:56:37 - INFO - total_loss: 0.8218437433242798, masked_loc_loss: 0.46637028455734253, masked_gen_loss: 0.35547345876693726 - (2126245:unified_unilip.py:1102)
2026-01-14 22:56:46 - INFO - total_loss: 0.8697569966316223, masked_loc_loss: 0.5263912677764893, masked_gen_loss: 0.34336572885513306 - (2126245:unified_unilip.py:1102)
2026-01-14 22:56:59 - INFO - total_loss: 0.9393708109855652, masked_loc_loss: 0.630871057510376, masked_gen_loss: 0.3084997534751892 - (2126245:unified_unilip.py:1102)
2026-01-14 22:57:07 - INFO - total_loss: 0.8314762115478516, masked_loc_loss: 0.49457699060440063, masked_gen_loss: 0.3368992507457733 - (2126245:unified_unilip.py:1102)
2026-01-14 22:57:16 - INFO - total_loss: 0.812212347984314, masked_loc_loss: 0.44030576944351196, masked_gen_loss: 0.3719065487384796 - (2126245:unified_unilip.py:1102)
2026-01-14 22:57:25 - INFO - total_loss: 0.7660151720046997, masked_loc_loss: 0.4032862186431885, masked_gen_loss: 0.36272895336151123 - (2126245:unified_unilip.py:1102)
2026-01-14 22:58:01 - INFO - total_loss: 0.8346314430236816, masked_loc_loss: 0.4611821174621582, masked_gen_loss: 0.3734493553638458 - (2126245:unified_unilip.py:1102)
2026-01-14 22:58:10 - INFO - total_loss: 0.8033491373062134, masked_loc_loss: 0.5340504050254822, masked_gen_loss: 0.2692987620830536 - (2126245:unified_unilip.py:1102)
2026-01-14 22:58:19 - INFO - total_loss: 0.7992975115776062, masked_loc_loss: 0.4217277765274048, masked_gen_loss: 0.3775697350502014 - (2126245:unified_unilip.py:1102)
2026-01-14 22:58:44 - INFO - total_loss: 0.8852779269218445, masked_loc_loss: 0.525452196598053, masked_gen_loss: 0.3598257303237915 - (2126245:unified_unilip.py:1102)
2026-01-14 22:58:59 - INFO - total_loss: 0.9408632516860962, masked_loc_loss: 0.5642918348312378, masked_gen_loss: 0.3765714466571808 - (2126245:unified_unilip.py:1102)
2026-01-14 22:59:08 - INFO - total_loss: 0.8173321485519409, masked_loc_loss: 0.4386870265007019, masked_gen_loss: 0.378645122051239 - (2126245:unified_unilip.py:1102)
2026-01-14 22:59:17 - INFO - total_loss: 0.7953572869300842, masked_loc_loss: 0.4147070050239563, masked_gen_loss: 0.38065028190612793 - (2126245:unified_unilip.py:1102)
2026-01-14 22:59:25 - INFO - total_loss: 0.82989102602005, masked_loc_loss: 0.4805378317832947, masked_gen_loss: 0.34935319423675537 - (2126245:unified_unilip.py:1102)
2026-01-14 23:00:00 - INFO - total_loss: 0.8221399784088135, masked_loc_loss: 0.4012223482131958, masked_gen_loss: 0.4209176301956177 - (2126245:unified_unilip.py:1102)
2026-01-14 23:00:09 - INFO - total_loss: 0.840503454208374, masked_loc_loss: 0.47629064321517944, masked_gen_loss: 0.3642128109931946 - (2126245:unified_unilip.py:1102)
2026-01-14 23:00:17 - INFO - total_loss: 0.8785045146942139, masked_loc_loss: 0.5150400400161743, masked_gen_loss: 0.36346450448036194 - (2126245:unified_unilip.py:1102)
2026-01-14 23:00:26 - INFO - total_loss: 0.814516007900238, masked_loc_loss: 0.40408235788345337, masked_gen_loss: 0.41043365001678467 - (2126245:unified_unilip.py:1102)
2026-01-14 23:00:58 - INFO - total_loss: 0.875548243522644, masked_loc_loss: 0.4996359050273895, masked_gen_loss: 0.3759123682975769 - (2126245:unified_unilip.py:1102)
2026-01-14 23:01:24 - INFO - total_loss: 0.8677821159362793, masked_loc_loss: 0.5394144654273987, masked_gen_loss: 0.3283676207065582 - (2126245:unified_unilip.py:1102)
2026-01-14 23:01:33 - INFO - total_loss: 0.778481125831604, masked_loc_loss: 0.44047510623931885, masked_gen_loss: 0.33800601959228516 - (2126245:unified_unilip.py:1102)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
2026-01-14 23:01:41 - WARNING - socket.send() raised exception. - (2126245:selector_events.py:1054)
