
import os
import cv2
import re
import argparse
import numpy as np
from tqdm import tqdm



def parse_filename(filename):
    """
    è§£ææ–‡ä»¶åï¼Œè¿”å› (file_num, frame_id)
    æ”¯æŒæ ¼å¼: "file_num12_frame_1005.jpg" æˆ–åŒ…å«æ­¤å‰ç¼€çš„è·¯å¾„
    """
    match = re.search(r'file_num(\d+)_frame_(\d+)', filename)
    if match:
        return int(match.group(1)), int(match.group(2))
    return None, None

def frames_to_video(args):
    """
    å°†æ–‡ä»¶å¤¹ä¸­çš„åºåˆ—å¸§åˆæˆä¸ºè§†é¢‘ã€‚
    é€»è¾‘ï¼š
    1. æ‰«ææ‰€æœ‰å›¾ç‰‡å¹¶æŒ‰ (file_num, frame_id) æ’åºã€‚
    2. è‡ªåŠ¨æ£€æµ‹ä¸è¿ç»­ç‚¹ï¼ˆæ–‡ä»¶IDå˜åŒ–æˆ–å¸§å·è·³å˜ï¼‰ï¼Œå°†å…¶åˆ‡åˆ†ä¸ºä¸åŒçš„ "Track"ã€‚
    3. æ¯ä¸ª "Track" å†…éƒ¨ï¼Œå†æ ¹æ® max_duration (10s) åˆ‡åˆ†ä¸ºå¤šä¸ª "Clip"ã€‚
    """

    img_dir = args.img_dir
    output_dir = args.output_dir
    fps = args.fps
    max_frames_per_clip = args.max_duration * fps

    os.makedirs(output_dir, exist_ok=True)

    # 1. æ‰«æå¹¶æ’åºå›¾ç‰‡
    print(f"ğŸ” Scanning images in {img_dir}...")
    valid_files = []
    for f in os.listdir(img_dir):
        if f.lower().endswith(('.jpg', '.png', '.jpeg')):
            rid, fid = parse_filename(f)
            if rid is not None:
                valid_files.append({
                    'path': os.path.join(img_dir, f),
                    'file_num': rid,
                    'frame_id': fid,
                    'name': f
                })

    # æ ¸å¿ƒæ’åºï¼šå…ˆæŒ‰æ–‡ä»¶å·ï¼Œå†æŒ‰å¸§å·
    valid_files.sort(key=lambda x: (x['file_num'], x['frame_id']))

    if not valid_files:
        print("âŒ No valid images found matching 'file_num*_frame_*' pattern.")
        return

    print(f"âœ… Found {len(valid_files)} frames. Grouping into tracks...")

    # 2. åˆ†ç»„é€»è¾‘ (Group into Tracks)
    # Track æ˜¯æŒ‡ä¸€æ®µç‰©ç†ä¸Šè¿ç»­çš„è½¨è¿¹ï¼ˆä¸­é—´æ²¡æœ‰æ–­å¸§ï¼‰
    tracks = []
    current_track = []

    # å®šä¹‰æ–­å¸§é˜ˆå€¼ (ä¸ä½ ç”Ÿæˆæ•°æ®æ—¶çš„é€»è¾‘ä¿æŒä¸€è‡´)
    FRAME_DIFF_THRESHOLD = 2

    for i, item in enumerate(valid_files):
        if not current_track:
            current_track.append(item)
            continue

        last_item = current_track[-1]

        # åˆ¤æ–­è¿ç»­æ€§æ¡ä»¶ï¼š
        # 1. åŒä¸€ä¸ªåŸå§‹å½•åˆ¶æ–‡ä»¶ (file_num ç›¸åŒ)
        # 2. å¸§å·è¿ç»­ (å·®å€¼ <= é˜ˆå€¼)
        is_same_file = (item['file_num'] == last_item['file_num'])
        is_continuous = (item['frame_id'] - last_item['frame_id'] <= FRAME_DIFF_THRESHOLD)

        if is_same_file and is_continuous:
            current_track.append(item)
        else:
            # ç»“æŸå½“å‰ Trackï¼Œå¼€å¯æ–° Track
            if current_track:
                tracks.append(current_track)
            current_track = [item]

    if current_track:
        tracks.append(current_track)

    print(f"ğŸ“‹ Identified {len(tracks)} continuous tracks.")

    # 3. è§†é¢‘åˆæˆé€»è¾‘ (Synthesis)
    video_count = 0

    for track_idx, track in enumerate(tracks):
        # è¿‡æ»¤è¿‡çŸ­çš„è½¨è¿¹
        if len(track) < args.min_frames:
            continue

        # è·å–å›¾ç‰‡å°ºå¯¸
        first_img = cv2.imread(track[0]['path'])
        if first_img is None:
            continue
        height, width, layers = first_img.shape
        size = (width, height)

        # æŒ‰ max_frames_per_clip åˆ‡åˆ†è¿™ä¸ª Track
        # range(0, len(track), 100) -> [0, 100, 200...]
        chunks = [track[i:i + max_frames_per_clip] for i in range(0, len(track), max_frames_per_clip)]

        for chunk_idx, chunk in enumerate(chunks):
            # åªæœ‰å½“åˆ‡ç‰‡é•¿åº¦è¶³å¤Ÿæ—¶æ‰ä¿å­˜ (å¯é€‰)
            if len(chunk) < args.min_frames // 2:
                continue

            # æ„é€ è¾“å‡ºæ–‡ä»¶å
            # æ ¼å¼: track_{åŸå§‹æ–‡ä»¶å·}_{èµ·å§‹å¸§}_{ç»“æŸå¸§}.mp4
            start_info = chunk[0]
            end_info = chunk[-1]
            out_name = f"track_{start_info['file_num']}_f{start_info['frame_id']}_to_f{end_info['frame_id']}.mp4"
            out_path = os.path.join(output_dir, out_name)

            print(f"  ğŸ¬ Writing Video {video_count+1}: {out_name} ({len(chunk)} frames)...")

            # åˆå§‹åŒ– VideoWriter
            # mp4v å…¼å®¹æ€§è¾ƒå¥½ï¼Œæˆ–è€…ç”¨ 'XVID' ç”Ÿæˆ .avi
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(out_path, fourcc, fps, size)

            for frame_info in chunk:
                img = cv2.imread(frame_info['path'])
                if img is not None:
                    # å¯é€‰ï¼šåœ¨è§†é¢‘å·¦ä¸Šè§’å†™å…¥å¸§ä¿¡æ¯ï¼Œæ–¹ä¾¿ Debug
                    if args.draw_text:
                        text = f"File {frame_info['file_num']} | Frame {frame_info['frame_id']}"
                        cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                                    0.8, (0, 255, 0), 2, cv2.LINE_AA)

                    out.write(img)

            out.release()
            video_count += 1

    print(f"\nğŸ‰ All done! Generated {video_count} videos in '{output_dir}'.")



def build_file_index(directory):
    """
    æ‰«æç›®å½•ï¼Œæ„å»º (file_num, frame_id) -> file_path çš„ç´¢å¼•å­—å…¸
    """
    index = {}
    if not os.path.exists(directory):
        return index

    print(f"ğŸ” Scanning directory: {directory}...")
    for f in os.listdir(directory):
        if f.lower().endswith(('.jpg', '.png', '.jpeg')):
            rid, fid = parse_filename(f)
            if rid is not None:
                index[(rid, fid)] = os.path.join(directory, f)
    return index

def compare_frames_to_video(args):
    img_dir = args.img_dir  # ç”Ÿæˆçš„å›¾ç‰‡ç›®å½•
    gt_dir = args.gt_dir    # Ground Truth å›¾ç‰‡ç›®å½•
    output_dir = args.output_dir
    fps = args.fps
    max_frames_per_clip = args.max_duration * fps

    os.makedirs(output_dir, exist_ok=True)

    # 1. å»ºç«‹ GT ç´¢å¼• (ç”¨äºå¿«é€ŸæŸ¥æ‰¾åŒ¹é…å¸§)
    gt_index = build_file_index(gt_dir)
    if not gt_index:
        print(f"âš ï¸ Warning: No valid images found in GT dir: {gt_dir}. Right side will be black.")

    # 2. æ‰«æç”Ÿæˆå›¾ç‰‡å¹¶åŒ¹é… GT
    print(f"ğŸ” Scanning generated images in {img_dir}...")
    valid_pairs = []

    for f in os.listdir(img_dir):
        if f.lower().endswith(('.jpg', '.png', '.jpeg')):
            rid, fid = parse_filename(f)
            if rid is not None:
                # å°è¯•æ‰¾åˆ°å¯¹åº”çš„ GT è·¯å¾„
                gt_path = gt_index.get((rid, fid), None)

                valid_pairs.append({
                    'gen_path': os.path.join(img_dir, f),
                    'gt_path': gt_path, # å¦‚æœæ²¡æ‰¾åˆ°åˆ™æ˜¯ None
                    'file_num': rid,
                    'frame_id': fid
                })

    # æ’åºï¼šå…ˆæŒ‰æ–‡ä»¶å·ï¼Œå†æŒ‰å¸§å·
    valid_pairs.sort(key=lambda x: (x['file_num'], x['frame_id']))

    if not valid_pairs:
        print("âŒ No valid generated images found.")
        return

    print(f"âœ… Found {len(valid_pairs)} frames. Grouping into tracks...")

    # 3. åˆ†ç»„é€»è¾‘ (Group into Tracks)
    tracks = []
    current_track = []
    FRAME_DIFF_THRESHOLD = 2

    for item in valid_pairs:
        if not current_track:
            current_track.append(item)
            continue

        last_item = current_track[-1]

        is_same_file = (item['file_num'] == last_item['file_num'])
        is_continuous = (item['frame_id'] - last_item['frame_id'] <= FRAME_DIFF_THRESHOLD)

        if is_same_file and is_continuous:
            current_track.append(item)
        else:
            if current_track:
                tracks.append(current_track)
            current_track = [item]

    if current_track:
        tracks.append(current_track)

    print(f"ğŸ“‹ Identified {len(tracks)} continuous tracks.")

    # 4. è§†é¢‘åˆæˆé€»è¾‘
    video_count = 0

    for track in tracks:
        if len(track) < args.min_frames:
            continue

        # è·å–ç¬¬ä¸€å¸§å°ºå¯¸ä»¥åˆå§‹åŒ– VideoWriter
        first_img = cv2.imread(track[0]['gen_path'])
        if first_img is None: continue

        h, w, _ = first_img.shape
        # è¾“å‡ºè§†é¢‘å®½åº¦ç¿»å€ (å·¦ Gen + å³ GT)
        # ä¸­é—´åŠ ä¸ª 10åƒç´ çš„é»‘è‰²åˆ†å‰²çº¿ç¾è§‚ä¸€ç‚¹
        padding = 10
        size = (w * 2 + padding, h)

        # åˆ‡åˆ†é•¿ç‰‡æ®µ
        chunks = [track[i:i + max_frames_per_clip] for i in range(0, len(track), max_frames_per_clip)]

        for chunk in chunks:
            if len(chunk) < args.min_frames // 2: continue

            start_info = chunk[0]
            end_info = chunk[-1]
            out_name = f"compare_file{start_info['file_num']}_f{start_info['frame_id']}_to_f{end_info['frame_id']}.mp4"
            out_path = os.path.join(output_dir, out_name)

            print(f"  ğŸ¬ Writing Video: {out_name} ({len(chunk)} frames)...")

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(out_path, fourcc, fps, size)

            for frame_info in chunk:
                # è¯»å–ç”Ÿæˆå›¾
                img_gen = cv2.imread(frame_info['gen_path'])
                if img_gen is None: continue

                # è¯»å– GT å›¾
                if frame_info['gt_path'] and os.path.exists(frame_info['gt_path']):
                    img_gt = cv2.imread(frame_info['gt_path'])
                    # å®¹é”™ï¼šå¦‚æœ GT å°ºå¯¸å’Œ Gen ä¸ä¸€è‡´ï¼Œå¼ºåˆ¶ resize GT
                    if img_gt.shape != img_gen.shape:
                        img_gt = cv2.resize(img_gt, (w, h))
                else:
                    # å¦‚æœæ‰¾ä¸åˆ° GTï¼Œç”¨çº¯é»‘å›¾å¡«å……ï¼Œå¹¶å†™ä¸Š "Missing GT"
                    img_gt = np.zeros_like(img_gen)
                    cv2.putText(img_gt, "Missing GT", (50, h//2), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)

                # ç»˜åˆ¶æ ‡ç­¾ (Prediction vs Ground Truth)
                if args.draw_text:
                    # å·¦ä¸Šè§’ä¿¡æ¯
                    info_text = f"File {frame_info['file_num']} | Frame {frame_info['frame_id']}"

                    # å·¦å›¾ (Pred) æ ‡ç­¾
                    cv2.putText(img_gen, "Prediction (Ours)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(img_gen, info_text, (10, h - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)

                    # å³å›¾ (GT) æ ‡ç­¾
                    cv2.putText(img_gt, "Ground Truth", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)

                # å·¦å³æ‹¼æ¥
                # åˆ›å»ºåˆ†å‰²çº¿
                separator = np.zeros((h, padding, 3), dtype=np.uint8)
                combined = cv2.hconcat([img_gen, separator, img_gt])

                out.write(combined)

            out.release()
            video_count += 1

    print(f"\nğŸ‰ All done! Generated {video_count} comparison videos in '{output_dir}'.")




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--img_dir", type=str, required=True, help="ç”Ÿæˆçš„å›¾ç‰‡æ–‡ä»¶å¤¹ (Prediction)")
    parser.add_argument("--gt_dir", type=str, help="çœŸå®å›¾ç‰‡æ–‡ä»¶å¤¹ (Ground Truth)")
    parser.add_argument("--output_dir", type=str, default="comparison_videos", help="è¾“å‡ºè·¯å¾„")
    parser.add_argument("--fps", type=int, default=10, help="è§†é¢‘å¸§ç‡")
    parser.add_argument("--max_duration", type=int, default=10, help="æœ€å¤§æ—¶é•¿(ç§’)")
    parser.add_argument("--min_frames", type=int, default=10, help="æœ€å°å¸§æ•°é˜ˆå€¼")
    parser.add_argument("--draw_text", action="store_true", default=True, help="æ˜¯å¦ç»˜åˆ¶æ–‡å­—æ ‡ç­¾")

    args = parser.parse_args()
    if args.gt_dir is not None:
        compare_frames_to_video(args)
    else:
        frames_to_video(args)




# python frames_to_video.py --img_dir my_generated_frames --output_dir my_videos --max_duration 10 --draw_text

# python frames_to_video.py --img_dir outputs_eval/exp2_1/test_20260103_220021/gen_imgs/de_dust2 --output_dir outputs_eval/exp2_1/test_20260103_220021/gen_videos/de_dust2 --max_duration 10 --draw_text

# python frames_to_video.py --img_dir outputs_eval/exp2_1/test_20260103_220021/gen_imgs/de_nuke --output_dir outputs_eval/exp2_1/test_20260103_220021/gen_videos/de_nuke --max_duration 10 --draw_text

# python frames_to_video.py --img_dir outputs_eval/exp2_1/test_20260103_220021/gen_imgs/de_ancient --output_dir outputs_eval/exp2_1/test_20260103_220021/gen_videos/de_ancient --max_duration 10 --draw_text





# python frames_to_video.py --img_dir my_generated_frames --gt_dir path/to/all_original_frames --output_dir video_comparison_results --max_duration 10

# python frames_to_video.py --img_dir outputs_eval/exp2_1/test_20260103_220021/gen_imgs/de_dust2 --gt_dir data/preprocessed_data/de_dust2/imgs --output_dir outputs_eval/exp2_1/test_20260103_220021/gen_compared_videos/de_dust2 --max_duration 10

# python frames_to_video.py --img_dir outputs_eval/exp2_1/test_20260103_220021/gen_imgs/de_nuke --gt_dir data/preprocessed_data/de_nuke/imgs --output_dir outputs_eval/exp2_1/test_20260103_220021/gen_compared_videos/de_nuke --max_duration 10

# python frames_to_video.py --img_dir outputs_eval/exp2_1/test_20260103_220021/gen_imgs/de_ancient --gt_dir data/preprocessed_data/de_ancient/imgs --output_dir outputs_eval/exp2_1/test_20260103_220021/gen_compared_videos/de_ancient --max_duration 10

