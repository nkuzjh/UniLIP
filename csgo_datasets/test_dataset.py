import sys
import os

# è·å–å½“å‰è„šæœ¬æ–‡ä»¶çš„ç›®å½• (.../UniLIP/csgo_datasets)
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–ä¸Šä¸€çº§ç›®å½• (.../UniLIP)
parent_dir = os.path.dirname(current_dir)
# å°†ä¸Šä¸€çº§ç›®å½•åŠ å…¥åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(parent_dir)

import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from transformers import AutoTokenizer, CLIPImageProcessor

from csgo_datasets.unified_task_dataset import UniLIPMultiTaskDataset, map_path_dict

# å‡è®¾æ‚¨çš„æ•°æ®é›†ä»£ç ä¿å­˜åœ¨ dataset_multitask.py ä¸­ï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ import
# from dataset_multitask import UniLIPMultiTaskDataset, map_path_dict

# ä¸ºäº†è®©æµ‹è¯•ä»£ç ç‹¬ç«‹è¿è¡Œï¼Œæˆ‘éœ€è¦ mock ä¸€ä¸‹æ‚¨çš„ Config å’Œ DataArgs
class MockConfig(dict):
    def __getattr__(self, name):
        return self.get(name)

class MockDataArgs:
    def __init__(self):
        # ä½¿ç”¨ CLIP çš„æ ‡å‡†å¤„ç†å™¨å‚æ•°
        self.image_processor = CLIPImageProcessor.from_pretrained("openai/clip-vit-large-patch14-336")
        self.image_aspect_ratio = "pad"
        self.is_multimodal = True

# ==========================================
# å¯è§†åŒ–è¾…åŠ©å‡½æ•°
# ==========================================
def denormalize_image(tensor):
    """åå½’ä¸€åŒ– CLIP çš„å›¾ç‰‡ Tensorï¼Œè½¬å› RGB numpy"""
    # CLIP mean/std
    mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).view(3, 1, 1)
    std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).view(3, 1, 1)

    # Reverse Normalize
    tensor = tensor * std + mean
    tensor = torch.clamp(tensor, 0, 1)

    # To Numpy (H, W, C)
    img_np = tensor.permute(1, 2, 0).numpy()
    return (img_np * 255).astype(np.uint8)

import textwrap

def visualize_sample(sample, idx, tokenizer, save_dir="_vis_results"):
    """å¯è§†åŒ–å•ä¸ªæ ·æœ¬"""
    task_id = sample['task_id']
    task_name = "LOCALIZATION" if task_id == 0 else "GENERATION"
    wrapped_prompt = "\n".join(textwrap.wrap(sample['raw_prompt'] + f"\n\nPose: {sample['pose_dict']}", width=100))

    print(f"\n[{idx}] Task: {task_name}")
    print(f"    Loss Mask: {sample['loss_mask']}")
    print(f"    Map ID: {sample['map_id']}")
    print(f"    Actions (Pose): {sample['actions']}")
    print(f"    Pose: {sample['pose_dict']}")
    print(f"    input_ids: {sample['input_ids']}")
    print(f"    Raw Prompt: {sample['raw_prompt']}") # åªæ‰“å°å‰100å­—ç¬¦
    print(f"    decode(input_ids): {tokenizer.decode(sample['input_ids'])}")



    # å‡†å¤‡ç”»å¸ƒ
    fig, axes = plt.subplots(1, 3, figsize=(18, 8))
    plt.suptitle(f"Sample {idx}: {task_name}", fontsize=16)

    # --- 1. Und Image (ç†è§£æµè¾“å…¥) ---
    # shape [1, 3, H, W] -> [3, H, W]
    und_img = denormalize_image(sample['und_image'][0])
    axes[0].imshow(und_img)
    axes[0].set_title("Und Image (Input)")
    axes[0].axis('off')

    # --- 2. Aux Image (è¾…åŠ©è¾“å…¥ - ä»…å®šä½ä»»åŠ¡æœ‰) ---
    aux_tensor = sample['aux_image'][0]
    if torch.all(aux_tensor == 0):
        # å…¨é»‘å›¾
        axes[1].imshow(np.zeros_like(und_img))
        axes[1].set_title("Aux Image (Empty)")
    else:
        aux_img = denormalize_image(aux_tensor)
        axes[1].imshow(aux_img)
        axes[1].set_title("Aux Image (Map)")
    axes[1].axis('off')

    # --- 3. Gen Image (ç”Ÿæˆç›®æ ‡ - ä»…ç”Ÿæˆä»»åŠ¡æœ‰) ---
    gen_tensor = sample['gen_image'][0]
    if torch.all(gen_tensor == 0):
        axes[2].imshow(np.zeros_like(und_img))
        axes[2].set_title("Gen Target (Empty)")
    else:
        gen_img = denormalize_image(gen_tensor)
        axes[2].imshow(gen_img)
        axes[2].set_title("Gen Target (GT FPS)")
    axes[2].axis('off')

    fig.text(0.5, 0.05, f"Prompt:\n{wrapped_prompt}",
             ha='center', va='bottom', fontsize=14,
             bbox=dict(boxstyle="round,pad=0.5", fc="lightyellow", ec="black", alpha=0.8),
             fontfamily='monospace')
    plt.subplots_adjust(bottom=0.25)

    # ä¿å­˜
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"_test_dataset_sample_{idx}_{task_name}.jpg")
    plt.savefig(save_path)
    print(f"    Saved visualization to {save_path}")
    plt.close()

# ==========================================
# ä¸»æµ‹è¯•æµç¨‹
# ==========================================
if __name__ == "__main__":
    # 1. æ¨¡æ‹Ÿé…ç½®
    # è¯·ä¿®æ”¹ä¸ºæ‚¨å®é™…çš„æ•°æ®è·¯å¾„
    DATA_DIR = "data/preprocessed_data"

    config = MockConfig({
        "data_dir": DATA_DIR,
        "train_maps": ['de_dust2','de_nuke', 'de_ancient'], # æµ‹è¯•å•å¼ åœ°å›¾
        "debug": True,              # å¼€å¯ debug æ¨¡å¼å¿«é€ŸåŠ è½½
        "debug_num_train_data": 100,
        "task_mix_ratio": 0.5,      # 50/50 æ··åˆ
        "is_fps_dropout": True,     # æµ‹è¯•æ•°æ®å¢å¼º
        "erasing_p": 0.6
    })

    data_args = MockDataArgs()

    # 2. æ¨¡æ‹Ÿ Tokenizer (ä½¿ç”¨ Llama æˆ– CLIP tokenizer å‡å¯ï¼Œè¿™é‡Œç”¨ç®€å•çš„ AutoTokenizer)
    print("â³ Loading Tokenizer...")
    try:
        # å°è¯•åŠ è½½ä¸€ä¸ªçœŸå®çš„ tokenizerï¼Œå¦‚æœæ²¡æœ‰ç½‘ç»œå¯ä»¥ç”¨æœ¬åœ°è·¯å¾„
        tokenizer = AutoTokenizer.from_pretrained("OpenGVLab/InternVL3-1B-hf")
    except:
        print("âš ï¸ Warning: Failed to load Vicuna tokenizer, using bert-base-uncased as fallback.")
        tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

    # 3. åˆå§‹åŒ–æ•°æ®é›†
    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦å¼•ç”¨ä½ å®šä¹‰çš„ Dataset ç±»
    # å‡è®¾ä½ çš„ä»£ç åœ¨å½“å‰è„šæœ¬çš„ä¸Šé¢ï¼Œæˆ–è€… import è¿›æ¥äº†
    try:
        dataset = UniLIPMultiTaskDataset(config, tokenizer, data_args)
    except Exception as e:
        print(f"âŒ Dataset Init Failed: {e}")
        print("ğŸ’¡ Hint: è¯·æ£€æŸ¥ config['data_dir'] è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼")
        exit()

    # 4. æŠ½å–æ ·æœ¬è¿›è¡Œæµ‹è¯•
    print(f"\nğŸš€ Start Testing... Dataset Length: {len(dataset)}")

    # éšæœºå– 5 ä¸ªæ ·æœ¬
    indices = np.random.choice(len(dataset), 10, replace=False)

    for i, idx in enumerate(indices):
        try:
            sample = dataset[idx]
            visualize_sample(sample, idx, tokenizer)
        except Exception as e:
            print(f"âŒ Error processing sample {idx}: {e}")
            import traceback
            traceback.print_exc()

    print("\nâœ… Test Finished. Check '_vis_results' folder.")