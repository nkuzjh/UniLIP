
import os
import json
import random
import numpy as np

import cv2
from PIL import Image

import torch
import torch.nn as nn
from torchvision import transforms
from torchvision.transforms import InterpolationMode

from transformers import AutoTokenizer

from csgo_datasets.utils import CoarseDropout, GridDropout
from csgo_datasets.random_erasing import RandomErasing
from loc_tokenizer import LocTokenizer



IGNORE_INDEX = -100



map_to_id_dict = {
    'de_dust2': 0,
    'de_inferno': 1,
    'de_mirage': 2,
    'de_nuke': 3,
    'de_ancient':4,
    'de_anubis': 5,
    'de_golden': 6,
    'de_overpass': 7,
    'de_palacio': 8,
    'de_train': 9,
    'de_vertigo': 10,
    'cs_agency': 11,
    'cs_italy': 12,
    'cs_office': 13
}

id_to_map_dict = {
    0: 'de_dust2',
    1: 'de_inferno',
    2: 'de_mirage',
    3: 'de_nuke',
    4: 'de_ancient',
    5: 'de_anubis',
    6: 'de_golden',
    7: 'de_overpass',
    8: 'de_palacio',
    9: 'de_train',
    10: 'de_vertigo',
    11: 'cs_agency',
    12: 'cs_italy',
    13: 'cs_office'
}

map_path_dict = {
    'de_dust2': 'de_dust2_radar_psd.png',
    'de_inferno': 'de_inferno_radar_psd.png',
    'de_mirage': 'de_mirage_radar_psd.png',
    'de_nuke': 'de_nuke_blended_radar_psd.png',
    'de_ancient': 'de_ancient_radar_psd.png',
    'de_anubis': 'de_anubis_radar_psd.png',
    'de_golden': 'de_golden_radar_tga.png',
    'de_overpass': 'de_overpass_radar_psd.png',
    'de_palacio': 'de_palacio_radar_tga.png',
    'de_train': 'de_train_blended_radar_psd.png',
    'de_vertigo': 'de_vertigo_blended_radar_psd.png',
    'cs_agency': 'cs_agency_radar_tga.png',
    'cs_italy': 'cs_italy_radar_psd.png',
    'cs_office': 'cs_office_radar_psd.png',
}

INSTRUCTION_TUNING_PROMPT_TEMPLATE = (
    "The following visual data has been fused and inserted into this sequence:\n"
    "1. First-Person View (FPV) Features.\n"
    "2. Overhead Radar Map (RADAR) Features.\n"
    "Analyze the spatial relationship between the FPV and the RADAR Map to determine the precise camera pose. "
    "Predict the 5D pose (x, y, z, pitch, yaw) in the required format.\n"
    "{action_token_sequence}"
)

class CsgoTrainDataset_IT(torch.utils.data.Dataset):
    def __init__(self, config, base_tokenizer = None, loc_tokenizer: LocTokenizer = None):
        self.config = config
        self.prompt_template = INSTRUCTION_TUNING_PROMPT_TEMPLATE

        self.data_entries = []
        self.map_z_range = {}
        for map_name in config["train_maps"]:
            # --- a. Âä†ËΩΩ‰ΩçÁΩÆÊï∞ÊçÆ ---
            if config['data_dir'] == 'data/preprocessed_data':
                # if map_name == 'de_ancient':
                #     position_data_path = f"{config['data_dir']}/{map_name}/splits_18000_2000/train_split.json"
                # else:
                if 1:
                    position_data_path = f"{config['data_dir']}/{map_name}/splits_20000_5000/train_split.json"
            elif config['data_dir'] == 'data/processed_data':
                position_data_path = f"{config['data_dir']}/{map_name}/positions.json"
            with open(position_data_path, "r", encoding="utf-8") as f:
                positions_data = json.load(f)
            # --- b. Âä†ËΩΩËØ•Âú∞ÂõæÁöÑ Z ËΩ¥ËåÉÂõ¥ ---
            max_z, min_z = -float('inf'), float('inf')
            for data in positions_data:
                if data['z'] > max_z:
                    max_z = data['z']
                if data['z'] < min_z:
                    min_z = data['z']
            self.map_z_range[map_name] = {
                'max_z':max_z,
                'min_z':min_z
            }
            # --- d. ÂêàÂπ∂Êï∞ÊçÆ ---
            for pos_data in positions_data:
                file_frame = pos_data['file_frame']
                map_name = pos_data['map']
                entry = {
                    'map': map_name,
                    'file_frame': file_frame,
                    'x': pos_data['x'],
                    'y': pos_data['y'],
                    'z': pos_data['z'],
                    'angle_v': pos_data['angle_v'],
                    'angle_h': pos_data['angle_h'],
                }
                self.data_entries.append(entry)

        if config['data_dir'] == 'data/processed_data':
            print(f"üìä Final total entries : {len(self.data_entries)}")
            self.data_entries = [data for data in self.data_entries if (data['map']=='de_dust2' and data['x']!=562 and data['y']!=736) or (data['map']!='de_dust2')]
            print(f"üìä after filter damaged entries: {len(self.data_entries)}")
            self.data_entries = self.data_entries[:-2000]

        print(f"üìä Final train entries : {len(self.data_entries)}")

        self.fps_transform, self.map_transform = self.get_transform(config)

        if config['debug']:
            indices = [335, 535, 707, 288, 21, 240, 20, 30, 809, 423, 857, 459, 557, 882, 893, 406, 24, 477, 407, 427, 453, 923, 925, 399, 752, 867, 547, 563, 424, 217, 789, 681]
            self.data_entries = [self.data_entries[i] for i in indices]
        else:
            # self.data_entries = self.data_entries[:config.get('debug_num_train_data', len(self.data_entries))]
            sampled_num = config.get('debug_num_train_data', len(self.data_entries))
            self.data_entries = random.sample(self.data_entries, sampled_num)

    def __len__(self):
        return len(self.data_entries)

    def __getitem__(self, idx):
        # Ëé∑ÂèñÂÆåÊï¥ÁöÑÊï∞ÊçÆÊù°ÁõÆ
        data = self.data_entries[idx]
        map_name = data['map']

        # Âä†ËΩΩÂíåËΩ¨Êç¢ÂõæÂÉè
        map_path = map_path_dict[map_name]
        map_img_path = f"{self.config['data_dir']}/{map_name}/{map_path}"
        map_img = Image.open(map_img_path).convert('RGB')#map_img.size=(1024, 1024)
        if self.config['is_dataset_aug']:
            map_img = self.map_transform(map_img) # -> radar_img_tensor =torch.Size([3, 224, 224])

        if self.config['data_dir'] == 'data/preprocessed_data':
            fps_img_path = f"{self.config['data_dir']}/{map_name}/imgs/{data['file_frame']}.jpg"
        else:
            fps_img_path = f"{self.config['data_dir']}/{map_name}/imgs/{data['file_frame']}.png"
        fps_img = Image.open(fps_img_path).convert('RGB')
        if self.config['is_dataset_aug']:
            fps_img = self.fps_transform(fps_img) # -> fps_img_tensor
        elif self.config.get('is_fps_dropout', False) or self.config.get('is_fps_resize_dropout', False):
            fps_img = self.fps_transform(fps_img)
            fps_img = np.array(fps_img.permute(1,2,0))
            fps_img = Image.fromarray((fps_img*255).astype(np.uint8))

        # ÂΩí‰∏ÄÂåñÂùêÊ†áÂÄº
        x_norm = data['x'] / 1024
        y_norm = data['y'] / 1024
        z_norm = (data['z'] - self.map_z_range[map_name]['min_z']) / (self.map_z_range[map_name]['max_z'] - self.map_z_range[map_name]['min_z'])
        v_norm = data['angle_v'] / (2 * np.pi)
        h_norm = data['angle_h'] / (2 * np.pi)
        loc_array = np.array([x_norm, y_norm, z_norm, v_norm, h_norm])
        gt_coords = torch.tensor(loc_array, dtype=torch.float32)

        # Instrcution Tuning Prompt Template
        prompt_string = self.prompt_template.split("{action_token_sequence}")[0].strip()

        # Get map_id integer
        map_id_int = map_to_id_dict.get(map_name, -1)
        return {
            "image": fps_img,
            "wrist_image": map_img,
            "state": torch.zeros(gt_coords.shape, dtype=gt_coords.dtype),
            "prompt": prompt_string,
            "actions": gt_coords.unsqueeze(0),
            "map_id": map_id_int

        }

    def get_transform(self, config):

        normalize = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))

        if config["is_fps_aug"]:
            fps_transform = transforms.Compose([
                transforms.Resize((config['fps_size'][0], config['fps_size'][1]), interpolation=InterpolationMode.BICUBIC),
                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
                transforms.ToTensor(),
                normalize,
                CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5),
                GridDropout(grid_size=4, p=0.3),
                RandomErasing(probability=config['erasing_p'], mean=[0.0, 0.0, 0.0])
            ])
        elif config.get('is_fps_dropout', False):
            fps_transform = transforms.Compose([
                transforms.ToTensor(),
                CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5),
                GridDropout(grid_size=4, p=0.3),
                RandomErasing(probability=config['erasing_p'], mean=[0.0, 0.0, 0.0])
            ])
        elif config.get('is_fps_resize_dropout', False):
            fps_transform = transforms.Compose([
                transforms.ToTensor(),
                transforms.Resize((config['fps_size'][0], config['fps_size'][1]), interpolation=InterpolationMode.BICUBIC),
                CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5),
                GridDropout(grid_size=4, p=0.3),
                RandomErasing(probability=config['erasing_p'], mean=[0.0, 0.0, 0.0])
            ])
        else:
            fps_transform = transforms.Compose([
                transforms.Resize((config['fps_size'][0], config['fps_size'][1]), interpolation=InterpolationMode.BICUBIC),
                transforms.ToTensor(),
                normalize,
            ])

        map_transform = transforms.Compose([
            transforms.Resize((config['map_size'][0], config['map_size'][1]), interpolation=InterpolationMode.BICUBIC),
            transforms.ToTensor(),
            normalize,
        ])

        return fps_transform, map_transform



class CsgoEvalDataset_IT(torch.utils.data.Dataset):
    def __init__(self, config, base_tokenizer = None, loc_tokenizer: LocTokenizer = None):
        self.config = config
        self.prompt_template = INSTRUCTION_TUNING_PROMPT_TEMPLATE

        self.data_entries = []
        self.map_z_range = {}
        for map_name in config["val_maps"]:
            # --- a. Âä†ËΩΩ‰ΩçÁΩÆÊï∞ÊçÆ ---
            if config['data_dir'] == 'data/preprocessed_data':
                # if map_name == 'de_ancient':
                #     position_data_path = f"{config['data_dir']}/{map_name}/splits_18000_2000/test_split.json"
                # else:
                if 1:
                    position_data_path = f"{config['data_dir']}/{map_name}/splits_20000_5000/test_split.json"
            elif config['data_dir'] == 'data/processed_data':
                position_data_path = f"{config['data_dir']}/{map_name}/positions.json"
            with open(position_data_path, "r", encoding="utf-8") as f:
                positions_data = json.load(f)
            # --- b. Âä†ËΩΩËØ•Âú∞ÂõæÁöÑ Z ËΩ¥ËåÉÂõ¥ ---
            max_z, min_z = -float('inf'), float('inf')
            for data in positions_data:
                if data['z'] > max_z:
                    max_z = data['z']
                if data['z'] < min_z:
                    min_z = data['z']
            self.map_z_range[map_name] = {
                'max_z':max_z,
                'min_z':min_z
            }
            # --- d. ÂêàÂπ∂Êï∞ÊçÆ ---
            for pos_data in positions_data:
                file_frame = pos_data['file_frame']
                map_name = pos_data['map']
                entry = {
                    'map': map_name,
                    'file_frame': file_frame,
                    'x': pos_data['x'],
                    'y': pos_data['y'],
                    'z': pos_data['z'],
                    'angle_v': pos_data['angle_v'],
                    'angle_h': pos_data['angle_h'],
                }
                self.data_entries.append(entry)

        if config['data_dir'] == 'data/processed_data':
            print(f"üìä Final total entries: {len(self.data_entries)}")
            self.data_entries = [data for data in self.data_entries if (data['map']=='de_dust2' and data['x']!=562 and data['y']!=736) or (data['map']!='de_dust2')]
            print(f"üìä after filter damaged entries: {len(self.data_entries)}")
            # print(len([data for data in self.data_entries if data['x']==562 and data['y']==736])) #87000
            self.data_entries = self.data_entries[-2000:]

        print(f"üìä Final eval entries : {len(self.data_entries)}")

        self.fps_transform, self.map_transform = self.get_transform(config)

        if config['debug']:
            indices = [335, 535, 707, 288, 21, 240, 20, 30, 809, 423, 857, 459, 557, 882, 893, 406, 24, 477, 407, 427, 453, 923, 925, 399, 752, 867, 547, 563, 424, 217, 789, 681]
            self.data_entries = [self.data_entries[i] for i in indices]
        else:
            # self.data_entries = self.data_entries[:config.get('debug_num_val_data', len(self.data_entries))]
            sampled_num = config.get('debug_num_val_data', len(self.data_entries))
            self.data_entries = random.sample(self.data_entries, sampled_num)


    def __len__(self):
        return len(self.data_entries)

    def __getitem__(self, idx):
        # Ëé∑ÂèñÂÆåÊï¥ÁöÑÊï∞ÊçÆÊù°ÁõÆ
        data = self.data_entries[idx]
        map_name = data['map']

        # Âä†ËΩΩÂíåËΩ¨Êç¢ÂõæÂÉè
        map_path = map_path_dict[map_name]
        map_img_path = f"{self.config['data_dir']}/{map_name}/{map_path}"
        map_img = Image.open(map_img_path).convert('RGB')
        if self.config['is_dataset_aug']:
            map_img = self.map_transform(map_img) # -> radar_img_tensor=torch.Size([3, 224, 224])
            # map_img = np.array(map_img)#.transpose(1,2,0)#=torch.Size([224, 224, 3])
        else:
            map_img = np.array(map_img) #np.array(PIL.Image)=h,w,c
        # Ê≥®ÊÑèevalÊó∂ÂÖ∂ÂÆûÊó†ËÆ∫‰ΩïÊó∂Âì™ÁßçsettingÈÉΩ‰∏çÈúÄË¶Ånp.array(map_img).transpose(1,2,0),ËøôÈáåÂè™ÊòØÊàëÂú®debugÁöÑÊó∂ÂÄôÂá∫‰∫ÜÁÇπÈóÆÈ¢ò;
        # Áé∞Âú®evalÂÖ∂ÂÆûÊúâ‰∏§Áßçsetting: ‰∏ÄÁßçÊòØÂíåtrainÂØπÈΩê,ÈÉΩ‰ΩøÁî®dataset.get_transform; Á¨¨‰∫åÁßçÊòØevalÊó∂‰∏ç‰ΩøÁî®‰ªª‰Ωïdataset.get_transform, ‰ΩÜÊ≠§Êó∂Â§ñÈù¢Â•ó‰∫Ü‰∏ÄÂ±Çbs=1ÁöÑnn.DataLoader, ‰∏∫Èò≤Ê≠¢PIL.ImageË¢´ÈªòËÆ§collate_fnË∞ÉÁî®Êä•ÈîôÊâÄ‰ª•ÈúÄË¶Åmap_img = np.array(map_img)ËΩ¨Êç¢‰∏Ä‰∏ãÁ±ªÂûã, ÂêåÊó∂Ê≥®ÈáäÊéâÊàëËá™ÂÆö‰πâÁöÑvisualize_batch_from_dataloaderÂáΩÊï∞(Ëøô‰∏™ÂáΩÊï∞‰πü‰∏çÊîØÊåÅÁõ¥Êé•map_img = np.array(map_img)ËΩ¨Êç¢ÁöÑnp.uint8, ËØ•ÂáΩÊï∞Âè™ÊîØÊåÅdataset.get_transformÂêéÁöÑtorch.float32)

        if self.config['data_dir'] == 'data/preprocessed_data':
            fps_img_path = f"{self.config['data_dir']}/{map_name}/imgs/{data['file_frame']}.jpg"
        else:
            fps_img_path = f"{self.config['data_dir']}/{map_name}/imgs/{data['file_frame']}.png"
        fps_img = Image.open(fps_img_path).convert('RGB')
        if self.config['is_dataset_aug']:
            fps_img = self.fps_transform(fps_img) # -> fps_img_tensor=torch.Size([3, 224, 224])
            # fps_img = np.array(fps_img)#.transpose(1,2,0)#=torch.Size([224, 224, 3])
        else:
            fps_img = np.array(fps_img)


        # ÂΩí‰∏ÄÂåñÂùêÊ†áÂÄº (Áî®‰∫éÂ°´ÂÖ• target Â≠óÁ¨¶‰∏≤)
        x_norm = data['x'] / 1024
        y_norm = data['y'] / 1024
        z_norm = (data['z'] - self.map_z_range[map_name]['min_z']) / (self.map_z_range[map_name]['max_z'] - self.map_z_range[map_name]['min_z'])
        v_norm = data['angle_v'] / (2 * np.pi)
        h_norm = data['angle_h'] / (2 * np.pi)
        loc_array = np.array([x_norm, y_norm, z_norm, v_norm, h_norm])
        gt_coords = torch.tensor(loc_array, dtype=torch.float32)

        # Instrcution Tuning Prompt Template
        prompt_string = self.prompt_template.split("{action_token_sequence}")[0].strip()

        # Get map_id integer
        map_id_int = map_to_id_dict[map_name]
        return {
            "image": fps_img,
            "wrist_image": map_img,
            "state": torch.zeros(gt_coords.shape, dtype=gt_coords.dtype),
            "prompt": prompt_string,
            "actions": gt_coords.unsqueeze(0),
            "map_id": map_id_int
        }

    def get_transform(self, config):

        normalize = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))

        fps_transform = transforms.Compose([
                transforms.Resize((config['fps_size'][0], config['fps_size'][1]), interpolation=InterpolationMode.BICUBIC),
                transforms.ToTensor(),
                normalize,
            ])

        map_transform = transforms.Compose([
            transforms.Resize((config['map_size'][0], config['map_size'][1]), interpolation=InterpolationMode.BICUBIC),
            transforms.ToTensor(),
            normalize,
        ])

        return fps_transform, map_transform

